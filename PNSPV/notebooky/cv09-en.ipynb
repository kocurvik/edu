{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "cv09-en.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "toc_visible": true,
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/kocurvik/edu/blob/master/PNNPPV/notebooky/cv09-en.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ZeMUn91mTYUB"
      },
      "source": [
        "# 9th lab - RNNs\n",
        "\n",
        "Todays lab deals with recurrent neural networks. We will create an artificial toy problem in which we will construct a large integer from a MNIST images and our goal will be to determine its modulo w.r.t to some number (ideally a prime number above 10)."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "iLAJA1b1Va7S"
      },
      "source": [
        "import keras\n",
        "from keras.datasets import mnist\n",
        "from keras.layers import TimeDistributed, Conv2D, Dense, Flatten, MaxPool2D, ConvLSTM2D, GlobalAveragePooling2D, LSTM, GRU\n",
        "from keras.models import Sequential\n",
        "from keras.optimizers import Adam\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "XiMg-TH8TDTa"
      },
      "source": [
        "(x, y), (x_test, y_test) = mnist.load_data()\n",
        "x = x / 255\n",
        "x_test = x_test / 255"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "prKQrtIrLoPc"
      },
      "source": [
        "## Fixex sequence - continual loss\n",
        "\n",
        "Let us design a model which has a few convolutional layers which are followed by Global Pooling and a GRU (gated recurrent unit) layer. The GRU layer is connected to the GRU layer for the previous element of the sequence. After the GRU layer we will apply a Dense layer with softmax. We use GRU instead of a more notorious LSTM because it is easier to train. Theoretically LSTM should have better long-term memory, but this is not as important for our toy problem.\n",
        "\n",
        "![GRU](https://raw.githubusercontent.com/kocurvik/edu/master/PNNPPV/supplementary/ntb_images/GRU_model.png)\n",
        "\n",
        "We can choose one of multiple ways in which the network can be trained. As input we will use a sequence of inputs in shape  $batch \\times seq \\times 28 \\times 28 \\times 1$, where $seq$ is the length of the sequence. On the output we have two options. We either use just the output from the last element of the sequence for loss or we use all of the intermediate outputs for loss. We will first try the first approach.\n",
        "\n",
        "![GRU Multiloss](https://raw.githubusercontent.com/kocurvik/edu/master/PNNPPV/supplementary/ntb_images/GRU_multi_loss.png)\n",
        "\n",
        "The model is defined below. The wrapper `TimeDistributed` allows us to call a layer type for each element of a seuqnce. When using a recurrent layer we do not need to use the wrapper."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "oU0CbiajNnDS"
      },
      "source": [
        "def build_model(modulo, seq_size):\n",
        "  model = Sequential()\n",
        "  model.add(TimeDistributed(Conv2D(16, (7,7), activation='relu'), input_shape=(seq_size, 28, 28, 1)))\n",
        "  model.add(TimeDistributed(Conv2D(32, (7,7), activation='relu')))\n",
        "  model.add(TimeDistributed(Conv2D(64, (7,7), activation='relu')))\n",
        "  model.add(TimeDistributed(Conv2D(64, (7,7), activation='relu')))\n",
        "  model.add(TimeDistributed(GlobalAveragePooling2D()))\n",
        "  model.add(GRU(64, activation='relu', recurrent_activation='hard_sigmoid', return_sequences=True))\n",
        "  model.add(TimeDistributed(Dense(modulo, activation='softmax')))\n",
        "\n",
        "  return model"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "4WDZKVPQNp0n"
      },
      "source": [
        "We will need to programm a generator which gives us the input data as well as the outputs to calculate the loss. Implement the method getitem. For the outputs we want to use classification into `self.modulo` classes. The output is determined by taking the sequence of numbers as the decimals in written one by one (from the left) and then taking a modulo by our selected number. Let us use 13 as a defualt value for this."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "YbA8RXlTZIYy"
      },
      "source": [
        "class SeqDataGenerator(keras.utils.Sequence):\n",
        "  def __init__(self, x, y, modulo=13, batch_size=32, seq_size=20, steps=1000):\n",
        "    self.x = x\n",
        "    self.y = y\n",
        "    self.modulo = modulo\n",
        "    self.batch_size = batch_size\n",
        "    self.seq_size = seq_size\n",
        "    self.steps = steps\n",
        "\n",
        "  def __len__(self):\n",
        "    return self.steps\n",
        "\n",
        "  def __getitem__(self, index):\n",
        "    X = np.empty([self.batch_size, self.seq_size, 28, 28, 1])\n",
        "    y = np.zeros([self.batch_size, self.seq_size, self.modulo])\n",
        "\n",
        "    ## doimplemtujte\n",
        "\n",
        "    return X, y"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "EaVRnO88PF74"
      },
      "source": [
        "This code should then train our network on the data. You can try different sequence lengths of sequnce."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "y44xHVI0N3sQ"
      },
      "source": [
        "seq_size = 10\n",
        "modulo = 13\n",
        "\n",
        "train_gen = SeqDataGenerator(x[10000:], y[10000:], modulo=modulo, batch_size=32, seq_size=seq_size)\n",
        "val_gen = SeqDataGenerator(x[:10000], y[:10000], modulo=modulo, batch_size=32, seq_size=seq_size, steps=100)\n",
        "model = build_model(modulo, seq_size)\n",
        "\n",
        "opt = Adam(lr=0.001)\n",
        "model.compile(optimizer=opt, loss='categorical_crossentropy', metrics=['accuracy'])\n",
        "\n",
        "print(model.summary())\n",
        "\n",
        "model.fit_generator(train_gen, validation_data=val_gen, epochs=5)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "PhT0rpPyOy8J"
      },
      "source": [
        "## Fixed sequence - Loss only at the end\n",
        "\n",
        "We will now try to train the network with the loss being calculated only at the end of the sequence.\n",
        "\n",
        "![alt text](https://raw.githubusercontent.com/kocurvik/edu/master/PNNPPV/supplementary/ntb_images/GRU_single_loss.png)\n",
        "\n",
        "Implement the relevant methods. Figure out what the `return_sequential` argument does with GRU layer and modify the network so that there is only one vector on output. Verify whether the training works and test it out for various sequence lengths."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Mn9xLFxlb6l9"
      },
      "source": [
        "def build_single_model(modulo, seq_size):\n",
        "  # doimplementujte\n",
        "  ..."
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "mMheDOiXOudl"
      },
      "source": [
        "class SingleSeqDataGenerator(keras.utils.Sequence):\n",
        "  def __init__(self, x, y, modulo=11, batch_size=32, seq_size=20, steps=1000):\n",
        "    self.x = x\n",
        "    self.y = y\n",
        "    self.modulo = modulo\n",
        "    self.batch_size = batch_size\n",
        "    self.seq_size = seq_size\n",
        "    self.steps = steps\n",
        "\n",
        "  def __len__(self):\n",
        "    return self.steps\n",
        "\n",
        "  def __getitem__(self, index):\n",
        "    X = np.empty([self.batch_size, self.seq_size, 28, 28, 1])\n",
        "    y = np.zeros([self.batch_size, self.modulo])\n",
        "\n",
        "    for b in range(self.batch_size):\n",
        "      # doimplementujte\n",
        "\n",
        "    return X, y"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "UvN-U9EshVxr"
      },
      "source": [
        "seq_size = 6\n",
        "modulo = 13\n",
        "\n",
        "train_gen = SingleSeqDataGenerator(x[10000:], y[10000:], modulo=modulo, batch_size=32, seq_size=seq_size)\n",
        "val_gen = SingleSeqDataGenerator(x[:10000], y[:10000], modulo=modulo, batch_size=32, seq_size=seq_size, steps=100)\n",
        "single_model = build_single_model(modulo, seq_size)\n",
        "\n",
        "opt = Adam(lr=0.001)\n",
        "single_model.compile(optimizer=opt, loss='categorical_crossentropy', metrics=['accuracy'])\n",
        "\n",
        "print(model.summary())\n",
        "\n",
        "single_model.fit_generator(train_gen, validation_data=val_gen, epochs=5)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "cs7bQfYbRnii"
      },
      "source": [
        "## Variable sequence lengths\n",
        "\n",
        "Now we will try to train a model with a different sequence length for each batch. The batch size will remain the same, but if we had a memory issue we could reduce it. The only difference in the model definition is the input argument which has None as the first dimension now."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "JsY0FR_7SA_w"
      },
      "source": [
        "def build_var_model(modulo):\n",
        "  model = Sequential()\n",
        "  model.add(TimeDistributed(Conv2D(16, (7,7), activation='relu'), input_shape=(None, 28, 28, 1)))\n",
        "  model.add(TimeDistributed(Conv2D(32, (7,7), activation='relu')))\n",
        "  model.add(TimeDistributed(Conv2D(64, (7,7), activation='relu')))\n",
        "  model.add(TimeDistributed(Conv2D(64, (7,7), activation='relu')))\n",
        "  model.add(TimeDistributed(GlobalAveragePooling2D()))\n",
        "  model.add(GRU(64, activation='relu', recurrent_activation='hard_sigmoid', return_sequences=True))\n",
        "  model.add(TimeDistributed(Dense(modulo, activation='softmax')))\n",
        "\n",
        "  return model"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "tof13X5oSJYg"
      },
      "source": [
        "We have to modify the generator so that we always choose a random sequence length.\n",
        "\n",
        "*Note:* The sequence has to be at least length 2 for tensorflow to be able to manage it."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "GQ06YJe7SWVg"
      },
      "source": [
        "class VarSeqDataGenerator(keras.utils.Sequence):\n",
        "  def __init__(self, x, y, modulo=11, batch_size=32, max_seq_size=20, steps=1000):\n",
        "    self.x = x\n",
        "    self.y = y\n",
        "    self.modulo = modulo\n",
        "    self.batch_size = batch_size\n",
        "    self.max_seq_size = max_seq_size\n",
        "    self.steps = steps\n",
        "\n",
        "  def __len__(self):\n",
        "    return self.steps\n",
        "\n",
        "  def __getitem__(self, index):\n",
        "    seq_size = np.random.randint(2, self.max_seq_size)   \n",
        "    X = np.empty([self.batch_size, seq_size, 28, 28, 1]) \n",
        "    y = np.zeros([self.batch_size, seq_size, self.modulo])\n",
        "\n",
        "    # doimplementujte\n",
        "\n",
        "    return X, y"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "4JUtLandSrrD"
      },
      "source": [
        "With this approach we can use the validation data in a fixed size (for example we will use length 10)."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "87HnuWv4Sq-q"
      },
      "source": [
        "max_seq_size = 20\n",
        "modulo = 13\n",
        "\n",
        "train_gen = VarSeqDataGenerator(x[10000:], y[10000:], modulo=modulo, batch_size=32, max_seq_size=max_seq_size)\n",
        "val_gen = SeqDataGenerator(x[:10000], y[:10000], modulo=modulo, batch_size=32, seq_size=10, steps=100)\n",
        "var_model = build_var_model(modulo)\n",
        "\n",
        "opt = Adam(lr=0.001)\n",
        "var_model.compile(optimizer=opt, loss='categorical_crossentropy', metrics=['accuracy'])\n",
        "\n",
        "print(var_model.summary())\n",
        "\n",
        "var_model.fit_generator(train_gen, validation_data=val_gen, epochs=5)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "_x7hqubEXQvq"
      },
      "source": [
        "## Inference with the whole sequence\n",
        "\n",
        "As input for the last var model we can use a sequence of any length. We can therefore verify the model."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "aTUHW0iHXzx8"
      },
      "source": [
        "seq_size = 10\n",
        "X = np.empty([1, seq_size, 28, 28, 1])\n",
        "\n",
        "sum = 0\n",
        "\n",
        "for s in range(seq_size):\n",
        "  idx = np.random.randint(10000)\n",
        "  X[0, s, :, :, 0] = x_test[idx]\n",
        "  sum = sum*10 + y_test[idx]\n",
        "  plt.imshow(x_test[idx], cmap='gray')\n",
        "  plt.show()\n",
        "  print(\"Current: {}, sum: {}, mod: {}\".format(y_test[idx], sum, sum % 13))\n",
        "\n",
        "pred = var_model.predict(X)\n",
        "pred_last = np.argmax(pred[0], axis=-1)\n",
        "print(pred_last)\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "16Y0pA6SZTZ8"
      },
      "source": [
        "## One-by-one inference\n",
        "\n",
        "If we want to feed the network the input one-by-one we have to convert the model into the so-called stateful mode. This means that the GRU layer remmembers the input from the previous example. If we have a stateful network we have to reset the model everytime we want to start a new sequence.\n",
        "\n",
        "To convert the model we can use this (somewhat hacky) function:"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "sKksuc_mYfdy"
      },
      "source": [
        "import json\n",
        "from keras.models import model_from_json\n",
        "\n",
        "def convert_to_inference_model(original_model):\n",
        "    original_model_json = original_model.to_json()\n",
        "    inference_model_dict = json.loads(original_model_json)\n",
        "    print(inference_model_dict)\n",
        "\n",
        "    layers = inference_model_dict['config']['layers']\n",
        "    for layer in layers:\n",
        "        if 'stateful' in layer['config']:\n",
        "            layer['config']['stateful'] = True\n",
        "\n",
        "        if 'batch_input_shape' in layer['config']:\n",
        "            layer['config']['batch_input_shape'][0] = 1\n",
        "            layer['config']['batch_input_shape'][1] = 1\n",
        "\n",
        "    inference_model = model_from_json(json.dumps(inference_model_dict))\n",
        "    inference_model.set_weights(original_model.get_weights())\n",
        "\n",
        "    return inference_model"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "XMHucR-DqXM7"
      },
      "source": [
        "inference_model = convert_to_inference_model(var_model)\n",
        "\n",
        "sum = 0\n",
        "\n",
        "for s in range(20):\n",
        "  idx = np.random.randint(10000)\n",
        "  img = x_test[idx]\n",
        "  # doimplementujte"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Y85tfyRXtONA"
      },
      "source": [
        "As mentioned above, if we want to start a new sequence we have to reset the network."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "cwasY0AKtRtc"
      },
      "source": [
        "sum = 0\n",
        "\n",
        "inference_model.reset_states()\n",
        "\n",
        "for s in range(20):\n",
        "  idx = np.random.randint(10000)\n",
        "  img = x_test[idx]\n",
        "  # doimplementujte"
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}