{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "cv02-solution.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/kocurvik/edu/blob/master/PNNPPV/notebooky/cv02_solution.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "kFF-Tzky4FpK",
        "colab_type": "text"
      },
      "source": [
        "# **2. cvičenie** - Linárna algebra s NumPy, Dopredný beh siete\n",
        "\n",
        "V tomto notebooku si prejdeme operácie lineárnej algebry v NumPy. Tie potom využijeme aby sme naprogramovali plne prepojenú sieť."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "wFCxQ5FfX-GE",
        "colab_type": "text"
      },
      "source": [
        "#Lineárna Algebra s NumPy\n",
        "\n",
        "Na implementáciu základnej plne prepojenej siete budeme potrebovať maticové násobenie. V skutočnosti budeme násobiť tenzory, ale najprv si precvičíme násobenie matíc."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "vFOOIwOB5mN-",
        "colab_type": "text"
      },
      "source": [
        "## Maticové násobenie\n",
        "Najdôležitejšia operácia, ktorú budeme potrebovať je maticové násobenie. Najprv definícia:\n",
        "\n",
        "Nech $\\mathbf{A} \\in \\mathbb{R}^{m\\times n}, \\mathbf{B} \\in \\mathbb{R}^{n \\times l}, \\mathbf{C} \\in \\mathbb{R}^{m \\times l} $ potom $\\mathbf{A}\\mathbf{B} = \\mathbf{C} \\iff (\\forall i \\in \\hat{m})(\\forall j \\in \\hat{l})(c_{i,j} = \\sum_{k=1}^{n} a_{i,k} \\cdot b_{k,j})$ \n",
        "\n",
        "K definícii je dobré si pripomenúť, že prvý index označuje riadok a druhý index označuje stĺpec."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "SzL2kACy7hDF",
        "colab_type": "text"
      },
      "source": [
        "### Úloha 1 (Na tabuľu)\n",
        "\n",
        "Spočítajte súčiny $\\mathbf{A}\\mathbf{B}$, $\\mathbf{B}\\mathbf{C}$, $\\mathbf{C}\\mathbf{B}$\n",
        "\n",
        "$\\mathbf{A} = \\begin{bmatrix} \n",
        "3 & 5 & -1 \\\\\n",
        "2 & -4 & 2\n",
        "\\end{bmatrix}$\n",
        "\n",
        "$\\mathbf{B} = \\begin{bmatrix} \n",
        "5 & 2 & 1 \\\\\n",
        "-6 & 5 & 2 \\\\\n",
        "3 & 4 & -1\n",
        "\\end{bmatrix}$\n",
        "\n",
        "$\\mathbf{C} = \\begin{bmatrix} \n",
        "4 & -4 & 3 \\\\\n",
        "-6 & -3 & 4 \\\\\n",
        "-1 & 1 & 0\n",
        "\\end{bmatrix}$"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "eJcOg7TqNbU1",
        "colab_type": "text"
      },
      "source": [
        "V numpy násobíme matice pomocou príkazu np.matmul(a,b), alebo pomocou operátora @. Dá sa použiť aj np.dot. Rozdiel medzi multiply a dot je v broadcastingu. Otestujte aj súčin $\\mathbf{BC}$ a $\\mathbf{CB}$\n",
        "\n",
        "*Pozn:* Vektory môžeme považovať za matice s jednou dimenziou jedna. Podľa toho či je stĺpcový, alebo riadkový. Formálne to mení možnosti násobenia. Toto ale v NumPy nieje tak vždy. Pri násobení sa tak arrays ktoré majú len jeden rád, tj. len(np.shape) == 1 upravia podľa toho čo sa viac hodí, či riadkový, alebo stĺpcový vektor."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "c0fMUJVrOAqW",
        "colab_type": "code",
        "outputId": "b9f09919-d1af-45d0-c96a-0603cfd63780",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 153
        }
      },
      "source": [
        "import numpy as np\n",
        "a = np.array([[3,5,-1],[2,-4,2]])\n",
        "b = np.array([[5,2,1],[-6,5,2],[3,4,-1]])\n",
        "print(np.matmul(a,b))\n",
        "d = a @ b\n",
        "print(d)\n",
        "v = np.array([10,20,30])\n",
        "print(v.shape)\n",
        "u = np.array([5,25])\n",
        "print(u.shape)\n",
        "print(a @ v)\n",
        "print(u @ a)\n"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "[[-18  27  14]\n",
            " [ 40  -8  -8]]\n",
            "[[-18  27  14]\n",
            " [ 40  -8  -8]]\n",
            "(3,)\n",
            "(2,)\n",
            "[100   0]\n",
            "[ 65 -75  45]\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "6aoY3A8ORqHp",
        "colab_type": "text"
      },
      "source": [
        "V prípade, že máme jeden tenzor vyššieho rádu ako 2, tak matmul ich bude brať ako zoznam matíc. Ak potrebujeme robiť exotickejšie operácie, tak môžeme použiť príkaz np.einsum."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "bl-b9KOdXf_6",
        "colab_type": "text"
      },
      "source": [
        "## Skalárne násobenie\n",
        "\n",
        "Skalárom môžeme jednoducho násobiť matícu. To sa robí pomocou np.multiply, alebo operátorom *. Ak nenásobíme skalárom ale tenzorom, tak dôjde k násobeniu po elementoch s príšlušným broadcastingom. "
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "WQsMp1YfYYeo",
        "colab_type": "code",
        "outputId": "a0e80da1-cf85-4717-cf4b-43a6729ba5db",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 85
        }
      },
      "source": [
        "print(a * d)\n",
        "print(5 * a)"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "[[-54 135 -14]\n",
            " [ 80  32 -16]]\n",
            "[[ 15  25  -5]\n",
            " [ 10 -20  10]]\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "XExe4ma_Qlyv",
        "colab_type": "text"
      },
      "source": [
        "## Transponované matice\n",
        "\n",
        "Definícia: Nech $\\mathbf{A} \\in \\mathbb{R}^{m,n}$ potom $\\mathbf{A}^T \\in \\mathbb{R}^{n,m}$ je jej transponovaná matica $\\iff (\\forall i \\in \\hat{m})(\\forall j \\in \\hat{n})(a_{i,j} = a^T_{j,i})$ \n",
        "\n",
        "V numpy jednoducho voláme metódu np.array .T, alternatívne možeme použiť funkciu np.transpose. Opäť platí, že rovnako môžeme postupovať aj v prípade vektorov zapísaných ako matice.\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "LyjACfi6Ro84",
        "colab_type": "code",
        "outputId": "051de3d8-f25b-4b92-b8f2-be5d06a5ddcc",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 221
        }
      },
      "source": [
        "print(a.T)\n",
        "print(np.transpose(a))\n",
        "\n",
        "r = np.array([[100,10,1]])\n",
        "print(r.shape)\n",
        "\n",
        "c = np.array([[3],[7],[8]])\n",
        "print(c.shape)\n",
        "\n",
        "print(a @ c)\n",
        "print(a @ r.T)\n",
        "\n"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "[[ 3  2]\n",
            " [ 5 -4]\n",
            " [-1  2]]\n",
            "[[ 3  2]\n",
            " [ 5 -4]\n",
            " [-1  2]]\n",
            "(1, 3)\n",
            "(3, 1)\n",
            "[[36]\n",
            " [-6]]\n",
            "[[349]\n",
            " [162]]\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "OUgGLfLYXggG",
        "colab_type": "text"
      },
      "source": [
        ""
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "6ScSyiORa836",
        "colab_type": "text"
      },
      "source": [
        "# Plne prepojená neurónová sieť\n",
        "Neurónová sieť je biologicky inšpirovaný model pre realizáciu výpočtov rôznych funkcií. Dnes ju budeme využívať na ako klasifikátor. \n",
        "\n",
        "Sieť obecne modelujeme ako orientovaný graf s ohodnotenými hranami ktorého vrcholy sú tzv. neuróny. Každý neurón má svoju aktiváciu, ktorá sa počíta na základe aktivácii neurónov s ktorými je prepojený. Táto aktivácia zas ovplivňuje ďalšie neuróny. Najobecnejšie tak môžeme popísať sieť ako:\n",
        "$$a_p = f \\left( \\sum_{q \\in p_{in}} w_{p,q} a_q + b_p \\right) = f\\left(z_p\\right),$$\n",
        "\n",
        "kde $a_p$ je aktivácia daného vrcholu, $w_{p,q}$ je váha vrcholu $q$ pre vrchol $p$, $b_p$ je prah vrcholu $p$, $f$ je aktivačná funckia, $z_p$ je zjednodušený zápis vstupu aktivačnej funkcie. V takomto zápise je však možné aby boli neuróny prepojené cyklicky, čo nechceme. Takisto nechceme, aby bola štruktúra siete komplikovaná. Preto zavedieme tzv. plne prepojenú neurónovú sieť, tiež označovaný ako Multi-Layer-Perceptron. Táto organizácia spočíva v tom, že každý neurón je v nejakej vrstve a každý neurón v jednej vrstve je prepojený s každým z predchádzajúcej.\n",
        "\n",
        "![Plne prepojená sieť](https://raw.githubusercontent.com/kocurvik/edu/master/PNNPPV/supplementary/ntb_images/NN1.jpg)\n",
        "\n",
        "Vyhodnotenie siete potom môžeme zapísať ako:\n",
        "\n",
        "$$a_j^l = f \\left( \\sum_{k} a_k^{l-1} a_{k,j}^l + b_j^l \\right) = f \\left(z_j^l \\right),$$\n",
        "\n",
        "resp. vektorovo:\n",
        "\n",
        "$$a^l = f \\left( a^{l-1}w^l + b^l \\right) =  f \\left(z^l \\right),$$\n",
        "\n",
        "kde $a^l$ je **riadkový** vektor aktivácií, $w^l$ je matica váh tvaru $size(l-1) \\times size(l)$, $a_l$ je **riadkový** vektor prahov, $f$ je skalárna aktivačná funkcia, ktorá je vo vektorovom prípade aplikovaná po elementoch, $z_l$ je taktiež riadkový vektor, ktorý použijeme na zjednodušenie výrazov. Horný index pri každom výraze značí, ku ktorej vrstve daný objekt partrí.\n",
        "\n",
        "Pre lepšiu predstavu o indexácií viď obrázky:\n",
        "\n",
        "![Indexy aktivácie a prahu](https://raw.githubusercontent.com/kocurvik/edu/master/PNNPPV/supplementary/ntb_images/activation_bias.jpg)\n",
        "![Indexy váh](https://raw.githubusercontent.com/kocurvik/edu/master/PNNPPV/supplementary/ntb_images/weight.jpg)\n",
        "\n",
        "*Pozn.:* Vektory by mohli byť aj stĺpcové (a matica tak transponovaná a násobenie v opačnom poradí), ale to by nám v NumPy skomplikovalo prácu kvôli broadcastingu.\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ZIld0vL36Aqs",
        "colab_type": "text"
      },
      "source": [
        "### Aktivačné funkcie\n",
        "\n",
        "Môžeme použiť rôzne aktivačné funkcie. Dnes ostaneme pri sigmoide, ale nabudúce si implementujeme aj ďalšie.\n",
        "\n",
        "1. Sigmoid: $f(z) = \\frac{1}{1 + e^{-z}}$\n",
        "2. Tanh: $f(z) = tanh(z)$\n",
        "3. ReLU: $f(z) = max(x,0)$\n",
        "4. SoftPlus: $f(z) = ln(1 + e^z)$\n",
        "5. LeakyReLU: $f(z) = max(x,ax), a \\le 1$\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "hwwrWrgO6-j_",
        "colab_type": "text"
      },
      "source": [
        "### Interpretácia poslednej vrstvy\n",
        "\n",
        "Zameriame sa na úlohu klasifikácie. Preto budeme interpretovať poslednú vrstvu v tomto zmysle. Ak chcem klasifikovať len do dvoch tried, tak nám stačí jeden neurón so sigmoidom. Ak je jeho hodnota menšia ako 0.5 klasifikujeme objekt ako prvú triedu a inak ako druhú.\n",
        "\n",
        "Pri viacerých $n \\gt 2$ triedach potrebujeme viacero neurónov môžeme použiť pravidlo: $k = {argmax}_{i \\in \\hat{n}}(a_i^L(x))$, kde $L$ je počet vrstiev, $x$ je vstupný vektor $n$ je počet tried a $k$ je trieda ktorú klasifikátor určil.\n",
        "\n",
        "Trocha sofistikvanejší postup je použitie. Tzv. softmax vrstvy na konci namiesto bežnej aktivácie. $P(k|x) = \\frac{e^{z^L_k(x)}}{\\sum_{i \\in \\hat n} e^{z^L_i(x)}}$, kde $P(k|x)$ je pravdepodobnosť, že pre vstup $x$ je správna trieda $k$.\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "7B0Wf7O19FZ2",
        "colab_type": "text"
      },
      "source": [
        "## Trénovanie\n",
        "\n",
        "Model je síce pekný, ale je nutné nájsť také aktivácie aby robil to, čo chceme. V našom prípade je to klasifikácia do $n$ tried. Na trénovanie budeme potrebovať trénovacie dáta. Teda páry $\\left(x, y\\right)$, kde $x$ je vstupný vektor a $y$ je výstupný vektor označujúci správnu triedu. Aby sa nám to hodilo do interpretácie poslednej vrstvy, tak $y$ bude vektor, ktorý bude mať na $k$-tom mieste jednotku a všade inde nuly. Toto je tzv. **one-hot** kódovanie."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "xhi87Qqa-Fnu",
        "colab_type": "text"
      },
      "source": [
        "### Cenová funkcia\n",
        "\n",
        "Trénovanie je podobné optimalizácii. Chceme nájsť také parametre siete (v našom prípade matice $w$ a vektory $b$), ktoré budú fungovať čo najlepšie pre náš problém. To sa budeme snažiť docieliť tým že budeme optimalizovať hodnotu tzv. ceny (loss function, cost function). Ideálne platí, že cím vyššia cena na nejakej množine, tým horšie na nej naša sieť funguje. Zároveň chceme aby bola cena pekne diferencovateľná. Dnes použijeme cenové funkcie pre $N$ párov $\\left(x^i, y^i\\right)$:\n",
        "\n",
        "1. MSE: $C = \\frac{1}{N} \\sum_i ||a^L(x^i) - y^i||_2^2$, kde $||v||_2$ je L-2 norma vektoru $v$.\n",
        "2. Cross-Entropy:  $C = -\\frac{1}{N} \\sum_{i,j} y_j^i ln\\left(a_j^L(x)\\right) + \\left(1-y_j^i\\right) ln\\left(1 - a_i^L(x) \\right)$\n",
        "3. CE + Softmax: $C = \\frac{1}{N} ln(z_y^L(x))$, kde $z_y^L(x)$ je ten element vektoru $z^L(x)$, pre ktorý je trieda správne. \n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "_xeWYehnAcjk",
        "colab_type": "text"
      },
      "source": [
        "### Gradientný zostup\n",
        "\n",
        "Na optimalizáciu použijeme jednoduché pravidlo gradientného zostupu s krokom $\\eta$ pre parameter $p$ a cenovú funkciu $C$.\n",
        "\n",
        "$$p := p - \\eta \\frac{\\partial C}{\\partial p}$$\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "wyRPBWdLBMN8",
        "colab_type": "text"
      },
      "source": [
        "### SGD\n",
        "\n",
        "Na každý krok pri trénovaní vždy použijeme náhodnú podmnožinu z trénovacej množiny. Na ďalší krok ďalšiu atď. Toto má výhody v tom, že vnášame do procesu šum, ktorý nás vie dostať z lokálnych miním. Takisto miesta v parametrickom priestore kam sa algoritmus dostane majú často lepšie vlastnosti, čo sa týka generalizácie ako čistá optimalizácia. Navyše tým šetríme miesto v pamäti, čo je jedna zo základných.\n",
        "\n",
        "Tento prístup sa volá **stochastic gradient descent (SGD)**.\n",
        "\n",
        "*Pozn.:* Výberom minibatchu vlastne approximujeme priestor funkciu $C$ pre celú trénovaciu množinu. \"Chyba\" tejto aproximácie klesá približne $\\sim \\frac{1}{\\sqrt{M}}$, kde $M$ je veľkosť minibatchu. Preto nieje úplne vhodné používať veľký minibatch, aj keď to pamäť dovoluje."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "yQU12OCyGN3j",
        "colab_type": "text"
      },
      "source": [
        "### Výpočet parciálnych derivácii\n",
        "Teraz si odvodíme postup ako vypočítať analyticky parciálne derivácie pre našu plne prepojenú sieť.\n",
        "\n",
        "Najprv si zavedieme pomocnú deriváciu.\n",
        "\n",
        "$ d_i^l = \\frac{\\partial C}{\\partial z_i^l}$\n",
        "\n",
        "V závislosti na výbere $C$ platí, značka $\\odot$ značí násobenie po elementoch (Hadamardov súčin)\n",
        "\n",
        "pre MSE: $d_i^L = (a_i^L - y_i) \\cdot f^{'} (z_i^L)$, \n",
        "\n",
        "pre CE: $d_i^L = (a_i^L - y_i)$\n",
        "\n",
        "Vektorovo MSE: $d_i^L = (a^L - y) \\odot f^{'} (z^L)$\n",
        "\n",
        "Vektorovo CE: $d^L = a^L - y$"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "_LcoHRfNISgK",
        "colab_type": "text"
      },
      "source": [
        "Na základe $d^{l+1}$ môžeme určiť $d^l$. Tento postup je tzv. **backpropagation**, keďže deriváciu (gradient) propagujeme v sieti opačným smerom ako pri doprednom výpočte.\n",
        "\n",
        "$ d^l = \\left(d^{l+1} \\left( w^{l+1} \\right)^T\\right) \\odot f^{'}(z^l)$\n",
        "\n",
        "Dôkaz:\n",
        "\n",
        "$z_j^{l+1} = \\sum_k \\left( f \\left( z^l_k\\right) w_{kj}^{l+1} \\right) + b_j^{l+1}$\n",
        "\n",
        "$\\frac{\\partial z_j^{l+1}}{\\partial z_k^l} = f^{'} \\left( z^l_k\\right) w_{kj}^{l+1}$\n",
        "\n",
        "$d_k^l = \\frac{\\partial C}{\\partial z_k^l} = \\sum_j \\frac{\\partial C}{\\partial z_j^{l+1}} \\frac{\\partial z_j^{l+1}}{\\partial z_k^l} = \\sum_j d_j^{l+1} f^{'} \\left( z^l_k\\right) w_{kj}^l$\n",
        "\n",
        "Pre parametre platí:\n",
        "\n",
        "$\\frac{\\partial C}{\\partial b_j^l} = d_j^l$\n",
        "\n",
        "$\\frac{\\partial C}{\\partial w_{kj}^l} = d_j^l a_k^{l-1}$\n",
        "\n",
        "Vektorovo:\n",
        "\n",
        "$\\frac{\\partial C}{\\partial b^l} = d^l$\n",
        "\n",
        "$\\frac{\\partial C}{\\partial w_{}^l} = (a^{l-1})^T d^l $\n",
        "\n",
        "Dôkaz:\n",
        "\n",
        "$z_j^l = \\sum_k a_k^{l-1} w_{kj}^l + b_j^l$\n",
        "\n",
        "$\\frac{\\partial C}{\\partial b_j^l} = \\sum_k \\frac{\\partial C}{\\partial z_k^l}\\frac{\\partial z_k^l}{\\partial b_j^l} = \\sum_k \\delta_{kj} d_k^l = d_j^l$\n",
        "\n",
        "$\\frac{\\partial C}{\\partial w_{kj}^l} = \\sum_p \\frac{\\partial C}{\\partial z_p^l}\\frac{\\partial z_p^l}{\\partial w_{kj}^l} = \\sum_p d_p^l \\delta_{pj} a_k^{l-1} = d_j^l a_k^{l-1}$  \n",
        "\n",
        "kde $\\delta_{jk} = 1$ ak $j = k$, inak $ 0$."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "uWA-YWo1uQpJ",
        "colab_type": "text"
      },
      "source": [
        "### Algoritmus\n",
        "Jeden krok algoritmu SGD potom vyzerá následovne\n",
        "1. Realizujeme dopredný výpočet - pamätáme si $z^l$ a $a^l$.\n",
        "2. Vypočitame $\\delta^L$ podľa cenovej funkcie\n",
        "3. Spätne propagujeme chybu $\\delta^l$ pomocou backpropagation pravidla.\n",
        "4. Vypočítame parciálne derivácie podľa rovníc z predchádzajúceho bloku.\n",
        "5. Opakujeme pre celý minibatch, derivácie spriemerujeme a updatneme parametre podľa gradientného zostupu.\n",
        "  \n",
        "**Pozor:** je nutné ešte nejako nainicializovať váhy. Ak ich nainicializujeme narovnako, tak derivácie pre jednotlivé vrstvy budú vždy rovnaké a tak sa sieť ani nemôže naučit komplikovanejšie reprezentácie. Tj. je to ako sieť kde v každej vrstve je len jeden neurón."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "p6xZS20luwdq",
        "colab_type": "text"
      },
      "source": [
        "## Implementácia\n",
        "\n",
        "V nasledujúcom kóde je implementácia základnej štruktúry kódu. Pre jednoduchú plne prepojenú sieť. V kóde budete musieť doplniť veci v jednotlivých úlohách. K úlohám je aj kód, ktorý Vám pomôže overiť či ste správne doimplementovali časť riešenia."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "gRbPiw8t210R",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import numpy as np\n",
        "\n",
        "def sigmoid(z):\n",
        "    # vráti hodnotu sigmoidu\n",
        "    return 1.0/(1.0+np.exp(-z))\n",
        "\n",
        "def sigmoid_prime(z):\n",
        "    # vráti gradient sigmoidu\n",
        "    return sigmoid(z)*(1-sigmoid(z))\n",
        "\n",
        "\n",
        "# def one_hot(j):\n",
        "#     # vráti one-hot zakodovaný vektor\n",
        "#     e = np.zeros((10, 1))\n",
        "#     e[j] = 1.0\n",
        "#     return e\n",
        "\n",
        "def get_one_hot(targets, nb_classes):\n",
        "    res = np.eye(nb_classes)[np.array(targets).reshape(-1)]\n",
        "    return res.reshape(list(targets.shape)+[nb_classes])\n",
        "\n",
        "class Network():\n",
        "    def __init__(self, arg):\n",
        "        if isinstance(arg, str):\n",
        "        \n",
        "            self.load(arg)\n",
        "        else:\n",
        "            if len(arg) < 2:\n",
        "                raise ValueError(\"Sizes must be at least 2!\")\n",
        "\n",
        "            self.w_list = []\n",
        "            self.b_list = []\n",
        "            for i in range(1, len(arg)):\n",
        "                self.w_list.append(np.random.randn(arg[i - 1], arg[i]))\n",
        "                self.b_list.append(0.1 * np.ones((arg[i])))\n",
        "\n",
        "    def save(self, filename):\n",
        "        dict = np.array([self.w_list, self.b_list])\n",
        "        np.save(filename, dict)\n",
        "\n",
        "    def load(self, filename):\n",
        "        d = np.load(filename, allow_pickle=True)\n",
        "        self.w_list = d[0].tolist()\n",
        "        self.b_list = d[1].tolist()\n",
        "\n",
        "    def fwd(self, a):\n",
        "        for b, w in zip(self.b_list, self.w_list):\n",
        "            a = sigmoid(np.dot(a, w)+b)\n",
        "        return a\n",
        "\n",
        "    def _step(self, X, y, batch_size, eta):\n",
        "        new_w_list = [np.empty_like(w) for w in self.w_list]\n",
        "        new_b_list = [np.empty_like(b) for b in self.b_list]\n",
        "        z_list = []\n",
        "        a_list = [X]\n",
        "        for i in range(len(self.w_list)):\n",
        "            z_list.append(np.matmul(a_list[i], self.w_list[i]))\n",
        "            a_list.append(sigmoid(z_list[i]))\n",
        "\n",
        "        d_list = [[] for _ in z_list]\n",
        "        err = np.sum((a_list[-1] - y)**2) / batch_size\n",
        "        # d_list[-1] = (a_list[-1] - y)*sigmoid_prime(z_list[-1])\n",
        "        d_list[-1] = a_list[-1] - y\n",
        "\n",
        "        new_w_list[-1] = self.w_list[-1] - (eta / batch_size) * np.matmul(a_list[-2].T, d_list[-1])\n",
        "        new_b_list[-1] = self.b_list[-1] - (eta / batch_size) * np.sum(d_list[-1], axis= 0)\n",
        "        for i in range(2, len(z_list)+1):\n",
        "            d_list[-i] = (np.matmul(d_list[-i+1], self.w_list[-i+1].T))*sigmoid_prime(z_list[-i])\n",
        "            new_w_list[-i] = self.w_list[-i] - (eta / batch_size) * np.matmul(a_list[-i-1].T, d_list[-i])\n",
        "            new_b_list[-i] = self.b_list[-i] - (eta / batch_size) * np.sum(d_list[-i], axis=0)\n",
        "        self.w_list = new_w_list\n",
        "        self.b_list = new_b_list\n",
        "        return err\n",
        "\n",
        "    def eval(self, X, y):\n",
        "        out = self.fwd(X)\n",
        "        err = np.mean((out - y)**2)\n",
        "        out_best = np.argmax(out, axis=-1)\n",
        "        y_best = np.argmax(y, axis=-1)\n",
        "        acc = np.sum(np.where(out_best == y_best, 1, 0))/y.shape[0]\n",
        "        return acc, err\n",
        "\n",
        "    def sgd(self, X, y, val_X, val_y, epochs, steps, batch_size, eta):\n",
        "        for epoch in range(epochs):\n",
        "            err_tot = 0\n",
        "            for step in range(steps):\n",
        "                batch_mask = np.random.choice(X.shape[0], batch_size)\n",
        "                batch_X = X[batch_mask,:]\n",
        "                batch_y = y[batch_mask,:]\n",
        "                err = self._step(batch_X, batch_y, batch_size, eta)\n",
        "                if step == 0:\n",
        "                    err_tot = err\n",
        "                else:\n",
        "                    err_tot = 0.1 * err + 0.9 * err_tot\n",
        "                print(\"At step: {}, running average training error: {}\".format(step, err_tot))\n",
        "\n",
        "            acc, err = self.eval(val_X, val_y)\n",
        "            print(\"At Epoch {}, validation error: {}, validation accuracy {}\".format(epoch, err, acc))"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "iH8VKEA75r37",
        "colab_type": "text"
      },
      "source": [
        "### Úloha 2\n",
        "\n",
        "Doimplementujte funkciu sigmoid, ktorá vráti výsledok funkcie sigmoid po elementoch pre každý vstupný tenzor.\n",
        "\n",
        "$$\\sigma(z) = \\frac{1}{1 + e^{-z}}$$\n",
        "\n",
        "Takisto doimplementujte aj deriváciu\n",
        "\n",
        "$$\\sigma (z)^{'} = \\sigma (z)\\left(1 - \\sigma (z) \\right)$$\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "n3yqkMFx7zzH",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "assert(sigmoid(0) == 0.5)\n",
        "assert(sigmoid(50) > 1.0-1e-10)\n",
        "assert(sigmoid(-50) <= 2e-22)\n",
        "assert((sigmoid(np.array([10, 20]))==np.array([sigmoid(10), sigmoid(20)])).all())\n",
        "assert(sigmoid_prime(0) == 0.25)\n",
        "assert(sigmoid_prime(-50) > 0 )\n",
        "assert(sigmoid_prime(30) > 0 )"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "2h6d73t044mf",
        "colab_type": "text"
      },
      "source": [
        "### Úloha 3"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "WCf2S6UF_TYP",
        "colab_type": "text"
      },
      "source": [
        "Pred treťou úlohou načítame mnist dataset a zobrazíme si jeden obrázok. Je dosť možné, že to chvílu potrvá."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "cI8hPz2W_S21",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "from sklearn.datasets import fetch_openml\n",
        "mnist = fetch_openml('mnist_784')\n",
        "\n",
        "X = mnist.data.astype('float32')/255\n",
        "y = mnist.target.astype('int64')"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "HT_nIXO9_jr_",
        "colab_type": "code",
        "outputId": "03edc0f7-5fda-4328-a5a6-5fa0ef4fe191",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 286
        }
      },
      "source": [
        "import matplotlib.pyplot as plt\n",
        "\n",
        "plt.imshow(np.reshape(X[0,],(28,28)), cmap='gray')\n",
        "print(y[0])"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "5\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "display_data",
          "data": {
            "image/png": "iVBORw0KGgoAAAANSUhEUgAAAP8AAAD8CAYAAAC4nHJkAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\n",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {
            "tags": []
          }
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "IH7H25CE-kaf",
        "colab_type": "text"
      },
      "source": [
        "Doimplementujte metódu fwd. V prvom teste sa testuje dimenzia výstupu a v druhuom sa stihane predtrénovaná sieť a spustí sa na obrázkoch z datasetu MNIST."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "AxW9P3YJ4AmX",
        "colab_type": "code",
        "outputId": "1280ec6c-51b6-43bd-a5a2-807469975d4c",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "net = Network([28*28,30,20,10])\n",
        "out = net.fwd(np.random.randn(32,784))\n",
        "assert(out.shape == (32,10))\n",
        "print(\"Prvý test prešiel\")"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Prvý test prešiel\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "UiD5eCtMJYM6",
        "colab_type": "code",
        "outputId": "93a164d9-debc-431d-aacd-ed8586171082",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 289
        }
      },
      "source": [
        "!wget https://github.com/kocurvik/edu/raw/master/PNNPPV/supplementary/test_net.npy"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "--2019-10-02 12:06:19--  https://github.com/kocurvik/edu/raw/master/PNNPPV/supplementary/test_net.npy\n",
            "Resolving github.com (github.com)... 140.82.114.4\n",
            "Connecting to github.com (github.com)|140.82.114.4|:443... connected.\n",
            "HTTP request sent, awaiting response... 302 Found\n",
            "Location: https://raw.githubusercontent.com/kocurvik/edu/master/PNNPPV/supplementary/test_net.npy [following]\n",
            "--2019-10-02 12:06:20--  https://raw.githubusercontent.com/kocurvik/edu/master/PNNPPV/supplementary/test_net.npy\n",
            "Resolving raw.githubusercontent.com (raw.githubusercontent.com)... 151.101.0.133, 151.101.64.133, 151.101.128.133, ...\n",
            "Connecting to raw.githubusercontent.com (raw.githubusercontent.com)|151.101.0.133|:443... connected.\n",
            "HTTP request sent, awaiting response... 200 OK\n",
            "Length: 304267 (297K) [application/octet-stream]\n",
            "Saving to: ‘test_net.npy’\n",
            "\n",
            "\rtest_net.npy          0%[                    ]       0  --.-KB/s               \rtest_net.npy        100%[===================>] 297.14K  --.-KB/s    in 0.03s   \n",
            "\n",
            "2019-10-02 12:06:20 (10.6 MB/s) - ‘test_net.npy’ saved [304267/304267]\n",
            "\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "RwMeAHDcAt1k",
        "colab_type": "code",
        "outputId": "68b57671-28f6-4c80-ef8b-b99c084d893d",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 994
        }
      },
      "source": [
        "net = Network(\"test_net.npy\")\n",
        "\n",
        "R = net.fwd(X[0:3,:])\n",
        "\n",
        "correct_list = [5,0,4]\n",
        "\n",
        "for i in range(3):\n",
        "  plt.imshow(np.reshape(X[i,:],(28,28)), cmap = 'gray')\n",
        "  plt.show()\n",
        "  print(R[i])\n",
        "  print(np.argmax(R[i,:]))\n",
        "  assert(np.argmax(R[i]) == correct_list[i])\n",
        "  \n",
        "print(\"Druhý test prešiel!\")"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "image/png": "iVBORw0KGgoAAAANSUhEUgAAAP8AAAD8CAYAAAC4nHJkAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\n",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {
            "tags": []
          }
        },
        {
          "output_type": "stream",
          "text": [
            "[9.37229037e-04 2.66838142e-04 2.75842143e-05 9.41889344e-03\n",
            " 2.84101542e-08 3.63257568e-01 1.62064850e-07 8.06202488e-05\n",
            " 7.02270024e-04 6.57032697e-04]\n",
            "5\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "display_data",
          "data": {
            "image/png": "iVBORw0KGgoAAAANSUhEUgAAAP8AAAD8CAYAAAC4nHJkAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\nIvxAUIQfCIrwA0H9H/00nuWz++2XAAAAAElFTkSuQmCC\n",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {
            "tags": []
          }
        },
        {
          "output_type": "stream",
          "text": [
            "[9.94378188e-01 4.89519245e-07 3.28816149e-05 8.06781030e-05\n",
            " 6.55497717e-06 4.25255977e-05 1.82384777e-04 7.61480364e-04\n",
            " 2.06510936e-05 1.62541578e-03]\n",
            "0\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "display_data",
          "data": {
            "image/png": "iVBORw0KGgoAAAANSUhEUgAAAP8AAAD8CAYAAAC4nHJkAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\nrwAAAABJRU5ErkJggg==\n",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {
            "tags": []
          }
        },
        {
          "output_type": "stream",
          "text": [
            "[1.53046899e-05 1.98120978e-04 1.47761151e-03 6.18961861e-05\n",
            " 5.35841113e-01 1.93294785e-06 6.89669687e-06 3.71849632e-02\n",
            " 4.93958997e-05 2.59638688e-02]\n",
            "4\n",
            "Druhý test prešiel!\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Q0wkQuKFJ7lC",
        "colab_type": "text"
      },
      "source": [
        "### Úloha 4 \n",
        "Doimplementujte metódu _step\n",
        "\n",
        "Ktorá výkoná krok SGD pre MSE, alebo CE cenovú funkciu. Túto metódu nebude testovať priamo, ale skúsime je apllikovať na trénovanie. Tieto parametre by mali fungovať aspoň tak, že model sa bude zlepšovať na validačnej množine."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "B_5kRZuWKZBS",
        "colab_type": "code",
        "outputId": "d35cef4c-b2a3-4217-c522-f4aa728b14bb",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        }
      },
      "source": [
        "train_X = X[:50000, :]\n",
        "train_y = get_one_hot(y[:50000], 10)\n",
        "\n",
        "\n",
        "val_X = X[50000:60000,:]\n",
        "val_y = get_one_hot(y[50000:60000],10)\n",
        "#\n",
        "net = Network([28*28,30,20,10])\n",
        "net.sgd(train_X, train_y, val_X, val_y, 10, 10000, 32, 0.01)\n",
        "net.sgd(train_X, train_y, val_X, val_y, 10, 10000, 32, 0.03)\n",
        "net.sgd(train_X, train_y, val_X, val_y, 10, 10000, 32, 0.001)\n",
        "net.save(\"net.npy\")"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "At step: 0 training error: 5.102115440233531\n",
            "At step: 1 training error: 5.081094806350565\n",
            "At step: 2 training error: 5.070079849369308\n",
            "At step: 3 training error: 5.037166941435059\n",
            "At step: 4 training error: 4.9819107610229665\n",
            "At step: 5 training error: 4.937761992739605\n",
            "At step: 6 training error: 4.937664792774155\n",
            "At step: 7 training error: 4.907921698892566\n",
            "At step: 8 training error: 4.8744858531654005\n",
            "At step: 9 training error: 4.8557840587178935\n",
            "At step: 10 training error: 4.8021571317660765\n",
            "At step: 11 training error: 4.768314249275084\n",
            "At step: 12 training error: 4.727487011088771\n",
            "At step: 13 training error: 4.684205913073173\n",
            "At step: 14 training error: 4.627842432121145\n",
            "At step: 15 training error: 4.605708242610705\n",
            "At step: 16 training error: 4.580204900235965\n",
            "At step: 17 training error: 4.524292091910626\n",
            "At step: 18 training error: 4.505084419911237\n",
            "At step: 19 training error: 4.471033629142642\n",
            "At step: 20 training error: 4.427585211647423\n",
            "At step: 21 training error: 4.365186383566249\n",
            "At step: 22 training error: 4.300355366624175\n",
            "At step: 23 training error: 4.252156917519911\n",
            "At step: 24 training error: 4.227758121403162\n",
            "At step: 25 training error: 4.167158624829201\n",
            "At step: 26 training error: 4.098906963726467\n",
            "At step: 27 training error: 4.025710309337905\n",
            "At step: 28 training error: 3.9847589836778337\n",
            "At step: 29 training error: 3.9456196483162307\n",
            "At step: 30 training error: 3.929960473414323\n",
            "At step: 31 training error: 3.8826288344297515\n",
            "At step: 32 training error: 3.8333664245412966\n",
            "At step: 33 training error: 3.7734677267421195\n",
            "At step: 34 training error: 3.7394219550200156\n",
            "At step: 35 training error: 3.685702908230659\n",
            "At step: 36 training error: 3.639981566242713\n",
            "At step: 37 training error: 3.589851322681932\n",
            "At step: 38 training error: 3.520999589902233\n",
            "At step: 39 training error: 3.4618138663637157\n",
            "At step: 40 training error: 3.4177116403325245\n",
            "At step: 41 training error: 3.358413683913599\n",
            "At step: 42 training error: 3.2812379959780364\n",
            "At step: 43 training error: 3.209217985217385\n",
            "At step: 44 training error: 3.1552624437492023\n",
            "At step: 45 training error: 3.096860535158365\n",
            "At step: 46 training error: 3.0416399898072233\n",
            "At step: 47 training error: 3.012425860255544\n",
            "At step: 48 training error: 2.9646892253204835\n",
            "At step: 49 training error: 2.9260182669362895\n",
            "At step: 50 training error: 2.8832506962293443\n",
            "At step: 51 training error: 2.838612096564285\n",
            "At step: 52 training error: 2.788647695513383\n",
            "At step: 53 training error: 2.738620661927299\n",
            "At step: 54 training error: 2.6939402468513043\n",
            "At step: 55 training error: 2.6508383264694024\n",
            "At step: 56 training error: 2.6099642469056157\n",
            "At step: 57 training error: 2.556693673555873\n",
            "At step: 58 training error: 2.536280244334386\n",
            "At step: 59 training error: 2.4832351664735253\n",
            "At step: 60 training error: 2.4499271158203966\n",
            "At step: 61 training error: 2.4025103728387185\n",
            "At step: 62 training error: 2.3706112604651324\n",
            "At step: 63 training error: 2.3304590783932957\n",
            "At step: 64 training error: 2.2976764995704415\n",
            "At step: 65 training error: 2.239895380489424\n",
            "At step: 66 training error: 2.1918854151279064\n",
            "At step: 67 training error: 2.159812795619162\n",
            "At step: 68 training error: 2.130241645892238\n",
            "At step: 69 training error: 2.097263680659913\n",
            "At step: 70 training error: 2.0765990343816396\n",
            "At step: 71 training error: 2.0432408043816452\n",
            "At step: 72 training error: 2.0359097647787303\n",
            "At step: 73 training error: 1.99279331897206\n",
            "At step: 74 training error: 1.9711658904861535\n",
            "At step: 75 training error: 1.961672980814615\n",
            "At step: 76 training error: 1.9252206634214537\n",
            "At step: 77 training error: 1.8923359882562956\n",
            "At step: 78 training error: 1.8730417510741133\n",
            "At step: 79 training error: 1.8599953923814228\n",
            "At step: 80 training error: 1.8472797457113344\n",
            "At step: 81 training error: 1.823363745479228\n",
            "At step: 82 training error: 1.8052797425983127\n",
            "At step: 83 training error: 1.7657878550100015\n",
            "At step: 84 training error: 1.7416207336251615\n",
            "At step: 85 training error: 1.7327481459442238\n",
            "At step: 86 training error: 1.7211413253888335\n",
            "At step: 87 training error: 1.6939017682570934\n",
            "At step: 88 training error: 1.6815111901261794\n",
            "At step: 89 training error: 1.6612284085155142\n",
            "At step: 90 training error: 1.6367416496568095\n",
            "At step: 91 training error: 1.6176445258509895\n",
            "At step: 92 training error: 1.578111042067339\n",
            "At step: 93 training error: 1.5672208496597175\n",
            "At step: 94 training error: 1.5410536047232173\n",
            "At step: 95 training error: 1.5340664759402574\n",
            "At step: 96 training error: 1.5226512077074095\n",
            "At step: 97 training error: 1.5094372204939532\n",
            "At step: 98 training error: 1.4881399532631423\n",
            "At step: 99 training error: 1.4623063931508344\n",
            "At step: 100 training error: 1.4649255844892248\n",
            "At step: 101 training error: 1.4393883998246593\n",
            "At step: 102 training error: 1.425719649385715\n",
            "At step: 103 training error: 1.4083750957061183\n",
            "At step: 104 training error: 1.3925779764774135\n",
            "At step: 105 training error: 1.3830000438140073\n",
            "At step: 106 training error: 1.3742924268783394\n",
            "At step: 107 training error: 1.3575652648097076\n",
            "At step: 108 training error: 1.3451795158758921\n",
            "At step: 109 training error: 1.3309658399600808\n",
            "At step: 110 training error: 1.3295773506844115\n",
            "At step: 111 training error: 1.3351731726563871\n",
            "At step: 112 training error: 1.3393969469038365\n",
            "At step: 113 training error: 1.3345705324890655\n",
            "At step: 114 training error: 1.3347026122056471\n",
            "At step: 115 training error: 1.3398838473775336\n",
            "At step: 116 training error: 1.333839917577816\n",
            "At step: 117 training error: 1.3206658341016277\n",
            "At step: 118 training error: 1.301986286006631\n",
            "At step: 119 training error: 1.2952060603206852\n",
            "At step: 120 training error: 1.294887238575654\n",
            "At step: 121 training error: 1.2837506361192266\n",
            "At step: 122 training error: 1.2753351967147588\n",
            "At step: 123 training error: 1.2713422213651973\n",
            "At step: 124 training error: 1.2476404203405957\n",
            "At step: 125 training error: 1.2309870467250308\n",
            "At step: 126 training error: 1.2213060864500251\n",
            "At step: 127 training error: 1.2247689625742337\n",
            "At step: 128 training error: 1.2241707730710285\n",
            "At step: 129 training error: 1.2221921100057214\n",
            "At step: 130 training error: 1.212180787185276\n",
            "At step: 131 training error: 1.212615304578075\n",
            "At step: 132 training error: 1.2073121252651282\n",
            "At step: 133 training error: 1.2059100102642724\n",
            "At step: 134 training error: 1.2009605850827085\n",
            "At step: 135 training error: 1.1972277285575117\n",
            "At step: 136 training error: 1.1940888490886508\n",
            "At step: 137 training error: 1.1968654823085145\n",
            "At step: 138 training error: 1.190193783118691\n",
            "At step: 139 training error: 1.1877124683557674\n",
            "At step: 140 training error: 1.198093728770731\n",
            "At step: 141 training error: 1.1969202967018313\n",
            "At step: 142 training error: 1.174162919103441\n",
            "At step: 143 training error: 1.176141467501001\n",
            "At step: 144 training error: 1.1628831492987417\n",
            "At step: 145 training error: 1.15676639124144\n",
            "At step: 146 training error: 1.136102478641087\n",
            "At step: 147 training error: 1.123745289729171\n",
            "At step: 148 training error: 1.106700818011217\n",
            "At step: 149 training error: 1.1121373348424763\n",
            "At step: 150 training error: 1.1074459138874995\n",
            "At step: 151 training error: 1.1076376993867512\n",
            "At step: 152 training error: 1.103109084762923\n",
            "At step: 153 training error: 1.1001243818852768\n",
            "At step: 154 training error: 1.1039043586588648\n",
            "At step: 155 training error: 1.100056273249272\n",
            "At step: 156 training error: 1.093981408526174\n",
            "At step: 157 training error: 1.0827779391005332\n",
            "At step: 158 training error: 1.076154639482236\n",
            "At step: 159 training error: 1.078824098672315\n",
            "At step: 160 training error: 1.0688513242580442\n",
            "At step: 161 training error: 1.0628178151412848\n",
            "At step: 162 training error: 1.0706972110112647\n",
            "At step: 163 training error: 1.0621789626655367\n",
            "At step: 164 training error: 1.0657089735763847\n",
            "At step: 165 training error: 1.0673729327728587\n",
            "At step: 166 training error: 1.0568224639303363\n",
            "At step: 167 training error: 1.0499971806875859\n",
            "At step: 168 training error: 1.0332773052350737\n",
            "At step: 169 training error: 1.0324470524642446\n",
            "At step: 170 training error: 1.0297624632845175\n",
            "At step: 171 training error: 1.0438855777311364\n",
            "At step: 172 training error: 1.043168012773478\n",
            "At step: 173 training error: 1.0350522937970035\n",
            "At step: 174 training error: 1.0399424816221967\n",
            "At step: 175 training error: 1.043478761588203\n",
            "At step: 176 training error: 1.0512087762779903\n",
            "At step: 177 training error: 1.0502554250463865\n",
            "At step: 178 training error: 1.0461430658941995\n",
            "At step: 179 training error: 1.0491071687266518\n",
            "At step: 180 training error: 1.0348115818043948\n",
            "At step: 181 training error: 1.0255839282821968\n",
            "At step: 182 training error: 1.034303326400187\n",
            "At step: 183 training error: 1.036265412576167\n",
            "At step: 184 training error: 1.037964740185672\n",
            "At step: 185 training error: 1.0348702164101986\n",
            "At step: 186 training error: 1.0411429202491744\n",
            "At step: 187 training error: 1.039181330240287\n",
            "At step: 188 training error: 1.0427433200652434\n",
            "At step: 189 training error: 1.0365970391464627\n",
            "At step: 190 training error: 1.0420300137105998\n",
            "At step: 191 training error: 1.0464428584725558\n",
            "At step: 192 training error: 1.0309467757261181\n",
            "At step: 193 training error: 1.025049049220094\n",
            "At step: 194 training error: 1.0265141352610572\n",
            "At step: 195 training error: 1.0205952986948865\n",
            "At step: 196 training error: 1.0238055008638676\n",
            "At step: 197 training error: 1.0174437883732619\n",
            "At step: 198 training error: 1.011602396843474\n",
            "At step: 199 training error: 1.0031999279255965\n",
            "At step: 200 training error: 0.9967534367822005\n",
            "At step: 201 training error: 0.9945893738153015\n",
            "At step: 202 training error: 0.9911465374340345\n",
            "At step: 203 training error: 0.9894707226384825\n",
            "At step: 204 training error: 0.9901011394205497\n",
            "At step: 205 training error: 0.9938712376157606\n",
            "At step: 206 training error: 0.9919456642709288\n",
            "At step: 207 training error: 0.9988163476936014\n",
            "At step: 208 training error: 0.9912108738903205\n",
            "At step: 209 training error: 0.9776514746727454\n",
            "At step: 210 training error: 0.9849387450963251\n",
            "At step: 211 training error: 0.9831965225254442\n",
            "At step: 212 training error: 0.9784674738013854\n",
            "At step: 213 training error: 0.9648996208833407\n",
            "At step: 214 training error: 0.9628840835722795\n",
            "At step: 215 training error: 0.9640580907711298\n",
            "At step: 216 training error: 0.9692083859314935\n",
            "At step: 217 training error: 0.9676437388749339\n",
            "At step: 218 training error: 0.9710268844455496\n",
            "At step: 219 training error: 0.9716389290448377\n",
            "At step: 220 training error: 0.9621921273846397\n",
            "At step: 221 training error: 0.964668400825998\n",
            "At step: 222 training error: 0.9632473916482664\n",
            "At step: 223 training error: 0.9599979075895608\n",
            "At step: 224 training error: 0.9620914142223272\n",
            "At step: 225 training error: 0.9619956278463961\n",
            "At step: 226 training error: 0.9579741790950671\n",
            "At step: 227 training error: 0.9557261568665029\n",
            "At step: 228 training error: 0.9631936329572754\n",
            "At step: 229 training error: 0.9681726366551058\n",
            "At step: 230 training error: 0.9690046519138754\n",
            "At step: 231 training error: 0.9725495781569143\n",
            "At step: 232 training error: 0.9694074522657001\n",
            "At step: 233 training error: 0.9617783511846744\n",
            "At step: 234 training error: 0.9652018274239362\n",
            "At step: 235 training error: 0.969420532223704\n",
            "At step: 236 training error: 0.9725359780465039\n",
            "At step: 237 training error: 0.9696042639809705\n",
            "At step: 238 training error: 0.9682291412576005\n",
            "At step: 239 training error: 0.9729055848929167\n",
            "At step: 240 training error: 0.9770354008222637\n",
            "At step: 241 training error: 0.9708058266760059\n",
            "At step: 242 training error: 0.9695512964605604\n",
            "At step: 243 training error: 0.9816589795547062\n",
            "At step: 244 training error: 0.9731966062726651\n",
            "At step: 245 training error: 0.972145807615068\n",
            "At step: 246 training error: 0.9628505180591028\n",
            "At step: 247 training error: 0.9625450539135201\n",
            "At step: 248 training error: 0.9617071137252337\n",
            "At step: 249 training error: 0.9643477690496903\n",
            "At step: 250 training error: 0.9635259055390071\n",
            "At step: 251 training error: 0.965349779815694\n",
            "At step: 252 training error: 0.9673354815899726\n",
            "At step: 253 training error: 0.9693860487011113\n",
            "At step: 254 training error: 0.9642209348404016\n",
            "At step: 255 training error: 0.9644410033650568\n",
            "At step: 256 training error: 0.9678186888316722\n",
            "At step: 257 training error: 0.9650732567643547\n",
            "At step: 258 training error: 0.9694681214896066\n",
            "At step: 259 training error: 0.97556858708069\n",
            "At step: 260 training error: 0.9674911484950042\n",
            "At step: 261 training error: 0.9695314152055529\n",
            "At step: 262 training error: 0.9585307847409555\n",
            "At step: 263 training error: 0.9558563128766009\n",
            "At step: 264 training error: 0.9577281145252776\n",
            "At step: 265 training error: 0.9576858641762568\n",
            "At step: 266 training error: 0.9583689944870852\n",
            "At step: 267 training error: 0.9524300169963151\n",
            "At step: 268 training error: 0.9644719170409903\n",
            "At step: 269 training error: 0.9595607696294826\n",
            "At step: 270 training error: 0.9560178298353629\n",
            "At step: 271 training error: 0.9514519932828635\n",
            "At step: 272 training error: 0.9469143330010583\n",
            "At step: 273 training error: 0.9496983689971044\n",
            "At step: 274 training error: 0.946583667376933\n",
            "At step: 275 training error: 0.9389476128676135\n",
            "At step: 276 training error: 0.9325109599541834\n",
            "At step: 277 training error: 0.9348628571388042\n",
            "At step: 278 training error: 0.9339244553105763\n",
            "At step: 279 training error: 0.9408758773654445\n",
            "At step: 280 training error: 0.952615449658704\n",
            "At step: 281 training error: 0.9506255844864024\n",
            "At step: 282 training error: 0.945020988224633\n",
            "At step: 283 training error: 0.9414976808447778\n",
            "At step: 284 training error: 0.9338606530412654\n",
            "At step: 285 training error: 0.9402621761555553\n",
            "At step: 286 training error: 0.9479311409605806\n",
            "At step: 287 training error: 0.9391801885380532\n",
            "At step: 288 training error: 0.9430483780622833\n",
            "At step: 289 training error: 0.9425772945214431\n",
            "At step: 290 training error: 0.9456653165754806\n",
            "At step: 291 training error: 0.942286727845777\n",
            "At step: 292 training error: 0.9413039808444824\n",
            "At step: 293 training error: 0.9451719259569377\n",
            "At step: 294 training error: 0.9517328188542316\n",
            "At step: 295 training error: 0.9516436874172729\n",
            "At step: 296 training error: 0.948650236961675\n",
            "At step: 297 training error: 0.9467435761661582\n",
            "At step: 298 training error: 0.9394324243966717\n",
            "At step: 299 training error: 0.934187470326856\n",
            "At step: 300 training error: 0.930432335819691\n",
            "At step: 301 training error: 0.9292314568510769\n",
            "At step: 302 training error: 0.9330896593248359\n",
            "At step: 303 training error: 0.9349322479625691\n",
            "At step: 304 training error: 0.9306429801861673\n",
            "At step: 305 training error: 0.9267847963598004\n",
            "At step: 306 training error: 0.9249050599980346\n",
            "At step: 307 training error: 0.9293981828349858\n",
            "At step: 308 training error: 0.9291658799286067\n",
            "At step: 309 training error: 0.9332316025766227\n",
            "At step: 310 training error: 0.9336056222866337\n",
            "At step: 311 training error: 0.9347632736300682\n",
            "At step: 312 training error: 0.9323938506481652\n",
            "At step: 313 training error: 0.9287991471935462\n",
            "At step: 314 training error: 0.9248708544311441\n",
            "At step: 315 training error: 0.9287835338420961\n",
            "At step: 316 training error: 0.9308030261828066\n",
            "At step: 317 training error: 0.9284438177194912\n",
            "At step: 318 training error: 0.9289803278065775\n",
            "At step: 319 training error: 0.9301816109351415\n",
            "At step: 320 training error: 0.9207898967193009\n",
            "At step: 321 training error: 0.9198331608338673\n",
            "At step: 322 training error: 0.9239614999642664\n",
            "At step: 323 training error: 0.9269156762664194\n",
            "At step: 324 training error: 0.9225125668145914\n",
            "At step: 325 training error: 0.9233570875637211\n",
            "At step: 326 training error: 0.9288264268453171\n",
            "At step: 327 training error: 0.9323624086780071\n",
            "At step: 328 training error: 0.9266221752601511\n",
            "At step: 329 training error: 0.9258008119464073\n",
            "At step: 330 training error: 0.9173115608849549\n",
            "At step: 331 training error: 0.9159116008564006\n",
            "At step: 332 training error: 0.9226883095608972\n",
            "At step: 333 training error: 0.9198458625000243\n",
            "At step: 334 training error: 0.9185675997409338\n",
            "At step: 335 training error: 0.9183167237296481\n",
            "At step: 336 training error: 0.9179004234686938\n",
            "At step: 337 training error: 0.9141550812475081\n",
            "At step: 338 training error: 0.917580623397751\n",
            "At step: 339 training error: 0.9146158091381772\n",
            "At step: 340 training error: 0.90921268509476\n",
            "At step: 341 training error: 0.9135989665574579\n",
            "At step: 342 training error: 0.9053492336174894\n",
            "At step: 343 training error: 0.9111725864415111\n",
            "At step: 344 training error: 0.9176361548341021\n",
            "At step: 345 training error: 0.9163313924978882\n",
            "At step: 346 training error: 0.915089328212576\n",
            "At step: 347 training error: 0.9086999329543168\n",
            "At step: 348 training error: 0.8991385862638475\n",
            "At step: 349 training error: 0.9020532644370799\n",
            "At step: 350 training error: 0.9036392516309389\n",
            "At step: 351 training error: 0.897716046255974\n",
            "At step: 352 training error: 0.9026680593310039\n",
            "At step: 353 training error: 0.8986540002426332\n",
            "At step: 354 training error: 0.8986451230595516\n",
            "At step: 355 training error: 0.8999661120585527\n",
            "At step: 356 training error: 0.9065858237548992\n",
            "At step: 357 training error: 0.9099725410227886\n",
            "At step: 358 training error: 0.9171567203135476\n",
            "At step: 359 training error: 0.921911765440112\n",
            "At step: 360 training error: 0.9189222301409645\n",
            "At step: 361 training error: 0.9233892993028194\n",
            "At step: 362 training error: 0.926962365476957\n",
            "At step: 363 training error: 0.9258420034395247\n",
            "At step: 364 training error: 0.9254028591581236\n",
            "At step: 365 training error: 0.9207424747649602\n",
            "At step: 366 training error: 0.9175731053145388\n",
            "At step: 367 training error: 0.9167070268550032\n",
            "At step: 368 training error: 0.9199539728248881\n",
            "At step: 369 training error: 0.926201680595527\n",
            "At step: 370 training error: 0.9297086626309387\n",
            "At step: 371 training error: 0.9308682780518078\n",
            "At step: 372 training error: 0.9268903164491895\n",
            "At step: 373 training error: 0.9198217224247139\n",
            "At step: 374 training error: 0.9213922234229317\n",
            "At step: 375 training error: 0.9233718072824163\n",
            "At step: 376 training error: 0.9206780404769888\n",
            "At step: 377 training error: 0.9176168321342697\n",
            "At step: 378 training error: 0.9182148220467043\n",
            "At step: 379 training error: 0.9082079537814346\n",
            "At step: 380 training error: 0.9099584524734865\n",
            "At step: 381 training error: 0.9130157186532823\n",
            "At step: 382 training error: 0.9070180682726301\n",
            "At step: 383 training error: 0.9100177858948294\n",
            "At step: 384 training error: 0.9099168024408444\n",
            "At step: 385 training error: 0.9077410502001237\n",
            "At step: 386 training error: 0.9106313398481701\n",
            "At step: 387 training error: 0.9107191505649039\n",
            "At step: 388 training error: 0.9186917095815692\n",
            "At step: 389 training error: 0.9117970088221864\n",
            "At step: 390 training error: 0.908699513278551\n",
            "At step: 391 training error: 0.9140239952275421\n",
            "At step: 392 training error: 0.9114945198079543\n",
            "At step: 393 training error: 0.9148014030740133\n",
            "At step: 394 training error: 0.9125470285198536\n",
            "At step: 395 training error: 0.9134318732728428\n",
            "At step: 396 training error: 0.91335025640795\n",
            "At step: 397 training error: 0.9098600660960819\n",
            "At step: 398 training error: 0.9110105658782603\n",
            "At step: 399 training error: 0.9109075189893688\n",
            "At step: 400 training error: 0.9144165513460514\n",
            "At step: 401 training error: 0.9138218552519475\n",
            "At step: 402 training error: 0.912472652849784\n",
            "At step: 403 training error: 0.910883783819411\n",
            "At step: 404 training error: 0.910690484671313\n",
            "At step: 405 training error: 0.9166759474483906\n",
            "At step: 406 training error: 0.9174173451031514\n",
            "At step: 407 training error: 0.9121225583234939\n",
            "At step: 408 training error: 0.9098048691107893\n",
            "At step: 409 training error: 0.9159712906008693\n",
            "At step: 410 training error: 0.9158655490743234\n",
            "At step: 411 training error: 0.9076398048978368\n",
            "At step: 412 training error: 0.9108468290664498\n",
            "At step: 413 training error: 0.9124325823537038\n",
            "At step: 414 training error: 0.9142821343138093\n",
            "At step: 415 training error: 0.9156297524543904\n",
            "At step: 416 training error: 0.9134276178039126\n",
            "At step: 417 training error: 0.9091089471635472\n",
            "At step: 418 training error: 0.9085492418823601\n",
            "At step: 419 training error: 0.9049466980369423\n",
            "At step: 420 training error: 0.9078587761410231\n",
            "At step: 421 training error: 0.9072418314813436\n",
            "At step: 422 training error: 0.9126112517460095\n",
            "At step: 423 training error: 0.9147270323276931\n",
            "At step: 424 training error: 0.918806149093973\n",
            "At step: 425 training error: 0.916294231264126\n",
            "At step: 426 training error: 0.9204287577319126\n",
            "At step: 427 training error: 0.9236103180835097\n",
            "At step: 428 training error: 0.9158468882813998\n",
            "At step: 429 training error: 0.9102267545896331\n",
            "At step: 430 training error: 0.9118279097670293\n",
            "At step: 431 training error: 0.9158130004555531\n",
            "At step: 432 training error: 0.9117702526144654\n",
            "At step: 433 training error: 0.9177959582601675\n",
            "At step: 434 training error: 0.9089416882478146\n",
            "At step: 435 training error: 0.9051125008111213\n",
            "At step: 436 training error: 0.9029301152898814\n",
            "At step: 437 training error: 0.9008453451576833\n",
            "At step: 438 training error: 0.9022686868745802\n",
            "At step: 439 training error: 0.9110202891686159\n",
            "At step: 440 training error: 0.9137233731232155\n",
            "At step: 441 training error: 0.9147340394211197\n",
            "At step: 442 training error: 0.9074860230383289\n",
            "At step: 443 training error: 0.9084277515832165\n",
            "At step: 444 training error: 0.9097304935087029\n",
            "At step: 445 training error: 0.913082189265149\n",
            "At step: 446 training error: 0.9099600404675136\n",
            "At step: 447 training error: 0.9022648729287311\n",
            "At step: 448 training error: 0.9016229256802333\n",
            "At step: 449 training error: 0.9098286119627491\n",
            "At step: 450 training error: 0.9123580947984751\n",
            "At step: 451 training error: 0.9166248266555024\n",
            "At step: 452 training error: 0.9148709261768526\n",
            "At step: 453 training error: 0.9141600579182478\n",
            "At step: 454 training error: 0.9171556471192455\n",
            "At step: 455 training error: 0.9119567052124229\n",
            "At step: 456 training error: 0.9107310144789321\n",
            "At step: 457 training error: 0.9007301248087265\n",
            "At step: 458 training error: 0.8957375543097801\n",
            "At step: 459 training error: 0.8939611217348997\n",
            "At step: 460 training error: 0.8937503371437177\n",
            "At step: 461 training error: 0.8866529659662498\n",
            "At step: 462 training error: 0.8945977207708898\n",
            "At step: 463 training error: 0.8964040521815657\n",
            "At step: 464 training error: 0.8930054216052914\n",
            "At step: 465 training error: 0.8974884001589102\n",
            "At step: 466 training error: 0.900145726929799\n",
            "At step: 467 training error: 0.896928377572463\n",
            "At step: 468 training error: 0.8936906412080095\n",
            "At step: 469 training error: 0.8953902870542545\n",
            "At step: 470 training error: 0.8979466984346252\n",
            "At step: 471 training error: 0.9004614216402209\n",
            "At step: 472 training error: 0.8980136167096348\n",
            "At step: 473 training error: 0.8972892085834554\n",
            "At step: 474 training error: 0.9024064472773146\n",
            "At step: 475 training error: 0.900478519608448\n",
            "At step: 476 training error: 0.8956436037842019\n",
            "At step: 477 training error: 0.8983586943802623\n",
            "At step: 478 training error: 0.8995543533017578\n",
            "At step: 479 training error: 0.8996365308807298\n",
            "At step: 480 training error: 0.8971783719476907\n",
            "At step: 481 training error: 0.8979615653361447\n",
            "At step: 482 training error: 0.8900006557035326\n",
            "At step: 483 training error: 0.8918112039651268\n",
            "At step: 484 training error: 0.892478752773793\n",
            "At step: 485 training error: 0.8897829995524611\n",
            "At step: 486 training error: 0.8954230220484068\n",
            "At step: 487 training error: 0.8919091829387389\n",
            "At step: 488 training error: 0.8938297449140711\n",
            "At step: 489 training error: 0.8919302450464457\n",
            "At step: 490 training error: 0.894436628316366\n",
            "At step: 491 training error: 0.9022662915596964\n",
            "At step: 492 training error: 0.9028298984319214\n",
            "At step: 493 training error: 0.903135136960638\n",
            "At step: 494 training error: 0.8973097393832846\n",
            "At step: 495 training error: 0.895296440869617\n",
            "At step: 496 training error: 0.8979975539723666\n",
            "At step: 497 training error: 0.8956135494665064\n",
            "At step: 498 training error: 0.8965796793436517\n",
            "At step: 499 training error: 0.894903073295684\n",
            "At step: 500 training error: 0.8907377099668722\n",
            "At step: 501 training error: 0.8925159951951274\n",
            "At step: 502 training error: 0.8960096007503113\n",
            "At step: 503 training error: 0.8973465137124237\n",
            "At step: 504 training error: 0.9012029750721732\n",
            "At step: 505 training error: 0.9006555975609326\n",
            "At step: 506 training error: 0.8954719733246874\n",
            "At step: 507 training error: 0.8989283891748678\n",
            "At step: 508 training error: 0.9044365366506799\n",
            "At step: 509 training error: 0.9025627043327132\n",
            "At step: 510 training error: 0.9009534542422287\n",
            "At step: 511 training error: 0.9023169815413692\n",
            "At step: 512 training error: 0.8985205736391362\n",
            "At step: 513 training error: 0.8907998302145483\n",
            "At step: 514 training error: 0.8982376730077127\n",
            "At step: 515 training error: 0.9037951385904996\n",
            "At step: 516 training error: 0.901378326450694\n",
            "At step: 517 training error: 0.9000493078197432\n",
            "At step: 518 training error: 0.8964660776073534\n",
            "At step: 519 training error: 0.8936229441505915\n",
            "At step: 520 training error: 0.9021227617760474\n",
            "At step: 521 training error: 0.9050416474773889\n",
            "At step: 522 training error: 0.8965003378933505\n",
            "At step: 523 training error: 0.8915021381983668\n",
            "At step: 524 training error: 0.8910552751322378\n",
            "At step: 525 training error: 0.8872887440999864\n",
            "At step: 526 training error: 0.8919327788576921\n",
            "At step: 527 training error: 0.8944032909832091\n",
            "At step: 528 training error: 0.895059190131311\n",
            "At step: 529 training error: 0.8987178812808836\n",
            "At step: 530 training error: 0.8981933034450172\n",
            "At step: 531 training error: 0.9043158284586921\n",
            "At step: 532 training error: 0.9056439015954604\n",
            "At step: 533 training error: 0.9025803482881921\n",
            "At step: 534 training error: 0.9066159804132816\n",
            "At step: 535 training error: 0.9061291294069027\n",
            "At step: 536 training error: 0.9067530858625119\n",
            "At step: 537 training error: 0.8998682883122933\n",
            "At step: 538 training error: 0.901335280756901\n",
            "At step: 539 training error: 0.9047132665177612\n",
            "At step: 540 training error: 0.8983834926986327\n",
            "At step: 541 training error: 0.8921881291075847\n",
            "At step: 542 training error: 0.8954757844151386\n",
            "At step: 543 training error: 0.8992616128783727\n",
            "At step: 544 training error: 0.8970827310999165\n",
            "At step: 545 training error: 0.9011070755629361\n",
            "At step: 546 training error: 0.8961749482419442\n",
            "At step: 547 training error: 0.8938144053534522\n",
            "At step: 548 training error: 0.8971884859517074\n",
            "At step: 549 training error: 0.8972305641814678\n",
            "At step: 550 training error: 0.8943994778082929\n",
            "At step: 551 training error: 0.8886359351909776\n",
            "At step: 552 training error: 0.8800111569592736\n",
            "At step: 553 training error: 0.8819154858877092\n",
            "At step: 554 training error: 0.8764310994650795\n",
            "At step: 555 training error: 0.8786266788267485\n",
            "At step: 556 training error: 0.8831231745367758\n",
            "At step: 557 training error: 0.8831020521512556\n",
            "At step: 558 training error: 0.8789380927517636\n",
            "At step: 559 training error: 0.8896798944764359\n",
            "At step: 560 training error: 0.8912565631461209\n",
            "At step: 561 training error: 0.8897770436156215\n",
            "At step: 562 training error: 0.8857850833904101\n",
            "At step: 563 training error: 0.8935364480921135\n",
            "At step: 564 training error: 0.9007126384544055\n",
            "At step: 565 training error: 0.9030764105454885\n",
            "At step: 566 training error: 0.9041215010928652\n",
            "At step: 567 training error: 0.905766870205132\n",
            "At step: 568 training error: 0.894864043488897\n",
            "At step: 569 training error: 0.8960494611308022\n",
            "At step: 570 training error: 0.8927455321015741\n",
            "At step: 571 training error: 0.8927423207321957\n",
            "At step: 572 training error: 0.8896617522856567\n",
            "At step: 573 training error: 0.8958107461494305\n",
            "At step: 574 training error: 0.8942890462054434\n",
            "At step: 575 training error: 0.8963926400159412\n",
            "At step: 576 training error: 0.8964775668262043\n",
            "At step: 577 training error: 0.8997370715431948\n",
            "At step: 578 training error: 0.8984065382750254\n",
            "At step: 579 training error: 0.9004808670454844\n",
            "At step: 580 training error: 0.8968294330807963\n",
            "At step: 581 training error: 0.8964132957297591\n",
            "At step: 582 training error: 0.8905214748291524\n",
            "At step: 583 training error: 0.8922490668189342\n",
            "At step: 584 training error: 0.8923409763088729\n",
            "At step: 585 training error: 0.8933289782210021\n",
            "At step: 586 training error: 0.8949418422198954\n",
            "At step: 587 training error: 0.8936093850199424\n",
            "At step: 588 training error: 0.8897950223577229\n",
            "At step: 589 training error: 0.8908212344693908\n",
            "At step: 590 training error: 0.8936861423637878\n",
            "At step: 591 training error: 0.8853470879051423\n",
            "At step: 592 training error: 0.8882629732071892\n",
            "At step: 593 training error: 0.891193274643753\n",
            "At step: 594 training error: 0.8827962122025484\n",
            "At step: 595 training error: 0.8875853034817837\n",
            "At step: 596 training error: 0.8962418474136089\n",
            "At step: 597 training error: 0.9011744964989044\n",
            "At step: 598 training error: 0.8976934019513667\n",
            "At step: 599 training error: 0.9030897931792908\n",
            "At step: 600 training error: 0.901877056615355\n",
            "At step: 601 training error: 0.8973929295122376\n",
            "At step: 602 training error: 0.9001282711479534\n",
            "At step: 603 training error: 0.898784835434757\n",
            "At step: 604 training error: 0.8986663098458506\n",
            "At step: 605 training error: 0.9004463242103238\n",
            "At step: 606 training error: 0.9051795271360061\n",
            "At step: 607 training error: 0.900919362963461\n",
            "At step: 608 training error: 0.8991816491336398\n",
            "At step: 609 training error: 0.9011623902295649\n",
            "At step: 610 training error: 0.89717302212467\n",
            "At step: 611 training error: 0.8938920571362762\n",
            "At step: 612 training error: 0.8825966734099349\n",
            "At step: 613 training error: 0.8768750639261096\n",
            "At step: 614 training error: 0.872392589608422\n",
            "At step: 615 training error: 0.8714191391903425\n",
            "At step: 616 training error: 0.8704062661583002\n",
            "At step: 617 training error: 0.8671975627050543\n",
            "At step: 618 training error: 0.8706495698760347\n",
            "At step: 619 training error: 0.8767313739579224\n",
            "At step: 620 training error: 0.8793019439964288\n",
            "At step: 621 training error: 0.8776048347368091\n",
            "At step: 622 training error: 0.8757717408620114\n",
            "At step: 623 training error: 0.8833504086814474\n",
            "At step: 624 training error: 0.8854443064064442\n",
            "At step: 625 training error: 0.8887736200625181\n",
            "At step: 626 training error: 0.8878144737008457\n",
            "At step: 627 training error: 0.8961538077481661\n",
            "At step: 628 training error: 0.9011017691881547\n",
            "At step: 629 training error: 0.8926999214774574\n",
            "At step: 630 training error: 0.8903600405713271\n",
            "At step: 631 training error: 0.882106512262903\n",
            "At step: 632 training error: 0.8776974487795204\n",
            "At step: 633 training error: 0.86928296307767\n",
            "At step: 634 training error: 0.8698233325204575\n",
            "At step: 635 training error: 0.875035266372279\n",
            "At step: 636 training error: 0.8742569483262059\n",
            "At step: 637 training error: 0.8747227940545279\n",
            "At step: 638 training error: 0.8747859670411632\n",
            "At step: 639 training error: 0.8743317798833321\n",
            "At step: 640 training error: 0.8670297627143281\n",
            "At step: 641 training error: 0.8663385583913625\n",
            "At step: 642 training error: 0.865145235502538\n",
            "At step: 643 training error: 0.8623501271357863\n",
            "At step: 644 training error: 0.8656038790144336\n",
            "At step: 645 training error: 0.860832720603337\n",
            "At step: 646 training error: 0.8601827123971266\n",
            "At step: 647 training error: 0.8641893681389201\n",
            "At step: 648 training error: 0.8643664379587813\n",
            "At step: 649 training error: 0.8658091076461446\n",
            "At step: 650 training error: 0.8765867436936301\n",
            "At step: 651 training error: 0.8794229540408107\n",
            "At step: 652 training error: 0.8809703489882106\n",
            "At step: 653 training error: 0.8801253652921277\n",
            "At step: 654 training error: 0.879211424361679\n",
            "At step: 655 training error: 0.8811782123377292\n",
            "At step: 656 training error: 0.8874403368363342\n",
            "At step: 657 training error: 0.8914848560084513\n",
            "At step: 658 training error: 0.8896276251005754\n",
            "At step: 659 training error: 0.8941033274179954\n",
            "At step: 660 training error: 0.8845285322598769\n",
            "At step: 661 training error: 0.8846645964770515\n",
            "At step: 662 training error: 0.8834810821862833\n",
            "At step: 663 training error: 0.883386991279184\n",
            "At step: 664 training error: 0.8758666143102114\n",
            "At step: 665 training error: 0.8832408661282161\n",
            "At step: 666 training error: 0.8837589090287883\n",
            "At step: 667 training error: 0.8795848303830096\n",
            "At step: 668 training error: 0.8828506878309542\n",
            "At step: 669 training error: 0.8816190840938325\n",
            "At step: 670 training error: 0.8791714057695683\n",
            "At step: 671 training error: 0.8811937306978526\n",
            "At step: 672 training error: 0.8762379273630562\n",
            "At step: 673 training error: 0.8724672362547425\n",
            "At step: 674 training error: 0.8727597909697007\n",
            "At step: 675 training error: 0.8719195688379464\n",
            "At step: 676 training error: 0.8771854591716389\n",
            "At step: 677 training error: 0.8807248834123756\n",
            "At step: 678 training error: 0.8787763699084739\n",
            "At step: 679 training error: 0.8787092602785522\n",
            "At step: 680 training error: 0.8728967726094736\n",
            "At step: 681 training error: 0.8759103030457723\n",
            "At step: 682 training error: 0.8807645069146494\n",
            "At step: 683 training error: 0.8813979433634604\n",
            "At step: 684 training error: 0.8802165615571098\n",
            "At step: 685 training error: 0.8721437023282262\n",
            "At step: 686 training error: 0.8746850873229194\n",
            "At step: 687 training error: 0.8721690524917045\n",
            "At step: 688 training error: 0.8719438731557608\n",
            "At step: 689 training error: 0.8713712908342554\n",
            "At step: 690 training error: 0.8722535944845571\n",
            "At step: 691 training error: 0.8794798970517479\n",
            "At step: 692 training error: 0.8805945161900058\n",
            "At step: 693 training error: 0.8855899506535533\n",
            "At step: 694 training error: 0.8862065825873081\n",
            "At step: 695 training error: 0.8874322210400655\n",
            "At step: 696 training error: 0.8868667718596908\n",
            "At step: 697 training error: 0.8930907617285123\n",
            "At step: 698 training error: 0.8981393156999435\n",
            "At step: 699 training error: 0.8941676552490323\n",
            "At step: 700 training error: 0.8835909858789062\n",
            "At step: 701 training error: 0.8846753301231407\n",
            "At step: 702 training error: 0.8849174836694546\n",
            "At step: 703 training error: 0.8902169190837284\n",
            "At step: 704 training error: 0.8914851502607831\n",
            "At step: 705 training error: 0.8861243342165159\n",
            "At step: 706 training error: 0.8868415702281003\n",
            "At step: 707 training error: 0.8884611660614892\n",
            "At step: 708 training error: 0.8892915286588898\n",
            "At step: 709 training error: 0.8799488146383867\n",
            "At step: 710 training error: 0.88542587919317\n",
            "At step: 711 training error: 0.891309433700707\n",
            "At step: 712 training error: 0.888537696372542\n",
            "At step: 713 training error: 0.8879342287709144\n",
            "At step: 714 training error: 0.8839991768925355\n",
            "At step: 715 training error: 0.8908164600460713\n",
            "At step: 716 training error: 0.8932557485753249\n",
            "At step: 717 training error: 0.886113355132022\n",
            "At step: 718 training error: 0.8775903920243281\n",
            "At step: 719 training error: 0.8768192596831839\n",
            "At step: 720 training error: 0.8753471105831983\n",
            "At step: 721 training error: 0.8779900828422442\n",
            "At step: 722 training error: 0.8723834309476727\n",
            "At step: 723 training error: 0.8746621244584454\n",
            "At step: 724 training error: 0.8680758658610672\n",
            "At step: 725 training error: 0.8703233720890462\n",
            "At step: 726 training error: 0.8646623429750844\n",
            "At step: 727 training error: 0.8668747520196609\n",
            "At step: 728 training error: 0.8634885138428872\n",
            "At step: 729 training error: 0.8603444927549055\n",
            "At step: 730 training error: 0.8604647410286558\n",
            "At step: 731 training error: 0.8597767848884469\n",
            "At step: 732 training error: 0.8627977947501168\n",
            "At step: 733 training error: 0.8647902849416412\n",
            "At step: 734 training error: 0.8670304446693915\n",
            "At step: 735 training error: 0.8709894581018567\n",
            "At step: 736 training error: 0.8715059497106918\n",
            "At step: 737 training error: 0.8792997768780956\n",
            "At step: 738 training error: 0.8787008892841031\n",
            "At step: 739 training error: 0.8732609066402862\n",
            "At step: 740 training error: 0.8716307709154183\n",
            "At step: 741 training error: 0.8731369901879853\n",
            "At step: 742 training error: 0.881929631690922\n",
            "At step: 743 training error: 0.8801153527913412\n",
            "At step: 744 training error: 0.8793263848957575\n",
            "At step: 745 training error: 0.880566099528579\n",
            "At step: 746 training error: 0.8790159322093561\n",
            "At step: 747 training error: 0.8753757839601136\n",
            "At step: 748 training error: 0.8779757959593238\n",
            "At step: 749 training error: 0.8749451469658722\n",
            "At step: 750 training error: 0.8701475716178206\n",
            "At step: 751 training error: 0.8686360734879305\n",
            "At step: 752 training error: 0.8609275768869726\n",
            "At step: 753 training error: 0.858785571917221\n",
            "At step: 754 training error: 0.8677000261703012\n",
            "At step: 755 training error: 0.8641879799733401\n",
            "At step: 756 training error: 0.8687498659578271\n",
            "At step: 757 training error: 0.8683163730842245\n",
            "At step: 758 training error: 0.863136577657581\n",
            "At step: 759 training error: 0.8656700376228428\n",
            "At step: 760 training error: 0.8666239940628594\n",
            "At step: 761 training error: 0.8685839678706818\n",
            "At step: 762 training error: 0.8675404371617574\n",
            "At step: 763 training error: 0.8665483986908896\n",
            "At step: 764 training error: 0.8661428564676839\n",
            "At step: 765 training error: 0.8668443610271704\n",
            "At step: 766 training error: 0.8621963101287428\n",
            "At step: 767 training error: 0.8673288117273544\n",
            "At step: 768 training error: 0.8700370991846861\n",
            "At step: 769 training error: 0.8706959755804538\n",
            "At step: 770 training error: 0.8717253888102063\n",
            "At step: 771 training error: 0.8745264230302299\n",
            "At step: 772 training error: 0.8716252557288873\n",
            "At step: 773 training error: 0.8719319376878554\n",
            "At step: 774 training error: 0.8720410785717876\n",
            "At step: 775 training error: 0.8723997910595037\n",
            "At step: 776 training error: 0.8691572726705323\n",
            "At step: 777 training error: 0.8769107376682133\n",
            "At step: 778 training error: 0.8748215558728067\n",
            "At step: 779 training error: 0.8710769910152381\n",
            "At step: 780 training error: 0.8749393832827661\n",
            "At step: 781 training error: 0.8698228915969276\n",
            "At step: 782 training error: 0.8750224756068589\n",
            "At step: 783 training error: 0.8714214594445848\n",
            "At step: 784 training error: 0.867438399887402\n",
            "At step: 785 training error: 0.8625982747178993\n",
            "At step: 786 training error: 0.868279976165185\n",
            "At step: 787 training error: 0.8662155300360824\n",
            "At step: 788 training error: 0.8628872297513767\n",
            "At step: 789 training error: 0.8591160941564759\n",
            "At step: 790 training error: 0.8641493792476045\n",
            "At step: 791 training error: 0.8723151146311754\n",
            "At step: 792 training error: 0.8717725549452908\n",
            "At step: 793 training error: 0.8732052455238253\n",
            "At step: 794 training error: 0.8812010552390627\n",
            "At step: 795 training error: 0.8797791923393321\n",
            "At step: 796 training error: 0.8772989888364019\n",
            "At step: 797 training error: 0.883503121526418\n",
            "At step: 798 training error: 0.8850512641768409\n",
            "At step: 799 training error: 0.8864807161332724\n",
            "At step: 800 training error: 0.8820289014508866\n",
            "At step: 801 training error: 0.8808144142342909\n",
            "At step: 802 training error: 0.8833475704114335\n",
            "At step: 803 training error: 0.883423603566867\n",
            "At step: 804 training error: 0.8822306620504414\n",
            "At step: 805 training error: 0.8819138385809673\n",
            "At step: 806 training error: 0.8795063345345514\n",
            "At step: 807 training error: 0.8787346607900492\n",
            "At step: 808 training error: 0.8838473198581414\n",
            "At step: 809 training error: 0.8881202239876457\n",
            "At step: 810 training error: 0.8828692099651019\n",
            "At step: 811 training error: 0.873950358852375\n",
            "At step: 812 training error: 0.876562489120265\n",
            "At step: 813 training error: 0.8748910780231628\n",
            "At step: 814 training error: 0.8747704320388413\n",
            "At step: 815 training error: 0.877640652572511\n",
            "At step: 816 training error: 0.88383943321899\n",
            "At step: 817 training error: 0.8788495287287394\n",
            "At step: 818 training error: 0.8792992805757773\n",
            "At step: 819 training error: 0.8786155709689533\n",
            "At step: 820 training error: 0.8747995336592598\n",
            "At step: 821 training error: 0.8729558358961643\n",
            "At step: 822 training error: 0.8712793331098696\n",
            "At step: 823 training error: 0.8746494469249455\n",
            "At step: 824 training error: 0.8777198672150475\n",
            "At step: 825 training error: 0.8769318260801303\n",
            "At step: 826 training error: 0.8794626774977684\n",
            "At step: 827 training error: 0.8880180217571791\n",
            "At step: 828 training error: 0.8845778108579836\n",
            "At step: 829 training error: 0.8864830215509736\n",
            "At step: 830 training error: 0.879064982116638\n",
            "At step: 831 training error: 0.8798299361920922\n",
            "At step: 832 training error: 0.8825120615123713\n",
            "At step: 833 training error: 0.8838409278753797\n",
            "At step: 834 training error: 0.8801893388141924\n",
            "At step: 835 training error: 0.8832009880496144\n",
            "At step: 836 training error: 0.8808985839814485\n",
            "At step: 837 training error: 0.8799780784059307\n",
            "At step: 838 training error: 0.8857568160767653\n",
            "At step: 839 training error: 0.8876278902657833\n",
            "At step: 840 training error: 0.8861425439633172\n",
            "At step: 841 training error: 0.8758710895253846\n",
            "At step: 842 training error: 0.8789972100957497\n",
            "At step: 843 training error: 0.8838526995970359\n",
            "At step: 844 training error: 0.8838074247614872\n",
            "At step: 845 training error: 0.883513836083533\n",
            "At step: 846 training error: 0.881420522533127\n",
            "At step: 847 training error: 0.8813236414264405\n",
            "At step: 848 training error: 0.8797638182379096\n",
            "At step: 849 training error: 0.8776056126669834\n",
            "At step: 850 training error: 0.8787594927858354\n",
            "At step: 851 training error: 0.8805266759632948\n",
            "At step: 852 training error: 0.8824294003202442\n",
            "At step: 853 training error: 0.8737689080057879\n",
            "At step: 854 training error: 0.8687662943778877\n",
            "At step: 855 training error: 0.8607022296867136\n",
            "At step: 856 training error: 0.8642338362298625\n",
            "At step: 857 training error: 0.864478883110026\n",
            "At step: 858 training error: 0.8674433837448781\n",
            "At step: 859 training error: 0.8681452667811675\n",
            "At step: 860 training error: 0.8683731165044063\n",
            "At step: 861 training error: 0.8685811641171102\n",
            "At step: 862 training error: 0.871289511227167\n",
            "At step: 863 training error: 0.8689631872150243\n",
            "At step: 864 training error: 0.8648635813195881\n",
            "At step: 865 training error: 0.8643535130265019\n",
            "At step: 866 training error: 0.8658899166047609\n",
            "At step: 867 training error: 0.855694458635787\n",
            "At step: 868 training error: 0.8527298314003358\n",
            "At step: 869 training error: 0.8559963131801225\n",
            "At step: 870 training error: 0.8576524565434285\n",
            "At step: 871 training error: 0.857385400898112\n",
            "At step: 872 training error: 0.8595283989902028\n",
            "At step: 873 training error: 0.8539489068517316\n",
            "At step: 874 training error: 0.8509121677437856\n",
            "At step: 875 training error: 0.8487035141674559\n",
            "At step: 876 training error: 0.8498212499559556\n",
            "At step: 877 training error: 0.8474490676262263\n",
            "At step: 878 training error: 0.8497363787511831\n",
            "At step: 879 training error: 0.8518048803251456\n",
            "At step: 880 training error: 0.857188464597266\n",
            "At step: 881 training error: 0.8566817742302384\n",
            "At step: 882 training error: 0.8574646990786721\n",
            "At step: 883 training error: 0.8564237898550806\n",
            "At step: 884 training error: 0.8520941535649527\n",
            "At step: 885 training error: 0.8524728539252624\n",
            "At step: 886 training error: 0.8520483043548566\n",
            "At step: 887 training error: 0.8495119441801837\n",
            "At step: 888 training error: 0.846267767891922\n",
            "At step: 889 training error: 0.8489517098812605\n",
            "At step: 890 training error: 0.85141111469929\n",
            "At step: 891 training error: 0.8492833986767192\n",
            "At step: 892 training error: 0.8510771705829923\n",
            "At step: 893 training error: 0.8565273292805782\n",
            "At step: 894 training error: 0.8583655260601811\n",
            "At step: 895 training error: 0.8574481830391187\n",
            "At step: 896 training error: 0.8607437809646017\n",
            "At step: 897 training error: 0.8582848294712453\n",
            "At step: 898 training error: 0.8543428091551322\n",
            "At step: 899 training error: 0.8562373775673277\n",
            "At step: 900 training error: 0.8535977018792699\n",
            "At step: 901 training error: 0.8661533853734126\n",
            "At step: 902 training error: 0.8640444406561079\n",
            "At step: 903 training error: 0.8594419440522328\n",
            "At step: 904 training error: 0.8662387183672676\n",
            "At step: 905 training error: 0.8657934721713157\n",
            "At step: 906 training error: 0.8667823038290456\n",
            "At step: 907 training error: 0.8616453811124151\n",
            "At step: 908 training error: 0.8586836967421302\n",
            "At step: 909 training error: 0.8521690803470383\n",
            "At step: 910 training error: 0.8553912510953042\n",
            "At step: 911 training error: 0.8559784422601819\n",
            "At step: 912 training error: 0.851906193143985\n",
            "At step: 913 training error: 0.8497583983257271\n",
            "At step: 914 training error: 0.8548440265875322\n",
            "At step: 915 training error: 0.860590280905984\n",
            "At step: 916 training error: 0.849925121521453\n",
            "At step: 917 training error: 0.8502820790685668\n",
            "At step: 918 training error: 0.8484566253903405\n",
            "At step: 919 training error: 0.8526583099419369\n",
            "At step: 920 training error: 0.8550494179529834\n",
            "At step: 921 training error: 0.8550861396644029\n",
            "At step: 922 training error: 0.8583036498049784\n",
            "At step: 923 training error: 0.8542322223447726\n",
            "At step: 924 training error: 0.8565821756927996\n",
            "At step: 925 training error: 0.8590774932449011\n",
            "At step: 926 training error: 0.8557056590938747\n",
            "At step: 927 training error: 0.8470452018452919\n",
            "At step: 928 training error: 0.8484242788389\n",
            "At step: 929 training error: 0.8549473742770248\n",
            "At step: 930 training error: 0.8550779170612121\n",
            "At step: 931 training error: 0.8567942518450801\n",
            "At step: 932 training error: 0.8577997703186427\n",
            "At step: 933 training error: 0.8590359667120929\n",
            "At step: 934 training error: 0.8583573454750154\n",
            "At step: 935 training error: 0.8582764249500974\n",
            "At step: 936 training error: 0.8584681442469321\n",
            "At step: 937 training error: 0.8458675789548403\n",
            "At step: 938 training error: 0.8551295454422442\n",
            "At step: 939 training error: 0.8614798392279184\n",
            "At step: 940 training error: 0.8612188086186136\n",
            "At step: 941 training error: 0.8629080144480369\n",
            "At step: 942 training error: 0.8615574825108778\n",
            "At step: 943 training error: 0.8587549032014897\n",
            "At step: 944 training error: 0.8647437807600339\n",
            "At step: 945 training error: 0.8687312214857833\n",
            "At step: 946 training error: 0.8615591716104035\n",
            "At step: 947 training error: 0.866671216349741\n",
            "At step: 948 training error: 0.8611807273916567\n",
            "At step: 949 training error: 0.8614901189670355\n",
            "At step: 950 training error: 0.8602017351624799\n",
            "At step: 951 training error: 0.8627303035182641\n",
            "At step: 952 training error: 0.8641069982463604\n",
            "At step: 953 training error: 0.8623628478108195\n",
            "At step: 954 training error: 0.8570531222717632\n",
            "At step: 955 training error: 0.8528891935290657\n",
            "At step: 956 training error: 0.8606792251288409\n",
            "At step: 957 training error: 0.8602030971989258\n",
            "At step: 958 training error: 0.8543453336936964\n",
            "At step: 959 training error: 0.8630599456270854\n",
            "At step: 960 training error: 0.8643392089540687\n",
            "At step: 961 training error: 0.857804408922416\n",
            "At step: 962 training error: 0.8564138901608142\n",
            "At step: 963 training error: 0.8555742084186647\n",
            "At step: 964 training error: 0.8524767931881406\n",
            "At step: 965 training error: 0.8486065369041542\n",
            "At step: 966 training error: 0.8489056805193527\n",
            "At step: 967 training error: 0.84895977586613\n",
            "At step: 968 training error: 0.857647903101333\n",
            "At step: 969 training error: 0.8588968346698649\n",
            "At step: 970 training error: 0.8536970823010247\n",
            "At step: 971 training error: 0.8500145578500717\n",
            "At step: 972 training error: 0.855391205065939\n",
            "At step: 973 training error: 0.8563594282848681\n",
            "At step: 974 training error: 0.8572595263400844\n",
            "At step: 975 training error: 0.8544163078475607\n",
            "At step: 976 training error: 0.857687535264189\n",
            "At step: 977 training error: 0.8555068110884405\n",
            "At step: 978 training error: 0.8571999093615528\n",
            "At step: 979 training error: 0.8564752630337202\n",
            "At step: 980 training error: 0.8529756354904193\n",
            "At step: 981 training error: 0.8440563404056469\n",
            "At step: 982 training error: 0.8463429420965577\n",
            "At step: 983 training error: 0.8441426779199831\n",
            "At step: 984 training error: 0.8452328143657674\n",
            "At step: 985 training error: 0.8477260846378466\n",
            "At step: 986 training error: 0.84558265981605\n",
            "At step: 987 training error: 0.8466569874720424\n",
            "At step: 988 training error: 0.8393494355323474\n",
            "At step: 989 training error: 0.8342297046827354\n",
            "At step: 990 training error: 0.8445954468254421\n",
            "At step: 991 training error: 0.8518677582506408\n",
            "At step: 992 training error: 0.8589622837226736\n",
            "At step: 993 training error: 0.85877334010313\n",
            "At step: 994 training error: 0.8607364722154442\n",
            "At step: 995 training error: 0.8657116280259916\n",
            "At step: 996 training error: 0.8710784205494051\n",
            "At step: 997 training error: 0.8727131398498569\n",
            "At step: 998 training error: 0.8745191222447466\n",
            "At step: 999 training error: 0.872139521429002\n",
            "At step: 1000 training error: 0.8726419115127801\n",
            "At step: 1001 training error: 0.8597125839495678\n",
            "At step: 1002 training error: 0.8560576666145477\n",
            "At step: 1003 training error: 0.8561313908847183\n",
            "At step: 1004 training error: 0.8598260975993073\n",
            "At step: 1005 training error: 0.8596494111549907\n",
            "At step: 1006 training error: 0.8526074286453994\n",
            "At step: 1007 training error: 0.8579315360104581\n",
            "At step: 1008 training error: 0.8510332732935955\n",
            "At step: 1009 training error: 0.8438561622702526\n",
            "At step: 1010 training error: 0.8463144298647441\n",
            "At step: 1011 training error: 0.844954996482508\n",
            "At step: 1012 training error: 0.8520298624634345\n",
            "At step: 1013 training error: 0.85423203158449\n",
            "At step: 1014 training error: 0.8507124211847126\n",
            "At step: 1015 training error: 0.85267344940112\n",
            "At step: 1016 training error: 0.8548073135986369\n",
            "At step: 1017 training error: 0.8574699333040362\n",
            "At step: 1018 training error: 0.8505257890313952\n",
            "At step: 1019 training error: 0.8430771347483028\n",
            "At step: 1020 training error: 0.8437411225121882\n",
            "At step: 1021 training error: 0.8470846283682943\n",
            "At step: 1022 training error: 0.8496386605479067\n",
            "At step: 1023 training error: 0.8501379521626825\n",
            "At step: 1024 training error: 0.8464745353894442\n",
            "At step: 1025 training error: 0.8477521496910401\n",
            "At step: 1026 training error: 0.8471617140089782\n",
            "At step: 1027 training error: 0.844275983472955\n",
            "At step: 1028 training error: 0.843782328252036\n",
            "At step: 1029 training error: 0.8406023290900303\n",
            "At step: 1030 training error: 0.8447939387888349\n",
            "At step: 1031 training error: 0.8450821888155409\n",
            "At step: 1032 training error: 0.841515543857299\n",
            "At step: 1033 training error: 0.8396081844624679\n",
            "At step: 1034 training error: 0.8306771182149822\n",
            "At step: 1035 training error: 0.836242084034607\n",
            "At step: 1036 training error: 0.8441256104153279\n",
            "At step: 1037 training error: 0.8406683479240784\n",
            "At step: 1038 training error: 0.8409995815019347\n",
            "At step: 1039 training error: 0.841569910039682\n",
            "At step: 1040 training error: 0.8410139511301398\n",
            "At step: 1041 training error: 0.8453252566697966\n",
            "At step: 1042 training error: 0.8449592302540887\n",
            "At step: 1043 training error: 0.8484741625924433\n",
            "At step: 1044 training error: 0.854183098305444\n",
            "At step: 1045 training error: 0.8559451157253288\n",
            "At step: 1046 training error: 0.8503545443464248\n",
            "At step: 1047 training error: 0.8437321219641819\n",
            "At step: 1048 training error: 0.8413062730770239\n",
            "At step: 1049 training error: 0.843244635190007\n",
            "At step: 1050 training error: 0.8369885628109006\n",
            "At step: 1051 training error: 0.8359622960993919\n",
            "At step: 1052 training error: 0.8425467003029965\n",
            "At step: 1053 training error: 0.842370948848533\n",
            "At step: 1054 training error: 0.8514354565101758\n",
            "At step: 1055 training error: 0.8514576134225517\n",
            "At step: 1056 training error: 0.8560861287250783\n",
            "At step: 1057 training error: 0.8572914693661352\n",
            "At step: 1058 training error: 0.8600606441565882\n",
            "At step: 1059 training error: 0.8593917668679631\n",
            "At step: 1060 training error: 0.8575286689916434\n",
            "At step: 1061 training error: 0.8503360801619462\n",
            "At step: 1062 training error: 0.8447638880905542\n",
            "At step: 1063 training error: 0.8394328813856626\n",
            "At step: 1064 training error: 0.8408058283746027\n",
            "At step: 1065 training error: 0.8417243639437006\n",
            "At step: 1066 training error: 0.8478677413018132\n",
            "At step: 1067 training error: 0.8447039955217227\n",
            "At step: 1068 training error: 0.8508145680164078\n",
            "At step: 1069 training error: 0.8451365647412807\n",
            "At step: 1070 training error: 0.8388481987139718\n",
            "At step: 1071 training error: 0.8470956497569426\n",
            "At step: 1072 training error: 0.8454234087446685\n",
            "At step: 1073 training error: 0.8462421207249959\n",
            "At step: 1074 training error: 0.8436921038359579\n",
            "At step: 1075 training error: 0.844632726176859\n",
            "At step: 1076 training error: 0.8411593048431886\n",
            "At step: 1077 training error: 0.8389473457492128\n",
            "At step: 1078 training error: 0.8417123111838416\n",
            "At step: 1079 training error: 0.8415639428455758\n",
            "At step: 1080 training error: 0.845170390480234\n",
            "At step: 1081 training error: 0.83639349292128\n",
            "At step: 1082 training error: 0.8379972440513432\n",
            "At step: 1083 training error: 0.836002371383898\n",
            "At step: 1084 training error: 0.8373658866970101\n",
            "At step: 1085 training error: 0.8413635015435387\n",
            "At step: 1086 training error: 0.843482671913117\n",
            "At step: 1087 training error: 0.8379690805265074\n",
            "At step: 1088 training error: 0.8426673715770867\n",
            "At step: 1089 training error: 0.8422694456169748\n",
            "At step: 1090 training error: 0.8385885867889254\n",
            "At step: 1091 training error: 0.8368853542001033\n",
            "At step: 1092 training error: 0.8360515639227492\n",
            "At step: 1093 training error: 0.8451517132856575\n",
            "At step: 1094 training error: 0.8485638505340982\n",
            "At step: 1095 training error: 0.8472715724257577\n",
            "At step: 1096 training error: 0.8398558140695151\n",
            "At step: 1097 training error: 0.843591757256463\n",
            "At step: 1098 training error: 0.8433765313439785\n",
            "At step: 1099 training error: 0.8380022087405914\n",
            "At step: 1100 training error: 0.8369164052183308\n",
            "At step: 1101 training error: 0.8333678837118799\n",
            "At step: 1102 training error: 0.8346687736552432\n",
            "At step: 1103 training error: 0.8451091558321652\n",
            "At step: 1104 training error: 0.8412854745943026\n",
            "At step: 1105 training error: 0.8449144380430363\n",
            "At step: 1106 training error: 0.8520826749482462\n",
            "At step: 1107 training error: 0.846318543016938\n",
            "At step: 1108 training error: 0.8539242179161327\n",
            "At step: 1109 training error: 0.8514156223822589\n",
            "At step: 1110 training error: 0.8483135422084589\n",
            "At step: 1111 training error: 0.8516172779779878\n",
            "At step: 1112 training error: 0.8510944881466564\n",
            "At step: 1113 training error: 0.8458252504981018\n",
            "At step: 1114 training error: 0.8488228405992568\n",
            "At step: 1115 training error: 0.8478278751338211\n",
            "At step: 1116 training error: 0.8472668015674745\n",
            "At step: 1117 training error: 0.8481490422585126\n",
            "At step: 1118 training error: 0.8429455267655792\n",
            "At step: 1119 training error: 0.8424493920521285\n",
            "At step: 1120 training error: 0.8456361412938178\n",
            "At step: 1121 training error: 0.8414021925272573\n",
            "At step: 1122 training error: 0.8429359414520932\n",
            "At step: 1123 training error: 0.8387184973766316\n",
            "At step: 1124 training error: 0.8387230873829629\n",
            "At step: 1125 training error: 0.8372294839545875\n",
            "At step: 1126 training error: 0.843880912746653\n",
            "At step: 1127 training error: 0.8442719367229498\n",
            "At step: 1128 training error: 0.8418975471770769\n",
            "At step: 1129 training error: 0.8432010270933151\n",
            "At step: 1130 training error: 0.8543796707377753\n",
            "At step: 1131 training error: 0.8470140866103165\n",
            "At step: 1132 training error: 0.8422407444908389\n",
            "At step: 1133 training error: 0.8413849166394587\n",
            "At step: 1134 training error: 0.8465811816368773\n",
            "At step: 1135 training error: 0.8450531018925547\n",
            "At step: 1136 training error: 0.8486973273891113\n",
            "At step: 1137 training error: 0.8495809992888704\n",
            "At step: 1138 training error: 0.8550573269504809\n",
            "At step: 1139 training error: 0.8565503583512935\n",
            "At step: 1140 training error: 0.8553179471621329\n",
            "At step: 1141 training error: 0.8526146731254645\n",
            "At step: 1142 training error: 0.8461273339150345\n",
            "At step: 1143 training error: 0.8487417571564941\n",
            "At step: 1144 training error: 0.8459582778176846\n",
            "At step: 1145 training error: 0.8469045713557672\n",
            "At step: 1146 training error: 0.8524681937456793\n",
            "At step: 1147 training error: 0.8553401013404053\n",
            "At step: 1148 training error: 0.855393658373366\n",
            "At step: 1149 training error: 0.8501250104543752\n",
            "At step: 1150 training error: 0.850281821995567\n",
            "At step: 1151 training error: 0.8388362458973988\n",
            "At step: 1152 training error: 0.8370441727477353\n",
            "At step: 1153 training error: 0.8380834167924762\n",
            "At step: 1154 training error: 0.840660694432181\n",
            "At step: 1155 training error: 0.833652868924536\n",
            "At step: 1156 training error: 0.8316042057525941\n",
            "At step: 1157 training error: 0.8288922970177267\n",
            "At step: 1158 training error: 0.8366876976536881\n",
            "At step: 1159 training error: 0.8411843124588001\n",
            "At step: 1160 training error: 0.8412539692900666\n",
            "At step: 1161 training error: 0.8475622218563483\n",
            "At step: 1162 training error: 0.8443718551047208\n",
            "At step: 1163 training error: 0.8395752991234415\n",
            "At step: 1164 training error: 0.8413219439402653\n",
            "At step: 1165 training error: 0.8426480008076025\n",
            "At step: 1166 training error: 0.8403909653942622\n",
            "At step: 1167 training error: 0.8445778155280208\n",
            "At step: 1168 training error: 0.8451367167773872\n",
            "At step: 1169 training error: 0.8396970280013403\n",
            "At step: 1170 training error: 0.841737619675213\n",
            "At step: 1171 training error: 0.8398313503628674\n",
            "At step: 1172 training error: 0.8301962920974141\n",
            "At step: 1173 training error: 0.8345471059370252\n",
            "At step: 1174 training error: 0.8297119682457089\n",
            "At step: 1175 training error: 0.837064682122386\n",
            "At step: 1176 training error: 0.8370840767389339\n",
            "At step: 1177 training error: 0.8388588075080031\n",
            "At step: 1178 training error: 0.8424602444772811\n",
            "At step: 1179 training error: 0.8454512424459508\n",
            "At step: 1180 training error: 0.8436301731806181\n",
            "At step: 1181 training error: 0.8407081390952579\n",
            "At step: 1182 training error: 0.8408511652144097\n",
            "At step: 1183 training error: 0.8398513623040144\n",
            "At step: 1184 training error: 0.8402480235998611\n",
            "At step: 1185 training error: 0.8341845579307322\n",
            "At step: 1186 training error: 0.836717349999537\n",
            "At step: 1187 training error: 0.8341763448219234\n",
            "At step: 1188 training error: 0.8318364614446815\n",
            "At step: 1189 training error: 0.8323723402594484\n",
            "At step: 1190 training error: 0.8301323285217682\n",
            "At step: 1191 training error: 0.8332844238375089\n",
            "At step: 1192 training error: 0.8364377984088731\n",
            "At step: 1193 training error: 0.8344654249481929\n",
            "At step: 1194 training error: 0.8460531476782481\n",
            "At step: 1195 training error: 0.8408720091601405\n",
            "At step: 1196 training error: 0.8371028150521043\n",
            "At step: 1197 training error: 0.8450366573309598\n",
            "At step: 1198 training error: 0.8404226984116007\n",
            "At step: 1199 training error: 0.8451692984022432\n",
            "At step: 1200 training error: 0.8432377877067717\n",
            "At step: 1201 training error: 0.8482280284743184\n",
            "At step: 1202 training error: 0.847118067226605\n",
            "At step: 1203 training error: 0.8444468507793133\n",
            "At step: 1204 training error: 0.8468531413600597\n",
            "At step: 1205 training error: 0.8484536421235156\n",
            "At step: 1206 training error: 0.8480210383296349\n",
            "At step: 1207 training error: 0.8577595757656098\n",
            "At step: 1208 training error: 0.8584544566931485\n",
            "At step: 1209 training error: 0.8573557680988718\n",
            "At step: 1210 training error: 0.8616201345250609\n",
            "At step: 1211 training error: 0.8582893743593916\n",
            "At step: 1212 training error: 0.8514325708415496\n",
            "At step: 1213 training error: 0.8545884207576135\n",
            "At step: 1214 training error: 0.8461987602395967\n",
            "At step: 1215 training error: 0.838834379202042\n",
            "At step: 1216 training error: 0.8393229654815845\n",
            "At step: 1217 training error: 0.8435791335754325\n",
            "At step: 1218 training error: 0.8314587464933979\n",
            "At step: 1219 training error: 0.8348923146374269\n",
            "At step: 1220 training error: 0.8402774900906596\n",
            "At step: 1221 training error: 0.8412388437141569\n",
            "At step: 1222 training error: 0.8439299971124412\n",
            "At step: 1223 training error: 0.8424961794156527\n",
            "At step: 1224 training error: 0.8397392192764328\n",
            "At step: 1225 training error: 0.8439391758827463\n",
            "At step: 1226 training error: 0.8479923064894828\n",
            "At step: 1227 training error: 0.8517859935342453\n",
            "At step: 1228 training error: 0.8445689103891638\n",
            "At step: 1229 training error: 0.8491703442187968\n",
            "At step: 1230 training error: 0.8421610723644856\n",
            "At step: 1231 training error: 0.8501552652524957\n",
            "At step: 1232 training error: 0.8389594325386708\n",
            "At step: 1233 training error: 0.8385776205768953\n",
            "At step: 1234 training error: 0.8393526528298162\n",
            "At step: 1235 training error: 0.8392050486112312\n",
            "At step: 1236 training error: 0.8329210498972814\n",
            "At step: 1237 training error: 0.8367944504353115\n",
            "At step: 1238 training error: 0.8255584466906496\n",
            "At step: 1239 training error: 0.8168630646265996\n",
            "At step: 1240 training error: 0.8216879923677528\n",
            "At step: 1241 training error: 0.8194200961698395\n",
            "At step: 1242 training error: 0.8226863939354201\n",
            "At step: 1243 training error: 0.8231618390348139\n",
            "At step: 1244 training error: 0.8178291800778184\n",
            "At step: 1245 training error: 0.8212451436084521\n",
            "At step: 1246 training error: 0.8196637980072773\n",
            "At step: 1247 training error: 0.820734368331076\n",
            "At step: 1248 training error: 0.8280369063338943\n",
            "At step: 1249 training error: 0.8249688552555461\n",
            "At step: 1250 training error: 0.8179340326478252\n",
            "At step: 1251 training error: 0.8247827443234828\n",
            "At step: 1252 training error: 0.8323683937357008\n",
            "At step: 1253 training error: 0.8288671121992777\n",
            "At step: 1254 training error: 0.8325449888729859\n",
            "At step: 1255 training error: 0.8344016810154318\n",
            "At step: 1256 training error: 0.8338243953881603\n",
            "At step: 1257 training error: 0.8396697773878119\n",
            "At step: 1258 training error: 0.8338197097157175\n",
            "At step: 1259 training error: 0.8287316576596111\n",
            "At step: 1260 training error: 0.8336216144779203\n",
            "At step: 1261 training error: 0.8332900810602637\n",
            "At step: 1262 training error: 0.83634957873691\n",
            "At step: 1263 training error: 0.8279628887688371\n",
            "At step: 1264 training error: 0.8278638771451122\n",
            "At step: 1265 training error: 0.8291554780165639\n",
            "At step: 1266 training error: 0.8310846019989186\n",
            "At step: 1267 training error: 0.8371985217861944\n",
            "At step: 1268 training error: 0.8405553599760853\n",
            "At step: 1269 training error: 0.8463588261521087\n",
            "At step: 1270 training error: 0.8456269597895648\n",
            "At step: 1271 training error: 0.8437508919048472\n",
            "At step: 1272 training error: 0.8449210008306687\n",
            "At step: 1273 training error: 0.8410322020217063\n",
            "At step: 1274 training error: 0.8385015343084206\n",
            "At step: 1275 training error: 0.8409873468734488\n",
            "At step: 1276 training error: 0.8478356981407775\n",
            "At step: 1277 training error: 0.850890141321864\n",
            "At step: 1278 training error: 0.8444274315539935\n",
            "At step: 1279 training error: 0.8365027510832648\n",
            "At step: 1280 training error: 0.8372184060155833\n",
            "At step: 1281 training error: 0.8354740686172896\n",
            "At step: 1282 training error: 0.8319102815008201\n",
            "At step: 1283 training error: 0.8375578725527112\n",
            "At step: 1284 training error: 0.8334999519830253\n",
            "At step: 1285 training error: 0.8293303135260183\n",
            "At step: 1286 training error: 0.8272230411181396\n",
            "At step: 1287 training error: 0.8306925479452516\n",
            "At step: 1288 training error: 0.8329131201055091\n",
            "At step: 1289 training error: 0.8370916196217192\n",
            "At step: 1290 training error: 0.8403655024334366\n",
            "At step: 1291 training error: 0.8459448518935677\n",
            "At step: 1292 training error: 0.8358051003091648\n",
            "At step: 1293 training error: 0.8295357719242833\n",
            "At step: 1294 training error: 0.8338534982730997\n",
            "At step: 1295 training error: 0.8308919051975419\n",
            "At step: 1296 training error: 0.8361280077982941\n",
            "At step: 1297 training error: 0.8391649490675246\n",
            "At step: 1298 training error: 0.8357227567241398\n",
            "At step: 1299 training error: 0.8340817426876177\n",
            "At step: 1300 training error: 0.8335336369834951\n",
            "At step: 1301 training error: 0.8368809775889835\n",
            "At step: 1302 training error: 0.8280248435968318\n",
            "At step: 1303 training error: 0.8247169195820468\n",
            "At step: 1304 training error: 0.8219150114686972\n",
            "At step: 1305 training error: 0.823530996327929\n",
            "At step: 1306 training error: 0.8248300326014464\n",
            "At step: 1307 training error: 0.8232749219026225\n",
            "At step: 1308 training error: 0.8184391368156663\n",
            "At step: 1309 training error: 0.8215820713502452\n",
            "At step: 1310 training error: 0.8248468923675003\n",
            "At step: 1311 training error: 0.8226575378633614\n",
            "At step: 1312 training error: 0.8261198229285239\n",
            "At step: 1313 training error: 0.8289388364627995\n",
            "At step: 1314 training error: 0.8209127627540616\n",
            "At step: 1315 training error: 0.8243753898069076\n",
            "At step: 1316 training error: 0.8346124537798739\n",
            "At step: 1317 training error: 0.8366399398292357\n",
            "At step: 1318 training error: 0.8357258533421014\n",
            "At step: 1319 training error: 0.8334369920576147\n",
            "At step: 1320 training error: 0.8382906939137564\n",
            "At step: 1321 training error: 0.8375976521773606\n",
            "At step: 1322 training error: 0.8385012884553256\n",
            "At step: 1323 training error: 0.8331979476389904\n",
            "At step: 1324 training error: 0.8294606887530651\n",
            "At step: 1325 training error: 0.8292686030768897\n",
            "At step: 1326 training error: 0.8282475809788582\n",
            "At step: 1327 training error: 0.8332532741873324\n",
            "At step: 1328 training error: 0.818714793296619\n",
            "At step: 1329 training error: 0.8222988555041183\n",
            "At step: 1330 training error: 0.8264582886615492\n",
            "At step: 1331 training error: 0.8231405755627441\n",
            "At step: 1332 training error: 0.8226640543076211\n",
            "At step: 1333 training error: 0.8213656171610603\n",
            "At step: 1334 training error: 0.8223933276731907\n",
            "At step: 1335 training error: 0.8225209045991202\n",
            "At step: 1336 training error: 0.8284760891263341\n",
            "At step: 1337 training error: 0.8321338039645435\n",
            "At step: 1338 training error: 0.8287905943074664\n",
            "At step: 1339 training error: 0.8226840106534478\n",
            "At step: 1340 training error: 0.8181195277709635\n",
            "At step: 1341 training error: 0.8253104000890243\n",
            "At step: 1342 training error: 0.8240523764210976\n",
            "At step: 1343 training error: 0.8276311493219957\n",
            "At step: 1344 training error: 0.8299977991846959\n",
            "At step: 1345 training error: 0.8318730082038396\n",
            "At step: 1346 training error: 0.8418543242018189\n",
            "At step: 1347 training error: 0.8431561852638262\n",
            "At step: 1348 training error: 0.8361111031316453\n",
            "At step: 1349 training error: 0.8357718025464143\n",
            "At step: 1350 training error: 0.83478462497484\n",
            "At step: 1351 training error: 0.8299357411053581\n",
            "At step: 1352 training error: 0.8331613871496618\n",
            "At step: 1353 training error: 0.8348625296103378\n",
            "At step: 1354 training error: 0.8353487710189567\n",
            "At step: 1355 training error: 0.8403249576408518\n",
            "At step: 1356 training error: 0.8509705850836127\n",
            "At step: 1357 training error: 0.8496870829761626\n",
            "At step: 1358 training error: 0.8478620072401122\n",
            "At step: 1359 training error: 0.8420177459167323\n",
            "At step: 1360 training error: 0.8445106420408658\n",
            "At step: 1361 training error: 0.847268760262006\n",
            "At step: 1362 training error: 0.8443834748462254\n",
            "At step: 1363 training error: 0.8367955786279083\n",
            "At step: 1364 training error: 0.833702681333017\n",
            "At step: 1365 training error: 0.8237115452098343\n",
            "At step: 1366 training error: 0.821850888101628\n",
            "At step: 1367 training error: 0.824679355984101\n",
            "At step: 1368 training error: 0.8255946749708077\n",
            "At step: 1369 training error: 0.8219108670921149\n",
            "At step: 1370 training error: 0.8191514607664334\n",
            "At step: 1371 training error: 0.8195942871862782\n",
            "At step: 1372 training error: 0.816349898027228\n",
            "At step: 1373 training error: 0.8169055328617386\n",
            "At step: 1374 training error: 0.8128510344219957\n",
            "At step: 1375 training error: 0.8181634072334272\n",
            "At step: 1376 training error: 0.8126322032296573\n",
            "At step: 1377 training error: 0.8198491026169503\n",
            "At step: 1378 training error: 0.8129961745475871\n",
            "At step: 1379 training error: 0.8108786530604309\n",
            "At step: 1380 training error: 0.8084775451174873\n",
            "At step: 1381 training error: 0.811386782369359\n",
            "At step: 1382 training error: 0.8086445812770591\n",
            "At step: 1383 training error: 0.8128328518603636\n",
            "At step: 1384 training error: 0.8144323362140518\n",
            "At step: 1385 training error: 0.8053887582998842\n",
            "At step: 1386 training error: 0.8055443404204623\n",
            "At step: 1387 training error: 0.8017621828762227\n",
            "At step: 1388 training error: 0.8105342204467939\n",
            "At step: 1389 training error: 0.8070209450203811\n",
            "At step: 1390 training error: 0.8041170558009569\n",
            "At step: 1391 training error: 0.8027847009790751\n",
            "At step: 1392 training error: 0.8052968217257048\n",
            "At step: 1393 training error: 0.7979917629748593\n",
            "At step: 1394 training error: 0.8028974241727466\n",
            "At step: 1395 training error: 0.8000948419719751\n",
            "At step: 1396 training error: 0.801176756006957\n",
            "At step: 1397 training error: 0.8021503743868612\n",
            "At step: 1398 training error: 0.8007103894313579\n",
            "At step: 1399 training error: 0.8053080988496559\n",
            "At step: 1400 training error: 0.8056245328446252\n",
            "At step: 1401 training error: 0.8115234775474935\n",
            "At step: 1402 training error: 0.8105579060187046\n",
            "At step: 1403 training error: 0.805950946967025\n",
            "At step: 1404 training error: 0.805643662436832\n",
            "At step: 1405 training error: 0.8106902813389061\n",
            "At step: 1406 training error: 0.8165795152429711\n",
            "At step: 1407 training error: 0.8191388734005723\n",
            "At step: 1408 training error: 0.8224127891533332\n",
            "At step: 1409 training error: 0.8182293995475269\n",
            "At step: 1410 training error: 0.8172116223564698\n",
            "At step: 1411 training error: 0.8292325018352964\n",
            "At step: 1412 training error: 0.8253649338626645\n",
            "At step: 1413 training error: 0.8085767972292938\n",
            "At step: 1414 training error: 0.812095172171019\n",
            "At step: 1415 training error: 0.8125624256895936\n",
            "At step: 1416 training error: 0.8118695224125014\n",
            "At step: 1417 training error: 0.8170095053089013\n",
            "At step: 1418 training error: 0.8178914596818931\n",
            "At step: 1419 training error: 0.8176512233059795\n",
            "At step: 1420 training error: 0.8120503268312905\n",
            "At step: 1421 training error: 0.8175996346809389\n",
            "At step: 1422 training error: 0.8153115040633679\n",
            "At step: 1423 training error: 0.825133915318105\n",
            "At step: 1424 training error: 0.8200174366969671\n",
            "At step: 1425 training error: 0.8185403488840857\n",
            "At step: 1426 training error: 0.8184645785138451\n",
            "At step: 1427 training error: 0.8249482709915108\n",
            "At step: 1428 training error: 0.8224672091241532\n",
            "At step: 1429 training error: 0.8243828442025609\n",
            "At step: 1430 training error: 0.8276895016799741\n",
            "At step: 1431 training error: 0.8242681410368458\n",
            "At step: 1432 training error: 0.8285267687539218\n",
            "At step: 1433 training error: 0.8193928195361513\n",
            "At step: 1434 training error: 0.8151220134682872\n",
            "At step: 1435 training error: 0.8165946795401792\n",
            "At step: 1436 training error: 0.8172623509831302\n",
            "At step: 1437 training error: 0.8130336063430375\n",
            "At step: 1438 training error: 0.8077467819281404\n",
            "At step: 1439 training error: 0.8046506463725849\n",
            "At step: 1440 training error: 0.8109221278976351\n",
            "At step: 1441 training error: 0.8151087492946651\n",
            "At step: 1442 training error: 0.8193619637106162\n",
            "At step: 1443 training error: 0.817416734501087\n",
            "At step: 1444 training error: 0.8187125241728305\n",
            "At step: 1445 training error: 0.8144552073473847\n",
            "At step: 1446 training error: 0.8043406011460305\n",
            "At step: 1447 training error: 0.8021666006286569\n",
            "At step: 1448 training error: 0.8070666004840177\n",
            "At step: 1449 training error: 0.805761975076399\n",
            "At step: 1450 training error: 0.8096811329257171\n",
            "At step: 1451 training error: 0.8110983760360575\n",
            "At step: 1452 training error: 0.8192397159521975\n",
            "At step: 1453 training error: 0.8182382839369875\n",
            "At step: 1454 training error: 0.823299690372582\n",
            "At step: 1455 training error: 0.8287784347406391\n",
            "At step: 1456 training error: 0.8322954590281059\n",
            "At step: 1457 training error: 0.835289772901256\n",
            "At step: 1458 training error: 0.8314924185189886\n",
            "At step: 1459 training error: 0.8339521211309913\n",
            "At step: 1460 training error: 0.8355255472207026\n",
            "At step: 1461 training error: 0.8296784345266083\n",
            "At step: 1462 training error: 0.8305599113776403\n",
            "At step: 1463 training error: 0.8238207901316226\n",
            "At step: 1464 training error: 0.8239143920525429\n",
            "At step: 1465 training error: 0.8228157987516961\n",
            "At step: 1466 training error: 0.818780553238831\n",
            "At step: 1467 training error: 0.8202074644956363\n",
            "At step: 1468 training error: 0.8231268509207982\n",
            "At step: 1469 training error: 0.81856785743393\n",
            "At step: 1470 training error: 0.8093878256588523\n",
            "At step: 1471 training error: 0.8127468798057641\n",
            "At step: 1472 training error: 0.8089646165820312\n",
            "At step: 1473 training error: 0.8054439757785024\n",
            "At step: 1474 training error: 0.8053909983556877\n",
            "At step: 1475 training error: 0.798584520400051\n",
            "At step: 1476 training error: 0.800629688264965\n",
            "At step: 1477 training error: 0.7961030869420878\n",
            "At step: 1478 training error: 0.8015718421910099\n",
            "At step: 1479 training error: 0.7962808219749576\n",
            "At step: 1480 training error: 0.7988771032241989\n",
            "At step: 1481 training error: 0.7971982549155342\n",
            "At step: 1482 training error: 0.7965134933822658\n",
            "At step: 1483 training error: 0.7973926919324829\n",
            "At step: 1484 training error: 0.7972584433633276\n",
            "At step: 1485 training error: 0.7941967806738738\n",
            "At step: 1486 training error: 0.8016693795182996\n",
            "At step: 1487 training error: 0.8040085863755536\n",
            "At step: 1488 training error: 0.807804764260132\n",
            "At step: 1489 training error: 0.8090224746971881\n",
            "At step: 1490 training error: 0.8124824033027584\n",
            "At step: 1491 training error: 0.8049902806397216\n",
            "At step: 1492 training error: 0.8045310221343256\n",
            "At step: 1493 training error: 0.8059229609415602\n",
            "At step: 1494 training error: 0.8075424246959559\n",
            "At step: 1495 training error: 0.8096776390308574\n",
            "At step: 1496 training error: 0.819480834593298\n",
            "At step: 1497 training error: 0.8131995742365574\n",
            "At step: 1498 training error: 0.812501791065999\n",
            "At step: 1499 training error: 0.8108607477637445\n",
            "At step: 1500 training error: 0.8132505071262256\n",
            "At step: 1501 training error: 0.8064237732317296\n",
            "At step: 1502 training error: 0.8052116492843439\n",
            "At step: 1503 training error: 0.8024155294771633\n",
            "At step: 1504 training error: 0.8014981968807666\n",
            "At step: 1505 training error: 0.8002672457068538\n",
            "At step: 1506 training error: 0.7984088637592568\n",
            "At step: 1507 training error: 0.7954310646310463\n",
            "At step: 1508 training error: 0.7955021099590116\n",
            "At step: 1509 training error: 0.8026917840399442\n",
            "At step: 1510 training error: 0.8010229230587244\n",
            "At step: 1511 training error: 0.7919297709808412\n",
            "At step: 1512 training error: 0.7852197911225937\n",
            "At step: 1513 training error: 0.7855206990566284\n",
            "At step: 1514 training error: 0.788439788765078\n",
            "At step: 1515 training error: 0.7977307495883852\n",
            "At step: 1516 training error: 0.7983829702838201\n",
            "At step: 1517 training error: 0.8013278451089851\n",
            "At step: 1518 training error: 0.8039774402922729\n",
            "At step: 1519 training error: 0.8028359198082574\n",
            "At step: 1520 training error: 0.804860221881885\n",
            "At step: 1521 training error: 0.804334032003928\n",
            "At step: 1522 training error: 0.7995765348850642\n",
            "At step: 1523 training error: 0.8067544158264465\n",
            "At step: 1524 training error: 0.8103832978521711\n",
            "At step: 1525 training error: 0.807524847158698\n",
            "At step: 1526 training error: 0.8039406398280453\n",
            "At step: 1527 training error: 0.8055323923098495\n",
            "At step: 1528 training error: 0.8074258032603944\n",
            "At step: 1529 training error: 0.8051349028945338\n",
            "At step: 1530 training error: 0.8086769581584015\n",
            "At step: 1531 training error: 0.8074238476439034\n",
            "At step: 1532 training error: 0.8009064945505318\n",
            "At step: 1533 training error: 0.8020935529593872\n",
            "At step: 1534 training error: 0.8014010285592785\n",
            "At step: 1535 training error: 0.8058720849124059\n",
            "At step: 1536 training error: 0.8044801133210475\n",
            "At step: 1537 training error: 0.8130979793533116\n",
            "At step: 1538 training error: 0.8126708887746913\n",
            "At step: 1539 training error: 0.8132722532107405\n",
            "At step: 1540 training error: 0.8114070708679634\n",
            "At step: 1541 training error: 0.81172125393092\n",
            "At step: 1542 training error: 0.8066994193243248\n",
            "At step: 1543 training error: 0.8062054727995548\n",
            "At step: 1544 training error: 0.8086337110774215\n",
            "At step: 1545 training error: 0.8085883593959926\n",
            "At step: 1546 training error: 0.7996467975236323\n",
            "At step: 1547 training error: 0.8057542984166374\n",
            "At step: 1548 training error: 0.8012542196829318\n",
            "At step: 1549 training error: 0.8052461012970351\n",
            "At step: 1550 training error: 0.803183600627041\n",
            "At step: 1551 training error: 0.8044972681388036\n",
            "At step: 1552 training error: 0.805612994985586\n",
            "At step: 1553 training error: 0.8058737649237995\n",
            "At step: 1554 training error: 0.8080157603100091\n",
            "At step: 1555 training error: 0.8101336082888022\n",
            "At step: 1556 training error: 0.8095033631345048\n",
            "At step: 1557 training error: 0.8133808697457643\n",
            "At step: 1558 training error: 0.8173550946827627\n",
            "At step: 1559 training error: 0.8189841865847549\n",
            "At step: 1560 training error: 0.8134689715208041\n",
            "At step: 1561 training error: 0.812206967586495\n",
            "At step: 1562 training error: 0.8073399042084588\n",
            "At step: 1563 training error: 0.805709218865558\n",
            "At step: 1564 training error: 0.8183757296934332\n",
            "At step: 1565 training error: 0.8222375321627496\n",
            "At step: 1566 training error: 0.8184781996825874\n",
            "At step: 1567 training error: 0.8116670742140276\n",
            "At step: 1568 training error: 0.8079140065040528\n",
            "At step: 1569 training error: 0.8038017502574347\n",
            "At step: 1570 training error: 0.8142258410820635\n",
            "At step: 1571 training error: 0.8109921500479441\n",
            "At step: 1572 training error: 0.8104410944900258\n",
            "At step: 1573 training error: 0.8113435419318797\n",
            "At step: 1574 training error: 0.8165359470690837\n",
            "At step: 1575 training error: 0.8136729734351404\n",
            "At step: 1576 training error: 0.8104568691696599\n",
            "At step: 1577 training error: 0.8088746219246578\n",
            "At step: 1578 training error: 0.8156670295994054\n",
            "At step: 1579 training error: 0.8145404718076679\n",
            "At step: 1580 training error: 0.8183956653408022\n",
            "At step: 1581 training error: 0.8146963069267485\n",
            "At step: 1582 training error: 0.8145540019806315\n",
            "At step: 1583 training error: 0.8192542315266318\n",
            "At step: 1584 training error: 0.815100428668172\n",
            "At step: 1585 training error: 0.8129704262070219\n",
            "At step: 1586 training error: 0.8202700469940643\n",
            "At step: 1587 training error: 0.8249596632222121\n",
            "At step: 1588 training error: 0.8228025198936784\n",
            "At step: 1589 training error: 0.8268208392029035\n",
            "At step: 1590 training error: 0.8252844775115808\n",
            "At step: 1591 training error: 0.8253515010198447\n",
            "At step: 1592 training error: 0.8237915777466189\n",
            "At step: 1593 training error: 0.817333089524035\n",
            "At step: 1594 training error: 0.8122563558569927\n",
            "At step: 1595 training error: 0.8112992725685514\n",
            "At step: 1596 training error: 0.8059718127051683\n",
            "At step: 1597 training error: 0.8029050137294922\n",
            "At step: 1598 training error: 0.8091451573633663\n",
            "At step: 1599 training error: 0.8070847728648262\n",
            "At step: 1600 training error: 0.8070888828929765\n",
            "At step: 1601 training error: 0.8040114191237209\n",
            "At step: 1602 training error: 0.8094017302110068\n",
            "At step: 1603 training error: 0.8107251034528046\n",
            "At step: 1604 training error: 0.803623114543004\n",
            "At step: 1605 training error: 0.8056285722087652\n",
            "At step: 1606 training error: 0.8095013753110125\n",
            "At step: 1607 training error: 0.8123228240239971\n",
            "At step: 1608 training error: 0.8120938571423787\n",
            "At step: 1609 training error: 0.811467931206611\n",
            "At step: 1610 training error: 0.8078684530454785\n",
            "At step: 1611 training error: 0.8110132617117105\n",
            "At step: 1612 training error: 0.8122872804661908\n",
            "At step: 1613 training error: 0.8161055641988925\n",
            "At step: 1614 training error: 0.8191140837044238\n",
            "At step: 1615 training error: 0.817677304942196\n",
            "At step: 1616 training error: 0.8210024457545512\n",
            "At step: 1617 training error: 0.817782524360166\n",
            "At step: 1618 training error: 0.815114118763083\n",
            "At step: 1619 training error: 0.8155963335649731\n",
            "At step: 1620 training error: 0.8157800402628989\n",
            "At step: 1621 training error: 0.8222847357205647\n",
            "At step: 1622 training error: 0.8194759297902672\n",
            "At step: 1623 training error: 0.8235070157246989\n",
            "At step: 1624 training error: 0.8214428975772206\n",
            "At step: 1625 training error: 0.8188539526870481\n",
            "At step: 1626 training error: 0.8188185255228825\n",
            "At step: 1627 training error: 0.812172763685034\n",
            "At step: 1628 training error: 0.8135736195835567\n",
            "At step: 1629 training error: 0.8145999537558519\n",
            "At step: 1630 training error: 0.8106783061730995\n",
            "At step: 1631 training error: 0.8100367113189769\n",
            "At step: 1632 training error: 0.8049509005945491\n",
            "At step: 1633 training error: 0.8041390523156287\n",
            "At step: 1634 training error: 0.8091769061062437\n",
            "At step: 1635 training error: 0.8034563077241725\n",
            "At step: 1636 training error: 0.800183791283627\n",
            "At step: 1637 training error: 0.7998050708958772\n",
            "At step: 1638 training error: 0.8002531310783243\n",
            "At step: 1639 training error: 0.8034193742819806\n",
            "At step: 1640 training error: 0.8075674706088811\n",
            "At step: 1641 training error: 0.8108208776495188\n",
            "At step: 1642 training error: 0.8127295860316872\n",
            "At step: 1643 training error: 0.8190108629951474\n",
            "At step: 1644 training error: 0.8139785897627327\n",
            "At step: 1645 training error: 0.8114538261122717\n",
            "At step: 1646 training error: 0.8076899775289939\n",
            "At step: 1647 training error: 0.803966163549164\n",
            "At step: 1648 training error: 0.8048741952791015\n",
            "At step: 1649 training error: 0.8065150421950988\n",
            "At step: 1650 training error: 0.8033480555478899\n",
            "At step: 1651 training error: 0.8031485189836144\n",
            "At step: 1652 training error: 0.8053085854056422\n",
            "At step: 1653 training error: 0.804874886373276\n",
            "At step: 1654 training error: 0.8008929139286248\n",
            "At step: 1655 training error: 0.8060940874120244\n",
            "At step: 1656 training error: 0.8124291848029401\n",
            "At step: 1657 training error: 0.8149738380312277\n",
            "At step: 1658 training error: 0.8137865671442452\n",
            "At step: 1659 training error: 0.8159614117520306\n",
            "At step: 1660 training error: 0.8158311729521436\n",
            "At step: 1661 training error: 0.8112364685807499\n",
            "At step: 1662 training error: 0.8074162906250493\n",
            "At step: 1663 training error: 0.805174160375302\n",
            "At step: 1664 training error: 0.8058355569907871\n",
            "At step: 1665 training error: 0.8067023490201969\n",
            "At step: 1666 training error: 0.8114173785161325\n",
            "At step: 1667 training error: 0.8065401325071799\n",
            "At step: 1668 training error: 0.8078948547323908\n",
            "At step: 1669 training error: 0.8100339346848411\n",
            "At step: 1670 training error: 0.8055300395744688\n",
            "At step: 1671 training error: 0.8072700046172898\n",
            "At step: 1672 training error: 0.8064723121771065\n",
            "At step: 1673 training error: 0.8059856106791511\n",
            "At step: 1674 training error: 0.8024438316357878\n",
            "At step: 1675 training error: 0.8063424517593867\n",
            "At step: 1676 training error: 0.8137801087577509\n",
            "At step: 1677 training error: 0.8093129414592741\n",
            "At step: 1678 training error: 0.8185220265236739\n",
            "At step: 1679 training error: 0.8144310619353449\n",
            "At step: 1680 training error: 0.818906586642365\n",
            "At step: 1681 training error: 0.8158737184936236\n",
            "At step: 1682 training error: 0.8175815111175115\n",
            "At step: 1683 training error: 0.808791460809547\n",
            "At step: 1684 training error: 0.8134360416116321\n",
            "At step: 1685 training error: 0.8055404005977373\n",
            "At step: 1686 training error: 0.8022598954164982\n",
            "At step: 1687 training error: 0.7998826680036145\n",
            "At step: 1688 training error: 0.7991066842864403\n",
            "At step: 1689 training error: 0.8019176086707579\n",
            "At step: 1690 training error: 0.7990531106614392\n",
            "At step: 1691 training error: 0.8012454764160459\n",
            "At step: 1692 training error: 0.8014352471517785\n",
            "At step: 1693 training error: 0.8017175283654487\n",
            "At step: 1694 training error: 0.8071473197033845\n",
            "At step: 1695 training error: 0.8061719898088263\n",
            "At step: 1696 training error: 0.8078741355080847\n",
            "At step: 1697 training error: 0.8069193042930402\n",
            "At step: 1698 training error: 0.8091312941694616\n",
            "At step: 1699 training error: 0.8134418200290194\n",
            "At step: 1700 training error: 0.8125053484008025\n",
            "At step: 1701 training error: 0.8067538913904191\n",
            "At step: 1702 training error: 0.8053837483055383\n",
            "At step: 1703 training error: 0.807590288348136\n",
            "At step: 1704 training error: 0.809094170321089\n",
            "At step: 1705 training error: 0.8119680981394656\n",
            "At step: 1706 training error: 0.8105900222899635\n",
            "At step: 1707 training error: 0.808676898534267\n",
            "At step: 1708 training error: 0.8068552228976992\n",
            "At step: 1709 training error: 0.8091295628035726\n",
            "At step: 1710 training error: 0.8072787034656308\n",
            "At step: 1711 training error: 0.8052113938483255\n",
            "At step: 1712 training error: 0.8044110260168187\n",
            "At step: 1713 training error: 0.8080420861523041\n",
            "At step: 1714 training error: 0.8155280188601757\n",
            "At step: 1715 training error: 0.8118982186892174\n",
            "At step: 1716 training error: 0.8064295353351538\n",
            "At step: 1717 training error: 0.8071798605897249\n",
            "At step: 1718 training error: 0.8053739839827417\n",
            "At step: 1719 training error: 0.8117394438889349\n",
            "At step: 1720 training error: 0.8244042485069331\n",
            "At step: 1721 training error: 0.820158390436888\n",
            "At step: 1722 training error: 0.8130555549801174\n",
            "At step: 1723 training error: 0.8095545376424533\n",
            "At step: 1724 training error: 0.8054030190108664\n",
            "At step: 1725 training error: 0.7977753502807704\n",
            "At step: 1726 training error: 0.8008348719000502\n",
            "At step: 1727 training error: 0.7990316763478665\n",
            "At step: 1728 training error: 0.7985970200460104\n",
            "At step: 1729 training error: 0.8040596653464894\n",
            "At step: 1730 training error: 0.8030815439359589\n",
            "At step: 1731 training error: 0.7975660464494879\n",
            "At step: 1732 training error: 0.8037133926578105\n",
            "At step: 1733 training error: 0.8050470858258292\n",
            "At step: 1734 training error: 0.8088858118697817\n",
            "At step: 1735 training error: 0.8141502549696625\n",
            "At step: 1736 training error: 0.812821293274079\n",
            "At step: 1737 training error: 0.817231586229007\n",
            "At step: 1738 training error: 0.8156052143345175\n",
            "At step: 1739 training error: 0.8106524613996808\n",
            "At step: 1740 training error: 0.8031417525975104\n",
            "At step: 1741 training error: 0.7922572443041138\n",
            "At step: 1742 training error: 0.7851043009350642\n",
            "At step: 1743 training error: 0.7852243801093006\n",
            "At step: 1744 training error: 0.7883834503846564\n",
            "At step: 1745 training error: 0.7871226621464047\n",
            "At step: 1746 training error: 0.7802437288816108\n",
            "At step: 1747 training error: 0.7785476508604312\n",
            "At step: 1748 training error: 0.7823068012700901\n",
            "At step: 1749 training error: 0.7806773698720849\n",
            "At step: 1750 training error: 0.7821205169930114\n",
            "At step: 1751 training error: 0.784422932468141\n",
            "At step: 1752 training error: 0.7880557328244504\n",
            "At step: 1753 training error: 0.788987237770613\n",
            "At step: 1754 training error: 0.7854803177327006\n",
            "At step: 1755 training error: 0.7822532325029653\n",
            "At step: 1756 training error: 0.7837223981558021\n",
            "At step: 1757 training error: 0.7836768876482286\n",
            "At step: 1758 training error: 0.7851251107911259\n",
            "At step: 1759 training error: 0.783522586831985\n",
            "At step: 1760 training error: 0.7832012900219608\n",
            "At step: 1761 training error: 0.7872736195850475\n",
            "At step: 1762 training error: 0.7958542952524692\n",
            "At step: 1763 training error: 0.7960282856023065\n",
            "At step: 1764 training error: 0.7925868249249114\n",
            "At step: 1765 training error: 0.7968756914274017\n",
            "At step: 1766 training error: 0.7968264659875945\n",
            "At step: 1767 training error: 0.7987002719957474\n",
            "At step: 1768 training error: 0.7896638899560345\n",
            "At step: 1769 training error: 0.7840420249456723\n",
            "At step: 1770 training error: 0.7892952094245371\n",
            "At step: 1771 training error: 0.7909868989691224\n",
            "At step: 1772 training error: 0.7914070839481954\n",
            "At step: 1773 training error: 0.7933390158468023\n",
            "At step: 1774 training error: 0.7971622579779406\n",
            "At step: 1775 training error: 0.7954675303152167\n",
            "At step: 1776 training error: 0.8017463063314829\n",
            "At step: 1777 training error: 0.8032286230524558\n",
            "At step: 1778 training error: 0.8012428678441514\n",
            "At step: 1779 training error: 0.8088640170592013\n",
            "At step: 1780 training error: 0.801261660169466\n",
            "At step: 1781 training error: 0.7978714456308077\n",
            "At step: 1782 training error: 0.7952358617800818\n",
            "At step: 1783 training error: 0.7976385804377994\n",
            "At step: 1784 training error: 0.7923660725405877\n",
            "At step: 1785 training error: 0.794081028219073\n",
            "At step: 1786 training error: 0.7892002920968292\n",
            "At step: 1787 training error: 0.7908236409803713\n",
            "At step: 1788 training error: 0.7923769644834572\n",
            "At step: 1789 training error: 0.793396953016413\n",
            "At step: 1790 training error: 0.7910925402912281\n",
            "At step: 1791 training error: 0.7854221799614372\n",
            "At step: 1792 training error: 0.780104430790122\n",
            "At step: 1793 training error: 0.7835009826538832\n",
            "At step: 1794 training error: 0.7916364322757858\n",
            "At step: 1795 training error: 0.7962405952456353\n",
            "At step: 1796 training error: 0.7932771655864433\n",
            "At step: 1797 training error: 0.7993447421257174\n",
            "At step: 1798 training error: 0.791600964307458\n",
            "At step: 1799 training error: 0.7897010606211785\n",
            "At step: 1800 training error: 0.7867497479302639\n",
            "At step: 1801 training error: 0.786677035437229\n",
            "At step: 1802 training error: 0.790606437089426\n",
            "At step: 1803 training error: 0.7818419099467429\n",
            "At step: 1804 training error: 0.78572433248919\n",
            "At step: 1805 training error: 0.7950128053893516\n",
            "At step: 1806 training error: 0.7953722409543945\n",
            "At step: 1807 training error: 0.7982610635353693\n",
            "At step: 1808 training error: 0.8021465074486738\n",
            "At step: 1809 training error: 0.8039141401676788\n",
            "At step: 1810 training error: 0.8049936445424709\n",
            "At step: 1811 training error: 0.8046736157366371\n",
            "At step: 1812 training error: 0.8008992736323038\n",
            "At step: 1813 training error: 0.8022464794070888\n",
            "At step: 1814 training error: 0.8101841011063907\n",
            "At step: 1815 training error: 0.8077140925690556\n",
            "At step: 1816 training error: 0.7988099175416016\n",
            "At step: 1817 training error: 0.7938430077690962\n",
            "At step: 1818 training error: 0.7962567860359904\n",
            "At step: 1819 training error: 0.8008543831212016\n",
            "At step: 1820 training error: 0.8007688059954532\n",
            "At step: 1821 training error: 0.8027587614807054\n",
            "At step: 1822 training error: 0.7983810424038305\n",
            "At step: 1823 training error: 0.7972491884815157\n",
            "At step: 1824 training error: 0.8009137069687697\n",
            "At step: 1825 training error: 0.7960657204077726\n",
            "At step: 1826 training error: 0.7978048194909968\n",
            "At step: 1827 training error: 0.8014518324424442\n",
            "At step: 1828 training error: 0.7978038008583273\n",
            "At step: 1829 training error: 0.7972648534870468\n",
            "At step: 1830 training error: 0.7976180588158117\n",
            "At step: 1831 training error: 0.8040346195993722\n",
            "At step: 1832 training error: 0.801205082411394\n",
            "At step: 1833 training error: 0.8012727956389033\n",
            "At step: 1834 training error: 0.8069779434774861\n",
            "At step: 1835 training error: 0.8083160421685973\n",
            "At step: 1836 training error: 0.8121783224601602\n",
            "At step: 1837 training error: 0.8149945679027563\n",
            "At step: 1838 training error: 0.8144451288378859\n",
            "At step: 1839 training error: 0.8147584309776049\n",
            "At step: 1840 training error: 0.8076325075505378\n",
            "At step: 1841 training error: 0.8081461139078329\n",
            "At step: 1842 training error: 0.7991919208748262\n",
            "At step: 1843 training error: 0.7982087884392969\n",
            "At step: 1844 training error: 0.8013880528388632\n",
            "At step: 1845 training error: 0.8008429865990747\n",
            "At step: 1846 training error: 0.8035008126467971\n",
            "At step: 1847 training error: 0.8049420503590407\n",
            "At step: 1848 training error: 0.8075832977606989\n",
            "At step: 1849 training error: 0.8018398715795572\n",
            "At step: 1850 training error: 0.794797776158688\n",
            "At step: 1851 training error: 0.7946644178593634\n",
            "At step: 1852 training error: 0.7845546939187688\n",
            "At step: 1853 training error: 0.7831570853383584\n",
            "At step: 1854 training error: 0.7821496021940453\n",
            "At step: 1855 training error: 0.7758892366980089\n",
            "At step: 1856 training error: 0.7800392426652216\n",
            "At step: 1857 training error: 0.7841067625881291\n",
            "At step: 1858 training error: 0.7806500904425786\n",
            "At step: 1859 training error: 0.7802616968557698\n",
            "At step: 1860 training error: 0.783547170452449\n",
            "At step: 1861 training error: 0.7797581553795189\n",
            "At step: 1862 training error: 0.7848028560750872\n",
            "At step: 1863 training error: 0.776761839063407\n",
            "At step: 1864 training error: 0.7811405750795921\n",
            "At step: 1865 training error: 0.7898795235454352\n",
            "At step: 1866 training error: 0.7910529231118472\n",
            "At step: 1867 training error: 0.7992988308750701\n",
            "At step: 1868 training error: 0.799990725773177\n",
            "At step: 1869 training error: 0.7912843895923549\n",
            "At step: 1870 training error: 0.7955738036269022\n",
            "At step: 1871 training error: 0.7995993476987094\n",
            "At step: 1872 training error: 0.795456802228326\n",
            "At step: 1873 training error: 0.7937943407789139\n",
            "At step: 1874 training error: 0.7874634726813118\n",
            "At step: 1875 training error: 0.7954385644321014\n",
            "At step: 1876 training error: 0.7930210251319882\n",
            "At step: 1877 training error: 0.792622644221055\n",
            "At step: 1878 training error: 0.795551143596032\n",
            "At step: 1879 training error: 0.7889584155060029\n",
            "At step: 1880 training error: 0.782682032793362\n",
            "At step: 1881 training error: 0.7902119309869805\n",
            "At step: 1882 training error: 0.7854654079160385\n",
            "At step: 1883 training error: 0.7874009516442632\n",
            "At step: 1884 training error: 0.7913648905315557\n",
            "At step: 1885 training error: 0.7964482521207863\n",
            "At step: 1886 training error: 0.802239637477293\n",
            "At step: 1887 training error: 0.7990428476476236\n",
            "At step: 1888 training error: 0.7872863045017005\n",
            "At step: 1889 training error: 0.7882402490961137\n",
            "At step: 1890 training error: 0.7785630862457074\n",
            "At step: 1891 training error: 0.7854114920264922\n",
            "At step: 1892 training error: 0.7901660380404839\n",
            "At step: 1893 training error: 0.7914955996358676\n",
            "At step: 1894 training error: 0.7905819374058829\n",
            "At step: 1895 training error: 0.7996843661190879\n",
            "At step: 1896 training error: 0.7935189678301688\n",
            "At step: 1897 training error: 0.7940338834459231\n",
            "At step: 1898 training error: 0.79645509128832\n",
            "At step: 1899 training error: 0.7953548506002369\n",
            "At step: 1900 training error: 0.7954350658499911\n",
            "At step: 1901 training error: 0.8014701347757596\n",
            "At step: 1902 training error: 0.794945174555185\n",
            "At step: 1903 training error: 0.8052200695316816\n",
            "At step: 1904 training error: 0.7979135728678517\n",
            "At step: 1905 training error: 0.8016587349865727\n",
            "At step: 1906 training error: 0.7990783262273156\n",
            "At step: 1907 training error: 0.8040009357522122\n",
            "At step: 1908 training error: 0.8049944091271729\n",
            "At step: 1909 training error: 0.8021144447056278\n",
            "At step: 1910 training error: 0.799405614636207\n",
            "At step: 1911 training error: 0.7960791803035494\n",
            "At step: 1912 training error: 0.7891315557567496\n",
            "At step: 1913 training error: 0.7958367948274352\n",
            "At step: 1914 training error: 0.7857322606102833\n",
            "At step: 1915 training error: 0.7796171468133211\n",
            "At step: 1916 training error: 0.7830904836959904\n",
            "At step: 1917 training error: 0.7890499035907613\n",
            "At step: 1918 training error: 0.7845973024727471\n",
            "At step: 1919 training error: 0.789005959170184\n",
            "At step: 1920 training error: 0.7893664244980244\n",
            "At step: 1921 training error: 0.7901895426640937\n",
            "At step: 1922 training error: 0.7911472459587152\n",
            "At step: 1923 training error: 0.7907952119314585\n",
            "At step: 1924 training error: 0.7897003276603735\n",
            "At step: 1925 training error: 0.7918865907413969\n",
            "At step: 1926 training error: 0.794937384174192\n",
            "At step: 1927 training error: 0.7967978644705503\n",
            "At step: 1928 training error: 0.7962351625063924\n",
            "At step: 1929 training error: 0.7905372247973766\n",
            "At step: 1930 training error: 0.7957015084961968\n",
            "At step: 1931 training error: 0.7957874077226493\n",
            "At step: 1932 training error: 0.7919980156670291\n",
            "At step: 1933 training error: 0.7989650686233625\n",
            "At step: 1934 training error: 0.7900025393510746\n",
            "At step: 1935 training error: 0.7877290181433023\n",
            "At step: 1936 training error: 0.7898680003657764\n",
            "At step: 1937 training error: 0.7931806862973388\n",
            "At step: 1938 training error: 0.7934194278868499\n",
            "At step: 1939 training error: 0.7936966301502097\n",
            "At step: 1940 training error: 0.7836733063129525\n",
            "At step: 1941 training error: 0.7823893621846824\n",
            "At step: 1942 training error: 0.7766562648892904\n",
            "At step: 1943 training error: 0.7844494285992456\n",
            "At step: 1944 training error: 0.7834268254255723\n",
            "At step: 1945 training error: 0.7808976567413722\n",
            "At step: 1946 training error: 0.7786234217460973\n",
            "At step: 1947 training error: 0.7805941645713946\n",
            "At step: 1948 training error: 0.7811955324510417\n",
            "At step: 1949 training error: 0.7880290133873131\n",
            "At step: 1950 training error: 0.7886352925177145\n",
            "At step: 1951 training error: 0.7936477665098962\n",
            "At step: 1952 training error: 0.7921674420659159\n",
            "At step: 1953 training error: 0.7907899960017384\n",
            "At step: 1954 training error: 0.7844571494075385\n",
            "At step: 1955 training error: 0.7876868844455915\n",
            "At step: 1956 training error: 0.7925711556561627\n",
            "At step: 1957 training error: 0.7936923047099079\n",
            "At step: 1958 training error: 0.7966169830127836\n",
            "At step: 1959 training error: 0.8027257655951309\n",
            "At step: 1960 training error: 0.795033375661279\n",
            "At step: 1961 training error: 0.7939117984152539\n",
            "At step: 1962 training error: 0.7946274293235904\n",
            "At step: 1963 training error: 0.7958611211368596\n",
            "At step: 1964 training error: 0.797417785701181\n",
            "At step: 1965 training error: 0.7909227913606506\n",
            "At step: 1966 training error: 0.7917460307845046\n",
            "At step: 1967 training error: 0.7885725066044992\n",
            "At step: 1968 training error: 0.7782330193755347\n",
            "At step: 1969 training error: 0.7753114993721981\n",
            "At step: 1970 training error: 0.7768475410053741\n",
            "At step: 1971 training error: 0.7828363862922286\n",
            "At step: 1972 training error: 0.7798181695287387\n",
            "At step: 1973 training error: 0.786697521679199\n",
            "At step: 1974 training error: 0.7895506957597793\n",
            "At step: 1975 training error: 0.7863785185103774\n",
            "At step: 1976 training error: 0.7771209294714629\n",
            "At step: 1977 training error: 0.7817115995203303\n",
            "At step: 1978 training error: 0.7830223380072203\n",
            "At step: 1979 training error: 0.7873029869588719\n",
            "At step: 1980 training error: 0.7919745206767321\n",
            "At step: 1981 training error: 0.7916371747219091\n",
            "At step: 1982 training error: 0.7891327736030705\n",
            "At step: 1983 training error: 0.7845309475452503\n",
            "At step: 1984 training error: 0.7782697091751193\n",
            "At step: 1985 training error: 0.7753517417455433\n",
            "At step: 1986 training error: 0.7786487808189139\n",
            "At step: 1987 training error: 0.7723352331657153\n",
            "At step: 1988 training error: 0.7635552669456255\n",
            "At step: 1989 training error: 0.7662205051816804\n",
            "At step: 1990 training error: 0.7632465028201\n",
            "At step: 1991 training error: 0.7589179149016586\n",
            "At step: 1992 training error: 0.7578731121828924\n",
            "At step: 1993 training error: 0.754053308590998\n",
            "At step: 1994 training error: 0.7527561420668537\n",
            "At step: 1995 training error: 0.753210979944524\n",
            "At step: 1996 training error: 0.7593734602182428\n",
            "At step: 1997 training error: 0.7665833657213622\n",
            "At step: 1998 training error: 0.7677252735271103\n",
            "At step: 1999 training error: 0.767098431509863\n",
            "At step: 2000 training error: 0.77265567376462\n",
            "At step: 2001 training error: 0.7760604421324822\n",
            "At step: 2002 training error: 0.7780171857568466\n",
            "At step: 2003 training error: 0.7752623269587897\n",
            "At step: 2004 training error: 0.7846093311348783\n",
            "At step: 2005 training error: 0.7835479680785051\n",
            "At step: 2006 training error: 0.7929768734130458\n",
            "At step: 2007 training error: 0.7848220415976591\n",
            "At step: 2008 training error: 0.7829393775004858\n",
            "At step: 2009 training error: 0.7809396540462222\n",
            "At step: 2010 training error: 0.7790872469387452\n",
            "At step: 2011 training error: 0.7826415108855408\n",
            "At step: 2012 training error: 0.7809035236107661\n",
            "At step: 2013 training error: 0.7753818091870157\n",
            "At step: 2014 training error: 0.7691805399247257\n",
            "At step: 2015 training error: 0.7730227582181561\n",
            "At step: 2016 training error: 0.7651409795479657\n",
            "At step: 2017 training error: 0.7575871724538296\n",
            "At step: 2018 training error: 0.755686351286588\n",
            "At step: 2019 training error: 0.7543812752219167\n",
            "At step: 2020 training error: 0.7599570477404708\n",
            "At step: 2021 training error: 0.7540158037120682\n",
            "At step: 2022 training error: 0.752526476635486\n",
            "At step: 2023 training error: 0.7611035717930259\n",
            "At step: 2024 training error: 0.7617577665179708\n",
            "At step: 2025 training error: 0.7619056167877728\n",
            "At step: 2026 training error: 0.7659287720857906\n",
            "At step: 2027 training error: 0.7690185483450822\n",
            "At step: 2028 training error: 0.7674847503960394\n",
            "At step: 2029 training error: 0.7665676610860682\n",
            "At step: 2030 training error: 0.7687829148647564\n",
            "At step: 2031 training error: 0.7724525524445929\n",
            "At step: 2032 training error: 0.7811916973519466\n",
            "At step: 2033 training error: 0.7826632032364136\n",
            "At step: 2034 training error: 0.7796197636467264\n",
            "At step: 2035 training error: 0.7731735080723499\n",
            "At step: 2036 training error: 0.778490849004153\n",
            "At step: 2037 training error: 0.7909038723837072\n",
            "At step: 2038 training error: 0.7924398381531591\n",
            "At step: 2039 training error: 0.7856892856015457\n",
            "At step: 2040 training error: 0.7815745420503825\n",
            "At step: 2041 training error: 0.7823065523493857\n",
            "At step: 2042 training error: 0.7872566128628847\n",
            "At step: 2043 training error: 0.7816863959635545\n",
            "At step: 2044 training error: 0.7846583693323139\n",
            "At step: 2045 training error: 0.7841921037805619\n",
            "At step: 2046 training error: 0.7824092996078879\n",
            "At step: 2047 training error: 0.7874598764383984\n",
            "At step: 2048 training error: 0.7789915005667797\n",
            "At step: 2049 training error: 0.7813037427833942\n",
            "At step: 2050 training error: 0.7787277350448203\n",
            "At step: 2051 training error: 0.7688270721695311\n",
            "At step: 2052 training error: 0.7720900699681543\n",
            "At step: 2053 training error: 0.7708852838054138\n",
            "At step: 2054 training error: 0.7758362650395223\n",
            "At step: 2055 training error: 0.7714790091993856\n",
            "At step: 2056 training error: 0.7646897609806123\n",
            "At step: 2057 training error: 0.7640280439502553\n",
            "At step: 2058 training error: 0.7696851608856917\n",
            "At step: 2059 training error: 0.7731620857446321\n",
            "At step: 2060 training error: 0.7709959222396442\n",
            "At step: 2061 training error: 0.7699999766632669\n",
            "At step: 2062 training error: 0.7706488160190319\n",
            "At step: 2063 training error: 0.7731406091163384\n",
            "At step: 2064 training error: 0.7648812879048122\n",
            "At step: 2065 training error: 0.7661118631521575\n",
            "At step: 2066 training error: 0.7596938181454355\n",
            "At step: 2067 training error: 0.7699522560227734\n",
            "At step: 2068 training error: 0.7697034953134336\n",
            "At step: 2069 training error: 0.7721958166423821\n",
            "At step: 2070 training error: 0.7747525492763881\n",
            "At step: 2071 training error: 0.7743182819003637\n",
            "At step: 2072 training error: 0.7753483911817027\n",
            "At step: 2073 training error: 0.7666810867142341\n",
            "At step: 2074 training error: 0.769003041097215\n",
            "At step: 2075 training error: 0.7691850841247307\n",
            "At step: 2076 training error: 0.7706572594010876\n",
            "At step: 2077 training error: 0.7698834826932348\n",
            "At step: 2078 training error: 0.7674102536635767\n",
            "At step: 2079 training error: 0.7703814704685561\n",
            "At step: 2080 training error: 0.7695317818309941\n",
            "At step: 2081 training error: 0.7666913563489398\n",
            "At step: 2082 training error: 0.759410994623223\n",
            "At step: 2083 training error: 0.7643869457791794\n",
            "At step: 2084 training error: 0.7709786351877342\n",
            "At step: 2085 training error: 0.770709964737742\n",
            "At step: 2086 training error: 0.7746164217073763\n",
            "At step: 2087 training error: 0.7638535948824989\n",
            "At step: 2088 training error: 0.7692553324043019\n",
            "At step: 2089 training error: 0.7709259404069118\n",
            "At step: 2090 training error: 0.764444320968287\n",
            "At step: 2091 training error: 0.7558226107085971\n",
            "At step: 2092 training error: 0.759314599078253\n",
            "At step: 2093 training error: 0.7619866815979832\n",
            "At step: 2094 training error: 0.7600157534430905\n",
            "At step: 2095 training error: 0.7627399304212077\n",
            "At step: 2096 training error: 0.7682474675974704\n",
            "At step: 2097 training error: 0.766331722286549\n",
            "At step: 2098 training error: 0.7718988458106929\n",
            "At step: 2099 training error: 0.7629347685649518\n",
            "At step: 2100 training error: 0.7665081577324143\n",
            "At step: 2101 training error: 0.7753777966184928\n",
            "At step: 2102 training error: 0.7704074939940002\n",
            "At step: 2103 training error: 0.77176728287676\n",
            "At step: 2104 training error: 0.7742974997455057\n",
            "At step: 2105 training error: 0.7740702132594087\n",
            "At step: 2106 training error: 0.7735534813275612\n",
            "At step: 2107 training error: 0.7828400353897788\n",
            "At step: 2108 training error: 0.7929614109632812\n",
            "At step: 2109 training error: 0.7928117148374378\n",
            "At step: 2110 training error: 0.7926481165637924\n",
            "At step: 2111 training error: 0.7843443206877766\n",
            "At step: 2112 training error: 0.7836043741267467\n",
            "At step: 2113 training error: 0.782737132872047\n",
            "At step: 2114 training error: 0.7828795291470131\n",
            "At step: 2115 training error: 0.7904093969311671\n",
            "At step: 2116 training error: 0.7811310428081703\n",
            "At step: 2117 training error: 0.7823979391895376\n",
            "At step: 2118 training error: 0.7786435016874464\n",
            "At step: 2119 training error: 0.782659598294334\n",
            "At step: 2120 training error: 0.7763890747588666\n",
            "At step: 2121 training error: 0.7747730872594902\n",
            "At step: 2122 training error: 0.7807320874664208\n",
            "At step: 2123 training error: 0.7800789763373996\n",
            "At step: 2124 training error: 0.7770656342202664\n",
            "At step: 2125 training error: 0.7634063687670051\n",
            "At step: 2126 training error: 0.7604009560081211\n",
            "At step: 2127 training error: 0.7587252455078738\n",
            "At step: 2128 training error: 0.7612124839393231\n",
            "At step: 2129 training error: 0.7617538445965161\n",
            "At step: 2130 training error: 0.7564365620930917\n",
            "At step: 2131 training error: 0.7539797281653002\n",
            "At step: 2132 training error: 0.7503155576595204\n",
            "At step: 2133 training error: 0.7551253220122449\n",
            "At step: 2134 training error: 0.7540996825766556\n",
            "At step: 2135 training error: 0.7571339331248044\n",
            "At step: 2136 training error: 0.7528894538265832\n",
            "At step: 2137 training error: 0.7545267217813945\n",
            "At step: 2138 training error: 0.7502914375393381\n",
            "At step: 2139 training error: 0.7533650841751248\n",
            "At step: 2140 training error: 0.758664093651254\n",
            "At step: 2141 training error: 0.7615571828797493\n",
            "At step: 2142 training error: 0.7619281490967094\n",
            "At step: 2143 training error: 0.770568514535289\n",
            "At step: 2144 training error: 0.777985645001311\n",
            "At step: 2145 training error: 0.781917500983079\n",
            "At step: 2146 training error: 0.7725425803993777\n",
            "At step: 2147 training error: 0.772505781798982\n",
            "At step: 2148 training error: 0.765694655008011\n",
            "At step: 2149 training error: 0.7725012649786236\n",
            "At step: 2150 training error: 0.7710555697976371\n",
            "At step: 2151 training error: 0.7602140469572176\n",
            "At step: 2152 training error: 0.7675383359128732\n",
            "At step: 2153 training error: 0.7665313701635366\n",
            "At step: 2154 training error: 0.7699833442803742\n",
            "At step: 2155 training error: 0.763821753169618\n",
            "At step: 2156 training error: 0.7720828143568601\n",
            "At step: 2157 training error: 0.7740009989408315\n",
            "At step: 2158 training error: 0.7709214562580786\n",
            "At step: 2159 training error: 0.771046257713419\n",
            "At step: 2160 training error: 0.7682200537788011\n",
            "At step: 2161 training error: 0.7700488414874659\n",
            "At step: 2162 training error: 0.772442349411565\n",
            "At step: 2163 training error: 0.7722130351349477\n",
            "At step: 2164 training error: 0.774510139497232\n",
            "At step: 2165 training error: 0.774950680867276\n",
            "At step: 2166 training error: 0.7774885167221447\n",
            "At step: 2167 training error: 0.7753568911229494\n",
            "At step: 2168 training error: 0.7796405853654331\n",
            "At step: 2169 training error: 0.783329676439147\n",
            "At step: 2170 training error: 0.7840061587376714\n",
            "At step: 2171 training error: 0.7785518291423595\n",
            "At step: 2172 training error: 0.7795266832049457\n",
            "At step: 2173 training error: 0.7798377851695681\n",
            "At step: 2174 training error: 0.7856509436140915\n",
            "At step: 2175 training error: 0.7843755987188066\n",
            "At step: 2176 training error: 0.7823481239748913\n",
            "At step: 2177 training error: 0.7807096488637674\n",
            "At step: 2178 training error: 0.7664281436632101\n",
            "At step: 2179 training error: 0.777129711759518\n",
            "At step: 2180 training error: 0.7652845531931003\n",
            "At step: 2181 training error: 0.7627953134168758\n",
            "At step: 2182 training error: 0.7573776417201719\n",
            "At step: 2183 training error: 0.7577084252627253\n",
            "At step: 2184 training error: 0.7570051313889674\n",
            "At step: 2185 training error: 0.7574739684528281\n",
            "At step: 2186 training error: 0.7603602004317511\n",
            "At step: 2187 training error: 0.7660456915176277\n",
            "At step: 2188 training error: 0.7629897027272321\n",
            "At step: 2189 training error: 0.7807659077279274\n",
            "At step: 2190 training error: 0.7798213485009664\n",
            "At step: 2191 training error: 0.7778354550136394\n",
            "At step: 2192 training error: 0.767273712120358\n",
            "At step: 2193 training error: 0.7737485555759357\n",
            "At step: 2194 training error: 0.7739619613813724\n",
            "At step: 2195 training error: 0.7771402568213004\n",
            "At step: 2196 training error: 0.7630261485922326\n",
            "At step: 2197 training error: 0.7582507306256042\n",
            "At step: 2198 training error: 0.757414852436179\n",
            "At step: 2199 training error: 0.7633989471232469\n",
            "At step: 2200 training error: 0.7692473671405219\n",
            "At step: 2201 training error: 0.7793923096006372\n",
            "At step: 2202 training error: 0.7755822247235449\n",
            "At step: 2203 training error: 0.7725589481520452\n",
            "At step: 2204 training error: 0.7704213308073068\n",
            "At step: 2205 training error: 0.7705167944823058\n",
            "At step: 2206 training error: 0.7730625507457376\n",
            "At step: 2207 training error: 0.7709593463375043\n",
            "At step: 2208 training error: 0.769527602849747\n",
            "At step: 2209 training error: 0.7743023230510706\n",
            "At step: 2210 training error: 0.769395703544866\n",
            "At step: 2211 training error: 0.7680430926131183\n",
            "At step: 2212 training error: 0.7724807798605895\n",
            "At step: 2213 training error: 0.7768826198026232\n",
            "At step: 2214 training error: 0.7793130752335681\n",
            "At step: 2215 training error: 0.7709465613823859\n",
            "At step: 2216 training error: 0.7754869037864283\n",
            "At step: 2217 training error: 0.7810351569807892\n",
            "At step: 2218 training error: 0.7810317479900626\n",
            "At step: 2219 training error: 0.7776758772132236\n",
            "At step: 2220 training error: 0.7823886216418726\n",
            "At step: 2221 training error: 0.7831109359689363\n",
            "At step: 2222 training error: 0.7846975694097779\n",
            "At step: 2223 training error: 0.77468346586317\n",
            "At step: 2224 training error: 0.7703632751144033\n",
            "At step: 2225 training error: 0.7722838372437755\n",
            "At step: 2226 training error: 0.7736879302004482\n",
            "At step: 2227 training error: 0.775341695762348\n",
            "At step: 2228 training error: 0.7759134648880804\n",
            "At step: 2229 training error: 0.7764361413665803\n",
            "At step: 2230 training error: 0.7715970792707234\n",
            "At step: 2231 training error: 0.7707063846872745\n",
            "At step: 2232 training error: 0.7775156371691664\n",
            "At step: 2233 training error: 0.7862317135747607\n",
            "At step: 2234 training error: 0.7772830414632723\n",
            "At step: 2235 training error: 0.7656655135541376\n",
            "At step: 2236 training error: 0.7653201773043408\n",
            "At step: 2237 training error: 0.7564814349069501\n",
            "At step: 2238 training error: 0.7586199563151687\n",
            "At step: 2239 training error: 0.7565511021632867\n",
            "At step: 2240 training error: 0.7578440628490952\n",
            "At step: 2241 training error: 0.7588540632309125\n",
            "At step: 2242 training error: 0.7608436873988879\n",
            "At step: 2243 training error: 0.76440457764654\n",
            "At step: 2244 training error: 0.7707730240738011\n",
            "At step: 2245 training error: 0.7717950030463545\n",
            "At step: 2246 training error: 0.7668089479116627\n",
            "At step: 2247 training error: 0.7678269930118874\n",
            "At step: 2248 training error: 0.7668152582189104\n",
            "At step: 2249 training error: 0.7686690372315312\n",
            "At step: 2250 training error: 0.7737946970058717\n",
            "At step: 2251 training error: 0.7668374474336127\n",
            "At step: 2252 training error: 0.7620063524085476\n",
            "At step: 2253 training error: 0.7549016694495276\n",
            "At step: 2254 training error: 0.7530571169117855\n",
            "At step: 2255 training error: 0.7668857077556265\n",
            "At step: 2256 training error: 0.7688579833488378\n",
            "At step: 2257 training error: 0.7692555093836042\n",
            "At step: 2258 training error: 0.7748476749187698\n",
            "At step: 2259 training error: 0.7755766053035716\n",
            "At step: 2260 training error: 0.7686105336663923\n",
            "At step: 2261 training error: 0.7668847933216454\n",
            "At step: 2262 training error: 0.7678978265992992\n",
            "At step: 2263 training error: 0.7766172853338588\n",
            "At step: 2264 training error: 0.7780269914140282\n",
            "At step: 2265 training error: 0.7744569859906725\n",
            "At step: 2266 training error: 0.7754440459027119\n",
            "At step: 2267 training error: 0.766699533668262\n",
            "At step: 2268 training error: 0.7602845755609884\n",
            "At step: 2269 training error: 0.7618990857585078\n",
            "At step: 2270 training error: 0.7585668840345918\n",
            "At step: 2271 training error: 0.764250557550255\n",
            "At step: 2272 training error: 0.7695525890394801\n",
            "At step: 2273 training error: 0.7688000883722799\n",
            "At step: 2274 training error: 0.7613016103788325\n",
            "At step: 2275 training error: 0.7566782667462704\n",
            "At step: 2276 training error: 0.7590413415441495\n",
            "At step: 2277 training error: 0.7586786358532077\n",
            "At step: 2278 training error: 0.7573452439214048\n",
            "At step: 2279 training error: 0.7670597046205578\n",
            "At step: 2280 training error: 0.7657822688961894\n",
            "At step: 2281 training error: 0.7690533194396758\n",
            "At step: 2282 training error: 0.7618054542760095\n",
            "At step: 2283 training error: 0.7638498533965569\n",
            "At step: 2284 training error: 0.7606683364035239\n",
            "At step: 2285 training error: 0.7700586077102841\n",
            "At step: 2286 training error: 0.7704146293215169\n",
            "At step: 2287 training error: 0.7671730215930128\n",
            "At step: 2288 training error: 0.7707145936661143\n",
            "At step: 2289 training error: 0.7747830480017628\n",
            "At step: 2290 training error: 0.767603244713995\n",
            "At step: 2291 training error: 0.7654664575525921\n",
            "At step: 2292 training error: 0.7651855077600032\n",
            "At step: 2293 training error: 0.7627532964518979\n",
            "At step: 2294 training error: 0.7679310048251211\n",
            "At step: 2295 training error: 0.7658370218827892\n",
            "At step: 2296 training error: 0.7632069238559784\n",
            "At step: 2297 training error: 0.7694153880402649\n",
            "At step: 2298 training error: 0.7661914455811487\n",
            "At step: 2299 training error: 0.765042573516547\n",
            "At step: 2300 training error: 0.7638082515263074\n",
            "At step: 2301 training error: 0.759656838980016\n",
            "At step: 2302 training error: 0.7619245853886512\n",
            "At step: 2303 training error: 0.7661871408503216\n",
            "At step: 2304 training error: 0.7696737589440863\n",
            "At step: 2305 training error: 0.7661968546626748\n",
            "At step: 2306 training error: 0.7604107172414547\n",
            "At step: 2307 training error: 0.7624182018987491\n",
            "At step: 2308 training error: 0.7577516652840511\n",
            "At step: 2309 training error: 0.7575085340648061\n",
            "At step: 2310 training error: 0.7599969753694557\n",
            "At step: 2311 training error: 0.7540688589101314\n",
            "At step: 2312 training error: 0.7443106614850792\n",
            "At step: 2313 training error: 0.7436625972240237\n",
            "At step: 2314 training error: 0.7475025322318307\n",
            "At step: 2315 training error: 0.7512673448525603\n",
            "At step: 2316 training error: 0.75499377269471\n",
            "At step: 2317 training error: 0.751695293825657\n",
            "At step: 2318 training error: 0.751224612177896\n",
            "At step: 2319 training error: 0.751172611256669\n",
            "At step: 2320 training error: 0.7495692033654338\n",
            "At step: 2321 training error: 0.7480211957686864\n",
            "At step: 2322 training error: 0.7503692082833381\n",
            "At step: 2323 training error: 0.7454817960306419\n",
            "At step: 2324 training error: 0.745899032950252\n",
            "At step: 2325 training error: 0.7506655037632581\n",
            "At step: 2326 training error: 0.7510939030748803\n",
            "At step: 2327 training error: 0.7608721658968328\n",
            "At step: 2328 training error: 0.7566664306537048\n",
            "At step: 2329 training error: 0.7547010033296656\n",
            "At step: 2330 training error: 0.7541640591294704\n",
            "At step: 2331 training error: 0.7492976216238892\n",
            "At step: 2332 training error: 0.7446266090947992\n",
            "At step: 2333 training error: 0.7536221935445228\n",
            "At step: 2334 training error: 0.7521228856286145\n",
            "At step: 2335 training error: 0.7491522646962523\n",
            "At step: 2336 training error: 0.738376405589668\n",
            "At step: 2337 training error: 0.7326009594354914\n",
            "At step: 2338 training error: 0.7347771670237632\n",
            "At step: 2339 training error: 0.7354337968912733\n",
            "At step: 2340 training error: 0.7390255881088807\n",
            "At step: 2341 training error: 0.73105104464974\n",
            "At step: 2342 training error: 0.7311292357872257\n",
            "At step: 2343 training error: 0.7277583849229082\n",
            "At step: 2344 training error: 0.7270506689793638\n",
            "At step: 2345 training error: 0.728814690324967\n",
            "At step: 2346 training error: 0.7219140439016065\n",
            "At step: 2347 training error: 0.7314751173891204\n",
            "At step: 2348 training error: 0.7362099918113351\n",
            "At step: 2349 training error: 0.7380609580307781\n",
            "At step: 2350 training error: 0.7325253272422836\n",
            "At step: 2351 training error: 0.7393520430455026\n",
            "At step: 2352 training error: 0.7446941767306735\n",
            "At step: 2353 training error: 0.7375045971516182\n",
            "At step: 2354 training error: 0.7400098373003141\n",
            "At step: 2355 training error: 0.7484947818980167\n",
            "At step: 2356 training error: 0.7417575466942595\n",
            "At step: 2357 training error: 0.7381794979146935\n",
            "At step: 2358 training error: 0.746823127292548\n",
            "At step: 2359 training error: 0.7428246924340485\n",
            "At step: 2360 training error: 0.737878003951693\n",
            "At step: 2361 training error: 0.7463812116993466\n",
            "At step: 2362 training error: 0.7484251005373159\n",
            "At step: 2363 training error: 0.7525758371958253\n",
            "At step: 2364 training error: 0.7575551824218735\n",
            "At step: 2365 training error: 0.7534453052613723\n",
            "At step: 2366 training error: 0.7567747054591583\n",
            "At step: 2367 training error: 0.7537473723551311\n",
            "At step: 2368 training error: 0.7498455379068483\n",
            "At step: 2369 training error: 0.744789304253579\n",
            "At step: 2370 training error: 0.7423310106015223\n",
            "At step: 2371 training error: 0.7479196122225344\n",
            "At step: 2372 training error: 0.7456609327446517\n",
            "At step: 2373 training error: 0.7454761233913458\n",
            "At step: 2374 training error: 0.733335994277094\n",
            "At step: 2375 training error: 0.7400774140367364\n",
            "At step: 2376 training error: 0.7323018411955107\n",
            "At step: 2377 training error: 0.7275213767779154\n",
            "At step: 2378 training error: 0.7326612069766353\n",
            "At step: 2379 training error: 0.7367599295545125\n",
            "At step: 2380 training error: 0.7353078181942084\n",
            "At step: 2381 training error: 0.7273880021514522\n",
            "At step: 2382 training error: 0.7280543416707661\n",
            "At step: 2383 training error: 0.7205695210655003\n",
            "At step: 2384 training error: 0.7264635417915565\n",
            "At step: 2385 training error: 0.7434377038415565\n",
            "At step: 2386 training error: 0.7344590325117587\n",
            "At step: 2387 training error: 0.7414113164984719\n",
            "At step: 2388 training error: 0.7471436505601793\n",
            "At step: 2389 training error: 0.7394462771258841\n",
            "At step: 2390 training error: 0.7455038657968143\n",
            "At step: 2391 training error: 0.7438985869059945\n",
            "At step: 2392 training error: 0.7423075448858711\n",
            "At step: 2393 training error: 0.7441558281225253\n",
            "At step: 2394 training error: 0.7456674241664631\n",
            "At step: 2395 training error: 0.7493380544420964\n",
            "At step: 2396 training error: 0.7517315817119108\n",
            "At step: 2397 training error: 0.7585771561855725\n",
            "At step: 2398 training error: 0.7568962572500428\n",
            "At step: 2399 training error: 0.7564509036512944\n",
            "At step: 2400 training error: 0.7505590322899977\n",
            "At step: 2401 training error: 0.7563975100711253\n",
            "At step: 2402 training error: 0.7491381542988397\n",
            "At step: 2403 training error: 0.7542254511001815\n",
            "At step: 2404 training error: 0.7527829443133393\n",
            "At step: 2405 training error: 0.7478057177811288\n",
            "At step: 2406 training error: 0.7449285798698384\n",
            "At step: 2407 training error: 0.7383331088580279\n",
            "At step: 2408 training error: 0.7442151363555838\n",
            "At step: 2409 training error: 0.7443848531150034\n",
            "At step: 2410 training error: 0.7496641997964314\n",
            "At step: 2411 training error: 0.7504806027373411\n",
            "At step: 2412 training error: 0.7479671982990196\n",
            "At step: 2413 training error: 0.740985076028003\n",
            "At step: 2414 training error: 0.7473724076589052\n",
            "At step: 2415 training error: 0.7427902572358329\n",
            "At step: 2416 training error: 0.745979706145374\n",
            "At step: 2417 training error: 0.753750860299483\n",
            "At step: 2418 training error: 0.7525070738221987\n",
            "At step: 2419 training error: 0.7571335526384807\n",
            "At step: 2420 training error: 0.7506948020561841\n",
            "At step: 2421 training error: 0.7536829313588902\n",
            "At step: 2422 training error: 0.7473456633214179\n",
            "At step: 2423 training error: 0.7459379736401786\n",
            "At step: 2424 training error: 0.7453681684928383\n",
            "At step: 2425 training error: 0.7401581446682227\n",
            "At step: 2426 training error: 0.7498963570893842\n",
            "At step: 2427 training error: 0.7568179494075679\n",
            "At step: 2428 training error: 0.7511948936930302\n",
            "At step: 2429 training error: 0.7511079946314887\n",
            "At step: 2430 training error: 0.7523572128738132\n",
            "At step: 2431 training error: 0.7459599047708871\n",
            "At step: 2432 training error: 0.7391044567538135\n",
            "At step: 2433 training error: 0.7382183426013845\n",
            "At step: 2434 training error: 0.7391830945140682\n",
            "At step: 2435 training error: 0.7411568238385794\n",
            "At step: 2436 training error: 0.7371699914759833\n",
            "At step: 2437 training error: 0.7371905740302479\n",
            "At step: 2438 training error: 0.7457176399802297\n",
            "At step: 2439 training error: 0.7415269924203329\n",
            "At step: 2440 training error: 0.7402970955757806\n",
            "At step: 2441 training error: 0.7336486226131538\n",
            "At step: 2442 training error: 0.7401981976452912\n",
            "At step: 2443 training error: 0.7428578074406866\n",
            "At step: 2444 training error: 0.7429643969581483\n",
            "At step: 2445 training error: 0.747138645822234\n",
            "At step: 2446 training error: 0.7465480257523536\n",
            "At step: 2447 training error: 0.7454478839535613\n",
            "At step: 2448 training error: 0.7477256657086273\n",
            "At step: 2449 training error: 0.7572274016389264\n",
            "At step: 2450 training error: 0.7513092542942845\n",
            "At step: 2451 training error: 0.7551454993046532\n",
            "At step: 2452 training error: 0.74394597638779\n",
            "At step: 2453 training error: 0.750478611457768\n",
            "At step: 2454 training error: 0.7514296168924339\n",
            "At step: 2455 training error: 0.7424731411686379\n",
            "At step: 2456 training error: 0.7427673982485382\n",
            "At step: 2457 training error: 0.7378518549571631\n",
            "At step: 2458 training error: 0.7393995788819852\n",
            "At step: 2459 training error: 0.7306755138431988\n",
            "At step: 2460 training error: 0.7283391881274534\n",
            "At step: 2461 training error: 0.7300618731090313\n",
            "At step: 2462 training error: 0.7441481125000782\n",
            "At step: 2463 training error: 0.7364270363505935\n",
            "At step: 2464 training error: 0.7314656561641557\n",
            "At step: 2465 training error: 0.7333428384952382\n",
            "At step: 2466 training error: 0.7308955578751662\n",
            "At step: 2467 training error: 0.7301433113222866\n",
            "At step: 2468 training error: 0.74435095916108\n",
            "At step: 2469 training error: 0.7429002922797038\n",
            "At step: 2470 training error: 0.746616425277717\n",
            "At step: 2471 training error: 0.7516851285924226\n",
            "At step: 2472 training error: 0.7468286711343307\n",
            "At step: 2473 training error: 0.7435695243068662\n",
            "At step: 2474 training error: 0.73825097959426\n",
            "At step: 2475 training error: 0.7381763967619827\n",
            "At step: 2476 training error: 0.7410239026808367\n",
            "At step: 2477 training error: 0.7534044332199342\n",
            "At step: 2478 training error: 0.7585283181995922\n",
            "At step: 2479 training error: 0.7555440268279268\n",
            "At step: 2480 training error: 0.7569546829001357\n",
            "At step: 2481 training error: 0.7553255016899089\n",
            "At step: 2482 training error: 0.7599174809360322\n",
            "At step: 2483 training error: 0.7526409677828417\n",
            "At step: 2484 training error: 0.7600969720512369\n",
            "At step: 2485 training error: 0.7592657152793723\n",
            "At step: 2486 training error: 0.7698521356020089\n",
            "At step: 2487 training error: 0.7582033202830634\n",
            "At step: 2488 training error: 0.7614801179925883\n",
            "At step: 2489 training error: 0.756382834922777\n",
            "At step: 2490 training error: 0.7572921085256583\n",
            "At step: 2491 training error: 0.7618852713206317\n",
            "At step: 2492 training error: 0.7534818885304313\n",
            "At step: 2493 training error: 0.7496762333836009\n",
            "At step: 2494 training error: 0.7490044910742667\n",
            "At step: 2495 training error: 0.7473429328844601\n",
            "At step: 2496 training error: 0.7426972828254818\n",
            "At step: 2497 training error: 0.7430605619947204\n",
            "At step: 2498 training error: 0.7447371927283197\n",
            "At step: 2499 training error: 0.7465536839050663\n",
            "At step: 2500 training error: 0.7455292805975808\n",
            "At step: 2501 training error: 0.746312804192536\n",
            "At step: 2502 training error: 0.7469371301823367\n",
            "At step: 2503 training error: 0.7372123613800782\n",
            "At step: 2504 training error: 0.7403024174376529\n",
            "At step: 2505 training error: 0.7388812450443472\n",
            "At step: 2506 training error: 0.7292208923826382\n",
            "At step: 2507 training error: 0.7355101349674101\n",
            "At step: 2508 training error: 0.7333388440512197\n",
            "At step: 2509 training error: 0.7347429497432182\n",
            "At step: 2510 training error: 0.7383194788516633\n",
            "At step: 2511 training error: 0.7405853302887122\n",
            "At step: 2512 training error: 0.7398565509028725\n",
            "At step: 2513 training error: 0.7497717549573677\n",
            "At step: 2514 training error: 0.7455066349469888\n",
            "At step: 2515 training error: 0.7467043008280503\n",
            "At step: 2516 training error: 0.7433247034783257\n",
            "At step: 2517 training error: 0.748384773643795\n",
            "At step: 2518 training error: 0.7417333397371928\n",
            "At step: 2519 training error: 0.7453917992241857\n",
            "At step: 2520 training error: 0.7483949473274878\n",
            "At step: 2521 training error: 0.7521256044605868\n",
            "At step: 2522 training error: 0.7474024786048953\n",
            "At step: 2523 training error: 0.7528350955697374\n",
            "At step: 2524 training error: 0.7496275696664041\n",
            "At step: 2525 training error: 0.7461541115180584\n",
            "At step: 2526 training error: 0.7519681132427976\n",
            "At step: 2527 training error: 0.7517848349009384\n",
            "At step: 2528 training error: 0.7509358189169469\n",
            "At step: 2529 training error: 0.7457571718832594\n",
            "At step: 2530 training error: 0.7446134042461285\n",
            "At step: 2531 training error: 0.749702698205613\n",
            "At step: 2532 training error: 0.7469251860274702\n",
            "At step: 2533 training error: 0.7525675475334287\n",
            "At step: 2534 training error: 0.7518158071506771\n",
            "At step: 2535 training error: 0.7553670692897044\n",
            "At step: 2536 training error: 0.7591624353091482\n",
            "At step: 2537 training error: 0.7560083473271129\n",
            "At step: 2538 training error: 0.7623038119071973\n",
            "At step: 2539 training error: 0.7604306276106988\n",
            "At step: 2540 training error: 0.765152696633805\n",
            "At step: 2541 training error: 0.7636073205189338\n",
            "At step: 2542 training error: 0.7636940309073867\n",
            "At step: 2543 training error: 0.7642563059993471\n",
            "At step: 2544 training error: 0.7556443314293623\n",
            "At step: 2545 training error: 0.7559795282171419\n",
            "At step: 2546 training error: 0.7476848461468971\n",
            "At step: 2547 training error: 0.7484105371551575\n",
            "At step: 2548 training error: 0.7498126277488455\n",
            "At step: 2549 training error: 0.7503837446349946\n",
            "At step: 2550 training error: 0.7506069307269343\n",
            "At step: 2551 training error: 0.7562337608631416\n",
            "At step: 2552 training error: 0.7510102159505941\n",
            "At step: 2553 training error: 0.7564289825618093\n",
            "At step: 2554 training error: 0.7606762114817176\n",
            "At step: 2555 training error: 0.7598897802316011\n",
            "At step: 2556 training error: 0.7655197185748817\n",
            "At step: 2557 training error: 0.7655378870242402\n",
            "At step: 2558 training error: 0.7634922583196931\n",
            "At step: 2559 training error: 0.7542984304970393\n",
            "At step: 2560 training error: 0.7514111341049018\n",
            "At step: 2561 training error: 0.7580751877133962\n",
            "At step: 2562 training error: 0.7549562225379383\n",
            "At step: 2563 training error: 0.754137017341975\n",
            "At step: 2564 training error: 0.7526769541158357\n",
            "At step: 2565 training error: 0.7454633577096466\n",
            "At step: 2566 training error: 0.7468278252320144\n",
            "At step: 2567 training error: 0.7474271708764672\n",
            "At step: 2568 training error: 0.7502924808522455\n",
            "At step: 2569 training error: 0.750970913495512\n",
            "At step: 2570 training error: 0.7498040833405074\n",
            "At step: 2571 training error: 0.7483915875443781\n",
            "At step: 2572 training error: 0.7401251275795769\n",
            "At step: 2573 training error: 0.7366399658823438\n",
            "At step: 2574 training error: 0.7449211118984794\n",
            "At step: 2575 training error: 0.7506158250347008\n",
            "At step: 2576 training error: 0.7442883151555156\n",
            "At step: 2577 training error: 0.7492255974575835\n",
            "At step: 2578 training error: 0.752073864592802\n",
            "At step: 2579 training error: 0.7539296834842282\n",
            "At step: 2580 training error: 0.7502716736531646\n",
            "At step: 2581 training error: 0.7491916941771418\n",
            "At step: 2582 training error: 0.7445013980659697\n",
            "At step: 2583 training error: 0.7499178327879377\n",
            "At step: 2584 training error: 0.7409936663887099\n",
            "At step: 2585 training error: 0.7381601309395835\n",
            "At step: 2586 training error: 0.7391419302597102\n",
            "At step: 2587 training error: 0.7505738714170105\n",
            "At step: 2588 training error: 0.7516452992274303\n",
            "At step: 2589 training error: 0.7450782353014732\n",
            "At step: 2590 training error: 0.7451645366177126\n",
            "At step: 2591 training error: 0.7367879885134588\n",
            "At step: 2592 training error: 0.7395592270070221\n",
            "At step: 2593 training error: 0.7435154351423124\n",
            "At step: 2594 training error: 0.7396651418056941\n",
            "At step: 2595 training error: 0.7322892278756218\n",
            "At step: 2596 training error: 0.7400266649321039\n",
            "At step: 2597 training error: 0.7400426965153776\n",
            "At step: 2598 training error: 0.7417654694692468\n",
            "At step: 2599 training error: 0.7437418341378178\n",
            "At step: 2600 training error: 0.7444172499303556\n",
            "At step: 2601 training error: 0.7459576355822275\n",
            "At step: 2602 training error: 0.7418443678924223\n",
            "At step: 2603 training error: 0.742823969812636\n",
            "At step: 2604 training error: 0.7354895956308055\n",
            "At step: 2605 training error: 0.7354926477947379\n",
            "At step: 2606 training error: 0.7430618388072269\n",
            "At step: 2607 training error: 0.7446160800831687\n",
            "At step: 2608 training error: 0.7398147779031137\n",
            "At step: 2609 training error: 0.7402895672052169\n",
            "At step: 2610 training error: 0.7429269857266232\n",
            "At step: 2611 training error: 0.7396691956548204\n",
            "At step: 2612 training error: 0.7430224201470869\n",
            "At step: 2613 training error: 0.7377888647842958\n",
            "At step: 2614 training error: 0.7487075578426344\n",
            "At step: 2615 training error: 0.7414823202136959\n",
            "At step: 2616 training error: 0.754279542802901\n",
            "At step: 2617 training error: 0.7596750175917826\n",
            "At step: 2618 training error: 0.7569652341621228\n",
            "At step: 2619 training error: 0.7605254029837024\n",
            "At step: 2620 training error: 0.7641634448008101\n",
            "At step: 2621 training error: 0.7572934928523727\n",
            "At step: 2622 training error: 0.7559765034208508\n",
            "At step: 2623 training error: 0.7502051112174607\n",
            "At step: 2624 training error: 0.7530406369121185\n",
            "At step: 2625 training error: 0.7580455267176239\n",
            "At step: 2626 training error: 0.7535139782179516\n",
            "At step: 2627 training error: 0.7526880204258845\n",
            "At step: 2628 training error: 0.7574142236110094\n",
            "At step: 2629 training error: 0.7551483767978111\n",
            "At step: 2630 training error: 0.7493866690770541\n",
            "At step: 2631 training error: 0.7533698209629458\n",
            "At step: 2632 training error: 0.7527045960875579\n",
            "At step: 2633 training error: 0.7548485736585631\n",
            "At step: 2634 training error: 0.7509732627521197\n",
            "At step: 2635 training error: 0.7516590795044984\n",
            "At step: 2636 training error: 0.7455662993957923\n",
            "At step: 2637 training error: 0.7561292842616102\n",
            "At step: 2638 training error: 0.7605312916878741\n",
            "At step: 2639 training error: 0.7599578626227538\n",
            "At step: 2640 training error: 0.7615047330774497\n",
            "At step: 2641 training error: 0.7605413527498233\n",
            "At step: 2642 training error: 0.7559944185485379\n",
            "At step: 2643 training error: 0.7553677807992877\n",
            "At step: 2644 training error: 0.7515152011735814\n",
            "At step: 2645 training error: 0.7485159648010062\n",
            "At step: 2646 training error: 0.7497064421745935\n",
            "At step: 2647 training error: 0.7559473205906194\n",
            "At step: 2648 training error: 0.7574416877648964\n",
            "At step: 2649 training error: 0.7556819538513402\n",
            "At step: 2650 training error: 0.7592500335184781\n",
            "At step: 2651 training error: 0.7584921077704291\n",
            "At step: 2652 training error: 0.7542957777646533\n",
            "At step: 2653 training error: 0.7555676881735991\n",
            "At step: 2654 training error: 0.7507176680716289\n",
            "At step: 2655 training error: 0.7424089744490842\n",
            "At step: 2656 training error: 0.7437823220772637\n",
            "At step: 2657 training error: 0.742289326873243\n",
            "At step: 2658 training error: 0.7339219169993267\n",
            "At step: 2659 training error: 0.7257041130746998\n",
            "At step: 2660 training error: 0.7272372197472438\n",
            "At step: 2661 training error: 0.731552892552909\n",
            "At step: 2662 training error: 0.7299432757599592\n",
            "At step: 2663 training error: 0.7277807226354053\n",
            "At step: 2664 training error: 0.7288894823309505\n",
            "At step: 2665 training error: 0.7368619209369525\n",
            "At step: 2666 training error: 0.7369549575809805\n",
            "At step: 2667 training error: 0.7373525136471456\n",
            "At step: 2668 training error: 0.7285646649148908\n",
            "At step: 2669 training error: 0.7283875555498368\n",
            "At step: 2670 training error: 0.7414658267967088\n",
            "At step: 2671 training error: 0.7343439944771412\n",
            "At step: 2672 training error: 0.7348131027278031\n",
            "At step: 2673 training error: 0.7249250493331438\n",
            "At step: 2674 training error: 0.7266273360088751\n",
            "At step: 2675 training error: 0.7280920078239663\n",
            "At step: 2676 training error: 0.7154342556251024\n",
            "At step: 2677 training error: 0.7194884141586579\n",
            "At step: 2678 training error: 0.7119342287269407\n",
            "At step: 2679 training error: 0.7121280808878963\n",
            "At step: 2680 training error: 0.7067833911414619\n",
            "At step: 2681 training error: 0.7026500248979461\n",
            "At step: 2682 training error: 0.7026831334177414\n",
            "At step: 2683 training error: 0.7090295534429767\n",
            "At step: 2684 training error: 0.7068327955045478\n",
            "At step: 2685 training error: 0.7124651278667975\n",
            "At step: 2686 training error: 0.7113918815886413\n",
            "At step: 2687 training error: 0.7105319814888393\n",
            "At step: 2688 training error: 0.7213173522078637\n",
            "At step: 2689 training error: 0.7329262120597402\n",
            "At step: 2690 training error: 0.7304096820489695\n",
            "At step: 2691 training error: 0.7289148197276497\n",
            "At step: 2692 training error: 0.727216104962727\n",
            "At step: 2693 training error: 0.730808967709161\n",
            "At step: 2694 training error: 0.7325185043153821\n",
            "At step: 2695 training error: 0.7260999566696332\n",
            "At step: 2696 training error: 0.7289472373954307\n",
            "At step: 2697 training error: 0.7174939389662858\n",
            "At step: 2698 training error: 0.7206552406882151\n",
            "At step: 2699 training error: 0.7250389708903455\n",
            "At step: 2700 training error: 0.724360965786235\n",
            "At step: 2701 training error: 0.7243642986229452\n",
            "At step: 2702 training error: 0.722930491747512\n",
            "At step: 2703 training error: 0.717399750693962\n",
            "At step: 2704 training error: 0.71740560934213\n",
            "At step: 2705 training error: 0.7094237146451624\n",
            "At step: 2706 training error: 0.7194604224392483\n",
            "At step: 2707 training error: 0.7211395967184886\n",
            "At step: 2708 training error: 0.7235805656165736\n",
            "At step: 2709 training error: 0.7213663444183841\n",
            "At step: 2710 training error: 0.7230896985083899\n",
            "At step: 2711 training error: 0.7271821278768347\n",
            "At step: 2712 training error: 0.7288274927272478\n",
            "At step: 2713 training error: 0.728736802990275\n",
            "At step: 2714 training error: 0.7283286159972608\n",
            "At step: 2715 training error: 0.7285112962268686\n",
            "At step: 2716 training error: 0.7245513300826066\n",
            "At step: 2717 training error: 0.7233044004557925\n",
            "At step: 2718 training error: 0.7280852076577562\n",
            "At step: 2719 training error: 0.7254772202641322\n",
            "At step: 2720 training error: 0.7247960057357007\n",
            "At step: 2721 training error: 0.7160633073567775\n",
            "At step: 2722 training error: 0.7208955642106074\n",
            "At step: 2723 training error: 0.7228035985852818\n",
            "At step: 2724 training error: 0.7292722428146095\n",
            "At step: 2725 training error: 0.7378075031544229\n",
            "At step: 2726 training error: 0.744198406735705\n",
            "At step: 2727 training error: 0.7462412724203902\n",
            "At step: 2728 training error: 0.7466179250162718\n",
            "At step: 2729 training error: 0.7462892482328579\n",
            "At step: 2730 training error: 0.7439349391271568\n",
            "At step: 2731 training error: 0.7412404718480009\n",
            "At step: 2732 training error: 0.7326962148509719\n",
            "At step: 2733 training error: 0.737480327978239\n",
            "At step: 2734 training error: 0.7398359083231604\n",
            "At step: 2735 training error: 0.7429808811396891\n",
            "At step: 2736 training error: 0.7377522764484994\n",
            "At step: 2737 training error: 0.7397821539798595\n",
            "At step: 2738 training error: 0.7452651311142697\n",
            "At step: 2739 training error: 0.7459641502643903\n",
            "At step: 2740 training error: 0.7451673838468176\n",
            "At step: 2741 training error: 0.7407142360295065\n",
            "At step: 2742 training error: 0.7428284399145717\n",
            "At step: 2743 training error: 0.7335518390717628\n",
            "At step: 2744 training error: 0.7243557978348333\n",
            "At step: 2745 training error: 0.717489979017905\n",
            "At step: 2746 training error: 0.7337728997182018\n",
            "At step: 2747 training error: 0.7346846867797666\n",
            "At step: 2748 training error: 0.7307267667353344\n",
            "At step: 2749 training error: 0.7227467874514839\n",
            "At step: 2750 training error: 0.7178984713405141\n",
            "At step: 2751 training error: 0.7168141225311865\n",
            "At step: 2752 training error: 0.7144677171733366\n",
            "At step: 2753 training error: 0.7207593831957673\n",
            "At step: 2754 training error: 0.7191663317735822\n",
            "At step: 2755 training error: 0.7182964155876777\n",
            "At step: 2756 training error: 0.7112730588106295\n",
            "At step: 2757 training error: 0.70884220537264\n",
            "At step: 2758 training error: 0.7046629490160771\n",
            "At step: 2759 training error: 0.7019657725434785\n",
            "At step: 2760 training error: 0.7125594274587761\n",
            "At step: 2761 training error: 0.7119218113623499\n",
            "At step: 2762 training error: 0.7145733866890663\n",
            "At step: 2763 training error: 0.718992093323599\n",
            "At step: 2764 training error: 0.7173620109258454\n",
            "At step: 2765 training error: 0.7154688636435032\n",
            "At step: 2766 training error: 0.7141384357174931\n",
            "At step: 2767 training error: 0.7090758731322133\n",
            "At step: 2768 training error: 0.706354616866411\n",
            "At step: 2769 training error: 0.7008795786142082\n",
            "At step: 2770 training error: 0.7053616000994544\n",
            "At step: 2771 training error: 0.7108300503366529\n",
            "At step: 2772 training error: 0.7201345818735185\n",
            "At step: 2773 training error: 0.725408473304653\n",
            "At step: 2774 training error: 0.7243624812324139\n",
            "At step: 2775 training error: 0.7240022833790192\n",
            "At step: 2776 training error: 0.7245163144941652\n",
            "At step: 2777 training error: 0.7330379102225786\n",
            "At step: 2778 training error: 0.73058270074901\n",
            "At step: 2779 training error: 0.7407796824314279\n",
            "At step: 2780 training error: 0.7473066614096753\n",
            "At step: 2781 training error: 0.7487468275537145\n",
            "At step: 2782 training error: 0.7434298527246909\n",
            "At step: 2783 training error: 0.7454511873231668\n",
            "At step: 2784 training error: 0.7530837216302663\n",
            "At step: 2785 training error: 0.7457476734326247\n",
            "At step: 2786 training error: 0.7462548504638222\n",
            "At step: 2787 training error: 0.7443914703593911\n",
            "At step: 2788 training error: 0.7440269648306372\n",
            "At step: 2789 training error: 0.7460084549544564\n",
            "At step: 2790 training error: 0.7286866481845731\n",
            "At step: 2791 training error: 0.7332829991278818\n",
            "At step: 2792 training error: 0.7324402810655368\n",
            "At step: 2793 training error: 0.728375838376521\n",
            "At step: 2794 training error: 0.7342297537574445\n",
            "At step: 2795 training error: 0.7283696136069878\n",
            "At step: 2796 training error: 0.7352509536335536\n",
            "At step: 2797 training error: 0.7401992370891359\n",
            "At step: 2798 training error: 0.7304427897929889\n",
            "At step: 2799 training error: 0.7363623485573512\n",
            "At step: 2800 training error: 0.7297941308969712\n",
            "At step: 2801 training error: 0.7316937690579621\n",
            "At step: 2802 training error: 0.7247630459622021\n",
            "At step: 2803 training error: 0.7094620885908391\n",
            "At step: 2804 training error: 0.7086161600439556\n",
            "At step: 2805 training error: 0.7123644354225664\n",
            "At step: 2806 training error: 0.7101480705379327\n",
            "At step: 2807 training error: 0.7131623599172682\n",
            "At step: 2808 training error: 0.7109045565629178\n",
            "At step: 2809 training error: 0.7113007722962278\n",
            "At step: 2810 training error: 0.720792973891376\n",
            "At step: 2811 training error: 0.7222130264707565\n",
            "At step: 2812 training error: 0.7412063839522532\n",
            "At step: 2813 training error: 0.7438231721284216\n",
            "At step: 2814 training error: 0.742978625588921\n",
            "At step: 2815 training error: 0.7437243773550932\n",
            "At step: 2816 training error: 0.7403060554187041\n",
            "At step: 2817 training error: 0.744442078955303\n",
            "At step: 2818 training error: 0.7484131233800613\n",
            "At step: 2819 training error: 0.7507805289534834\n",
            "At step: 2820 training error: 0.7479443788528335\n",
            "At step: 2821 training error: 0.7562615303078027\n",
            "At step: 2822 training error: 0.763577722793863\n",
            "At step: 2823 training error: 0.7570525123276515\n",
            "At step: 2824 training error: 0.763852123506739\n",
            "At step: 2825 training error: 0.756927603223501\n",
            "At step: 2826 training error: 0.7514244879452853\n",
            "At step: 2827 training error: 0.7546923869912923\n",
            "At step: 2828 training error: 0.7512439697086607\n",
            "At step: 2829 training error: 0.7303002224913727\n",
            "At step: 2830 training error: 0.7411450285576121\n",
            "At step: 2831 training error: 0.742169699804603\n",
            "At step: 2832 training error: 0.7424932511445763\n",
            "At step: 2833 training error: 0.7372767417586286\n",
            "At step: 2834 training error: 0.7355530379843408\n",
            "At step: 2835 training error: 0.7317634112194595\n",
            "At step: 2836 training error: 0.737834810230039\n",
            "At step: 2837 training error: 0.7317813636894099\n",
            "At step: 2838 training error: 0.731226446828297\n",
            "At step: 2839 training error: 0.724700655171447\n",
            "At step: 2840 training error: 0.7320210771125708\n",
            "At step: 2841 training error: 0.7350781650883047\n",
            "At step: 2842 training error: 0.7382258346551613\n",
            "At step: 2843 training error: 0.7319542856635743\n",
            "At step: 2844 training error: 0.7397951473336982\n",
            "At step: 2845 training error: 0.7342969564108707\n",
            "At step: 2846 training error: 0.7419826339680764\n",
            "At step: 2847 training error: 0.7430493986143449\n",
            "At step: 2848 training error: 0.7367761313426179\n",
            "At step: 2849 training error: 0.7473521750937163\n",
            "At step: 2850 training error: 0.7341961405261881\n",
            "At step: 2851 training error: 0.7362041028735583\n",
            "At step: 2852 training error: 0.7346862598904574\n",
            "At step: 2853 training error: 0.727666734529894\n",
            "At step: 2854 training error: 0.7328019908864862\n",
            "At step: 2855 training error: 0.7247343478359604\n",
            "At step: 2856 training error: 0.7253768639105127\n",
            "At step: 2857 training error: 0.723107291640517\n",
            "At step: 2858 training error: 0.7207554059771222\n",
            "At step: 2859 training error: 0.7334278656581302\n",
            "At step: 2860 training error: 0.7302491266100709\n",
            "At step: 2861 training error: 0.7354911465088997\n",
            "At step: 2862 training error: 0.7231993950090204\n",
            "At step: 2863 training error: 0.7296887606672837\n",
            "At step: 2864 training error: 0.7291191188480841\n",
            "At step: 2865 training error: 0.732200328551502\n",
            "At step: 2866 training error: 0.7235118039505816\n",
            "At step: 2867 training error: 0.7306658309598136\n",
            "At step: 2868 training error: 0.7309916480268538\n",
            "At step: 2869 training error: 0.7405124789986647\n",
            "At step: 2870 training error: 0.7374420821812607\n",
            "At step: 2871 training error: 0.735300419780625\n",
            "At step: 2872 training error: 0.7349622395272037\n",
            "At step: 2873 training error: 0.7337050879073244\n",
            "At step: 2874 training error: 0.7299803900936186\n",
            "At step: 2875 training error: 0.718412938595109\n",
            "At step: 2876 training error: 0.7144838841486619\n",
            "At step: 2877 training error: 0.7137550780519122\n",
            "At step: 2878 training error: 0.7174977118185655\n",
            "At step: 2879 training error: 0.7262164361610137\n",
            "At step: 2880 training error: 0.7220866290104111\n",
            "At step: 2881 training error: 0.724596697728892\n",
            "At step: 2882 training error: 0.7298247882507358\n",
            "At step: 2883 training error: 0.7284873690841003\n",
            "At step: 2884 training error: 0.7275289850013649\n",
            "At step: 2885 training error: 0.7277567907441098\n",
            "At step: 2886 training error: 0.7260185671274131\n",
            "At step: 2887 training error: 0.7152214142847875\n",
            "At step: 2888 training error: 0.719713398281273\n",
            "At step: 2889 training error: 0.7204659897304637\n",
            "At step: 2890 training error: 0.7150228263518298\n",
            "At step: 2891 training error: 0.719309358096657\n",
            "At step: 2892 training error: 0.7255727670789549\n",
            "At step: 2893 training error: 0.7195973537559079\n",
            "At step: 2894 training error: 0.7236392103744352\n",
            "At step: 2895 training error: 0.727222655886937\n",
            "At step: 2896 training error: 0.7324214963318549\n",
            "At step: 2897 training error: 0.731203339044803\n",
            "At step: 2898 training error: 0.7293841845407619\n",
            "At step: 2899 training error: 0.7267124794998122\n",
            "At step: 2900 training error: 0.7214143213067193\n",
            "At step: 2901 training error: 0.7182175725993137\n",
            "At step: 2902 training error: 0.7181567569869554\n",
            "At step: 2903 training error: 0.7224696163328579\n",
            "At step: 2904 training error: 0.7147633175779321\n",
            "At step: 2905 training error: 0.7217653528449508\n",
            "At step: 2906 training error: 0.7172443977081252\n",
            "At step: 2907 training error: 0.7144288608579291\n",
            "At step: 2908 training error: 0.722613336925684\n",
            "At step: 2909 training error: 0.7260009475270326\n",
            "At step: 2910 training error: 0.7193890280594295\n",
            "At step: 2911 training error: 0.7141911361499068\n",
            "At step: 2912 training error: 0.7140527178728432\n",
            "At step: 2913 training error: 0.7229865874581689\n",
            "At step: 2914 training error: 0.7090925733384646\n",
            "At step: 2915 training error: 0.7121418156122444\n",
            "At step: 2916 training error: 0.7144044592245342\n",
            "At step: 2917 training error: 0.7096991987589635\n",
            "At step: 2918 training error: 0.7134395231775539\n",
            "At step: 2919 training error: 0.7187641808518284\n",
            "At step: 2920 training error: 0.7181927316354288\n",
            "At step: 2921 training error: 0.7217141898851294\n",
            "At step: 2922 training error: 0.7225754128365441\n",
            "At step: 2923 training error: 0.7337541324167627\n",
            "At step: 2924 training error: 0.7424034831065406\n",
            "At step: 2925 training error: 0.7411118965000155\n",
            "At step: 2926 training error: 0.7434641376214376\n",
            "At step: 2927 training error: 0.7404815926583089\n",
            "At step: 2928 training error: 0.7383429827578174\n",
            "At step: 2929 training error: 0.7394986137252878\n",
            "At step: 2930 training error: 0.7343214091191711\n",
            "At step: 2931 training error: 0.7403756441409931\n",
            "At step: 2932 training error: 0.744575176587164\n",
            "At step: 2933 training error: 0.7423844600913018\n",
            "At step: 2934 training error: 0.7412580425437189\n",
            "At step: 2935 training error: 0.7455048002105198\n",
            "At step: 2936 training error: 0.7373697585955183\n",
            "At step: 2937 training error: 0.7421422062388723\n",
            "At step: 2938 training error: 0.7421464523790582\n",
            "At step: 2939 training error: 0.7413274638079952\n",
            "At step: 2940 training error: 0.7384590309892501\n",
            "At step: 2941 training error: 0.7449483389988028\n",
            "At step: 2942 training error: 0.7373521344673117\n",
            "At step: 2943 training error: 0.7285609799349344\n",
            "At step: 2944 training error: 0.7369820950247296\n",
            "At step: 2945 training error: 0.736845474360889\n",
            "At step: 2946 training error: 0.7266687050826655\n",
            "At step: 2947 training error: 0.7287013481059794\n",
            "At step: 2948 training error: 0.7279147408162013\n",
            "At step: 2949 training error: 0.7377702741383115\n",
            "At step: 2950 training error: 0.7325296465271047\n",
            "At step: 2951 training error: 0.7256288988066102\n",
            "At step: 2952 training error: 0.7238041104516366\n",
            "At step: 2953 training error: 0.7128489244634796\n",
            "At step: 2954 training error: 0.7160134034392345\n",
            "At step: 2955 training error: 0.7167502045903944\n",
            "At step: 2956 training error: 0.7197846081036514\n",
            "At step: 2957 training error: 0.7123567355190107\n",
            "At step: 2958 training error: 0.7079666952908074\n",
            "At step: 2959 training error: 0.7062271257457992\n",
            "At step: 2960 training error: 0.715535661909909\n",
            "At step: 2961 training error: 0.706489762196593\n",
            "At step: 2962 training error: 0.7040032553730425\n",
            "At step: 2963 training error: 0.7133690095149245\n",
            "At step: 2964 training error: 0.7054884745912695\n",
            "At step: 2965 training error: 0.7081726727031696\n",
            "At step: 2966 training error: 0.7062179352716301\n",
            "At step: 2967 training error: 0.7093808608830142\n",
            "At step: 2968 training error: 0.7082138100430984\n",
            "At step: 2969 training error: 0.7124007283114444\n",
            "At step: 2970 training error: 0.7128562314857898\n",
            "At step: 2971 training error: 0.7148758179529947\n",
            "At step: 2972 training error: 0.7118023956532492\n",
            "At step: 2973 training error: 0.7139514571208301\n",
            "At step: 2974 training error: 0.7215045689188755\n",
            "At step: 2975 training error: 0.7172623948409299\n",
            "At step: 2976 training error: 0.7228445601376465\n",
            "At step: 2977 training error: 0.7198016389866956\n",
            "At step: 2978 training error: 0.7206498811858136\n",
            "At step: 2979 training error: 0.7289982137047482\n",
            "At step: 2980 training error: 0.7209023920019634\n",
            "At step: 2981 training error: 0.7178770245663698\n",
            "At step: 2982 training error: 0.7069071006417651\n",
            "At step: 2983 training error: 0.7039099147424107\n",
            "At step: 2984 training error: 0.7132002748562947\n",
            "At step: 2985 training error: 0.7189931129313336\n",
            "At step: 2986 training error: 0.724016665950328\n",
            "At step: 2987 training error: 0.723810250467045\n",
            "At step: 2988 training error: 0.7195347240620249\n",
            "At step: 2989 training error: 0.7198490438483434\n",
            "At step: 2990 training error: 0.7183776408445469\n",
            "At step: 2991 training error: 0.718233944201532\n",
            "At step: 2992 training error: 0.7178826351234893\n",
            "At step: 2993 training error: 0.7138912919787151\n",
            "At step: 2994 training error: 0.7126426663258726\n",
            "At step: 2995 training error: 0.708293834660766\n",
            "At step: 2996 training error: 0.7023090923159481\n",
            "At step: 2997 training error: 0.7030786780778167\n",
            "At step: 2998 training error: 0.7037075185439309\n",
            "At step: 2999 training error: 0.7099335713105566\n",
            "At step: 3000 training error: 0.7104931887920282\n",
            "At step: 3001 training error: 0.6966921135506052\n",
            "At step: 3002 training error: 0.6954826710692923\n",
            "At step: 3003 training error: 0.7009192043672204\n",
            "At step: 3004 training error: 0.7013501402818988\n",
            "At step: 3005 training error: 0.7050620896260258\n",
            "At step: 3006 training error: 0.7062529012454866\n",
            "At step: 3007 training error: 0.7110570950061043\n",
            "At step: 3008 training error: 0.7071075104414987\n",
            "At step: 3009 training error: 0.7108575955850032\n",
            "At step: 3010 training error: 0.7087240011891407\n",
            "At step: 3011 training error: 0.7008347296321294\n",
            "At step: 3012 training error: 0.7019517232800779\n",
            "At step: 3013 training error: 0.7096894718873414\n",
            "At step: 3014 training error: 0.7147809657389357\n",
            "At step: 3015 training error: 0.7158056746928378\n",
            "At step: 3016 training error: 0.7083279650467603\n",
            "At step: 3017 training error: 0.7162484326941811\n",
            "At step: 3018 training error: 0.7149029217295697\n",
            "At step: 3019 training error: 0.7154926855331445\n",
            "At step: 3020 training error: 0.7162615450578351\n",
            "At step: 3021 training error: 0.7080250278881847\n",
            "At step: 3022 training error: 0.7066375403311699\n",
            "At step: 3023 training error: 0.7108736766625303\n",
            "At step: 3024 training error: 0.7055077849843431\n",
            "At step: 3025 training error: 0.7008005998868756\n",
            "At step: 3026 training error: 0.702606667461741\n",
            "At step: 3027 training error: 0.7015755977344675\n",
            "At step: 3028 training error: 0.7051644177507501\n",
            "At step: 3029 training error: 0.7099845870106638\n",
            "At step: 3030 training error: 0.7062242760643835\n",
            "At step: 3031 training error: 0.7034688758357982\n",
            "At step: 3032 training error: 0.7055547826057589\n",
            "At step: 3033 training error: 0.7116878431761938\n",
            "At step: 3034 training error: 0.714857280876748\n",
            "At step: 3035 training error: 0.719264464369758\n",
            "At step: 3036 training error: 0.7260817208890774\n",
            "At step: 3037 training error: 0.7261080336614512\n",
            "At step: 3038 training error: 0.7271125480500289\n",
            "At step: 3039 training error: 0.720164898444303\n",
            "At step: 3040 training error: 0.7182645706295585\n",
            "At step: 3041 training error: 0.7182912426798611\n",
            "At step: 3042 training error: 0.7246577303565711\n",
            "At step: 3043 training error: 0.7284516322670807\n",
            "At step: 3044 training error: 0.7235609761737016\n",
            "At step: 3045 training error: 0.7243907493344527\n",
            "At step: 3046 training error: 0.721072674056785\n",
            "At step: 3047 training error: 0.727008205914402\n",
            "At step: 3048 training error: 0.734718567029291\n",
            "At step: 3049 training error: 0.7368797056855177\n",
            "At step: 3050 training error: 0.7380700966853858\n",
            "At step: 3051 training error: 0.7349719191987208\n",
            "At step: 3052 training error: 0.7294150933036727\n",
            "At step: 3053 training error: 0.7375682071220946\n",
            "At step: 3054 training error: 0.7309310696770603\n",
            "At step: 3055 training error: 0.739946125250705\n",
            "At step: 3056 training error: 0.738059930839695\n",
            "At step: 3057 training error: 0.7473399861944349\n",
            "At step: 3058 training error: 0.745167077297068\n",
            "At step: 3059 training error: 0.7434128605719155\n",
            "At step: 3060 training error: 0.7459668943692214\n",
            "At step: 3061 training error: 0.7517870694009195\n",
            "At step: 3062 training error: 0.7515378775266527\n",
            "At step: 3063 training error: 0.7553879284598748\n",
            "At step: 3064 training error: 0.7532394251782083\n",
            "At step: 3065 training error: 0.7427117447050205\n",
            "At step: 3066 training error: 0.7483069335291594\n",
            "At step: 3067 training error: 0.7464357626404884\n",
            "At step: 3068 training error: 0.7457270059261493\n",
            "At step: 3069 training error: 0.742643058043745\n",
            "At step: 3070 training error: 0.7461073351958959\n",
            "At step: 3071 training error: 0.7451783086648689\n",
            "At step: 3072 training error: 0.7439818441349545\n",
            "At step: 3073 training error: 0.7474607006855477\n",
            "At step: 3074 training error: 0.7454557327746432\n",
            "At step: 3075 training error: 0.740395550835401\n",
            "At step: 3076 training error: 0.7445629978885341\n",
            "At step: 3077 training error: 0.7347547096901439\n",
            "At step: 3078 training error: 0.7301845538794287\n",
            "At step: 3079 training error: 0.7304418123051017\n",
            "At step: 3080 training error: 0.7319679115908266\n",
            "At step: 3081 training error: 0.7257090661474275\n",
            "At step: 3082 training error: 0.7273572472235442\n",
            "At step: 3083 training error: 0.7299212096712743\n",
            "At step: 3084 training error: 0.7188729428738218\n",
            "At step: 3085 training error: 0.7090574256662097\n",
            "At step: 3086 training error: 0.6984716254873202\n",
            "At step: 3087 training error: 0.7052099576051549\n",
            "At step: 3088 training error: 0.7137406138121363\n",
            "At step: 3089 training error: 0.7175211777696651\n",
            "At step: 3090 training error: 0.7210177936224067\n",
            "At step: 3091 training error: 0.7214837643225984\n",
            "At step: 3092 training error: 0.7226075239647871\n",
            "At step: 3093 training error: 0.7107994340672572\n",
            "At step: 3094 training error: 0.704984160911958\n",
            "At step: 3095 training error: 0.7089138870391778\n",
            "At step: 3096 training error: 0.7083247800276264\n",
            "At step: 3097 training error: 0.7094167322103585\n",
            "At step: 3098 training error: 0.7195311129964252\n",
            "At step: 3099 training error: 0.706057937356211\n",
            "At step: 3100 training error: 0.7094243529638824\n",
            "At step: 3101 training error: 0.7095192291133007\n",
            "At step: 3102 training error: 0.7116567918417891\n",
            "At step: 3103 training error: 0.7157616237779215\n",
            "At step: 3104 training error: 0.7238839713000231\n",
            "At step: 3105 training error: 0.7167406473669355\n",
            "At step: 3106 training error: 0.7211655648136794\n",
            "At step: 3107 training error: 0.7312597786284788\n",
            "At step: 3108 training error: 0.7330160916505941\n",
            "At step: 3109 training error: 0.7307199298258501\n",
            "At step: 3110 training error: 0.7363547082712191\n",
            "At step: 3111 training error: 0.735313283762909\n",
            "At step: 3112 training error: 0.7371334922891625\n",
            "At step: 3113 training error: 0.7456930702006581\n",
            "At step: 3114 training error: 0.7498508415441612\n",
            "At step: 3115 training error: 0.7563013306334317\n",
            "At step: 3116 training error: 0.7482934329271688\n",
            "At step: 3117 training error: 0.7404256188378797\n",
            "At step: 3118 training error: 0.7341111765293982\n",
            "At step: 3119 training error: 0.7331353851568984\n",
            "At step: 3120 training error: 0.7302093705536166\n",
            "At step: 3121 training error: 0.7263528565545213\n",
            "At step: 3122 training error: 0.7276023488648976\n",
            "At step: 3123 training error: 0.726911436641804\n",
            "At step: 3124 training error: 0.7265344251375883\n",
            "At step: 3125 training error: 0.7211082608064445\n",
            "At step: 3126 training error: 0.7128382605163641\n",
            "At step: 3127 training error: 0.7140565390876182\n",
            "At step: 3128 training error: 0.710541734792788\n",
            "At step: 3129 training error: 0.7127157060173033\n",
            "At step: 3130 training error: 0.7110839539302549\n",
            "At step: 3131 training error: 0.7175392281963817\n",
            "At step: 3132 training error: 0.7199539098915825\n",
            "At step: 3133 training error: 0.7247443097768655\n",
            "At step: 3134 training error: 0.7267479790599368\n",
            "At step: 3135 training error: 0.7273659767008478\n",
            "At step: 3136 training error: 0.7291788063918793\n",
            "At step: 3137 training error: 0.7303217169853188\n",
            "At step: 3138 training error: 0.7212528131575208\n",
            "At step: 3139 training error: 0.7250646173145875\n",
            "At step: 3140 training error: 0.7255628648262056\n",
            "At step: 3141 training error: 0.719401762074382\n",
            "At step: 3142 training error: 0.7213717982970984\n",
            "At step: 3143 training error: 0.718637835573837\n",
            "At step: 3144 training error: 0.7155211454222676\n",
            "At step: 3145 training error: 0.7195915933467978\n",
            "At step: 3146 training error: 0.7290999174567406\n",
            "At step: 3147 training error: 0.7301828958261867\n",
            "At step: 3148 training error: 0.7270585100971655\n",
            "At step: 3149 training error: 0.7166237875674341\n",
            "At step: 3150 training error: 0.7276944947135756\n",
            "At step: 3151 training error: 0.7227866321948536\n",
            "At step: 3152 training error: 0.7276821359499388\n",
            "At step: 3153 training error: 0.7173931544326182\n",
            "At step: 3154 training error: 0.7159987957955258\n",
            "At step: 3155 training error: 0.7165492278499238\n",
            "At step: 3156 training error: 0.7150424935925165\n",
            "At step: 3157 training error: 0.7196829651804111\n",
            "At step: 3158 training error: 0.7337688441337967\n",
            "At step: 3159 training error: 0.7280657935135854\n",
            "At step: 3160 training error: 0.7313167990788298\n",
            "At step: 3161 training error: 0.7291909941268583\n",
            "At step: 3162 training error: 0.7315171086149219\n",
            "At step: 3163 training error: 0.7323248795233845\n",
            "At step: 3164 training error: 0.7377958533125131\n",
            "At step: 3165 training error: 0.7315083854306894\n",
            "At step: 3166 training error: 0.7300860812604241\n",
            "At step: 3167 training error: 0.7226497834962113\n",
            "At step: 3168 training error: 0.7154665744074247\n",
            "At step: 3169 training error: 0.7132574319465753\n",
            "At step: 3170 training error: 0.7113575642027514\n",
            "At step: 3171 training error: 0.7172420747030348\n",
            "At step: 3172 training error: 0.7291613706438256\n",
            "At step: 3173 training error: 0.7273972453762805\n",
            "At step: 3174 training error: 0.7278676380224194\n",
            "At step: 3175 training error: 0.7264962468821021\n",
            "At step: 3176 training error: 0.7261916684013273\n",
            "At step: 3177 training error: 0.7248715349270887\n",
            "At step: 3178 training error: 0.7142493387370893\n",
            "At step: 3179 training error: 0.7093437825549587\n",
            "At step: 3180 training error: 0.7119877603342027\n",
            "At step: 3181 training error: 0.7086023781701067\n",
            "At step: 3182 training error: 0.7122131556653858\n",
            "At step: 3183 training error: 0.7107811025572788\n",
            "At step: 3184 training error: 0.7123613669636293\n",
            "At step: 3185 training error: 0.7190011543533157\n",
            "At step: 3186 training error: 0.7161361684584608\n",
            "At step: 3187 training error: 0.7214389804880705\n",
            "At step: 3188 training error: 0.7145537816942098\n",
            "At step: 3189 training error: 0.7105634579911244\n",
            "At step: 3190 training error: 0.7127929806225546\n",
            "At step: 3191 training error: 0.7103460271574952\n",
            "At step: 3192 training error: 0.7043515713928248\n",
            "At step: 3193 training error: 0.7036720106327686\n",
            "At step: 3194 training error: 0.7066659150734229\n",
            "At step: 3195 training error: 0.703435418532332\n",
            "At step: 3196 training error: 0.697898799632781\n",
            "At step: 3197 training error: 0.6890014491911687\n",
            "At step: 3198 training error: 0.6917988987003433\n",
            "At step: 3199 training error: 0.7005171061035398\n",
            "At step: 3200 training error: 0.7045949652203836\n",
            "At step: 3201 training error: 0.7087724361647949\n",
            "At step: 3202 training error: 0.7011023259979948\n",
            "At step: 3203 training error: 0.7057492492775901\n",
            "At step: 3204 training error: 0.7099360024430365\n",
            "At step: 3205 training error: 0.7133376735620488\n",
            "At step: 3206 training error: 0.7154068839899167\n",
            "At step: 3207 training error: 0.7155656171359553\n",
            "At step: 3208 training error: 0.7257547595926566\n",
            "At step: 3209 training error: 0.7207846282285919\n",
            "At step: 3210 training error: 0.7193432913053249\n",
            "At step: 3211 training error: 0.7094592639152728\n",
            "At step: 3212 training error: 0.7116787905294922\n",
            "At step: 3213 training error: 0.7126984973008539\n",
            "At step: 3214 training error: 0.710363866976476\n",
            "At step: 3215 training error: 0.7094042055798282\n",
            "At step: 3216 training error: 0.7146744002359817\n",
            "At step: 3217 training error: 0.716808332600337\n",
            "At step: 3218 training error: 0.7122076022180327\n",
            "At step: 3219 training error: 0.7153425027973057\n",
            "At step: 3220 training error: 0.7160149820235994\n",
            "At step: 3221 training error: 0.7178378446991754\n",
            "At step: 3222 training error: 0.7149250565133414\n",
            "At step: 3223 training error: 0.7078993328174289\n",
            "At step: 3224 training error: 0.7083254777821258\n",
            "At step: 3225 training error: 0.7151522640792914\n",
            "At step: 3226 training error: 0.7195462737540036\n",
            "At step: 3227 training error: 0.71430882569727\n",
            "At step: 3228 training error: 0.7161307334104053\n",
            "At step: 3229 training error: 0.7121331285548028\n",
            "At step: 3230 training error: 0.7139314742404951\n",
            "At step: 3231 training error: 0.7208185401563911\n",
            "At step: 3232 training error: 0.7113612339558838\n",
            "At step: 3233 training error: 0.7181733575616313\n",
            "At step: 3234 training error: 0.7127449145785629\n",
            "At step: 3235 training error: 0.7117282269415027\n",
            "At step: 3236 training error: 0.7104684874157484\n",
            "At step: 3237 training error: 0.7007877080853306\n",
            "At step: 3238 training error: 0.694062725428465\n",
            "At step: 3239 training error: 0.6927065180117309\n",
            "At step: 3240 training error: 0.701016011692559\n",
            "At step: 3241 training error: 0.7015612880261125\n",
            "At step: 3242 training error: 0.7032888910736199\n",
            "At step: 3243 training error: 0.703987158483284\n",
            "At step: 3244 training error: 0.70841638202115\n",
            "At step: 3245 training error: 0.7047196384290112\n",
            "At step: 3246 training error: 0.7063296519076524\n",
            "At step: 3247 training error: 0.7113333821017955\n",
            "At step: 3248 training error: 0.7151354978969922\n",
            "At step: 3249 training error: 0.7136566108953807\n",
            "At step: 3250 training error: 0.7145339357072114\n",
            "At step: 3251 training error: 0.7197210893420605\n",
            "At step: 3252 training error: 0.7151756247626295\n",
            "At step: 3253 training error: 0.7121264026854026\n",
            "At step: 3254 training error: 0.7104545135346858\n",
            "At step: 3255 training error: 0.7023717133616091\n",
            "At step: 3256 training error: 0.7003454680561382\n",
            "At step: 3257 training error: 0.6967676786740163\n",
            "At step: 3258 training error: 0.7021962943212483\n",
            "At step: 3259 training error: 0.7051536809970284\n",
            "At step: 3260 training error: 0.7128069772678938\n",
            "At step: 3261 training error: 0.7188514756488227\n",
            "At step: 3262 training error: 0.7089269009020998\n",
            "At step: 3263 training error: 0.7052501297772187\n",
            "At step: 3264 training error: 0.7076010354641327\n",
            "At step: 3265 training error: 0.7099744979626106\n",
            "At step: 3266 training error: 0.7088100517143299\n",
            "At step: 3267 training error: 0.7075522912694248\n",
            "At step: 3268 training error: 0.7110046959760781\n",
            "At step: 3269 training error: 0.7043876519703609\n",
            "At step: 3270 training error: 0.7066034855357959\n",
            "At step: 3271 training error: 0.7094800946037645\n",
            "At step: 3272 training error: 0.7114626671711715\n",
            "At step: 3273 training error: 0.7166951757095522\n",
            "At step: 3274 training error: 0.7189209726956438\n",
            "At step: 3275 training error: 0.7118129878764671\n",
            "At step: 3276 training error: 0.7090832677318091\n",
            "At step: 3277 training error: 0.7110130739751471\n",
            "At step: 3278 training error: 0.7124371803334566\n",
            "At step: 3279 training error: 0.7269371919163784\n",
            "At step: 3280 training error: 0.7269861044281681\n",
            "At step: 3281 training error: 0.7258388473730102\n",
            "At step: 3282 training error: 0.7249796029004291\n",
            "At step: 3283 training error: 0.721386387988493\n",
            "At step: 3284 training error: 0.724491134424978\n",
            "At step: 3285 training error: 0.7202061043786242\n",
            "At step: 3286 training error: 0.7145500299860533\n",
            "At step: 3287 training error: 0.7146291794020931\n",
            "At step: 3288 training error: 0.7119380807480828\n",
            "At step: 3289 training error: 0.7094731346170733\n",
            "At step: 3290 training error: 0.7054146294135178\n",
            "At step: 3291 training error: 0.7039825221434107\n",
            "At step: 3292 training error: 0.7035072296232294\n",
            "At step: 3293 training error: 0.7010390215825942\n",
            "At step: 3294 training error: 0.7047740537957671\n",
            "At step: 3295 training error: 0.7029813138903442\n",
            "At step: 3296 training error: 0.6957227401206513\n",
            "At step: 3297 training error: 0.6914242395426919\n",
            "At step: 3298 training error: 0.7021286309620063\n",
            "At step: 3299 training error: 0.7008575609425237\n",
            "At step: 3300 training error: 0.7049427156931269\n",
            "At step: 3301 training error: 0.7051414964716958\n",
            "At step: 3302 training error: 0.6865895927978064\n",
            "At step: 3303 training error: 0.6821999356319514\n",
            "At step: 3304 training error: 0.6914273654149197\n",
            "At step: 3305 training error: 0.6818596168338641\n",
            "At step: 3306 training error: 0.6903965509889126\n",
            "At step: 3307 training error: 0.6893253480428085\n",
            "At step: 3308 training error: 0.6984237721468987\n",
            "At step: 3309 training error: 0.7055774365071235\n",
            "At step: 3310 training error: 0.7106037925441643\n",
            "At step: 3311 training error: 0.7153532402888574\n",
            "At step: 3312 training error: 0.7077240708120803\n",
            "At step: 3313 training error: 0.7055916579256386\n",
            "At step: 3314 training error: 0.7105027865092223\n",
            "At step: 3315 training error: 0.7007602396072372\n",
            "At step: 3316 training error: 0.6990095829616779\n",
            "At step: 3317 training error: 0.7030228790855666\n",
            "At step: 3318 training error: 0.7096322342720013\n",
            "At step: 3319 training error: 0.7049512556120359\n",
            "At step: 3320 training error: 0.6951566026505408\n",
            "At step: 3321 training error: 0.6956065703775087\n",
            "At step: 3322 training error: 0.6927181116051541\n",
            "At step: 3323 training error: 0.6959703783422058\n",
            "At step: 3324 training error: 0.6923424494660233\n",
            "At step: 3325 training error: 0.6910503111980382\n",
            "At step: 3326 training error: 0.6930169466734649\n",
            "At step: 3327 training error: 0.6966328052999624\n",
            "At step: 3328 training error: 0.6979476548220891\n",
            "At step: 3329 training error: 0.694058070247008\n",
            "At step: 3330 training error: 0.6936312383951008\n",
            "At step: 3331 training error: 0.6951598448063719\n",
            "At step: 3332 training error: 0.7024356579405053\n",
            "At step: 3333 training error: 0.7044112270420513\n",
            "At step: 3334 training error: 0.7112999047590943\n",
            "At step: 3335 training error: 0.706963135143398\n",
            "At step: 3336 training error: 0.7102993903553212\n",
            "At step: 3337 training error: 0.7095893751934158\n",
            "At step: 3338 training error: 0.6956390303445871\n",
            "At step: 3339 training error: 0.6964261439241296\n",
            "At step: 3340 training error: 0.6939879353375159\n",
            "At step: 3341 training error: 0.6952385289694889\n",
            "At step: 3342 training error: 0.6901696407135045\n",
            "At step: 3343 training error: 0.6942321851028012\n",
            "At step: 3344 training error: 0.6911191765177052\n",
            "At step: 3345 training error: 0.6818444578492853\n",
            "At step: 3346 training error: 0.6862824694751488\n",
            "At step: 3347 training error: 0.6860477074947066\n",
            "At step: 3348 training error: 0.6975997151870383\n",
            "At step: 3349 training error: 0.7053198800295942\n",
            "At step: 3350 training error: 0.7079681188805602\n",
            "At step: 3351 training error: 0.7113410939408075\n",
            "At step: 3352 training error: 0.719506163031753\n",
            "At step: 3353 training error: 0.7221077088050977\n",
            "At step: 3354 training error: 0.7203095875224375\n",
            "At step: 3355 training error: 0.7170497138991556\n",
            "At step: 3356 training error: 0.7199634016021161\n",
            "At step: 3357 training error: 0.7153459106788758\n",
            "At step: 3358 training error: 0.717828440905989\n",
            "At step: 3359 training error: 0.7198132781479695\n",
            "At step: 3360 training error: 0.7259561851744032\n",
            "At step: 3361 training error: 0.7189468320127153\n",
            "At step: 3362 training error: 0.7122703582756623\n",
            "At step: 3363 training error: 0.7038009935349739\n",
            "At step: 3364 training error: 0.7019176009763549\n",
            "At step: 3365 training error: 0.7011181335982778\n",
            "At step: 3366 training error: 0.7042282046073506\n",
            "At step: 3367 training error: 0.7025723889586629\n",
            "At step: 3368 training error: 0.7015296184449902\n",
            "At step: 3369 training error: 0.703783526209514\n",
            "At step: 3370 training error: 0.71054922231757\n",
            "At step: 3371 training error: 0.7064330928970138\n",
            "At step: 3372 training error: 0.7143037568972977\n",
            "At step: 3373 training error: 0.7137757490771945\n",
            "At step: 3374 training error: 0.7230056741042145\n",
            "At step: 3375 training error: 0.7177062793449152\n",
            "At step: 3376 training error: 0.7300227540428829\n",
            "At step: 3377 training error: 0.7180472176593786\n",
            "At step: 3378 training error: 0.7093461043779011\n",
            "At step: 3379 training error: 0.707081074058567\n",
            "At step: 3380 training error: 0.7083881201008083\n",
            "At step: 3381 training error: 0.7013576831266123\n",
            "At step: 3382 training error: 0.7049419776497006\n",
            "At step: 3383 training error: 0.7049758222431972\n",
            "At step: 3384 training error: 0.7006053333790586\n",
            "At step: 3385 training error: 0.7080031121201019\n",
            "At step: 3386 training error: 0.7097983248689507\n",
            "At step: 3387 training error: 0.7059399249111942\n",
            "At step: 3388 training error: 0.6987489892872364\n",
            "At step: 3389 training error: 0.7030013042775811\n",
            "At step: 3390 training error: 0.7071759294578714\n",
            "At step: 3391 training error: 0.7019366001072553\n",
            "At step: 3392 training error: 0.7102654362278213\n",
            "At step: 3393 training error: 0.7166380624800048\n",
            "At step: 3394 training error: 0.7191143875921259\n",
            "At step: 3395 training error: 0.7133655541401378\n",
            "At step: 3396 training error: 0.7166216648297362\n",
            "At step: 3397 training error: 0.7108961886450211\n",
            "At step: 3398 training error: 0.7197979862805051\n",
            "At step: 3399 training error: 0.7089520828193557\n",
            "At step: 3400 training error: 0.7129836564219615\n",
            "At step: 3401 training error: 0.7162644972379352\n",
            "At step: 3402 training error: 0.7095672722910816\n",
            "At step: 3403 training error: 0.702112124354091\n",
            "At step: 3404 training error: 0.6910212021833883\n",
            "At step: 3405 training error: 0.6844309880595821\n",
            "At step: 3406 training error: 0.6851778021861971\n",
            "At step: 3407 training error: 0.676069018830196\n",
            "At step: 3408 training error: 0.6774148942516469\n",
            "At step: 3409 training error: 0.6766077657685008\n",
            "At step: 3410 training error: 0.6751333865663861\n",
            "At step: 3411 training error: 0.67289878160309\n",
            "At step: 3412 training error: 0.6729847093111068\n",
            "At step: 3413 training error: 0.6757772532665193\n",
            "At step: 3414 training error: 0.6749134774016748\n",
            "At step: 3415 training error: 0.6787274230293874\n",
            "At step: 3416 training error: 0.684537133978094\n",
            "At step: 3417 training error: 0.6813095417746506\n",
            "At step: 3418 training error: 0.6874553129100525\n",
            "At step: 3419 training error: 0.6863408261715931\n",
            "At step: 3420 training error: 0.6826735527092498\n",
            "At step: 3421 training error: 0.6864195104904226\n",
            "At step: 3422 training error: 0.6897918288470188\n",
            "At step: 3423 training error: 0.6952831757622764\n",
            "At step: 3424 training error: 0.6965606849464366\n",
            "At step: 3425 training error: 0.6922716597304099\n",
            "At step: 3426 training error: 0.6975859039356649\n",
            "At step: 3427 training error: 0.6924970959658926\n",
            "At step: 3428 training error: 0.6913637875857296\n",
            "At step: 3429 training error: 0.6972939303333159\n",
            "At step: 3430 training error: 0.6930734090451877\n",
            "At step: 3431 training error: 0.6922976720125833\n",
            "At step: 3432 training error: 0.6968689079008994\n",
            "At step: 3433 training error: 0.6937926964173753\n",
            "At step: 3434 training error: 0.7022044525220869\n",
            "At step: 3435 training error: 0.7028578141536895\n",
            "At step: 3436 training error: 0.7049988710739016\n",
            "At step: 3437 training error: 0.7063119484121513\n",
            "At step: 3438 training error: 0.6953920598462875\n",
            "At step: 3439 training error: 0.6944736025032346\n",
            "At step: 3440 training error: 0.6946413588279026\n",
            "At step: 3441 training error: 0.685108660387522\n",
            "At step: 3442 training error: 0.6882982886665688\n",
            "At step: 3443 training error: 0.6941652588285646\n",
            "At step: 3444 training error: 0.6941174718921266\n",
            "At step: 3445 training error: 0.6886013716269387\n",
            "At step: 3446 training error: 0.6854859037217085\n",
            "At step: 3447 training error: 0.6989150671193431\n",
            "At step: 3448 training error: 0.6956485353366161\n",
            "At step: 3449 training error: 0.6912769658762122\n",
            "At step: 3450 training error: 0.6879315224880944\n",
            "At step: 3451 training error: 0.6894626798016078\n",
            "At step: 3452 training error: 0.6880058080707359\n",
            "At step: 3453 training error: 0.6836570019613522\n",
            "At step: 3454 training error: 0.6849394456095426\n",
            "At step: 3455 training error: 0.6833447480924469\n",
            "At step: 3456 training error: 0.6850807737497986\n",
            "At step: 3457 training error: 0.6809892982105213\n",
            "At step: 3458 training error: 0.6866676587732693\n",
            "At step: 3459 training error: 0.6885145872869862\n",
            "At step: 3460 training error: 0.6823408682769772\n",
            "At step: 3461 training error: 0.6759251390890624\n",
            "At step: 3462 training error: 0.6866263413139625\n",
            "At step: 3463 training error: 0.6800084063399386\n",
            "At step: 3464 training error: 0.6833578938957151\n",
            "At step: 3465 training error: 0.6901498304275743\n",
            "At step: 3466 training error: 0.6978186220345899\n",
            "At step: 3467 training error: 0.701726214215417\n",
            "At step: 3468 training error: 0.6972668106396873\n",
            "At step: 3469 training error: 0.7050931490457516\n",
            "At step: 3470 training error: 0.7131458397533152\n",
            "At step: 3471 training error: 0.7088611737413146\n",
            "At step: 3472 training error: 0.7068655336690217\n",
            "At step: 3473 training error: 0.6992796863826337\n",
            "At step: 3474 training error: 0.7073962196586614\n",
            "At step: 3475 training error: 0.7107233460073082\n",
            "At step: 3476 training error: 0.7063845061575594\n",
            "At step: 3477 training error: 0.7153191176137347\n",
            "At step: 3478 training error: 0.7061480154502907\n",
            "At step: 3479 training error: 0.7059016319667237\n",
            "At step: 3480 training error: 0.7063318770759845\n",
            "At step: 3481 training error: 0.7129517633658045\n",
            "At step: 3482 training error: 0.7151139969998421\n",
            "At step: 3483 training error: 0.712671442741083\n",
            "At step: 3484 training error: 0.7092420278830528\n",
            "At step: 3485 training error: 0.7125150399926159\n",
            "At step: 3486 training error: 0.7036135529444691\n",
            "At step: 3487 training error: 0.7053818364639537\n",
            "At step: 3488 training error: 0.7008222272837963\n",
            "At step: 3489 training error: 0.6972416743712558\n",
            "At step: 3490 training error: 0.6938675697655262\n",
            "At step: 3491 training error: 0.6955544008789107\n",
            "At step: 3492 training error: 0.6901620064097616\n",
            "At step: 3493 training error: 0.6892271818283138\n",
            "At step: 3494 training error: 0.6911739471731642\n",
            "At step: 3495 training error: 0.6838818796211443\n",
            "At step: 3496 training error: 0.683078059011575\n",
            "At step: 3497 training error: 0.6849159388956901\n",
            "At step: 3498 training error: 0.690560770622009\n",
            "At step: 3499 training error: 0.6914956845801293\n",
            "At step: 3500 training error: 0.7002337405051251\n",
            "At step: 3501 training error: 0.7045684609489292\n",
            "At step: 3502 training error: 0.7060592617308314\n",
            "At step: 3503 training error: 0.7050018380307855\n",
            "At step: 3504 training error: 0.7108395245192156\n",
            "At step: 3505 training error: 0.702958749502405\n",
            "At step: 3506 training error: 0.7130690597997755\n",
            "At step: 3507 training error: 0.7062414955537341\n",
            "At step: 3508 training error: 0.7018304634640639\n",
            "At step: 3509 training error: 0.7018939299509471\n",
            "At step: 3510 training error: 0.7119917869497918\n",
            "At step: 3511 training error: 0.7098270318616651\n",
            "At step: 3512 training error: 0.7146051345610881\n",
            "At step: 3513 training error: 0.7147812285421404\n",
            "At step: 3514 training error: 0.7064762529917946\n",
            "At step: 3515 training error: 0.7013848573476851\n",
            "At step: 3516 training error: 0.6953466853546509\n",
            "At step: 3517 training error: 0.7001326747410475\n",
            "At step: 3518 training error: 0.694845288131236\n",
            "At step: 3519 training error: 0.6982044630784787\n",
            "At step: 3520 training error: 0.7038459398848257\n",
            "At step: 3521 training error: 0.7032036792399067\n",
            "At step: 3522 training error: 0.7001382399383514\n",
            "At step: 3523 training error: 0.6963949221559865\n",
            "At step: 3524 training error: 0.6949124076404677\n",
            "At step: 3525 training error: 0.6884646795985906\n",
            "At step: 3526 training error: 0.6876506432389397\n",
            "At step: 3527 training error: 0.6873209872082026\n",
            "At step: 3528 training error: 0.6890201432988048\n",
            "At step: 3529 training error: 0.6985025127011184\n",
            "At step: 3530 training error: 0.6970624342762263\n",
            "At step: 3531 training error: 0.6974932269261239\n",
            "At step: 3532 training error: 0.6927588564326501\n",
            "At step: 3533 training error: 0.6911444238067969\n",
            "At step: 3534 training error: 0.6918877143383247\n",
            "At step: 3535 training error: 0.6973598455590888\n",
            "At step: 3536 training error: 0.701746363271327\n",
            "At step: 3537 training error: 0.6953699622408558\n",
            "At step: 3538 training error: 0.6992388151482101\n",
            "At step: 3539 training error: 0.7005537194472429\n",
            "At step: 3540 training error: 0.7046417655258617\n",
            "At step: 3541 training error: 0.7081372342109771\n",
            "At step: 3542 training error: 0.7064727590042\n",
            "At step: 3543 training error: 0.7079967308245113\n",
            "At step: 3544 training error: 0.7051336761766955\n",
            "At step: 3545 training error: 0.7136708041038242\n",
            "At step: 3546 training error: 0.7110766968281711\n",
            "At step: 3547 training error: 0.7204874529276486\n",
            "At step: 3548 training error: 0.7150482064670254\n",
            "At step: 3549 training error: 0.7072239940162879\n",
            "At step: 3550 training error: 0.7110044783905368\n",
            "At step: 3551 training error: 0.7028367674813576\n",
            "At step: 3552 training error: 0.7056821927145834\n",
            "At step: 3553 training error: 0.7066039005209859\n",
            "At step: 3554 training error: 0.7055884948680589\n",
            "At step: 3555 training error: 0.7033500668213576\n",
            "At step: 3556 training error: 0.7014908275959398\n",
            "At step: 3557 training error: 0.6926973148191627\n",
            "At step: 3558 training error: 0.6978665211877397\n",
            "At step: 3559 training error: 0.6890018962407626\n",
            "At step: 3560 training error: 0.6976215542905827\n",
            "At step: 3561 training error: 0.6922921013539507\n",
            "At step: 3562 training error: 0.6956025378738955\n",
            "At step: 3563 training error: 0.7017037742440728\n",
            "At step: 3564 training error: 0.6970240403728015\n",
            "At step: 3565 training error: 0.6950715914353119\n",
            "At step: 3566 training error: 0.6938817711377836\n",
            "At step: 3567 training error: 0.6883509443744502\n",
            "At step: 3568 training error: 0.6823177589909976\n",
            "At step: 3569 training error: 0.6829207461011381\n",
            "At step: 3570 training error: 0.6787833220301339\n",
            "At step: 3571 training error: 0.68301871203553\n",
            "At step: 3572 training error: 0.6825739385917737\n",
            "At step: 3573 training error: 0.6840363585631433\n",
            "At step: 3574 training error: 0.6848380267864832\n",
            "At step: 3575 training error: 0.6940391862745179\n",
            "At step: 3576 training error: 0.6973440369705438\n",
            "At step: 3577 training error: 0.6959896254024315\n",
            "At step: 3578 training error: 0.6918586852319404\n",
            "At step: 3579 training error: 0.6986199467134336\n",
            "At step: 3580 training error: 0.7002099336814909\n",
            "At step: 3581 training error: 0.6946260270184932\n",
            "At step: 3582 training error: 0.708983588598812\n",
            "At step: 3583 training error: 0.7086305540448901\n",
            "At step: 3584 training error: 0.7081898989638757\n",
            "At step: 3585 training error: 0.7048798926161507\n",
            "At step: 3586 training error: 0.6916197412782761\n",
            "At step: 3587 training error: 0.694082466537581\n",
            "At step: 3588 training error: 0.7019491889124017\n",
            "At step: 3589 training error: 0.7014892833598035\n",
            "At step: 3590 training error: 0.7070596553277454\n",
            "At step: 3591 training error: 0.7044320623454274\n",
            "At step: 3592 training error: 0.702129102258859\n",
            "At step: 3593 training error: 0.695994884100673\n",
            "At step: 3594 training error: 0.6924839455577881\n",
            "At step: 3595 training error: 0.6911968818831266\n",
            "At step: 3596 training error: 0.6912776764537016\n",
            "At step: 3597 training error: 0.6922302469504866\n",
            "At step: 3598 training error: 0.6897201476992622\n",
            "At step: 3599 training error: 0.7003168556628709\n",
            "At step: 3600 training error: 0.6985236466539791\n",
            "At step: 3601 training error: 0.6984606563525104\n",
            "At step: 3602 training error: 0.7022846305483769\n",
            "At step: 3603 training error: 0.7057515136225143\n",
            "At step: 3604 training error: 0.702765653523997\n",
            "At step: 3605 training error: 0.703583814909751\n",
            "At step: 3606 training error: 0.6949061098967909\n",
            "At step: 3607 training error: 0.6945203511300261\n",
            "At step: 3608 training error: 0.6948257982016438\n",
            "At step: 3609 training error: 0.6959008004648388\n",
            "At step: 3610 training error: 0.6962716578104283\n",
            "At step: 3611 training error: 0.6852573194403618\n",
            "At step: 3612 training error: 0.6716853400151341\n",
            "At step: 3613 training error: 0.6696612458435388\n",
            "At step: 3614 training error: 0.6712391820967701\n",
            "At step: 3615 training error: 0.6655393274587774\n",
            "At step: 3616 training error: 0.6569662516504988\n",
            "At step: 3617 training error: 0.6570159758274025\n",
            "At step: 3618 training error: 0.6709643063189212\n",
            "At step: 3619 training error: 0.6730305046541396\n",
            "At step: 3620 training error: 0.6726362641392998\n",
            "At step: 3621 training error: 0.6691610192279038\n",
            "At step: 3622 training error: 0.6676373807611129\n",
            "At step: 3623 training error: 0.6672915212662216\n",
            "At step: 3624 training error: 0.6787571649442362\n",
            "At step: 3625 training error: 0.6854355187221938\n",
            "At step: 3626 training error: 0.6930411196876327\n",
            "At step: 3627 training error: 0.6914065586603467\n",
            "At step: 3628 training error: 0.6893766235816798\n",
            "At step: 3629 training error: 0.6868434195558124\n",
            "At step: 3630 training error: 0.6903084754676412\n",
            "At step: 3631 training error: 0.6953242718967502\n",
            "At step: 3632 training error: 0.7057588526435677\n",
            "At step: 3633 training error: 0.6985880159049586\n",
            "At step: 3634 training error: 0.6929863918883464\n",
            "At step: 3635 training error: 0.6885115235172418\n",
            "At step: 3636 training error: 0.6908943998681797\n",
            "At step: 3637 training error: 0.6953876520796953\n",
            "At step: 3638 training error: 0.6918635371477297\n",
            "At step: 3639 training error: 0.6883561108216424\n",
            "At step: 3640 training error: 0.6947587354659233\n",
            "At step: 3641 training error: 0.6949875711988069\n",
            "At step: 3642 training error: 0.6969548896199997\n",
            "At step: 3643 training error: 0.7019910653516784\n",
            "At step: 3644 training error: 0.7029381722889126\n",
            "At step: 3645 training error: 0.7010008981145327\n",
            "At step: 3646 training error: 0.6971258781960538\n",
            "At step: 3647 training error: 0.6887511484099437\n",
            "At step: 3648 training error: 0.6924929765333867\n",
            "At step: 3649 training error: 0.693202966971154\n",
            "At step: 3650 training error: 0.6896918595214334\n",
            "At step: 3651 training error: 0.6912120891266501\n",
            "At step: 3652 training error: 0.6834432057341373\n",
            "At step: 3653 training error: 0.6904519478793515\n",
            "At step: 3654 training error: 0.6894628960968202\n",
            "At step: 3655 training error: 0.6904114034864164\n",
            "At step: 3656 training error: 0.6904971596778144\n",
            "At step: 3657 training error: 0.6956624688053886\n",
            "At step: 3658 training error: 0.6981818591290099\n",
            "At step: 3659 training error: 0.6973774247642122\n",
            "At step: 3660 training error: 0.6912212559933061\n",
            "At step: 3661 training error: 0.6929709745876086\n",
            "At step: 3662 training error: 0.6916259054122066\n",
            "At step: 3663 training error: 0.6891423596152231\n",
            "At step: 3664 training error: 0.6981056121619627\n",
            "At step: 3665 training error: 0.7057755189683226\n",
            "At step: 3666 training error: 0.7015015957400487\n",
            "At step: 3667 training error: 0.7054070032120141\n",
            "At step: 3668 training error: 0.7016367419686004\n",
            "At step: 3669 training error: 0.6977516016132039\n",
            "At step: 3670 training error: 0.702362390757405\n",
            "At step: 3671 training error: 0.6957563660579781\n",
            "At step: 3672 training error: 0.6889346151565537\n",
            "At step: 3673 training error: 0.6856749197675632\n",
            "At step: 3674 training error: 0.6713942985706736\n",
            "At step: 3675 training error: 0.676960461985424\n",
            "At step: 3676 training error: 0.6776447899352531\n",
            "At step: 3677 training error: 0.6769491142977814\n",
            "At step: 3678 training error: 0.6723322290235856\n",
            "At step: 3679 training error: 0.6693160365267716\n",
            "At step: 3680 training error: 0.6718806546111745\n",
            "At step: 3681 training error: 0.6543305613523126\n",
            "At step: 3682 training error: 0.6649210489551315\n",
            "At step: 3683 training error: 0.6676573399176126\n",
            "At step: 3684 training error: 0.6677001885217901\n",
            "At step: 3685 training error: 0.6668391666918703\n",
            "At step: 3686 training error: 0.6703183043145564\n",
            "At step: 3687 training error: 0.6742306404624727\n",
            "At step: 3688 training error: 0.6682036572704962\n",
            "At step: 3689 training error: 0.6709589442664251\n",
            "At step: 3690 training error: 0.6689690842874746\n",
            "At step: 3691 training error: 0.6775032907817677\n",
            "At step: 3692 training error: 0.6714825171659153\n",
            "At step: 3693 training error: 0.678296251583995\n",
            "At step: 3694 training error: 0.67719361110229\n",
            "At step: 3695 training error: 0.6721569231230696\n",
            "At step: 3696 training error: 0.677178170483825\n",
            "At step: 3697 training error: 0.6872146060845887\n",
            "At step: 3698 training error: 0.6908917575152612\n",
            "At step: 3699 training error: 0.6918243007093654\n",
            "At step: 3700 training error: 0.6929454135224665\n",
            "At step: 3701 training error: 0.6939847291601614\n",
            "At step: 3702 training error: 0.6913564167354274\n",
            "At step: 3703 training error: 0.6895138380148386\n",
            "At step: 3704 training error: 0.685804066971784\n",
            "At step: 3705 training error: 0.6875999215045885\n",
            "At step: 3706 training error: 0.6887447634832499\n",
            "At step: 3707 training error: 0.6826049938502494\n",
            "At step: 3708 training error: 0.6837140918045747\n",
            "At step: 3709 training error: 0.686052340541051\n",
            "At step: 3710 training error: 0.6907147173537116\n",
            "At step: 3711 training error: 0.6882883989225858\n",
            "At step: 3712 training error: 0.6894010616557547\n",
            "At step: 3713 training error: 0.6862759585373872\n",
            "At step: 3714 training error: 0.6869516703186127\n",
            "At step: 3715 training error: 0.6845141595039597\n",
            "At step: 3716 training error: 0.6839605078727236\n",
            "At step: 3717 training error: 0.6815464353232463\n",
            "At step: 3718 training error: 0.6871290452420554\n",
            "At step: 3719 training error: 0.6858273717161318\n",
            "At step: 3720 training error: 0.6803789708715968\n",
            "At step: 3721 training error: 0.6814449781069185\n",
            "At step: 3722 training error: 0.6890200833029633\n",
            "At step: 3723 training error: 0.6889627361643111\n",
            "At step: 3724 training error: 0.6887901069828138\n",
            "At step: 3725 training error: 0.688494629842547\n",
            "At step: 3726 training error: 0.6945292600872293\n",
            "At step: 3727 training error: 0.6900552346030838\n",
            "At step: 3728 training error: 0.6950276123892678\n",
            "At step: 3729 training error: 0.6928699810245266\n",
            "At step: 3730 training error: 0.6858113164888878\n",
            "At step: 3731 training error: 0.6795972380111038\n",
            "At step: 3732 training error: 0.6738029135693449\n",
            "At step: 3733 training error: 0.679658589164933\n",
            "At step: 3734 training error: 0.6855381184157581\n",
            "At step: 3735 training error: 0.6904723694819674\n",
            "At step: 3736 training error: 0.6974209557481454\n",
            "At step: 3737 training error: 0.6969359935413431\n",
            "At step: 3738 training error: 0.6914604425655191\n",
            "At step: 3739 training error: 0.6942286454637456\n",
            "At step: 3740 training error: 0.6894877569101118\n",
            "At step: 3741 training error: 0.6858887074349388\n",
            "At step: 3742 training error: 0.6926745356961441\n",
            "At step: 3743 training error: 0.6959349954131866\n",
            "At step: 3744 training error: 0.6952808242715479\n",
            "At step: 3745 training error: 0.6928011008946396\n",
            "At step: 3746 training error: 0.6884699559197969\n",
            "At step: 3747 training error: 0.6966175608288061\n",
            "At step: 3748 training error: 0.6995224328035858\n",
            "At step: 3749 training error: 0.7012533622577313\n",
            "At step: 3750 training error: 0.6989274317878093\n",
            "At step: 3751 training error: 0.699438378039549\n",
            "At step: 3752 training error: 0.7020440873398989\n",
            "At step: 3753 training error: 0.7048538946592555\n",
            "At step: 3754 training error: 0.7035368492812369\n",
            "At step: 3755 training error: 0.7090008321122945\n",
            "At step: 3756 training error: 0.7005028746315672\n",
            "At step: 3757 training error: 0.6963146001903366\n",
            "At step: 3758 training error: 0.6947112521009134\n",
            "At step: 3759 training error: 0.697030081100674\n",
            "At step: 3760 training error: 0.7009069909556772\n",
            "At step: 3761 training error: 0.6949160100073798\n",
            "At step: 3762 training error: 0.7027866953182931\n",
            "At step: 3763 training error: 0.7005965979023081\n",
            "At step: 3764 training error: 0.7004249798246489\n",
            "At step: 3765 training error: 0.6927683451609197\n",
            "At step: 3766 training error: 0.6938054526755011\n",
            "At step: 3767 training error: 0.6895059239042408\n",
            "At step: 3768 training error: 0.691064763880775\n",
            "At step: 3769 training error: 0.6887145865326914\n",
            "At step: 3770 training error: 0.6889449490753456\n",
            "At step: 3771 training error: 0.681325084567014\n",
            "At step: 3772 training error: 0.6899880038644728\n",
            "At step: 3773 training error: 0.6981656107523809\n",
            "At step: 3774 training error: 0.7038943895767642\n",
            "At step: 3775 training error: 0.7003500160183477\n",
            "At step: 3776 training error: 0.6995830950587106\n",
            "At step: 3777 training error: 0.6946588513175365\n",
            "At step: 3778 training error: 0.6951979120848274\n",
            "At step: 3779 training error: 0.6913866644129257\n",
            "At step: 3780 training error: 0.6868662420174917\n",
            "At step: 3781 training error: 0.6939334279773992\n",
            "At step: 3782 training error: 0.684449221325896\n",
            "At step: 3783 training error: 0.6923734405635714\n",
            "At step: 3784 training error: 0.6880798296567956\n",
            "At step: 3785 training error: 0.6777200878786662\n",
            "At step: 3786 training error: 0.6775341572519248\n",
            "At step: 3787 training error: 0.6867991690949723\n",
            "At step: 3788 training error: 0.6890320441728508\n",
            "At step: 3789 training error: 0.689112517505695\n",
            "At step: 3790 training error: 0.6909354750789343\n",
            "At step: 3791 training error: 0.692690182408372\n",
            "At step: 3792 training error: 0.6872496766379643\n",
            "At step: 3793 training error: 0.6886759224020884\n",
            "At step: 3794 training error: 0.6935833604109616\n",
            "At step: 3795 training error: 0.6848678594697104\n",
            "At step: 3796 training error: 0.6797002669130597\n",
            "At step: 3797 training error: 0.6799643813583574\n",
            "At step: 3798 training error: 0.6750719193938161\n",
            "At step: 3799 training error: 0.6735948117860115\n",
            "At step: 3800 training error: 0.6796660760544985\n",
            "At step: 3801 training error: 0.6824245377540837\n",
            "At step: 3802 training error: 0.6837028569868735\n",
            "At step: 3803 training error: 0.6839412672942644\n",
            "At step: 3804 training error: 0.6907108412690935\n",
            "At step: 3805 training error: 0.6930614108878747\n",
            "At step: 3806 training error: 0.688378542815617\n",
            "At step: 3807 training error: 0.6865084057724216\n",
            "At step: 3808 training error: 0.6821924469480374\n",
            "At step: 3809 training error: 0.6735686821269886\n",
            "At step: 3810 training error: 0.6716021299094408\n",
            "At step: 3811 training error: 0.6778902932856218\n",
            "At step: 3812 training error: 0.6870454286459046\n",
            "At step: 3813 training error: 0.6814002920263309\n",
            "At step: 3814 training error: 0.6794967463787985\n",
            "At step: 3815 training error: 0.6840509144521942\n",
            "At step: 3816 training error: 0.678618943014824\n",
            "At step: 3817 training error: 0.6774281770546638\n",
            "At step: 3818 training error: 0.6841888686711454\n",
            "At step: 3819 training error: 0.692819028318835\n",
            "At step: 3820 training error: 0.6921825286681325\n",
            "At step: 3821 training error: 0.7014889223144873\n",
            "At step: 3822 training error: 0.696021502688639\n",
            "At step: 3823 training error: 0.69107180294128\n",
            "At step: 3824 training error: 0.6895716941183642\n",
            "At step: 3825 training error: 0.690101070016639\n",
            "At step: 3826 training error: 0.6897761555659752\n",
            "At step: 3827 training error: 0.6883373468955719\n",
            "At step: 3828 training error: 0.6849082273492805\n",
            "At step: 3829 training error: 0.6854708876197416\n",
            "At step: 3830 training error: 0.68609417872859\n",
            "At step: 3831 training error: 0.6854345523947266\n",
            "At step: 3832 training error: 0.6875258480183766\n",
            "At step: 3833 training error: 0.6779011513885888\n",
            "At step: 3834 training error: 0.6762408316772796\n",
            "At step: 3835 training error: 0.6740217413169132\n",
            "At step: 3836 training error: 0.6725743219169621\n",
            "At step: 3837 training error: 0.673867418315084\n",
            "At step: 3838 training error: 0.6740101398930425\n",
            "At step: 3839 training error: 0.6759260045333246\n",
            "At step: 3840 training error: 0.6740215482862154\n",
            "At step: 3841 training error: 0.6707196270073794\n",
            "At step: 3842 training error: 0.6731307256561262\n",
            "At step: 3843 training error: 0.6649919489908792\n",
            "At step: 3844 training error: 0.6645490740155772\n",
            "At step: 3845 training error: 0.6672890374123996\n",
            "At step: 3846 training error: 0.6633598551932245\n",
            "At step: 3847 training error: 0.6584685281532485\n",
            "At step: 3848 training error: 0.6667444922964898\n",
            "At step: 3849 training error: 0.6572613677015606\n",
            "At step: 3850 training error: 0.666103214682709\n",
            "At step: 3851 training error: 0.6635004809469663\n",
            "At step: 3852 training error: 0.6660753534827513\n",
            "At step: 3853 training error: 0.6671759359131976\n",
            "At step: 3854 training error: 0.6753825929095959\n",
            "At step: 3855 training error: 0.6819013113676751\n",
            "At step: 3856 training error: 0.6834752485838826\n",
            "At step: 3857 training error: 0.6876973454788117\n",
            "At step: 3858 training error: 0.686586149683227\n",
            "At step: 3859 training error: 0.6937195680782434\n",
            "At step: 3860 training error: 0.6909589982513045\n",
            "At step: 3861 training error: 0.678234162247864\n",
            "At step: 3862 training error: 0.6757048877832423\n",
            "At step: 3863 training error: 0.6831327540844772\n",
            "At step: 3864 training error: 0.6767106638992114\n",
            "At step: 3865 training error: 0.6810347486885748\n",
            "At step: 3866 training error: 0.6843210340448818\n",
            "At step: 3867 training error: 0.6876344558033883\n",
            "At step: 3868 training error: 0.6857018947960345\n",
            "At step: 3869 training error: 0.6859390768149574\n",
            "At step: 3870 training error: 0.6892278078029869\n",
            "At step: 3871 training error: 0.6832199352351253\n",
            "At step: 3872 training error: 0.6776625154261994\n",
            "At step: 3873 training error: 0.6834000977661977\n",
            "At step: 3874 training error: 0.6849889406890995\n",
            "At step: 3875 training error: 0.6933308032199201\n",
            "At step: 3876 training error: 0.6880441530788525\n",
            "At step: 3877 training error: 0.6824334985003051\n",
            "At step: 3878 training error: 0.6856938563503837\n",
            "At step: 3879 training error: 0.6842167137824853\n",
            "At step: 3880 training error: 0.6830565473354511\n",
            "At step: 3881 training error: 0.6800504757353999\n",
            "At step: 3882 training error: 0.6828204072506704\n",
            "At step: 3883 training error: 0.6878323650924419\n",
            "At step: 3884 training error: 0.6833857225857263\n",
            "At step: 3885 training error: 0.6828526107270481\n",
            "At step: 3886 training error: 0.6749676411416952\n",
            "At step: 3887 training error: 0.6732027505498935\n",
            "At step: 3888 training error: 0.6716317662293089\n",
            "At step: 3889 training error: 0.6761240370768234\n",
            "At step: 3890 training error: 0.6733065063864627\n",
            "At step: 3891 training error: 0.6693678554857275\n",
            "At step: 3892 training error: 0.672883947538819\n",
            "At step: 3893 training error: 0.6752167537273693\n",
            "At step: 3894 training error: 0.6680526957966004\n",
            "At step: 3895 training error: 0.660969885986566\n",
            "At step: 3896 training error: 0.657983351165527\n",
            "At step: 3897 training error: 0.6584751196847666\n",
            "At step: 3898 training error: 0.6599677778750122\n",
            "At step: 3899 training error: 0.6598577680420673\n",
            "At step: 3900 training error: 0.6575786304440739\n",
            "At step: 3901 training error: 0.6585940554368128\n",
            "At step: 3902 training error: 0.655387235202367\n",
            "At step: 3903 training error: 0.6714281811364522\n",
            "At step: 3904 training error: 0.6752445044674039\n",
            "At step: 3905 training error: 0.6693705985947277\n",
            "At step: 3906 training error: 0.6686391990632177\n",
            "At step: 3907 training error: 0.6679199424251514\n",
            "At step: 3908 training error: 0.6674539013004827\n",
            "At step: 3909 training error: 0.6703268659109142\n",
            "At step: 3910 training error: 0.6781284409724045\n",
            "At step: 3911 training error: 0.6766316546765044\n",
            "At step: 3912 training error: 0.6797370009430185\n",
            "At step: 3913 training error: 0.681213090059991\n",
            "At step: 3914 training error: 0.6879858603809652\n",
            "At step: 3915 training error: 0.6795051617299469\n",
            "At step: 3916 training error: 0.6737267376765183\n",
            "At step: 3917 training error: 0.6780126723321979\n",
            "At step: 3918 training error: 0.6780886429746547\n",
            "At step: 3919 training error: 0.6831970231896698\n",
            "At step: 3920 training error: 0.6912564311923145\n",
            "At step: 3921 training error: 0.6880196165113676\n",
            "At step: 3922 training error: 0.6938892604050316\n",
            "At step: 3923 training error: 0.6857193701087266\n",
            "At step: 3924 training error: 0.6899172632666932\n",
            "At step: 3925 training error: 0.6798775934316431\n",
            "At step: 3926 training error: 0.6788807514556655\n",
            "At step: 3927 training error: 0.6767419741432296\n",
            "At step: 3928 training error: 0.6766391569315247\n",
            "At step: 3929 training error: 0.6743030816571811\n",
            "At step: 3930 training error: 0.6830043680685253\n",
            "At step: 3931 training error: 0.6811844893238821\n",
            "At step: 3932 training error: 0.6885228856475565\n",
            "At step: 3933 training error: 0.6915333938732943\n",
            "At step: 3934 training error: 0.6928438462043219\n",
            "At step: 3935 training error: 0.6953821816787737\n",
            "At step: 3936 training error: 0.6958073486187194\n",
            "At step: 3937 training error: 0.693429957896906\n",
            "At step: 3938 training error: 0.6990240400563312\n",
            "At step: 3939 training error: 0.6983281928029957\n",
            "At step: 3940 training error: 0.7036097797429356\n",
            "At step: 3941 training error: 0.6916063343520602\n",
            "At step: 3942 training error: 0.6809167641083665\n",
            "At step: 3943 training error: 0.6790375394901145\n",
            "At step: 3944 training error: 0.6825477802013238\n",
            "At step: 3945 training error: 0.6901901689921983\n",
            "At step: 3946 training error: 0.7011424118808307\n",
            "At step: 3947 training error: 0.7001332498514552\n",
            "At step: 3948 training error: 0.7018437593049596\n",
            "At step: 3949 training error: 0.6959245494824088\n",
            "At step: 3950 training error: 0.6899806939682581\n",
            "At step: 3951 training error: 0.6859214955563341\n",
            "At step: 3952 training error: 0.6957847252019228\n",
            "At step: 3953 training error: 0.6900001185526844\n",
            "At step: 3954 training error: 0.6891085297477535\n",
            "At step: 3955 training error: 0.6941385756986357\n",
            "At step: 3956 training error: 0.6983645030032469\n",
            "At step: 3957 training error: 0.6980833547363111\n",
            "At step: 3958 training error: 0.6978290045775575\n",
            "At step: 3959 training error: 0.6870685551033354\n",
            "At step: 3960 training error: 0.6862815707160296\n",
            "At step: 3961 training error: 0.6867419791767685\n",
            "At step: 3962 training error: 0.6858208085252289\n",
            "At step: 3963 training error: 0.6860525369576802\n",
            "At step: 3964 training error: 0.6879023336017975\n",
            "At step: 3965 training error: 0.6879597868286886\n",
            "At step: 3966 training error: 0.6816503985213835\n",
            "At step: 3967 training error: 0.6883071170980202\n",
            "At step: 3968 training error: 0.690011832869601\n",
            "At step: 3969 training error: 0.6871146948500609\n",
            "At step: 3970 training error: 0.6894615460276565\n",
            "At step: 3971 training error: 0.6888808647027709\n",
            "At step: 3972 training error: 0.6906081542372505\n",
            "At step: 3973 training error: 0.689065926031566\n",
            "At step: 3974 training error: 0.687675969017794\n",
            "At step: 3975 training error: 0.6886207219873347\n",
            "At step: 3976 training error: 0.6862780578087407\n",
            "At step: 3977 training error: 0.6744991446804185\n",
            "At step: 3978 training error: 0.6824373096937819\n",
            "At step: 3979 training error: 0.6776644479343936\n",
            "At step: 3980 training error: 0.670668121276203\n",
            "At step: 3981 training error: 0.6679584673415419\n",
            "At step: 3982 training error: 0.6593570965445876\n",
            "At step: 3983 training error: 0.6596927847467108\n",
            "At step: 3984 training error: 0.6589201649863924\n",
            "At step: 3985 training error: 0.6544023992263066\n",
            "At step: 3986 training error: 0.6582308710540811\n",
            "At step: 3987 training error: 0.654734702639019\n",
            "At step: 3988 training error: 0.65529187096967\n",
            "At step: 3989 training error: 0.6540754628618355\n",
            "At step: 3990 training error: 0.6518619458714267\n",
            "At step: 3991 training error: 0.6555962913793113\n",
            "At step: 3992 training error: 0.6500483149685861\n",
            "At step: 3993 training error: 0.6610770153792193\n",
            "At step: 3994 training error: 0.6549026885114753\n",
            "At step: 3995 training error: 0.6569880389975586\n",
            "At step: 3996 training error: 0.6537632294407347\n",
            "At step: 3997 training error: 0.6593789292976546\n",
            "At step: 3998 training error: 0.6555911357947495\n",
            "At step: 3999 training error: 0.6536632201374855\n",
            "At step: 4000 training error: 0.6607787299442966\n",
            "At step: 4001 training error: 0.656978729315431\n",
            "At step: 4002 training error: 0.6666037508867123\n",
            "At step: 4003 training error: 0.6654855844308378\n",
            "At step: 4004 training error: 0.6644539924323142\n",
            "At step: 4005 training error: 0.6686686440673262\n",
            "At step: 4006 training error: 0.6745554878885465\n",
            "At step: 4007 training error: 0.6732986222692517\n",
            "At step: 4008 training error: 0.6746131094987152\n",
            "At step: 4009 training error: 0.671793817271057\n",
            "At step: 4010 training error: 0.6721234813211644\n",
            "At step: 4011 training error: 0.6787388068776703\n",
            "At step: 4012 training error: 0.6714905382120014\n",
            "At step: 4013 training error: 0.675954195654587\n",
            "At step: 4014 training error: 0.6716900757012768\n",
            "At step: 4015 training error: 0.6724796127251162\n",
            "At step: 4016 training error: 0.673794481538592\n",
            "At step: 4017 training error: 0.6593313314270103\n",
            "At step: 4018 training error: 0.652462244123467\n",
            "At step: 4019 training error: 0.6498604345846979\n",
            "At step: 4020 training error: 0.6476683243232859\n",
            "At step: 4021 training error: 0.6604629900953446\n",
            "At step: 4022 training error: 0.66509137577194\n",
            "At step: 4023 training error: 0.6620814380652681\n",
            "At step: 4024 training error: 0.6510456844726404\n",
            "At step: 4025 training error: 0.6551823349313912\n",
            "At step: 4026 training error: 0.6566524561101444\n",
            "At step: 4027 training error: 0.6560619808805042\n",
            "At step: 4028 training error: 0.6565278317215306\n",
            "At step: 4029 training error: 0.6565031207906622\n",
            "At step: 4030 training error: 0.6593155264807181\n",
            "At step: 4031 training error: 0.6602572952317726\n",
            "At step: 4032 training error: 0.6502844355078814\n",
            "At step: 4033 training error: 0.6483688430941791\n",
            "At step: 4034 training error: 0.6537707622825746\n",
            "At step: 4035 training error: 0.6529867563912234\n",
            "At step: 4036 training error: 0.6574138361791635\n",
            "At step: 4037 training error: 0.6613222563435612\n",
            "At step: 4038 training error: 0.657867163343385\n",
            "At step: 4039 training error: 0.6610529609408137\n",
            "At step: 4040 training error: 0.6567223123604253\n",
            "At step: 4041 training error: 0.6574910217837692\n",
            "At step: 4042 training error: 0.6460132692957886\n",
            "At step: 4043 training error: 0.6493473324122415\n",
            "At step: 4044 training error: 0.6554485858557639\n",
            "At step: 4045 training error: 0.6610222026657993\n",
            "At step: 4046 training error: 0.6541978759174077\n",
            "At step: 4047 training error: 0.6470087850879546\n",
            "At step: 4048 training error: 0.6510317205673603\n",
            "At step: 4049 training error: 0.6557851041710745\n",
            "At step: 4050 training error: 0.6506824327251042\n",
            "At step: 4051 training error: 0.6504577886391141\n",
            "At step: 4052 training error: 0.6509204012886354\n",
            "At step: 4053 training error: 0.6532885952291103\n",
            "At step: 4054 training error: 0.6482891631499498\n",
            "At step: 4055 training error: 0.6498753127213869\n",
            "At step: 4056 training error: 0.651382247158468\n",
            "At step: 4057 training error: 0.6493267192018494\n",
            "At step: 4058 training error: 0.6498159266449267\n",
            "At step: 4059 training error: 0.649629125403472\n",
            "At step: 4060 training error: 0.6522548973773116\n",
            "At step: 4061 training error: 0.6591555331422363\n",
            "At step: 4062 training error: 0.6497004848824365\n",
            "At step: 4063 training error: 0.6572050211560404\n",
            "At step: 4064 training error: 0.6598065588498433\n",
            "At step: 4065 training error: 0.6563301962053281\n",
            "At step: 4066 training error: 0.6575441381256337\n",
            "At step: 4067 training error: 0.6662421238357958\n",
            "At step: 4068 training error: 0.668349935861294\n",
            "At step: 4069 training error: 0.6668401773221986\n",
            "At step: 4070 training error: 0.6625689201906121\n",
            "At step: 4071 training error: 0.6658198779322256\n",
            "At step: 4072 training error: 0.6589333693141614\n",
            "At step: 4073 training error: 0.6679186652344123\n",
            "At step: 4074 training error: 0.6656060349492029\n",
            "At step: 4075 training error: 0.6597289562241392\n",
            "At step: 4076 training error: 0.6642189429543582\n",
            "At step: 4077 training error: 0.6628267261032148\n",
            "At step: 4078 training error: 0.6592272902950543\n",
            "At step: 4079 training error: 0.661205738778054\n",
            "At step: 4080 training error: 0.6741461347476435\n",
            "At step: 4081 training error: 0.6829591049517132\n",
            "At step: 4082 training error: 0.6732702589473912\n",
            "At step: 4083 training error: 0.6703170969453645\n",
            "At step: 4084 training error: 0.6661503338734438\n",
            "At step: 4085 training error: 0.6636900662779074\n",
            "At step: 4086 training error: 0.6651748785315663\n",
            "At step: 4087 training error: 0.6623355013451414\n",
            "At step: 4088 training error: 0.6666070812731609\n",
            "At step: 4089 training error: 0.670658902547949\n",
            "At step: 4090 training error: 0.668240468124838\n",
            "At step: 4091 training error: 0.6742587096821817\n",
            "At step: 4092 training error: 0.6809179489069516\n",
            "At step: 4093 training error: 0.6812204583259514\n",
            "At step: 4094 training error: 0.6837397726750107\n",
            "At step: 4095 training error: 0.6853573590732562\n",
            "At step: 4096 training error: 0.6889848164573971\n",
            "At step: 4097 training error: 0.6790836785467504\n",
            "At step: 4098 training error: 0.6698604771169099\n",
            "At step: 4099 training error: 0.6717140334149173\n",
            "At step: 4100 training error: 0.6700109090553483\n",
            "At step: 4101 training error: 0.6812641386625077\n",
            "At step: 4102 training error: 0.6836558362198137\n",
            "At step: 4103 training error: 0.6788901944681555\n",
            "At step: 4104 training error: 0.6808009422912098\n",
            "At step: 4105 training error: 0.6727741779291231\n",
            "At step: 4106 training error: 0.681626709290871\n",
            "At step: 4107 training error: 0.6707399530639618\n",
            "At step: 4108 training error: 0.667333042209486\n",
            "At step: 4109 training error: 0.6814378049794034\n",
            "At step: 4110 training error: 0.6999176423895279\n",
            "At step: 4111 training error: 0.6908684229150899\n",
            "At step: 4112 training error: 0.689243929632976\n",
            "At step: 4113 training error: 0.6858561498356658\n",
            "At step: 4114 training error: 0.681537524834652\n",
            "At step: 4115 training error: 0.6813923212441817\n",
            "At step: 4116 training error: 0.6795718128804384\n",
            "At step: 4117 training error: 0.6787376339235901\n",
            "At step: 4118 training error: 0.6755136735089624\n",
            "At step: 4119 training error: 0.6723512910945804\n",
            "At step: 4120 training error: 0.6714113560626561\n",
            "At step: 4121 training error: 0.6610660796983456\n",
            "At step: 4122 training error: 0.6698154488404244\n",
            "At step: 4123 training error: 0.6734960967257563\n",
            "At step: 4124 training error: 0.6741460361523494\n",
            "At step: 4125 training error: 0.6765320589960419\n",
            "At step: 4126 training error: 0.6738810115306941\n",
            "At step: 4127 training error: 0.6742251396683819\n",
            "At step: 4128 training error: 0.6728887599098832\n",
            "At step: 4129 training error: 0.6726180166422331\n",
            "At step: 4130 training error: 0.6674119995897104\n",
            "At step: 4131 training error: 0.6676315390164907\n",
            "At step: 4132 training error: 0.675581168577141\n",
            "At step: 4133 training error: 0.6717655136992777\n",
            "At step: 4134 training error: 0.6738175049020224\n",
            "At step: 4135 training error: 0.6817898434568159\n",
            "At step: 4136 training error: 0.666688146668947\n",
            "At step: 4137 training error: 0.6700177123669859\n",
            "At step: 4138 training error: 0.6672440892866051\n",
            "At step: 4139 training error: 0.6700756950471642\n",
            "At step: 4140 training error: 0.6692876734303536\n",
            "At step: 4141 training error: 0.6684855665278152\n",
            "At step: 4142 training error: 0.6616918333781686\n",
            "At step: 4143 training error: 0.6570950286902325\n",
            "At step: 4144 training error: 0.6570639520404787\n",
            "At step: 4145 training error: 0.6599536213477749\n",
            "At step: 4146 training error: 0.6562594041095271\n",
            "At step: 4147 training error: 0.6544838357977706\n",
            "At step: 4148 training error: 0.6653770716477271\n",
            "At step: 4149 training error: 0.6777690271014419\n",
            "At step: 4150 training error: 0.6775420428184431\n",
            "At step: 4151 training error: 0.6833556339427598\n",
            "At step: 4152 training error: 0.6833538265710357\n",
            "At step: 4153 training error: 0.6820303802178072\n",
            "At step: 4154 training error: 0.6859606130968519\n",
            "At step: 4155 training error: 0.6767965334527166\n",
            "At step: 4156 training error: 0.6849391734766458\n",
            "At step: 4157 training error: 0.6862123718827695\n",
            "At step: 4158 training error: 0.6890603103047176\n",
            "At step: 4159 training error: 0.6843756429750065\n",
            "At step: 4160 training error: 0.6799679007454578\n",
            "At step: 4161 training error: 0.672281876049069\n",
            "At step: 4162 training error: 0.670441380645916\n",
            "At step: 4163 training error: 0.6730012434950441\n",
            "At step: 4164 training error: 0.6675137488686094\n",
            "At step: 4165 training error: 0.6565843498205407\n",
            "At step: 4166 training error: 0.6662202074967596\n",
            "At step: 4167 training error: 0.6665440796641346\n",
            "At step: 4168 training error: 0.6601265957835073\n",
            "At step: 4169 training error: 0.6651685068691716\n",
            "At step: 4170 training error: 0.6682716140174316\n",
            "At step: 4171 training error: 0.673231881164832\n",
            "At step: 4172 training error: 0.6713736017536053\n",
            "At step: 4173 training error: 0.667685769308738\n",
            "At step: 4174 training error: 0.6642879460402282\n",
            "At step: 4175 training error: 0.6632403876403732\n",
            "At step: 4176 training error: 0.6653589499776335\n",
            "At step: 4177 training error: 0.6706436094844002\n",
            "At step: 4178 training error: 0.6742692739463928\n",
            "At step: 4179 training error: 0.6746143846811721\n",
            "At step: 4180 training error: 0.666917340840664\n",
            "At step: 4181 training error: 0.6642608486623092\n",
            "At step: 4182 training error: 0.6580883486247349\n",
            "At step: 4183 training error: 0.6585745349788827\n",
            "At step: 4184 training error: 0.6604646517148509\n",
            "At step: 4185 training error: 0.6578991306805286\n",
            "At step: 4186 training error: 0.6632628422815267\n",
            "At step: 4187 training error: 0.6771961156136934\n",
            "At step: 4188 training error: 0.6763357534530134\n",
            "At step: 4189 training error: 0.6822397251713775\n",
            "At step: 4190 training error: 0.6824942111883073\n",
            "At step: 4191 training error: 0.6843186039064594\n",
            "At step: 4192 training error: 0.686481820300379\n",
            "At step: 4193 training error: 0.68467608810187\n",
            "At step: 4194 training error: 0.6795278578964518\n",
            "At step: 4195 training error: 0.6778747713348214\n",
            "At step: 4196 training error: 0.6765882073248823\n",
            "At step: 4197 training error: 0.6807131904414059\n",
            "At step: 4198 training error: 0.6834267047155497\n",
            "At step: 4199 training error: 0.6841497379754347\n",
            "At step: 4200 training error: 0.6731975510805004\n",
            "At step: 4201 training error: 0.6702840066806413\n",
            "At step: 4202 training error: 0.6767945726151526\n",
            "At step: 4203 training error: 0.6777612490108575\n",
            "At step: 4204 training error: 0.6751285450499219\n",
            "At step: 4205 training error: 0.6831302996209103\n",
            "At step: 4206 training error: 0.6821303160093957\n",
            "At step: 4207 training error: 0.6865224228909873\n",
            "At step: 4208 training error: 0.6785544606697886\n",
            "At step: 4209 training error: 0.6728536379200498\n",
            "At step: 4210 training error: 0.6716385534985068\n",
            "At step: 4211 training error: 0.6657048237612021\n",
            "At step: 4212 training error: 0.6706502416511326\n",
            "At step: 4213 training error: 0.6751012675932314\n",
            "At step: 4214 training error: 0.6803551163372403\n",
            "At step: 4215 training error: 0.6775134955842753\n",
            "At step: 4216 training error: 0.6750670447953225\n",
            "At step: 4217 training error: 0.6769315857680283\n",
            "At step: 4218 training error: 0.6733114150082031\n",
            "At step: 4219 training error: 0.6696877804848577\n",
            "At step: 4220 training error: 0.6726718949074953\n",
            "At step: 4221 training error: 0.6682845955049862\n",
            "At step: 4222 training error: 0.6652064600651338\n",
            "At step: 4223 training error: 0.6653445853507712\n",
            "At step: 4224 training error: 0.6664458340869327\n",
            "At step: 4225 training error: 0.6632029776037386\n",
            "At step: 4226 training error: 0.6630385824053215\n",
            "At step: 4227 training error: 0.666807439976906\n",
            "At step: 4228 training error: 0.6650593763566052\n",
            "At step: 4229 training error: 0.6721982776034626\n",
            "At step: 4230 training error: 0.6599911730823428\n",
            "At step: 4231 training error: 0.6625393634776789\n",
            "At step: 4232 training error: 0.6682786395347187\n",
            "At step: 4233 training error: 0.6730932373020471\n",
            "At step: 4234 training error: 0.6785029918296728\n",
            "At step: 4235 training error: 0.6728991331891929\n",
            "At step: 4236 training error: 0.6719478876375522\n",
            "At step: 4237 training error: 0.6693962091068305\n",
            "At step: 4238 training error: 0.6680747806615678\n",
            "At step: 4239 training error: 0.6666119010404857\n",
            "At step: 4240 training error: 0.6573467719392291\n",
            "At step: 4241 training error: 0.6518002501298844\n",
            "At step: 4242 training error: 0.6610084300095328\n",
            "At step: 4243 training error: 0.6641669897619372\n",
            "At step: 4244 training error: 0.6704277868114262\n",
            "At step: 4245 training error: 0.6792618821979528\n",
            "At step: 4246 training error: 0.6838800406918314\n",
            "At step: 4247 training error: 0.6741828342082749\n",
            "At step: 4248 training error: 0.6821124716047535\n",
            "At step: 4249 training error: 0.6890441608726929\n",
            "At step: 4250 training error: 0.6874526282600479\n",
            "At step: 4251 training error: 0.6752768837438606\n",
            "At step: 4252 training error: 0.6678060792043842\n",
            "At step: 4253 training error: 0.6713085872858966\n",
            "At step: 4254 training error: 0.6705077363996059\n",
            "At step: 4255 training error: 0.674721280154648\n",
            "At step: 4256 training error: 0.6797019587689526\n",
            "At step: 4257 training error: 0.6737359017921067\n",
            "At step: 4258 training error: 0.6710419480086407\n",
            "At step: 4259 training error: 0.667507927455216\n",
            "At step: 4260 training error: 0.6647177673351476\n",
            "At step: 4261 training error: 0.6572314764838959\n",
            "At step: 4262 training error: 0.6596871129060183\n",
            "At step: 4263 training error: 0.6587133072219005\n",
            "At step: 4264 training error: 0.6599164101636736\n",
            "At step: 4265 training error: 0.6645334679186664\n",
            "At step: 4266 training error: 0.6662577515446546\n",
            "At step: 4267 training error: 0.6637132757044532\n",
            "At step: 4268 training error: 0.6720756741711965\n",
            "At step: 4269 training error: 0.6711859821514525\n",
            "At step: 4270 training error: 0.6692785645208074\n",
            "At step: 4271 training error: 0.6654296500465787\n",
            "At step: 4272 training error: 0.6562114133978669\n",
            "At step: 4273 training error: 0.6631190354132717\n",
            "At step: 4274 training error: 0.6674137073668408\n",
            "At step: 4275 training error: 0.6686843709880171\n",
            "At step: 4276 training error: 0.663480157324868\n",
            "At step: 4277 training error: 0.6689347169825794\n",
            "At step: 4278 training error: 0.6707268889185691\n",
            "At step: 4279 training error: 0.6801832589391934\n",
            "At step: 4280 training error: 0.6722149444531417\n",
            "At step: 4281 training error: 0.6755227683851149\n",
            "At step: 4282 training error: 0.6711439275344634\n",
            "At step: 4283 training error: 0.6691754294793223\n",
            "At step: 4284 training error: 0.6628600928678258\n",
            "At step: 4285 training error: 0.6665080001723765\n",
            "At step: 4286 training error: 0.6596416708692864\n",
            "At step: 4287 training error: 0.6551075051321837\n",
            "At step: 4288 training error: 0.6586188122244205\n",
            "At step: 4289 training error: 0.6697389247874272\n",
            "At step: 4290 training error: 0.6636895036836417\n",
            "At step: 4291 training error: 0.6641322822985969\n",
            "At step: 4292 training error: 0.6678502159228648\n",
            "At step: 4293 training error: 0.6598686892302976\n",
            "At step: 4294 training error: 0.658560449837917\n",
            "At step: 4295 training error: 0.6600002675751566\n",
            "At step: 4296 training error: 0.6579534299396415\n",
            "At step: 4297 training error: 0.6556785211606208\n",
            "At step: 4298 training error: 0.6552965516103365\n",
            "At step: 4299 training error: 0.6562923589761157\n",
            "At step: 4300 training error: 0.6594614474577777\n",
            "At step: 4301 training error: 0.6677467459305215\n",
            "At step: 4302 training error: 0.6756455170514094\n",
            "At step: 4303 training error: 0.6711598355901089\n",
            "At step: 4304 training error: 0.6719734334226011\n",
            "At step: 4305 training error: 0.6718421900115144\n",
            "At step: 4306 training error: 0.6682893758458417\n",
            "At step: 4307 training error: 0.6692294715044799\n",
            "At step: 4308 training error: 0.6777094481943385\n",
            "At step: 4309 training error: 0.6707691123378648\n",
            "At step: 4310 training error: 0.6706230503488932\n",
            "At step: 4311 training error: 0.6640808216456866\n",
            "At step: 4312 training error: 0.6563793250057969\n",
            "At step: 4313 training error: 0.6512927520736155\n",
            "At step: 4314 training error: 0.6538119531166859\n",
            "At step: 4315 training error: 0.64964626620152\n",
            "At step: 4316 training error: 0.6460560076836085\n",
            "At step: 4317 training error: 0.6519587248281183\n",
            "At step: 4318 training error: 0.6499983552733759\n",
            "At step: 4319 training error: 0.6442085679973371\n",
            "At step: 4320 training error: 0.652756799216555\n",
            "At step: 4321 training error: 0.658186387165486\n",
            "At step: 4322 training error: 0.652421074275454\n",
            "At step: 4323 training error: 0.6454289978280547\n",
            "At step: 4324 training error: 0.6472269181493829\n",
            "At step: 4325 training error: 0.6549038666591078\n",
            "At step: 4326 training error: 0.6589484148293966\n",
            "At step: 4327 training error: 0.6573676000968571\n",
            "At step: 4328 training error: 0.6561779097558824\n",
            "At step: 4329 training error: 0.661416495024004\n",
            "At step: 4330 training error: 0.6563894720062973\n",
            "At step: 4331 training error: 0.6613637350993828\n",
            "At step: 4332 training error: 0.6601052892843915\n",
            "At step: 4333 training error: 0.6534612830265298\n",
            "At step: 4334 training error: 0.658986751676587\n",
            "At step: 4335 training error: 0.6664001339583703\n",
            "At step: 4336 training error: 0.6560137120480763\n",
            "At step: 4337 training error: 0.6631416039611765\n",
            "At step: 4338 training error: 0.6636290946953995\n",
            "At step: 4339 training error: 0.6692972190998668\n",
            "At step: 4340 training error: 0.6641921684588612\n",
            "At step: 4341 training error: 0.6645999081470474\n",
            "At step: 4342 training error: 0.6661954437527945\n",
            "At step: 4343 training error: 0.6769116108173161\n",
            "At step: 4344 training error: 0.667156044621709\n",
            "At step: 4345 training error: 0.6643193299255304\n",
            "At step: 4346 training error: 0.6622994261725949\n",
            "At step: 4347 training error: 0.6678898294811796\n",
            "At step: 4348 training error: 0.6617062681466194\n",
            "At step: 4349 training error: 0.6590226846222618\n",
            "At step: 4350 training error: 0.6537446389885386\n",
            "At step: 4351 training error: 0.6553589966029634\n",
            "At step: 4352 training error: 0.672464934499571\n",
            "At step: 4353 training error: 0.6748188425336801\n",
            "At step: 4354 training error: 0.6720647246204806\n",
            "At step: 4355 training error: 0.6704353653224054\n",
            "At step: 4356 training error: 0.6621443893940281\n",
            "At step: 4357 training error: 0.6588303037800376\n",
            "At step: 4358 training error: 0.655119341289407\n",
            "At step: 4359 training error: 0.6565197891927587\n",
            "At step: 4360 training error: 0.6619814697464546\n",
            "At step: 4361 training error: 0.6647001105447641\n",
            "At step: 4362 training error: 0.6524118135113984\n",
            "At step: 4363 training error: 0.6559863652030481\n",
            "At step: 4364 training error: 0.6616749463890899\n",
            "At step: 4365 training error: 0.6594061594297665\n",
            "At step: 4366 training error: 0.6523483882118665\n",
            "At step: 4367 training error: 0.6510057619948431\n",
            "At step: 4368 training error: 0.6538155657018792\n",
            "At step: 4369 training error: 0.6563420425621409\n",
            "At step: 4370 training error: 0.6528049436729625\n",
            "At step: 4371 training error: 0.6559371400804762\n",
            "At step: 4372 training error: 0.6499866268056399\n",
            "At step: 4373 training error: 0.6554346577416191\n",
            "At step: 4374 training error: 0.6559523244128728\n",
            "At step: 4375 training error: 0.6557202553469689\n",
            "At step: 4376 training error: 0.6597518922384112\n",
            "At step: 4377 training error: 0.6614533987055994\n",
            "At step: 4378 training error: 0.6576534435010674\n",
            "At step: 4379 training error: 0.6678687020083687\n",
            "At step: 4380 training error: 0.6599800343833359\n",
            "At step: 4381 training error: 0.6636516365628198\n",
            "At step: 4382 training error: 0.6702293338651607\n",
            "At step: 4383 training error: 0.6640424023921023\n",
            "At step: 4384 training error: 0.6624569386100181\n",
            "At step: 4385 training error: 0.6547616764463507\n",
            "At step: 4386 training error: 0.6490189952504065\n",
            "At step: 4387 training error: 0.6530103345809101\n",
            "At step: 4388 training error: 0.6498395957051535\n",
            "At step: 4389 training error: 0.651055211545157\n",
            "At step: 4390 training error: 0.6565846411360274\n",
            "At step: 4391 training error: 0.6515592387130802\n",
            "At step: 4392 training error: 0.6507466101788376\n",
            "At step: 4393 training error: 0.656553785424091\n",
            "At step: 4394 training error: 0.6566881143440711\n",
            "At step: 4395 training error: 0.6649466313579582\n",
            "At step: 4396 training error: 0.6634737990643782\n",
            "At step: 4397 training error: 0.6714463330941656\n",
            "At step: 4398 training error: 0.6732675588134703\n",
            "At step: 4399 training error: 0.6774252321224828\n",
            "At step: 4400 training error: 0.6755118838462227\n",
            "At step: 4401 training error: 0.6705525397111874\n",
            "At step: 4402 training error: 0.6708803164570607\n",
            "At step: 4403 training error: 0.6658311035273657\n",
            "At step: 4404 training error: 0.6568479024458517\n",
            "At step: 4405 training error: 0.6522721313839493\n",
            "At step: 4406 training error: 0.6454529386233571\n",
            "At step: 4407 training error: 0.6348001540451332\n",
            "At step: 4408 training error: 0.6232941986127486\n",
            "At step: 4409 training error: 0.6274842522804958\n",
            "At step: 4410 training error: 0.6272000134720735\n",
            "At step: 4411 training error: 0.6339049954883468\n",
            "At step: 4412 training error: 0.6418443414123415\n",
            "At step: 4413 training error: 0.645658846944952\n",
            "At step: 4414 training error: 0.6390666178782715\n",
            "At step: 4415 training error: 0.6340261061826207\n",
            "At step: 4416 training error: 0.6339310872588657\n",
            "At step: 4417 training error: 0.6289916458938293\n",
            "At step: 4418 training error: 0.6396340739865725\n",
            "At step: 4419 training error: 0.6387402395929781\n",
            "At step: 4420 training error: 0.6501197451558258\n",
            "At step: 4421 training error: 0.6427987820684044\n",
            "At step: 4422 training error: 0.6346633192287977\n",
            "At step: 4423 training error: 0.6453746230904601\n",
            "At step: 4424 training error: 0.6490055909982037\n",
            "At step: 4425 training error: 0.6536928859178562\n",
            "At step: 4426 training error: 0.6601075854575179\n",
            "At step: 4427 training error: 0.6678916710589916\n",
            "At step: 4428 training error: 0.6671267752889669\n",
            "At step: 4429 training error: 0.667031431189628\n",
            "At step: 4430 training error: 0.6625699791982315\n",
            "At step: 4431 training error: 0.6545096737324853\n",
            "At step: 4432 training error: 0.6581883681518176\n",
            "At step: 4433 training error: 0.6615483435517809\n",
            "At step: 4434 training error: 0.6651130002099758\n",
            "At step: 4435 training error: 0.6681171112738834\n",
            "At step: 4436 training error: 0.6688330278888768\n",
            "At step: 4437 training error: 0.6657389887507407\n",
            "At step: 4438 training error: 0.6630605649670352\n",
            "At step: 4439 training error: 0.6607311435899654\n",
            "At step: 4440 training error: 0.6546510506306322\n",
            "At step: 4441 training error: 0.656330218959287\n",
            "At step: 4442 training error: 0.6576719924404653\n",
            "At step: 4443 training error: 0.6583714076466826\n",
            "At step: 4444 training error: 0.6652807923633173\n",
            "At step: 4445 training error: 0.6644214198300746\n",
            "At step: 4446 training error: 0.6624224577726968\n",
            "At step: 4447 training error: 0.6652459772643934\n",
            "At step: 4448 training error: 0.6749854036449349\n",
            "At step: 4449 training error: 0.669880407567463\n",
            "At step: 4450 training error: 0.6694300795350412\n",
            "At step: 4451 training error: 0.6729104000627415\n",
            "At step: 4452 training error: 0.6790349911763164\n",
            "At step: 4453 training error: 0.677701595332399\n",
            "At step: 4454 training error: 0.6713796461896632\n",
            "At step: 4455 training error: 0.6746475902691623\n",
            "At step: 4456 training error: 0.6751325858271607\n",
            "At step: 4457 training error: 0.6766806915769494\n",
            "At step: 4458 training error: 0.6779244063366769\n",
            "At step: 4459 training error: 0.6723156063533946\n",
            "At step: 4460 training error: 0.6778740315356724\n",
            "At step: 4461 training error: 0.6750280778310136\n",
            "At step: 4462 training error: 0.6705767731618593\n",
            "At step: 4463 training error: 0.6732969658664207\n",
            "At step: 4464 training error: 0.6644869239639645\n",
            "At step: 4465 training error: 0.6704693582082148\n",
            "At step: 4466 training error: 0.669201954577902\n",
            "At step: 4467 training error: 0.6558778476647885\n",
            "At step: 4468 training error: 0.6674030412890948\n",
            "At step: 4469 training error: 0.6671931219868947\n",
            "At step: 4470 training error: 0.6643120555722326\n",
            "At step: 4471 training error: 0.6599028688746763\n",
            "At step: 4472 training error: 0.6577640865971723\n",
            "At step: 4473 training error: 0.6605931547649875\n",
            "At step: 4474 training error: 0.6639445686737495\n",
            "At step: 4475 training error: 0.6728019527484673\n",
            "At step: 4476 training error: 0.6705325090762401\n",
            "At step: 4477 training error: 0.6721035767816375\n",
            "At step: 4478 training error: 0.6700177995505574\n",
            "At step: 4479 training error: 0.6722081583427761\n",
            "At step: 4480 training error: 0.6756804086614268\n",
            "At step: 4481 training error: 0.6715501879726029\n",
            "At step: 4482 training error: 0.6591849712239346\n",
            "At step: 4483 training error: 0.6593842821754886\n",
            "At step: 4484 training error: 0.6550909041988063\n",
            "At step: 4485 training error: 0.6653299511783709\n",
            "At step: 4486 training error: 0.663575947671091\n",
            "At step: 4487 training error: 0.6661780989238133\n",
            "At step: 4488 training error: 0.6628745283140126\n",
            "At step: 4489 training error: 0.6681688220167495\n",
            "At step: 4490 training error: 0.6811850510972454\n",
            "At step: 4491 training error: 0.6773057377900601\n",
            "At step: 4492 training error: 0.6710384472529121\n",
            "At step: 4493 training error: 0.670811821228915\n",
            "At step: 4494 training error: 0.6682092417765831\n",
            "At step: 4495 training error: 0.6615320406369116\n",
            "At step: 4496 training error: 0.6637999640437465\n",
            "At step: 4497 training error: 0.6570820177601353\n",
            "At step: 4498 training error: 0.663585703526105\n",
            "At step: 4499 training error: 0.6517131188596754\n",
            "At step: 4500 training error: 0.6520716903733923\n",
            "At step: 4501 training error: 0.6514102707772563\n",
            "At step: 4502 training error: 0.6463507538525998\n",
            "At step: 4503 training error: 0.6559176726058326\n",
            "At step: 4504 training error: 0.6556959765142757\n",
            "At step: 4505 training error: 0.6615756215752405\n",
            "At step: 4506 training error: 0.6704716911289058\n",
            "At step: 4507 training error: 0.6661361683436972\n",
            "At step: 4508 training error: 0.6654498804350124\n",
            "At step: 4509 training error: 0.6690244951274967\n",
            "At step: 4510 training error: 0.6450408248340986\n",
            "At step: 4511 training error: 0.6473689347113684\n",
            "At step: 4512 training error: 0.6552323818537489\n",
            "At step: 4513 training error: 0.6497160140818098\n",
            "At step: 4514 training error: 0.6516243776946337\n",
            "At step: 4515 training error: 0.6541441669759613\n",
            "At step: 4516 training error: 0.6541036022966824\n",
            "At step: 4517 training error: 0.6594733261537522\n",
            "At step: 4518 training error: 0.6634933690495934\n",
            "At step: 4519 training error: 0.6611537056197118\n",
            "At step: 4520 training error: 0.658098046730272\n",
            "At step: 4521 training error: 0.6510844444542303\n",
            "At step: 4522 training error: 0.6545087654482349\n",
            "At step: 4523 training error: 0.6591078179011024\n",
            "At step: 4524 training error: 0.6534674564359797\n",
            "At step: 4525 training error: 0.6537921703181876\n",
            "At step: 4526 training error: 0.6484333935680416\n",
            "At step: 4527 training error: 0.6463019557303584\n",
            "At step: 4528 training error: 0.6441506548470566\n",
            "At step: 4529 training error: 0.6512300140146654\n",
            "At step: 4530 training error: 0.6552601896916596\n",
            "At step: 4531 training error: 0.6466353037803416\n",
            "At step: 4532 training error: 0.643852112077029\n",
            "At step: 4533 training error: 0.6410812733010258\n",
            "At step: 4534 training error: 0.6368933779367836\n",
            "At step: 4535 training error: 0.6474788909847352\n",
            "At step: 4536 training error: 0.6445710469676429\n",
            "At step: 4537 training error: 0.6385808069889418\n",
            "At step: 4538 training error: 0.6480375061865515\n",
            "At step: 4539 training error: 0.6563888499534581\n",
            "At step: 4540 training error: 0.6491116396577579\n",
            "At step: 4541 training error: 0.6351055315304786\n",
            "At step: 4542 training error: 0.6416350716043107\n",
            "At step: 4543 training error: 0.6396215697101445\n",
            "At step: 4544 training error: 0.637149008092054\n",
            "At step: 4545 training error: 0.6361379520018952\n",
            "At step: 4546 training error: 0.6404259526284234\n",
            "At step: 4547 training error: 0.634659639310487\n",
            "At step: 4548 training error: 0.6341376498033094\n",
            "At step: 4549 training error: 0.6362252282920893\n",
            "At step: 4550 training error: 0.6435163252593442\n",
            "At step: 4551 training error: 0.638215770419665\n",
            "At step: 4552 training error: 0.6515633901773779\n",
            "At step: 4553 training error: 0.644034522635287\n",
            "At step: 4554 training error: 0.6471061512918902\n",
            "At step: 4555 training error: 0.6522847138797557\n",
            "At step: 4556 training error: 0.6536830019742265\n",
            "At step: 4557 training error: 0.6487222439608891\n",
            "At step: 4558 training error: 0.6442979737884509\n",
            "At step: 4559 training error: 0.6452143440807221\n",
            "At step: 4560 training error: 0.6469441310679362\n",
            "At step: 4561 training error: 0.6513324954156273\n",
            "At step: 4562 training error: 0.6579849734199634\n",
            "At step: 4563 training error: 0.6601843322618254\n",
            "At step: 4564 training error: 0.6581048433371135\n",
            "At step: 4565 training error: 0.6556178683122104\n",
            "At step: 4566 training error: 0.6507511754204527\n",
            "At step: 4567 training error: 0.6532763350972661\n",
            "At step: 4568 training error: 0.6510762241230059\n",
            "At step: 4569 training error: 0.6597722930916196\n",
            "At step: 4570 training error: 0.6683496049412565\n",
            "At step: 4571 training error: 0.6660943490461119\n",
            "At step: 4572 training error: 0.6677994622991823\n",
            "At step: 4573 training error: 0.6666843651461207\n",
            "At step: 4574 training error: 0.6596676469706181\n",
            "At step: 4575 training error: 0.6530830519388197\n",
            "At step: 4576 training error: 0.6581371949345675\n",
            "At step: 4577 training error: 0.6604822796269406\n",
            "At step: 4578 training error: 0.6667475871211519\n",
            "At step: 4579 training error: 0.6695041867067619\n",
            "At step: 4580 training error: 0.6654157196740808\n",
            "At step: 4581 training error: 0.6658421270459511\n",
            "At step: 4582 training error: 0.6736627613333304\n",
            "At step: 4583 training error: 0.6787534929219567\n",
            "At step: 4584 training error: 0.6717052496162599\n",
            "At step: 4585 training error: 0.6705453663782626\n",
            "At step: 4586 training error: 0.6635126950548957\n",
            "At step: 4587 training error: 0.6635512339465263\n",
            "At step: 4588 training error: 0.6541779147977438\n",
            "At step: 4589 training error: 0.654214010161744\n",
            "At step: 4590 training error: 0.6528154523165313\n",
            "At step: 4591 training error: 0.6595088083643031\n",
            "At step: 4592 training error: 0.6557711066058949\n",
            "At step: 4593 training error: 0.6541831437356999\n",
            "At step: 4594 training error: 0.6563178823643573\n",
            "At step: 4595 training error: 0.6559830192320599\n",
            "At step: 4596 training error: 0.6551474212420575\n",
            "At step: 4597 training error: 0.6534169506782035\n",
            "At step: 4598 training error: 0.6562764234835219\n",
            "At step: 4599 training error: 0.6553660543213871\n",
            "At step: 4600 training error: 0.6477517741155963\n",
            "At step: 4601 training error: 0.6500552472944966\n",
            "At step: 4602 training error: 0.644087101385334\n",
            "At step: 4603 training error: 0.6389775723128551\n",
            "At step: 4604 training error: 0.6404712588276084\n",
            "At step: 4605 training error: 0.6472595709876228\n",
            "At step: 4606 training error: 0.6509639216356399\n",
            "At step: 4607 training error: 0.6536765361927108\n",
            "At step: 4608 training error: 0.648752411962365\n",
            "At step: 4609 training error: 0.652220421073562\n",
            "At step: 4610 training error: 0.6448487640189372\n",
            "At step: 4611 training error: 0.6486319194282242\n",
            "At step: 4612 training error: 0.6471670958917703\n",
            "At step: 4613 training error: 0.6437935966707582\n",
            "At step: 4614 training error: 0.644651609426697\n",
            "At step: 4615 training error: 0.6376100934047542\n",
            "At step: 4616 training error: 0.6461731454839659\n",
            "At step: 4617 training error: 0.6535868649676992\n",
            "At step: 4618 training error: 0.6495056828379022\n",
            "At step: 4619 training error: 0.6426410569224174\n",
            "At step: 4620 training error: 0.6457772908779514\n",
            "At step: 4621 training error: 0.643751118346802\n",
            "At step: 4622 training error: 0.6415921192209351\n",
            "At step: 4623 training error: 0.6427919697981518\n",
            "At step: 4624 training error: 0.6561897314561089\n",
            "At step: 4625 training error: 0.6609776738618489\n",
            "At step: 4626 training error: 0.6543439847746788\n",
            "At step: 4627 training error: 0.6631298088549581\n",
            "At step: 4628 training error: 0.6592677844289591\n",
            "At step: 4629 training error: 0.6632017269693529\n",
            "At step: 4630 training error: 0.6576438814949283\n",
            "At step: 4631 training error: 0.655384112630494\n",
            "At step: 4632 training error: 0.6650991237747428\n",
            "At step: 4633 training error: 0.6645913776449441\n",
            "At step: 4634 training error: 0.6624320227061329\n",
            "At step: 4635 training error: 0.661928081723409\n",
            "At step: 4636 training error: 0.6631976975863483\n",
            "At step: 4637 training error: 0.6584848125722024\n",
            "At step: 4638 training error: 0.6577975473933116\n",
            "At step: 4639 training error: 0.6595837874080165\n",
            "At step: 4640 training error: 0.6483894927321354\n",
            "At step: 4641 training error: 0.6466903727092355\n",
            "At step: 4642 training error: 0.646080904550974\n",
            "At step: 4643 training error: 0.6474398903606022\n",
            "At step: 4644 training error: 0.6549529020634876\n",
            "At step: 4645 training error: 0.663190252159316\n",
            "At step: 4646 training error: 0.668027081182537\n",
            "At step: 4647 training error: 0.6742772653787807\n",
            "At step: 4648 training error: 0.6732342381796314\n",
            "At step: 4649 training error: 0.6750673317462835\n",
            "At step: 4650 training error: 0.6676286240877185\n",
            "At step: 4651 training error: 0.6636520412239698\n",
            "At step: 4652 training error: 0.6573330260956987\n",
            "At step: 4653 training error: 0.6494462925000829\n",
            "At step: 4654 training error: 0.6544475398675224\n",
            "At step: 4655 training error: 0.6553442526325953\n",
            "At step: 4656 training error: 0.660377688974941\n",
            "At step: 4657 training error: 0.660025850406657\n",
            "At step: 4658 training error: 0.6571386687011262\n",
            "At step: 4659 training error: 0.6538360871941448\n",
            "At step: 4660 training error: 0.6492495412688477\n",
            "At step: 4661 training error: 0.6604391389180114\n",
            "At step: 4662 training error: 0.6609806377059284\n",
            "At step: 4663 training error: 0.6564619219843454\n",
            "At step: 4664 training error: 0.6471694616933164\n",
            "At step: 4665 training error: 0.6433961989694904\n",
            "At step: 4666 training error: 0.6422291369968819\n",
            "At step: 4667 training error: 0.6477638215652244\n",
            "At step: 4668 training error: 0.6472962687460211\n",
            "At step: 4669 training error: 0.6476054274538668\n",
            "At step: 4670 training error: 0.6505906008463183\n",
            "At step: 4671 training error: 0.6553045058491949\n",
            "At step: 4672 training error: 0.6626256532954805\n",
            "At step: 4673 training error: 0.6705196578295582\n",
            "At step: 4674 training error: 0.6712129885035155\n",
            "At step: 4675 training error: 0.6655884187647131\n",
            "At step: 4676 training error: 0.6682706916257855\n",
            "At step: 4677 training error: 0.6673184662922174\n",
            "At step: 4678 training error: 0.6596537063706559\n",
            "At step: 4679 training error: 0.6595720836869204\n",
            "At step: 4680 training error: 0.6587817787730815\n",
            "At step: 4681 training error: 0.6550613513756678\n",
            "At step: 4682 training error: 0.6501573735076539\n",
            "At step: 4683 training error: 0.6624470014957147\n",
            "At step: 4684 training error: 0.6580019947972139\n",
            "At step: 4685 training error: 0.6592487158570108\n",
            "At step: 4686 training error: 0.6574307346650854\n",
            "At step: 4687 training error: 0.6614562628400678\n",
            "At step: 4688 training error: 0.6655967395572798\n",
            "At step: 4689 training error: 0.6682008241020604\n",
            "At step: 4690 training error: 0.6596416380294935\n",
            "At step: 4691 training error: 0.6533271171379477\n",
            "At step: 4692 training error: 0.6520593476727574\n",
            "At step: 4693 training error: 0.6502572929632116\n",
            "At step: 4694 training error: 0.6584136395236285\n",
            "At step: 4695 training error: 0.6555669232461719\n",
            "At step: 4696 training error: 0.6520426199906636\n",
            "At step: 4697 training error: 0.6542490647067574\n",
            "At step: 4698 training error: 0.647661170199863\n",
            "At step: 4699 training error: 0.6511340190303094\n",
            "At step: 4700 training error: 0.6568617662985267\n",
            "At step: 4701 training error: 0.6547096904930294\n",
            "At step: 4702 training error: 0.6531690801118709\n",
            "At step: 4703 training error: 0.653785394699154\n",
            "At step: 4704 training error: 0.6514280381526256\n",
            "At step: 4705 training error: 0.6466825727359827\n",
            "At step: 4706 training error: 0.6431305450523876\n",
            "At step: 4707 training error: 0.6402961231069251\n",
            "At step: 4708 training error: 0.6403425983723702\n",
            "At step: 4709 training error: 0.6439618113035338\n",
            "At step: 4710 training error: 0.64309856728324\n",
            "At step: 4711 training error: 0.6375005387383599\n",
            "At step: 4712 training error: 0.6455934613714824\n",
            "At step: 4713 training error: 0.6388378878601453\n",
            "At step: 4714 training error: 0.6340545053070825\n",
            "At step: 4715 training error: 0.6382173195717815\n",
            "At step: 4716 training error: 0.6300281660350269\n",
            "At step: 4717 training error: 0.631284707824636\n",
            "At step: 4718 training error: 0.6333550571543576\n",
            "At step: 4719 training error: 0.6375173629829561\n",
            "At step: 4720 training error: 0.6368725705495202\n",
            "At step: 4721 training error: 0.6435052852483553\n",
            "At step: 4722 training error: 0.6469005317231817\n",
            "At step: 4723 training error: 0.644705338538634\n",
            "At step: 4724 training error: 0.6530235835275991\n",
            "At step: 4725 training error: 0.6469935713610204\n",
            "At step: 4726 training error: 0.651343272443867\n",
            "At step: 4727 training error: 0.6436477102385343\n",
            "At step: 4728 training error: 0.6434972490167651\n",
            "At step: 4729 training error: 0.6442238138633987\n",
            "At step: 4730 training error: 0.6386445320346399\n",
            "At step: 4731 training error: 0.6451042643615734\n",
            "At step: 4732 training error: 0.6467785605032178\n",
            "At step: 4733 training error: 0.6499842883950919\n",
            "At step: 4734 training error: 0.6523604403293424\n",
            "At step: 4735 training error: 0.650330198232667\n",
            "At step: 4736 training error: 0.648915630737637\n",
            "At step: 4737 training error: 0.6453269533835588\n",
            "At step: 4738 training error: 0.6415418800148847\n",
            "At step: 4739 training error: 0.6464070244893602\n",
            "At step: 4740 training error: 0.6453013944668494\n",
            "At step: 4741 training error: 0.6417647042555091\n",
            "At step: 4742 training error: 0.6349495602383152\n",
            "At step: 4743 training error: 0.6384695698313646\n",
            "At step: 4744 training error: 0.6415484236697778\n",
            "At step: 4745 training error: 0.6430312636917731\n",
            "At step: 4746 training error: 0.6555776615693233\n",
            "At step: 4747 training error: 0.6582974268721521\n",
            "At step: 4748 training error: 0.659226958307307\n",
            "At step: 4749 training error: 0.6579254404162028\n",
            "At step: 4750 training error: 0.6617418232217727\n",
            "At step: 4751 training error: 0.6639383578715113\n",
            "At step: 4752 training error: 0.670734215385152\n",
            "At step: 4753 training error: 0.6808574742310866\n",
            "At step: 4754 training error: 0.6769646852288349\n",
            "At step: 4755 training error: 0.6666026534206353\n",
            "At step: 4756 training error: 0.6660377075476592\n",
            "At step: 4757 training error: 0.6626982719055133\n",
            "At step: 4758 training error: 0.6559561394033709\n",
            "At step: 4759 training error: 0.6590852879755967\n",
            "At step: 4760 training error: 0.6628230570366203\n",
            "At step: 4761 training error: 0.6624652083810639\n",
            "At step: 4762 training error: 0.6531836888139361\n",
            "At step: 4763 training error: 0.6467263692431624\n",
            "At step: 4764 training error: 0.6418181250770821\n",
            "At step: 4765 training error: 0.6401737962458252\n",
            "At step: 4766 training error: 0.6434511387036916\n",
            "At step: 4767 training error: 0.639993745494886\n",
            "At step: 4768 training error: 0.6303300044731567\n",
            "At step: 4769 training error: 0.6400869412105481\n",
            "At step: 4770 training error: 0.6455979543160376\n",
            "At step: 4771 training error: 0.6438698918679394\n",
            "At step: 4772 training error: 0.6445492557626114\n",
            "At step: 4773 training error: 0.6437930215009109\n",
            "At step: 4774 training error: 0.6424567625147031\n",
            "At step: 4775 training error: 0.6419430585503845\n",
            "At step: 4776 training error: 0.6490213105813828\n",
            "At step: 4777 training error: 0.6575995379035907\n",
            "At step: 4778 training error: 0.6494913130765599\n",
            "At step: 4779 training error: 0.6451044934546758\n",
            "At step: 4780 training error: 0.6447980365164246\n",
            "At step: 4781 training error: 0.6464782689888843\n",
            "At step: 4782 training error: 0.6512995606939542\n",
            "At step: 4783 training error: 0.657766781024262\n",
            "At step: 4784 training error: 0.6604005993688536\n",
            "At step: 4785 training error: 0.6624153757502557\n",
            "At step: 4786 training error: 0.6589263201765424\n",
            "At step: 4787 training error: 0.6584526293637512\n",
            "At step: 4788 training error: 0.6478426665769852\n",
            "At step: 4789 training error: 0.6458123119180168\n",
            "At step: 4790 training error: 0.6370350809315344\n",
            "At step: 4791 training error: 0.6413306818037453\n",
            "At step: 4792 training error: 0.63370469627434\n",
            "At step: 4793 training error: 0.6383546554775981\n",
            "At step: 4794 training error: 0.6301437997444354\n",
            "At step: 4795 training error: 0.633881485459503\n",
            "At step: 4796 training error: 0.635099311275816\n",
            "At step: 4797 training error: 0.6316268192055428\n",
            "At step: 4798 training error: 0.638209418015185\n",
            "At step: 4799 training error: 0.6392102433910487\n",
            "At step: 4800 training error: 0.6367461110573659\n",
            "At step: 4801 training error: 0.639351793301504\n",
            "At step: 4802 training error: 0.6422941265255873\n",
            "At step: 4803 training error: 0.644365991100755\n",
            "At step: 4804 training error: 0.63939877289412\n",
            "At step: 4805 training error: 0.6453226912189626\n",
            "At step: 4806 training error: 0.6499803125607433\n",
            "At step: 4807 training error: 0.6348727400795776\n",
            "At step: 4808 training error: 0.6263793579523573\n",
            "At step: 4809 training error: 0.6243636585601536\n",
            "At step: 4810 training error: 0.6268620743232743\n",
            "At step: 4811 training error: 0.6241693866019867\n",
            "At step: 4812 training error: 0.6139288720586583\n",
            "At step: 4813 training error: 0.6113236663743548\n",
            "At step: 4814 training error: 0.6216002391770152\n",
            "At step: 4815 training error: 0.6318182950577574\n",
            "At step: 4816 training error: 0.634752467068536\n",
            "At step: 4817 training error: 0.6433015895829637\n",
            "At step: 4818 training error: 0.6404961953813972\n",
            "At step: 4819 training error: 0.6292922631720405\n",
            "At step: 4820 training error: 0.6294980821370438\n",
            "At step: 4821 training error: 0.6219344759151685\n",
            "At step: 4822 training error: 0.6336650177771518\n",
            "At step: 4823 training error: 0.6365368631159882\n",
            "At step: 4824 training error: 0.6380680121340029\n",
            "At step: 4825 training error: 0.6514158751012223\n",
            "At step: 4826 training error: 0.6350126261531328\n",
            "At step: 4827 training error: 0.6363457749527046\n",
            "At step: 4828 training error: 0.6353225246024695\n",
            "At step: 4829 training error: 0.6284114995579786\n",
            "At step: 4830 training error: 0.6307059649531801\n",
            "At step: 4831 training error: 0.6297305817114435\n",
            "At step: 4832 training error: 0.6349865404631543\n",
            "At step: 4833 training error: 0.6295920931559196\n",
            "At step: 4834 training error: 0.631032594152482\n",
            "At step: 4835 training error: 0.6241582519229291\n",
            "At step: 4836 training error: 0.6144689956315642\n",
            "At step: 4837 training error: 0.6193374822466768\n",
            "At step: 4838 training error: 0.6228873376535748\n",
            "At step: 4839 training error: 0.6254094058715436\n",
            "At step: 4840 training error: 0.6246502088673253\n",
            "At step: 4841 training error: 0.6264281120429805\n",
            "At step: 4842 training error: 0.6244569715590799\n",
            "At step: 4843 training error: 0.6246984829878603\n",
            "At step: 4844 training error: 0.625174815932059\n",
            "At step: 4845 training error: 0.6298020102558679\n",
            "At step: 4846 training error: 0.6270217304173618\n",
            "At step: 4847 training error: 0.6229699346452517\n",
            "At step: 4848 training error: 0.6345957455698784\n",
            "At step: 4849 training error: 0.640182931221841\n",
            "At step: 4850 training error: 0.6444046083661842\n",
            "At step: 4851 training error: 0.6466937592979045\n",
            "At step: 4852 training error: 0.6375948848977067\n",
            "At step: 4853 training error: 0.6329820757241155\n",
            "At step: 4854 training error: 0.6422143382561348\n",
            "At step: 4855 training error: 0.6373172294177467\n",
            "At step: 4856 training error: 0.6412296021293632\n",
            "At step: 4857 training error: 0.636193580478822\n",
            "At step: 4858 training error: 0.6343819019014351\n",
            "At step: 4859 training error: 0.6427572112217186\n",
            "At step: 4860 training error: 0.6570797351444679\n",
            "At step: 4861 training error: 0.6608420858494092\n",
            "At step: 4862 training error: 0.6627548198158255\n",
            "At step: 4863 training error: 0.6601327955019853\n",
            "At step: 4864 training error: 0.667587977569484\n",
            "At step: 4865 training error: 0.6730627872042207\n",
            "At step: 4866 training error: 0.6710204680950426\n",
            "At step: 4867 training error: 0.6705488179429863\n",
            "At step: 4868 training error: 0.6780613908622233\n",
            "At step: 4869 training error: 0.6773323827024423\n",
            "At step: 4870 training error: 0.6664688715121363\n",
            "At step: 4871 training error: 0.663480514980155\n",
            "At step: 4872 training error: 0.6590942237641028\n",
            "At step: 4873 training error: 0.6571172873330458\n",
            "At step: 4874 training error: 0.6500329177759191\n",
            "At step: 4875 training error: 0.6503630793527928\n",
            "At step: 4876 training error: 0.6516844328180517\n",
            "At step: 4877 training error: 0.6452832214340465\n",
            "At step: 4878 training error: 0.6436859747672122\n",
            "At step: 4879 training error: 0.6504399664723752\n",
            "At step: 4880 training error: 0.6549155555427074\n",
            "At step: 4881 training error: 0.6600773017568549\n",
            "At step: 4882 training error: 0.6631075696966724\n",
            "At step: 4883 training error: 0.6568319192106076\n",
            "At step: 4884 training error: 0.660132781992222\n",
            "At step: 4885 training error: 0.6608922239700172\n",
            "At step: 4886 training error: 0.6636270608694136\n",
            "At step: 4887 training error: 0.6733684787128329\n",
            "At step: 4888 training error: 0.6748046155119474\n",
            "At step: 4889 training error: 0.6675986684861307\n",
            "At step: 4890 training error: 0.6674780534474415\n",
            "At step: 4891 training error: 0.668733998968923\n",
            "At step: 4892 training error: 0.6607471464523349\n",
            "At step: 4893 training error: 0.6485427563653214\n",
            "At step: 4894 training error: 0.644007174128342\n",
            "At step: 4895 training error: 0.6377983914471128\n",
            "At step: 4896 training error: 0.6332480597640529\n",
            "At step: 4897 training error: 0.6266957980039359\n",
            "At step: 4898 training error: 0.6257490303322338\n",
            "At step: 4899 training error: 0.6361903545331735\n",
            "At step: 4900 training error: 0.6422307369555871\n",
            "At step: 4901 training error: 0.6549526749259995\n",
            "At step: 4902 training error: 0.6468991420595982\n",
            "At step: 4903 training error: 0.6470685685961587\n",
            "At step: 4904 training error: 0.6477326535355611\n",
            "At step: 4905 training error: 0.6441842828970378\n",
            "At step: 4906 training error: 0.656491209726318\n",
            "At step: 4907 training error: 0.6460130644525315\n",
            "At step: 4908 training error: 0.649867489717163\n",
            "At step: 4909 training error: 0.6447128323559729\n",
            "At step: 4910 training error: 0.6310189941991655\n",
            "At step: 4911 training error: 0.6282666217469449\n",
            "At step: 4912 training error: 0.6318399563817515\n",
            "At step: 4913 training error: 0.6479887616802746\n",
            "At step: 4914 training error: 0.6494933408658019\n",
            "At step: 4915 training error: 0.6352087981447664\n",
            "At step: 4916 training error: 0.6388791187949475\n",
            "At step: 4917 training error: 0.6349327806355067\n",
            "At step: 4918 training error: 0.628164581905801\n",
            "At step: 4919 training error: 0.6307161157115408\n",
            "At step: 4920 training error: 0.6265081249398158\n",
            "At step: 4921 training error: 0.6278731954371346\n",
            "At step: 4922 training error: 0.6208460908456471\n",
            "At step: 4923 training error: 0.6221472808482077\n",
            "At step: 4924 training error: 0.6309454932396723\n",
            "At step: 4925 training error: 0.633310687132868\n",
            "At step: 4926 training error: 0.646300731200699\n",
            "At step: 4927 training error: 0.6432078723566295\n",
            "At step: 4928 training error: 0.6472058764895038\n",
            "At step: 4929 training error: 0.6386189667916506\n",
            "At step: 4930 training error: 0.6387449864980662\n",
            "At step: 4931 training error: 0.6381666787892917\n",
            "At step: 4932 training error: 0.6473368114299852\n",
            "At step: 4933 training error: 0.637786990584191\n",
            "At step: 4934 training error: 0.6380230267826686\n",
            "At step: 4935 training error: 0.6413324397351438\n",
            "At step: 4936 training error: 0.646283441939718\n",
            "At step: 4937 training error: 0.6371240728607228\n",
            "At step: 4938 training error: 0.6327000732600017\n",
            "At step: 4939 training error: 0.6400730129308525\n",
            "At step: 4940 training error: 0.6359015333256725\n",
            "At step: 4941 training error: 0.6375502060039057\n",
            "At step: 4942 training error: 0.6467091213223779\n",
            "At step: 4943 training error: 0.6487444178595166\n",
            "At step: 4944 training error: 0.6516886010942491\n",
            "At step: 4945 training error: 0.6535425342859074\n",
            "At step: 4946 training error: 0.6542569881132478\n",
            "At step: 4947 training error: 0.6546209830817971\n",
            "At step: 4948 training error: 0.6540586565875047\n",
            "At step: 4949 training error: 0.6543119460147051\n",
            "At step: 4950 training error: 0.6480020889249638\n",
            "At step: 4951 training error: 0.6365830671161157\n",
            "At step: 4952 training error: 0.6287939673037192\n",
            "At step: 4953 training error: 0.6299546019094607\n",
            "At step: 4954 training error: 0.6390637918069281\n",
            "At step: 4955 training error: 0.6490836026480538\n",
            "At step: 4956 training error: 0.6582944858485587\n",
            "At step: 4957 training error: 0.6582817616127523\n",
            "At step: 4958 training error: 0.6538804459977491\n",
            "At step: 4959 training error: 0.6471644050804232\n",
            "At step: 4960 training error: 0.6439733799908743\n",
            "At step: 4961 training error: 0.642173942340377\n",
            "At step: 4962 training error: 0.6375422459571868\n",
            "At step: 4963 training error: 0.6269927207933317\n",
            "At step: 4964 training error: 0.6271393705635191\n",
            "At step: 4965 training error: 0.6227041865622197\n",
            "At step: 4966 training error: 0.6213524579600072\n",
            "At step: 4967 training error: 0.6134135623895163\n",
            "At step: 4968 training error: 0.6264165145828612\n",
            "At step: 4969 training error: 0.625740427328213\n",
            "At step: 4970 training error: 0.6260971099730184\n",
            "At step: 4971 training error: 0.6265986149608201\n",
            "At step: 4972 training error: 0.6439050544619893\n",
            "At step: 4973 training error: 0.6549953849840872\n",
            "At step: 4974 training error: 0.6582256863756685\n",
            "At step: 4975 training error: 0.6567836993154226\n",
            "At step: 4976 training error: 0.651002330048571\n",
            "At step: 4977 training error: 0.6538154150681679\n",
            "At step: 4978 training error: 0.6467607971580587\n",
            "At step: 4979 training error: 0.6475239996515356\n",
            "At step: 4980 training error: 0.6452465909325695\n",
            "At step: 4981 training error: 0.6413271288989759\n",
            "At step: 4982 training error: 0.6449385067750159\n",
            "At step: 4983 training error: 0.6532631922757579\n",
            "At step: 4984 training error: 0.6527141148771193\n",
            "At step: 4985 training error: 0.6584122810408459\n",
            "At step: 4986 training error: 0.6530310829523627\n",
            "At step: 4987 training error: 0.6564020788563352\n",
            "At step: 4988 training error: 0.6463798812224739\n",
            "At step: 4989 training error: 0.6446129546848719\n",
            "At step: 4990 training error: 0.6466724199476283\n",
            "At step: 4991 training error: 0.6433545934737641\n",
            "At step: 4992 training error: 0.6522758816209685\n",
            "At step: 4993 training error: 0.6496852142581843\n",
            "At step: 4994 training error: 0.6467441135662778\n",
            "At step: 4995 training error: 0.6481581634362784\n",
            "At step: 4996 training error: 0.6550709160059395\n",
            "At step: 4997 training error: 0.6517706704948569\n",
            "At step: 4998 training error: 0.6557039411086791\n",
            "At step: 4999 training error: 0.6549275813289922\n",
            "At step: 5000 training error: 0.6521437732755033\n",
            "At step: 5001 training error: 0.6545566294311245\n",
            "At step: 5002 training error: 0.6488791300501088\n",
            "At step: 5003 training error: 0.6476231854203425\n",
            "At step: 5004 training error: 0.6425077785986687\n",
            "At step: 5005 training error: 0.6336343536085185\n",
            "At step: 5006 training error: 0.637852170532788\n",
            "At step: 5007 training error: 0.6390521713399411\n",
            "At step: 5008 training error: 0.6397749255507559\n",
            "At step: 5009 training error: 0.6315725813786469\n",
            "At step: 5010 training error: 0.6331371070787021\n",
            "At step: 5011 training error: 0.6329323856408849\n",
            "At step: 5012 training error: 0.6359976916424536\n",
            "At step: 5013 training error: 0.6307293530644524\n",
            "At step: 5014 training error: 0.6368847722245351\n",
            "At step: 5015 training error: 0.6402729681534141\n",
            "At step: 5016 training error: 0.650473817166485\n",
            "At step: 5017 training error: 0.6537593491316321\n",
            "At step: 5018 training error: 0.6532375112115258\n",
            "At step: 5019 training error: 0.6374510664782109\n",
            "At step: 5020 training error: 0.6389006438546406\n",
            "At step: 5021 training error: 0.6320298498279553\n",
            "At step: 5022 training error: 0.6342341795173604\n",
            "At step: 5023 training error: 0.6347844109464003\n",
            "At step: 5024 training error: 0.629709602659783\n",
            "At step: 5025 training error: 0.6297966663053725\n",
            "At step: 5026 training error: 0.6414532644338183\n",
            "At step: 5027 training error: 0.6470257735462402\n",
            "At step: 5028 training error: 0.6457124532884335\n",
            "At step: 5029 training error: 0.6405961930164816\n",
            "At step: 5030 training error: 0.6408818787816356\n",
            "At step: 5031 training error: 0.6434346589240743\n",
            "At step: 5032 training error: 0.638344694416907\n",
            "At step: 5033 training error: 0.6355750432394586\n",
            "At step: 5034 training error: 0.6402180778888967\n",
            "At step: 5035 training error: 0.6486504080028532\n",
            "At step: 5036 training error: 0.6604526275484732\n",
            "At step: 5037 training error: 0.6605655169254903\n",
            "At step: 5038 training error: 0.6556649162797576\n",
            "At step: 5039 training error: 0.6500098497643645\n",
            "At step: 5040 training error: 0.6535127071323674\n",
            "At step: 5041 training error: 0.6456450824298862\n",
            "At step: 5042 training error: 0.638136570583788\n",
            "At step: 5043 training error: 0.6389189810971673\n",
            "At step: 5044 training error: 0.6459672875421834\n",
            "At step: 5045 training error: 0.6505657053450173\n",
            "At step: 5046 training error: 0.6451005380822884\n",
            "At step: 5047 training error: 0.6354308579477572\n",
            "At step: 5048 training error: 0.6433441413767198\n",
            "At step: 5049 training error: 0.6449760088947408\n",
            "At step: 5050 training error: 0.6398904657824838\n",
            "At step: 5051 training error: 0.6348317111943435\n",
            "At step: 5052 training error: 0.6290584810771122\n",
            "At step: 5053 training error: 0.6300398564635804\n",
            "At step: 5054 training error: 0.6258011805903567\n",
            "At step: 5055 training error: 0.6261069972538165\n",
            "At step: 5056 training error: 0.6229230913427971\n",
            "At step: 5057 training error: 0.6319840740697568\n",
            "At step: 5058 training error: 0.6327617984778198\n",
            "At step: 5059 training error: 0.6217361559683061\n",
            "At step: 5060 training error: 0.6141087175147791\n",
            "At step: 5061 training error: 0.6169161364280425\n",
            "At step: 5062 training error: 0.6158212396308254\n",
            "At step: 5063 training error: 0.6156289887729763\n",
            "At step: 5064 training error: 0.6163291607091121\n",
            "At step: 5065 training error: 0.6331878787425546\n",
            "At step: 5066 training error: 0.6190530074500346\n",
            "At step: 5067 training error: 0.6234057098529142\n",
            "At step: 5068 training error: 0.6324662381074951\n",
            "At step: 5069 training error: 0.6375005991141659\n",
            "At step: 5070 training error: 0.629016438363593\n",
            "At step: 5071 training error: 0.6333715510886624\n",
            "At step: 5072 training error: 0.6399352039780761\n",
            "At step: 5073 training error: 0.6366456632840918\n",
            "At step: 5074 training error: 0.6280812611468152\n",
            "At step: 5075 training error: 0.6365371240720156\n",
            "At step: 5076 training error: 0.6380823121511071\n",
            "At step: 5077 training error: 0.6381130448679884\n",
            "At step: 5078 training error: 0.6320698712386094\n",
            "At step: 5079 training error: 0.6387159737579173\n",
            "At step: 5080 training error: 0.63817871835199\n",
            "At step: 5081 training error: 0.6378302702364227\n",
            "At step: 5082 training error: 0.6371917972129039\n",
            "At step: 5083 training error: 0.6352930035446369\n",
            "At step: 5084 training error: 0.6377751946982468\n",
            "At step: 5085 training error: 0.639358244588705\n",
            "At step: 5086 training error: 0.643070842047628\n",
            "At step: 5087 training error: 0.6395614952843639\n",
            "At step: 5088 training error: 0.6464955483110879\n",
            "At step: 5089 training error: 0.6482446194811434\n",
            "At step: 5090 training error: 0.6467971389158399\n",
            "At step: 5091 training error: 0.6558311208804242\n",
            "At step: 5092 training error: 0.6501515210682566\n",
            "At step: 5093 training error: 0.6509414296990581\n",
            "At step: 5094 training error: 0.6428901972347192\n",
            "At step: 5095 training error: 0.6437307475285217\n",
            "At step: 5096 training error: 0.634252883138199\n",
            "At step: 5097 training error: 0.6367746993144341\n",
            "At step: 5098 training error: 0.6375165364435559\n",
            "At step: 5099 training error: 0.6383106604665173\n",
            "At step: 5100 training error: 0.6315046571000774\n",
            "At step: 5101 training error: 0.6318979588415248\n",
            "At step: 5102 training error: 0.6399093268784982\n",
            "At step: 5103 training error: 0.6472696420532162\n",
            "At step: 5104 training error: 0.6492081946076897\n",
            "At step: 5105 training error: 0.641253046586825\n",
            "At step: 5106 training error: 0.6368564354611864\n",
            "At step: 5107 training error: 0.6410013516718343\n",
            "At step: 5108 training error: 0.6410756549411203\n",
            "At step: 5109 training error: 0.6313760581670446\n",
            "At step: 5110 training error: 0.6335711028223987\n",
            "At step: 5111 training error: 0.6346019507542521\n",
            "At step: 5112 training error: 0.6393388332615804\n",
            "At step: 5113 training error: 0.6507995453292444\n",
            "At step: 5114 training error: 0.6522093035728895\n",
            "At step: 5115 training error: 0.6458826403322414\n",
            "At step: 5116 training error: 0.6455829402956511\n",
            "At step: 5117 training error: 0.6420621826503841\n",
            "At step: 5118 training error: 0.6549483151061508\n",
            "At step: 5119 training error: 0.6567758888431646\n",
            "At step: 5120 training error: 0.6535396048849927\n",
            "At step: 5121 training error: 0.6519884273184933\n",
            "At step: 5122 training error: 0.653353885459501\n",
            "At step: 5123 training error: 0.6518912712271803\n",
            "At step: 5124 training error: 0.6431360774882007\n",
            "At step: 5125 training error: 0.6379184236494413\n",
            "At step: 5126 training error: 0.6406618164065484\n",
            "At step: 5127 training error: 0.6385738960125404\n",
            "At step: 5128 training error: 0.6407329910641951\n",
            "At step: 5129 training error: 0.6285084773351228\n",
            "At step: 5130 training error: 0.6358824469112648\n",
            "At step: 5131 training error: 0.6355381110432177\n",
            "At step: 5132 training error: 0.6393571781590331\n",
            "At step: 5133 training error: 0.6380152991993584\n",
            "At step: 5134 training error: 0.6421874887009498\n",
            "At step: 5135 training error: 0.632791586920897\n",
            "At step: 5136 training error: 0.6368244347902114\n",
            "At step: 5137 training error: 0.6419244852088559\n",
            "At step: 5138 training error: 0.639977879761457\n",
            "At step: 5139 training error: 0.6430126352577592\n",
            "At step: 5140 training error: 0.6469660824449182\n",
            "At step: 5141 training error: 0.6510502471263437\n",
            "At step: 5142 training error: 0.6505755946397059\n",
            "At step: 5143 training error: 0.653534929225736\n",
            "At step: 5144 training error: 0.6420327134000979\n",
            "At step: 5145 training error: 0.6359890515185349\n",
            "At step: 5146 training error: 0.6471402389109677\n",
            "At step: 5147 training error: 0.6448148084696317\n",
            "At step: 5148 training error: 0.6515159917362771\n",
            "At step: 5149 training error: 0.6514551931103917\n",
            "At step: 5150 training error: 0.6582633791824557\n",
            "At step: 5151 training error: 0.6515507626669694\n",
            "At step: 5152 training error: 0.6504165496159858\n",
            "At step: 5153 training error: 0.6511348617679049\n",
            "At step: 5154 training error: 0.6474744970705563\n",
            "At step: 5155 training error: 0.648535694952198\n",
            "At step: 5156 training error: 0.6392372016408513\n",
            "At step: 5157 training error: 0.6280129868327443\n",
            "At step: 5158 training error: 0.6312521717538184\n",
            "At step: 5159 training error: 0.639310123581393\n",
            "At step: 5160 training error: 0.6316182318420632\n",
            "At step: 5161 training error: 0.6274519375927294\n",
            "At step: 5162 training error: 0.6175301699046729\n",
            "At step: 5163 training error: 0.6136116857610843\n",
            "At step: 5164 training error: 0.6114168641275551\n",
            "At step: 5165 training error: 0.6188356202230446\n",
            "At step: 5166 training error: 0.6247164517893383\n",
            "At step: 5167 training error: 0.6201210098387594\n",
            "At step: 5168 training error: 0.6236698025165714\n",
            "At step: 5169 training error: 0.6256120617720913\n",
            "At step: 5170 training error: 0.6249231214690828\n",
            "At step: 5171 training error: 0.6208579177495238\n",
            "At step: 5172 training error: 0.6200925623073581\n",
            "At step: 5173 training error: 0.610317198767167\n",
            "At step: 5174 training error: 0.609406593989229\n",
            "At step: 5175 training error: 0.6174220354922688\n",
            "At step: 5176 training error: 0.6221740937222957\n",
            "At step: 5177 training error: 0.6187027309305786\n",
            "At step: 5178 training error: 0.6205677368801736\n",
            "At step: 5179 training error: 0.6183668828937218\n",
            "At step: 5180 training error: 0.6154251569275256\n",
            "At step: 5181 training error: 0.6219051200960063\n",
            "At step: 5182 training error: 0.6244587198229493\n",
            "At step: 5183 training error: 0.6256502860863596\n",
            "At step: 5184 training error: 0.633118113032356\n",
            "At step: 5185 training error: 0.6240690590578171\n",
            "At step: 5186 training error: 0.6250765066081295\n",
            "At step: 5187 training error: 0.629679468890914\n",
            "At step: 5188 training error: 0.628260795314963\n",
            "At step: 5189 training error: 0.6326378749809839\n",
            "At step: 5190 training error: 0.6346105290859785\n",
            "At step: 5191 training error: 0.6337569420612512\n",
            "At step: 5192 training error: 0.6390973823553678\n",
            "At step: 5193 training error: 0.6406260518668416\n",
            "At step: 5194 training error: 0.6313830967321449\n",
            "At step: 5195 training error: 0.6339457237086857\n",
            "At step: 5196 training error: 0.6320677438368444\n",
            "At step: 5197 training error: 0.633261711147842\n",
            "At step: 5198 training error: 0.625574905222748\n",
            "At step: 5199 training error: 0.6224712944242341\n",
            "At step: 5200 training error: 0.6248121942840801\n",
            "At step: 5201 training error: 0.6261159842994217\n",
            "At step: 5202 training error: 0.6392150143791262\n",
            "At step: 5203 training error: 0.63419239260123\n",
            "At step: 5204 training error: 0.6437090934632741\n",
            "At step: 5205 training error: 0.6391713846170776\n",
            "At step: 5206 training error: 0.6410949004107408\n",
            "At step: 5207 training error: 0.6323467714615116\n",
            "At step: 5208 training error: 0.6303602828350718\n",
            "At step: 5209 training error: 0.6374216116227862\n",
            "At step: 5210 training error: 0.6420146713313548\n",
            "At step: 5211 training error: 0.6392193732104556\n",
            "At step: 5212 training error: 0.6376748921851785\n",
            "At step: 5213 training error: 0.643260801858989\n",
            "At step: 5214 training error: 0.6443173766307462\n",
            "At step: 5215 training error: 0.646017435949547\n",
            "At step: 5216 training error: 0.6364752493135954\n",
            "At step: 5217 training error: 0.6339126969581039\n",
            "At step: 5218 training error: 0.6349095206160095\n",
            "At step: 5219 training error: 0.6269816914105497\n",
            "At step: 5220 training error: 0.6270280657305612\n",
            "At step: 5221 training error: 0.6263184372598316\n",
            "At step: 5222 training error: 0.624602909530152\n",
            "At step: 5223 training error: 0.625569220848109\n",
            "At step: 5224 training error: 0.6318920917316947\n",
            "At step: 5225 training error: 0.6367963253631919\n",
            "At step: 5226 training error: 0.6352658406804188\n",
            "At step: 5227 training error: 0.6304708491798632\n",
            "At step: 5228 training error: 0.6486461326440642\n",
            "At step: 5229 training error: 0.6423949591459168\n",
            "At step: 5230 training error: 0.6444198269172488\n",
            "At step: 5231 training error: 0.6409502449038099\n",
            "At step: 5232 training error: 0.6445018667779402\n",
            "At step: 5233 training error: 0.6564015916669957\n",
            "At step: 5234 training error: 0.6540327409180088\n",
            "At step: 5235 training error: 0.6545945663592933\n",
            "At step: 5236 training error: 0.6555280814686492\n",
            "At step: 5237 training error: 0.6636299939922174\n",
            "At step: 5238 training error: 0.6590754556116074\n",
            "At step: 5239 training error: 0.6638217511665073\n",
            "At step: 5240 training error: 0.6580304791993381\n",
            "At step: 5241 training error: 0.6573528988214958\n",
            "At step: 5242 training error: 0.6493177900656244\n",
            "At step: 5243 training error: 0.6440486608091431\n",
            "At step: 5244 training error: 0.639978482429634\n",
            "At step: 5245 training error: 0.6346135883659884\n",
            "At step: 5246 training error: 0.6285183440979214\n",
            "At step: 5247 training error: 0.6272242173295217\n",
            "At step: 5248 training error: 0.6333854362316002\n",
            "At step: 5249 training error: 0.6287359090177104\n",
            "At step: 5250 training error: 0.6264273899450842\n",
            "At step: 5251 training error: 0.6224460919871307\n",
            "At step: 5252 training error: 0.6381711660879521\n",
            "At step: 5253 training error: 0.6386286837206094\n",
            "At step: 5254 training error: 0.6325343813337576\n",
            "At step: 5255 training error: 0.626765834984819\n",
            "At step: 5256 training error: 0.6245566757726317\n",
            "At step: 5257 training error: 0.625666001807015\n",
            "At step: 5258 training error: 0.6315069013259221\n",
            "At step: 5259 training error: 0.6315636062976684\n",
            "At step: 5260 training error: 0.634936167640667\n",
            "At step: 5261 training error: 0.6193409724856535\n",
            "At step: 5262 training error: 0.6227879030483077\n",
            "At step: 5263 training error: 0.6193374461907086\n",
            "At step: 5264 training error: 0.6232497864484486\n",
            "At step: 5265 training error: 0.621815504496973\n",
            "At step: 5266 training error: 0.6308409758472532\n",
            "At step: 5267 training error: 0.6264257498310143\n",
            "At step: 5268 training error: 0.6311833241864255\n",
            "At step: 5269 training error: 0.6217207117080379\n",
            "At step: 5270 training error: 0.6215607199783361\n",
            "At step: 5271 training error: 0.6166359250149107\n",
            "At step: 5272 training error: 0.6214940057409672\n",
            "At step: 5273 training error: 0.6181196653522822\n",
            "At step: 5274 training error: 0.6192226682085887\n",
            "At step: 5275 training error: 0.6205364480811112\n",
            "At step: 5276 training error: 0.6184650390995651\n",
            "At step: 5277 training error: 0.622501009402896\n",
            "At step: 5278 training error: 0.62059318037338\n",
            "At step: 5279 training error: 0.6183498718122515\n",
            "At step: 5280 training error: 0.6233178480665016\n",
            "At step: 5281 training error: 0.6214660422145402\n",
            "At step: 5282 training error: 0.6181590636521804\n",
            "At step: 5283 training error: 0.6181363188305311\n",
            "At step: 5284 training error: 0.6238386842250093\n",
            "At step: 5285 training error: 0.6234058955167371\n",
            "At step: 5286 training error: 0.6273983131420524\n",
            "At step: 5287 training error: 0.6223710066236783\n",
            "At step: 5288 training error: 0.6166325066729479\n",
            "At step: 5289 training error: 0.6199352589951715\n",
            "At step: 5290 training error: 0.6237803179151777\n",
            "At step: 5291 training error: 0.624410474891805\n",
            "At step: 5292 training error: 0.6323518516533772\n",
            "At step: 5293 training error: 0.6373952837365204\n",
            "At step: 5294 training error: 0.6335427521655785\n",
            "At step: 5295 training error: 0.6284134960442687\n",
            "At step: 5296 training error: 0.6265007799625723\n",
            "At step: 5297 training error: 0.633789804047587\n",
            "At step: 5298 training error: 0.6325790712347756\n",
            "At step: 5299 training error: 0.635463499581251\n",
            "At step: 5300 training error: 0.6347399392688339\n",
            "At step: 5301 training error: 0.627703584070717\n",
            "At step: 5302 training error: 0.6222833171704473\n",
            "At step: 5303 training error: 0.6282048432638465\n",
            "At step: 5304 training error: 0.6238089979632512\n",
            "At step: 5305 training error: 0.6272477530258275\n",
            "At step: 5306 training error: 0.6290679043573534\n",
            "At step: 5307 training error: 0.6424916216005563\n",
            "At step: 5308 training error: 0.6485260349723879\n",
            "At step: 5309 training error: 0.6481384851636174\n",
            "At step: 5310 training error: 0.6490160286984039\n",
            "At step: 5311 training error: 0.6479293023538456\n",
            "At step: 5312 training error: 0.623119387968741\n",
            "At step: 5313 training error: 0.6168096846215302\n",
            "At step: 5314 training error: 0.6240644766975832\n",
            "At step: 5315 training error: 0.621388055051748\n",
            "At step: 5316 training error: 0.6333182427190994\n",
            "At step: 5317 training error: 0.6320926247237009\n",
            "At step: 5318 training error: 0.645388836610134\n",
            "At step: 5319 training error: 0.6381004644307575\n",
            "At step: 5320 training error: 0.6406864513067743\n",
            "At step: 5321 training error: 0.6451179828178827\n",
            "At step: 5322 training error: 0.638537134038794\n",
            "At step: 5323 training error: 0.6356987340411306\n",
            "At step: 5324 training error: 0.6412830899581384\n",
            "At step: 5325 training error: 0.6357671657094617\n",
            "At step: 5326 training error: 0.6428161736211091\n",
            "At step: 5327 training error: 0.6394665495057605\n",
            "At step: 5328 training error: 0.6361204213421302\n",
            "At step: 5329 training error: 0.6289374381167473\n",
            "At step: 5330 training error: 0.6266919675934127\n",
            "At step: 5331 training error: 0.6293371408440354\n",
            "At step: 5332 training error: 0.631266651859304\n",
            "At step: 5333 training error: 0.6274361157667785\n",
            "At step: 5334 training error: 0.6280505112801822\n",
            "At step: 5335 training error: 0.6375840421920862\n",
            "At step: 5336 training error: 0.6347885288364707\n",
            "At step: 5337 training error: 0.6275172756691679\n",
            "At step: 5338 training error: 0.6245772081922487\n",
            "At step: 5339 training error: 0.6290801481181703\n",
            "At step: 5340 training error: 0.6205823638964869\n",
            "At step: 5341 training error: 0.6284724340892386\n",
            "At step: 5342 training error: 0.6355800450163981\n",
            "At step: 5343 training error: 0.6282160827690336\n",
            "At step: 5344 training error: 0.6119393014234952\n",
            "At step: 5345 training error: 0.6194499614107313\n",
            "At step: 5346 training error: 0.6139342570828631\n",
            "At step: 5347 training error: 0.6220025868525444\n",
            "At step: 5348 training error: 0.6262657487229346\n",
            "At step: 5349 training error: 0.6327150583163744\n",
            "At step: 5350 training error: 0.6347223276149198\n",
            "At step: 5351 training error: 0.6288115989890722\n",
            "At step: 5352 training error: 0.6268712911762123\n",
            "At step: 5353 training error: 0.6301326655296151\n",
            "At step: 5354 training error: 0.6271094460486989\n",
            "At step: 5355 training error: 0.629345248268814\n",
            "At step: 5356 training error: 0.6352114266211024\n",
            "At step: 5357 training error: 0.6327709390301426\n",
            "At step: 5358 training error: 0.6229957574366363\n",
            "At step: 5359 training error: 0.6177785404558013\n",
            "At step: 5360 training error: 0.6135456998893812\n",
            "At step: 5361 training error: 0.628088238742202\n",
            "At step: 5362 training error: 0.6263659496043064\n",
            "At step: 5363 training error: 0.6269833995884773\n",
            "At step: 5364 training error: 0.6218091071130678\n",
            "At step: 5365 training error: 0.6219775891082987\n",
            "At step: 5366 training error: 0.6161699665994709\n",
            "At step: 5367 training error: 0.6213958223864715\n",
            "At step: 5368 training error: 0.6271037363579453\n",
            "At step: 5369 training error: 0.6330099877904383\n",
            "At step: 5370 training error: 0.6422596106517857\n",
            "At step: 5371 training error: 0.6385447500980097\n",
            "At step: 5372 training error: 0.6375248867848167\n",
            "At step: 5373 training error: 0.6325308726111257\n",
            "At step: 5374 training error: 0.6247766105035251\n",
            "At step: 5375 training error: 0.6171537422134995\n",
            "At step: 5376 training error: 0.6090048833051463\n",
            "At step: 5377 training error: 0.6169280852321177\n",
            "At step: 5378 training error: 0.6214733071598924\n",
            "At step: 5379 training error: 0.6176023221273615\n",
            "At step: 5380 training error: 0.6228037581140111\n",
            "At step: 5381 training error: 0.617563623570168\n",
            "At step: 5382 training error: 0.6151898478941757\n",
            "At step: 5383 training error: 0.6180473641562296\n",
            "At step: 5384 training error: 0.6073409279924886\n",
            "At step: 5385 training error: 0.605692844819024\n",
            "At step: 5386 training error: 0.6045958969091815\n",
            "At step: 5387 training error: 0.6026281718429503\n",
            "At step: 5388 training error: 0.6004176725770973\n",
            "At step: 5389 training error: 0.6089520774993952\n",
            "At step: 5390 training error: 0.6129759886178814\n",
            "At step: 5391 training error: 0.6227788501033646\n",
            "At step: 5392 training error: 0.6245606031464677\n",
            "At step: 5393 training error: 0.6319279552533703\n",
            "At step: 5394 training error: 0.6323958989181564\n",
            "At step: 5395 training error: 0.6328084757714889\n",
            "At step: 5396 training error: 0.6395588628686715\n",
            "At step: 5397 training error: 0.6418806554022591\n",
            "At step: 5398 training error: 0.6419795331199376\n",
            "At step: 5399 training error: 0.6438460987138868\n",
            "At step: 5400 training error: 0.6484368444599529\n",
            "At step: 5401 training error: 0.6482838984343402\n",
            "At step: 5402 training error: 0.6359747257509227\n",
            "At step: 5403 training error: 0.6417247621738185\n",
            "At step: 5404 training error: 0.6360285343844844\n",
            "At step: 5405 training error: 0.6396974637478005\n",
            "At step: 5406 training error: 0.6459782588775096\n",
            "At step: 5407 training error: 0.65316099656652\n",
            "At step: 5408 training error: 0.6447643574853258\n",
            "At step: 5409 training error: 0.6407827280072789\n",
            "At step: 5410 training error: 0.6251823634209824\n",
            "At step: 5411 training error: 0.6376954992700843\n",
            "At step: 5412 training error: 0.6293461657619812\n",
            "At step: 5413 training error: 0.6294251144201498\n",
            "At step: 5414 training error: 0.6302463212923658\n",
            "At step: 5415 training error: 0.6340874990297893\n",
            "At step: 5416 training error: 0.6324055071310346\n",
            "At step: 5417 training error: 0.6278598647052429\n",
            "At step: 5418 training error: 0.6283188403278172\n",
            "At step: 5419 training error: 0.6389828537503919\n",
            "At step: 5420 training error: 0.6352433852557146\n",
            "At step: 5421 training error: 0.6372673737791215\n",
            "At step: 5422 training error: 0.6370259579237754\n",
            "At step: 5423 training error: 0.6354385174925063\n",
            "At step: 5424 training error: 0.6284872791796088\n",
            "At step: 5425 training error: 0.6316124776326912\n",
            "At step: 5426 training error: 0.6278562748924351\n",
            "At step: 5427 training error: 0.6262720977319174\n",
            "At step: 5428 training error: 0.6256426081664206\n",
            "At step: 5429 training error: 0.6330498365185664\n",
            "At step: 5430 training error: 0.6308079400934383\n",
            "At step: 5431 training error: 0.6307046406190527\n",
            "At step: 5432 training error: 0.6424601383042858\n",
            "At step: 5433 training error: 0.649063810769354\n",
            "At step: 5434 training error: 0.6370520962589028\n",
            "At step: 5435 training error: 0.6336304926344625\n",
            "At step: 5436 training error: 0.6324649392166553\n",
            "At step: 5437 training error: 0.630412104304064\n",
            "At step: 5438 training error: 0.625934554936945\n",
            "At step: 5439 training error: 0.6307152459014862\n",
            "At step: 5440 training error: 0.6298418385793849\n",
            "At step: 5441 training error: 0.6332314972559926\n",
            "At step: 5442 training error: 0.6415918925177216\n",
            "At step: 5443 training error: 0.6377138925746018\n",
            "At step: 5444 training error: 0.626272750524263\n",
            "At step: 5445 training error: 0.6260550426958915\n",
            "At step: 5446 training error: 0.6249840540977156\n",
            "At step: 5447 training error: 0.6358048172690784\n",
            "At step: 5448 training error: 0.6293245336535283\n",
            "At step: 5449 training error: 0.6279103575408671\n",
            "At step: 5450 training error: 0.618864943932629\n",
            "At step: 5451 training error: 0.6187941655341083\n",
            "At step: 5452 training error: 0.6179211122859672\n",
            "At step: 5453 training error: 0.6164202532029082\n",
            "At step: 5454 training error: 0.6077540233505601\n",
            "At step: 5455 training error: 0.6183459248314686\n",
            "At step: 5456 training error: 0.6184783708470196\n",
            "At step: 5457 training error: 0.6039054845245078\n",
            "At step: 5458 training error: 0.5993523867368944\n",
            "At step: 5459 training error: 0.6034080226996767\n",
            "At step: 5460 training error: 0.5972861028676244\n",
            "At step: 5461 training error: 0.6040146052938599\n",
            "At step: 5462 training error: 0.6087036349525797\n",
            "At step: 5463 training error: 0.6047186403413166\n",
            "At step: 5464 training error: 0.6096577508483835\n",
            "At step: 5465 training error: 0.6127642067343072\n",
            "At step: 5466 training error: 0.620929431641693\n",
            "At step: 5467 training error: 0.6154402552062578\n",
            "At step: 5468 training error: 0.6196401478126763\n",
            "At step: 5469 training error: 0.6200424662676043\n",
            "At step: 5470 training error: 0.61345840606116\n",
            "At step: 5471 training error: 0.6211806452462425\n",
            "At step: 5472 training error: 0.6218657821489227\n",
            "At step: 5473 training error: 0.62334036827837\n",
            "At step: 5474 training error: 0.613098523240843\n",
            "At step: 5475 training error: 0.6081639092118857\n",
            "At step: 5476 training error: 0.6061236861893299\n",
            "At step: 5477 training error: 0.6154440518739781\n",
            "At step: 5478 training error: 0.6213530937087237\n",
            "At step: 5479 training error: 0.6157518535943747\n",
            "At step: 5480 training error: 0.60937079442256\n",
            "At step: 5481 training error: 0.6018575749356556\n",
            "At step: 5482 training error: 0.6039678617351151\n",
            "At step: 5483 training error: 0.6086889243546345\n",
            "At step: 5484 training error: 0.6075471005331077\n",
            "At step: 5485 training error: 0.6151726206761156\n",
            "At step: 5486 training error: 0.6196477940115481\n",
            "At step: 5487 training error: 0.6271528153722407\n",
            "At step: 5488 training error: 0.6266757594260364\n",
            "At step: 5489 training error: 0.6230754587214162\n",
            "At step: 5490 training error: 0.6289357581304611\n",
            "At step: 5491 training error: 0.6275465618083919\n",
            "At step: 5492 training error: 0.6280469796693339\n",
            "At step: 5493 training error: 0.6292635906516642\n",
            "At step: 5494 training error: 0.6230309022130087\n",
            "At step: 5495 training error: 0.6187429241543378\n",
            "At step: 5496 training error: 0.6140842307093942\n",
            "At step: 5497 training error: 0.6204581782717999\n",
            "At step: 5498 training error: 0.6146367702971639\n",
            "At step: 5499 training error: 0.6227869777650121\n",
            "At step: 5500 training error: 0.6222720846539169\n",
            "At step: 5501 training error: 0.6264994155797687\n",
            "At step: 5502 training error: 0.625322029056273\n",
            "At step: 5503 training error: 0.6256574828416536\n",
            "At step: 5504 training error: 0.6258549177320979\n",
            "At step: 5505 training error: 0.6277358201913258\n",
            "At step: 5506 training error: 0.6216785453035484\n",
            "At step: 5507 training error: 0.628420714687143\n",
            "At step: 5508 training error: 0.6266793125844314\n",
            "At step: 5509 training error: 0.6304158021114845\n",
            "At step: 5510 training error: 0.6413255153267691\n",
            "At step: 5511 training error: 0.644713426102685\n",
            "At step: 5512 training error: 0.6420576599083966\n",
            "At step: 5513 training error: 0.6413870084698248\n",
            "At step: 5514 training error: 0.6342895270573509\n",
            "At step: 5515 training error: 0.6392481417278252\n",
            "At step: 5516 training error: 0.6430859507974891\n",
            "At step: 5517 training error: 0.6469863931385964\n",
            "At step: 5518 training error: 0.6417351151249724\n",
            "At step: 5519 training error: 0.6369493447854516\n",
            "At step: 5520 training error: 0.6326159869079828\n",
            "At step: 5521 training error: 0.6267009994180684\n",
            "At step: 5522 training error: 0.6314692632240778\n",
            "At step: 5523 training error: 0.6274959383592794\n",
            "At step: 5524 training error: 0.6232190564467283\n",
            "At step: 5525 training error: 0.619881088753634\n",
            "At step: 5526 training error: 0.6195281793627762\n",
            "At step: 5527 training error: 0.6204602652846207\n",
            "At step: 5528 training error: 0.6258285751931941\n",
            "At step: 5529 training error: 0.6179908515402242\n",
            "At step: 5530 training error: 0.6195852739782923\n",
            "At step: 5531 training error: 0.6350781907382593\n",
            "At step: 5532 training error: 0.6207240370313104\n",
            "At step: 5533 training error: 0.6234420293266892\n",
            "At step: 5534 training error: 0.6239038894819903\n",
            "At step: 5535 training error: 0.6161372063770967\n",
            "At step: 5536 training error: 0.6249934315664568\n",
            "At step: 5537 training error: 0.630457653094745\n",
            "At step: 5538 training error: 0.6328368706798807\n",
            "At step: 5539 training error: 0.6313422837452618\n",
            "At step: 5540 training error: 0.6329452093949224\n",
            "At step: 5541 training error: 0.6242690321173663\n",
            "At step: 5542 training error: 0.621170051719052\n",
            "At step: 5543 training error: 0.6219153734806577\n",
            "At step: 5544 training error: 0.6105654810121467\n",
            "At step: 5545 training error: 0.6116400547514769\n",
            "At step: 5546 training error: 0.6258455955851894\n",
            "At step: 5547 training error: 0.6189305960608013\n",
            "At step: 5548 training error: 0.6240311458343427\n",
            "At step: 5549 training error: 0.6157316716863372\n",
            "At step: 5550 training error: 0.6138193134284325\n",
            "At step: 5551 training error: 0.6145256545616262\n",
            "At step: 5552 training error: 0.6073650128093725\n",
            "At step: 5553 training error: 0.6024195879364346\n",
            "At step: 5554 training error: 0.6208237642889791\n",
            "At step: 5555 training error: 0.6070632640481126\n",
            "At step: 5556 training error: 0.6134030737137738\n",
            "At step: 5557 training error: 0.6148308276848392\n",
            "At step: 5558 training error: 0.6116965916984863\n",
            "At step: 5559 training error: 0.6085229890505593\n",
            "At step: 5560 training error: 0.6058650198319363\n",
            "At step: 5561 training error: 0.6072047969998613\n",
            "At step: 5562 training error: 0.6170893326084174\n",
            "At step: 5563 training error: 0.6130395457389345\n",
            "At step: 5564 training error: 0.6103917915304604\n",
            "At step: 5565 training error: 0.609505307462831\n",
            "At step: 5566 training error: 0.6002426502126059\n",
            "At step: 5567 training error: 0.6031321519899432\n",
            "At step: 5568 training error: 0.6113561686558426\n",
            "At step: 5569 training error: 0.6087311765997289\n",
            "At step: 5570 training error: 0.6139569154137081\n",
            "At step: 5571 training error: 0.6073487686543579\n",
            "At step: 5572 training error: 0.6089225457900993\n",
            "At step: 5573 training error: 0.6087814951408872\n",
            "At step: 5574 training error: 0.6170148335917106\n",
            "At step: 5575 training error: 0.6200786179562832\n",
            "At step: 5576 training error: 0.6192824877147293\n",
            "At step: 5577 training error: 0.6225611964359207\n",
            "At step: 5578 training error: 0.614544375768129\n",
            "At step: 5579 training error: 0.6136344948861034\n",
            "At step: 5580 training error: 0.6063558776137024\n",
            "At step: 5581 training error: 0.6000746647535757\n",
            "At step: 5582 training error: 0.6065256841238524\n",
            "At step: 5583 training error: 0.6136425419858111\n",
            "At step: 5584 training error: 0.6127640831539723\n",
            "At step: 5585 training error: 0.6157712518285657\n",
            "At step: 5586 training error: 0.6187314987882137\n",
            "At step: 5587 training error: 0.6127598643517166\n",
            "At step: 5588 training error: 0.6161830893985745\n",
            "At step: 5589 training error: 0.6157189099665591\n",
            "At step: 5590 training error: 0.6166525049983274\n",
            "At step: 5591 training error: 0.6106370960003854\n",
            "At step: 5592 training error: 0.5988225170799717\n",
            "At step: 5593 training error: 0.5960822526081455\n",
            "At step: 5594 training error: 0.5923336493477415\n",
            "At step: 5595 training error: 0.6055381538202137\n",
            "At step: 5596 training error: 0.6087808527605085\n",
            "At step: 5597 training error: 0.615229242030347\n",
            "At step: 5598 training error: 0.6216662505340184\n",
            "At step: 5599 training error: 0.6271207586692102\n",
            "At step: 5600 training error: 0.6243058049809328\n",
            "At step: 5601 training error: 0.6249227087330722\n",
            "At step: 5602 training error: 0.625407081687758\n",
            "At step: 5603 training error: 0.6276884270339492\n",
            "At step: 5604 training error: 0.6297747660387782\n",
            "At step: 5605 training error: 0.6338119510931978\n",
            "At step: 5606 training error: 0.6360192788498371\n",
            "At step: 5607 training error: 0.6370689413632306\n",
            "At step: 5608 training error: 0.6301167718973355\n",
            "At step: 5609 training error: 0.6237423596621374\n",
            "At step: 5610 training error: 0.6242393420229969\n",
            "At step: 5611 training error: 0.6123595977149162\n",
            "At step: 5612 training error: 0.6141766859452857\n",
            "At step: 5613 training error: 0.6088516023632737\n",
            "At step: 5614 training error: 0.6132135659231606\n",
            "At step: 5615 training error: 0.6063595952743607\n",
            "At step: 5616 training error: 0.6118937240191886\n",
            "At step: 5617 training error: 0.6065415343120449\n",
            "At step: 5618 training error: 0.6070617605110117\n",
            "At step: 5619 training error: 0.6043372035444454\n",
            "At step: 5620 training error: 0.6102421146243787\n",
            "At step: 5621 training error: 0.6183860494921876\n",
            "At step: 5622 training error: 0.6185675738207882\n",
            "At step: 5623 training error: 0.6108162086021333\n",
            "At step: 5624 training error: 0.6141599899976506\n",
            "At step: 5625 training error: 0.6128257252797145\n",
            "At step: 5626 training error: 0.6147018484122462\n",
            "At step: 5627 training error: 0.618459758081727\n",
            "At step: 5628 training error: 0.6176390875971334\n",
            "At step: 5629 training error: 0.6148894268437088\n",
            "At step: 5630 training error: 0.622131955279222\n",
            "At step: 5631 training error: 0.6232834689790364\n",
            "At step: 5632 training error: 0.6142112323759584\n",
            "At step: 5633 training error: 0.6138384969700529\n",
            "At step: 5634 training error: 0.6146146561896882\n",
            "At step: 5635 training error: 0.6076998725444971\n",
            "At step: 5636 training error: 0.6109499600598328\n",
            "At step: 5637 training error: 0.6148304613476553\n",
            "At step: 5638 training error: 0.6044496645295543\n",
            "At step: 5639 training error: 0.5960358743155708\n",
            "At step: 5640 training error: 0.6056717488610319\n",
            "At step: 5641 training error: 0.6062702415864861\n",
            "At step: 5642 training error: 0.597678281344806\n",
            "At step: 5643 training error: 0.594468622806437\n",
            "At step: 5644 training error: 0.6000151844994678\n",
            "At step: 5645 training error: 0.5939792410928726\n",
            "At step: 5646 training error: 0.6018488211879325\n",
            "At step: 5647 training error: 0.6166154121986449\n",
            "At step: 5648 training error: 0.6171670035843213\n",
            "At step: 5649 training error: 0.6065750086064559\n",
            "At step: 5650 training error: 0.6070188567712148\n",
            "At step: 5651 training error: 0.610935437324372\n",
            "At step: 5652 training error: 0.6088776170155807\n",
            "At step: 5653 training error: 0.6073684064573154\n",
            "At step: 5654 training error: 0.6061447547936636\n",
            "At step: 5655 training error: 0.6025743822893258\n",
            "At step: 5656 training error: 0.6046745215706832\n",
            "At step: 5657 training error: 0.5991922316241313\n",
            "At step: 5658 training error: 0.595464606268029\n",
            "At step: 5659 training error: 0.596486176873512\n",
            "At step: 5660 training error: 0.604941822173195\n",
            "At step: 5661 training error: 0.6108170485610854\n",
            "At step: 5662 training error: 0.6089540097911904\n",
            "At step: 5663 training error: 0.6119854052372318\n",
            "At step: 5664 training error: 0.6108452364380976\n",
            "At step: 5665 training error: 0.6074677508586942\n",
            "At step: 5666 training error: 0.5984374421988741\n",
            "At step: 5667 training error: 0.6074176099097157\n",
            "At step: 5668 training error: 0.60570961851494\n",
            "At step: 5669 training error: 0.6126982172593574\n",
            "At step: 5670 training error: 0.6131563627644846\n",
            "At step: 5671 training error: 0.6066176233044462\n",
            "At step: 5672 training error: 0.6104507557989493\n",
            "At step: 5673 training error: 0.609995774409191\n",
            "At step: 5674 training error: 0.618743004452147\n",
            "At step: 5675 training error: 0.6148311671676786\n",
            "At step: 5676 training error: 0.6196772134328378\n",
            "At step: 5677 training error: 0.6238015425540981\n",
            "At step: 5678 training error: 0.6193833953300584\n",
            "At step: 5679 training error: 0.6144502320910991\n",
            "At step: 5680 training error: 0.6101927528439561\n",
            "At step: 5681 training error: 0.6117911949403618\n",
            "At step: 5682 training error: 0.614793381244646\n",
            "At step: 5683 training error: 0.6150347031545994\n",
            "At step: 5684 training error: 0.6023587723759344\n",
            "At step: 5685 training error: 0.5946297702105793\n",
            "At step: 5686 training error: 0.5941233397805947\n",
            "At step: 5687 training error: 0.5907699218567253\n",
            "At step: 5688 training error: 0.5886881736642651\n",
            "At step: 5689 training error: 0.5927110374580103\n",
            "At step: 5690 training error: 0.5955625383055889\n",
            "At step: 5691 training error: 0.5873738530323056\n",
            "At step: 5692 training error: 0.5941776087281583\n",
            "At step: 5693 training error: 0.5893497756813862\n",
            "At step: 5694 training error: 0.5944052064528695\n",
            "At step: 5695 training error: 0.6042374917049176\n",
            "At step: 5696 training error: 0.5960568716883597\n",
            "At step: 5697 training error: 0.6051245621617073\n",
            "At step: 5698 training error: 0.6077768004811908\n",
            "At step: 5699 training error: 0.6105540743071972\n",
            "At step: 5700 training error: 0.6139750506871806\n",
            "At step: 5701 training error: 0.620942175192186\n",
            "At step: 5702 training error: 0.6212283179191925\n",
            "At step: 5703 training error: 0.6250019022810324\n",
            "At step: 5704 training error: 0.6253587345936082\n",
            "At step: 5705 training error: 0.6224264571394338\n",
            "At step: 5706 training error: 0.6228989048898121\n",
            "At step: 5707 training error: 0.6302460783239511\n",
            "At step: 5708 training error: 0.6366622578010179\n",
            "At step: 5709 training error: 0.6275036993516826\n",
            "At step: 5710 training error: 0.6187737627705966\n",
            "At step: 5711 training error: 0.6180990350738512\n",
            "At step: 5712 training error: 0.6235786724092337\n",
            "At step: 5713 training error: 0.6232305024594164\n",
            "At step: 5714 training error: 0.6220651768048594\n",
            "At step: 5715 training error: 0.6202660113952194\n",
            "At step: 5716 training error: 0.6237124691879654\n",
            "At step: 5717 training error: 0.6257216983380548\n",
            "At step: 5718 training error: 0.6203387036116543\n",
            "At step: 5719 training error: 0.6241182886319593\n",
            "At step: 5720 training error: 0.634759772719346\n",
            "At step: 5721 training error: 0.6298184751742294\n",
            "At step: 5722 training error: 0.6337334161213779\n",
            "At step: 5723 training error: 0.6405475943397626\n",
            "At step: 5724 training error: 0.6429664284159843\n",
            "At step: 5725 training error: 0.640042415983611\n",
            "At step: 5726 training error: 0.6347732225775903\n",
            "At step: 5727 training error: 0.6379897746808184\n",
            "At step: 5728 training error: 0.6361608077048682\n",
            "At step: 5729 training error: 0.6414550526644388\n",
            "At step: 5730 training error: 0.6348165340861047\n",
            "At step: 5731 training error: 0.6307734332971352\n",
            "At step: 5732 training error: 0.6292209597626279\n",
            "At step: 5733 training error: 0.6283432844276545\n",
            "At step: 5734 training error: 0.6163456334037589\n",
            "At step: 5735 training error: 0.6171727674170683\n",
            "At step: 5736 training error: 0.6093765158799389\n",
            "At step: 5737 training error: 0.6138485297670183\n",
            "At step: 5738 training error: 0.6107440947342931\n",
            "At step: 5739 training error: 0.6109634741004331\n",
            "At step: 5740 training error: 0.6086466559880571\n",
            "At step: 5741 training error: 0.6108262471433549\n",
            "At step: 5742 training error: 0.6063781132990389\n",
            "At step: 5743 training error: 0.6033724750281576\n",
            "At step: 5744 training error: 0.6132453314224063\n",
            "At step: 5745 training error: 0.5962730905894983\n",
            "At step: 5746 training error: 0.5962577282183571\n",
            "At step: 5747 training error: 0.5887775467496037\n",
            "At step: 5748 training error: 0.59350978746987\n",
            "At step: 5749 training error: 0.5982676547627521\n",
            "At step: 5750 training error: 0.606455908168394\n",
            "At step: 5751 training error: 0.600185705372335\n",
            "At step: 5752 training error: 0.6006595007053173\n",
            "At step: 5753 training error: 0.5861169972392475\n",
            "At step: 5754 training error: 0.589298168450494\n",
            "At step: 5755 training error: 0.583486007358225\n",
            "At step: 5756 training error: 0.5853573986201499\n",
            "At step: 5757 training error: 0.6002596995569182\n",
            "At step: 5758 training error: 0.602487470004123\n",
            "At step: 5759 training error: 0.6067504203575903\n",
            "At step: 5760 training error: 0.6158758040815789\n",
            "At step: 5761 training error: 0.6126483209351408\n",
            "At step: 5762 training error: 0.605669462530622\n",
            "At step: 5763 training error: 0.6029057695678947\n",
            "At step: 5764 training error: 0.6080647663001056\n",
            "At step: 5765 training error: 0.610817378320886\n",
            "At step: 5766 training error: 0.606755604884906\n",
            "At step: 5767 training error: 0.6054752599389877\n",
            "At step: 5768 training error: 0.6066569407119903\n",
            "At step: 5769 training error: 0.6087620851844471\n",
            "At step: 5770 training error: 0.607232154636687\n",
            "At step: 5771 training error: 0.6048713687286903\n",
            "At step: 5772 training error: 0.6053866129681127\n",
            "At step: 5773 training error: 0.5988263757901626\n",
            "At step: 5774 training error: 0.6064050971320948\n",
            "At step: 5775 training error: 0.6024635779110485\n",
            "At step: 5776 training error: 0.60745780672049\n",
            "At step: 5777 training error: 0.610602038493726\n",
            "At step: 5778 training error: 0.6090401562904015\n",
            "At step: 5779 training error: 0.612315472680651\n",
            "At step: 5780 training error: 0.6206300475097761\n",
            "At step: 5781 training error: 0.6121176008389029\n",
            "At step: 5782 training error: 0.6026342800107708\n",
            "At step: 5783 training error: 0.6016868779589208\n",
            "At step: 5784 training error: 0.6083567414126111\n",
            "At step: 5785 training error: 0.6122780802139058\n",
            "At step: 5786 training error: 0.6093436811912534\n",
            "At step: 5787 training error: 0.6078580514445705\n",
            "At step: 5788 training error: 0.6055137239075025\n",
            "At step: 5789 training error: 0.6118020274857987\n",
            "At step: 5790 training error: 0.6060749476169611\n",
            "At step: 5791 training error: 0.6122966681989086\n",
            "At step: 5792 training error: 0.6123667041894171\n",
            "At step: 5793 training error: 0.6149220572241734\n",
            "At step: 5794 training error: 0.6146465577541437\n",
            "At step: 5795 training error: 0.6096117285636717\n",
            "At step: 5796 training error: 0.6143782381472018\n",
            "At step: 5797 training error: 0.619534037289071\n",
            "At step: 5798 training error: 0.6212439091450613\n",
            "At step: 5799 training error: 0.6240381985296798\n",
            "At step: 5800 training error: 0.6304727303546239\n",
            "At step: 5801 training error: 0.6258030606361282\n",
            "At step: 5802 training error: 0.6208997267569258\n",
            "At step: 5803 training error: 0.6131077386274816\n",
            "At step: 5804 training error: 0.6103972567061358\n",
            "At step: 5805 training error: 0.6035401782289332\n",
            "At step: 5806 training error: 0.6141007211524262\n",
            "At step: 5807 training error: 0.6093174164161818\n",
            "At step: 5808 training error: 0.6040197169858161\n",
            "At step: 5809 training error: 0.6042039460768277\n",
            "At step: 5810 training error: 0.6046672109606589\n",
            "At step: 5811 training error: 0.6028746928904406\n",
            "At step: 5812 training error: 0.6088788159005464\n",
            "At step: 5813 training error: 0.5978416290161533\n",
            "At step: 5814 training error: 0.6000999435679075\n",
            "At step: 5815 training error: 0.608225066571025\n",
            "At step: 5816 training error: 0.6077482174893967\n",
            "At step: 5817 training error: 0.6055642401813948\n",
            "At step: 5818 training error: 0.6050444323820124\n",
            "At step: 5819 training error: 0.6022343693084156\n",
            "At step: 5820 training error: 0.6049338521257951\n",
            "At step: 5821 training error: 0.6108188433988161\n",
            "At step: 5822 training error: 0.6036445496192065\n",
            "At step: 5823 training error: 0.6152712156291972\n",
            "At step: 5824 training error: 0.6088332476122845\n",
            "At step: 5825 training error: 0.6159118038761158\n",
            "At step: 5826 training error: 0.623619747141593\n",
            "At step: 5827 training error: 0.6152601731880529\n",
            "At step: 5828 training error: 0.6121898127910601\n",
            "At step: 5829 training error: 0.6118144714679459\n",
            "At step: 5830 training error: 0.6103867324438698\n",
            "At step: 5831 training error: 0.6156478769367723\n",
            "At step: 5832 training error: 0.6177854796407498\n",
            "At step: 5833 training error: 0.6131928251269034\n",
            "At step: 5834 training error: 0.6181883513292138\n",
            "At step: 5835 training error: 0.615864444455375\n",
            "At step: 5836 training error: 0.6119883474210389\n",
            "At step: 5837 training error: 0.6194154251062102\n",
            "At step: 5838 training error: 0.6210368653159485\n",
            "At step: 5839 training error: 0.615534206077317\n",
            "At step: 5840 training error: 0.6091542285471632\n",
            "At step: 5841 training error: 0.6092863769870244\n",
            "At step: 5842 training error: 0.6035888146554425\n",
            "At step: 5843 training error: 0.6000498387126607\n",
            "At step: 5844 training error: 0.6027793308226409\n",
            "At step: 5845 training error: 0.608902128975622\n",
            "At step: 5846 training error: 0.6083502718453905\n",
            "At step: 5847 training error: 0.6053892825543638\n",
            "At step: 5848 training error: 0.5991726905888041\n",
            "At step: 5849 training error: 0.5972721795228645\n",
            "At step: 5850 training error: 0.5987747904847682\n",
            "At step: 5851 training error: 0.5945801421144492\n",
            "At step: 5852 training error: 0.6008024686349925\n",
            "At step: 5853 training error: 0.5909328712434124\n",
            "At step: 5854 training error: 0.5914736947562673\n",
            "At step: 5855 training error: 0.600035253512616\n",
            "At step: 5856 training error: 0.6083912174926588\n",
            "At step: 5857 training error: 0.6206934724236572\n",
            "At step: 5858 training error: 0.6290997625416477\n",
            "At step: 5859 training error: 0.6271543596557714\n",
            "At step: 5860 training error: 0.6172914903649853\n",
            "At step: 5861 training error: 0.6096442055950082\n",
            "At step: 5862 training error: 0.6083936469383444\n",
            "At step: 5863 training error: 0.6101800489535568\n",
            "At step: 5864 training error: 0.607338809806215\n",
            "At step: 5865 training error: 0.6011615332466238\n",
            "At step: 5866 training error: 0.601679732074757\n",
            "At step: 5867 training error: 0.6055489887079145\n",
            "At step: 5868 training error: 0.6027112468817756\n",
            "At step: 5869 training error: 0.6054966465450408\n",
            "At step: 5870 training error: 0.6079874656046486\n",
            "At step: 5871 training error: 0.6045518324301788\n",
            "At step: 5872 training error: 0.606256705440857\n",
            "At step: 5873 training error: 0.604930231808961\n",
            "At step: 5874 training error: 0.6065175132698263\n",
            "At step: 5875 training error: 0.6011806812744335\n",
            "At step: 5876 training error: 0.6031444537606644\n",
            "At step: 5877 training error: 0.6041027182315917\n",
            "At step: 5878 training error: 0.6133073768008939\n",
            "At step: 5879 training error: 0.6055409338913874\n",
            "At step: 5880 training error: 0.5996363996152374\n",
            "At step: 5881 training error: 0.6059933525045258\n",
            "At step: 5882 training error: 0.600224305903242\n",
            "At step: 5883 training error: 0.6149455188577269\n",
            "At step: 5884 training error: 0.6197629396826022\n",
            "At step: 5885 training error: 0.6171100626983879\n",
            "At step: 5886 training error: 0.6183825459228391\n",
            "At step: 5887 training error: 0.620858188078289\n",
            "At step: 5888 training error: 0.6127358483182794\n",
            "At step: 5889 training error: 0.6101286677706094\n",
            "At step: 5890 training error: 0.614289160860509\n",
            "At step: 5891 training error: 0.620861631685168\n",
            "At step: 5892 training error: 0.6127069225223722\n",
            "At step: 5893 training error: 0.6070852437264957\n",
            "At step: 5894 training error: 0.6054947802299493\n",
            "At step: 5895 training error: 0.6037368248824055\n",
            "At step: 5896 training error: 0.6064241836579225\n",
            "At step: 5897 training error: 0.6123125276387877\n",
            "At step: 5898 training error: 0.6106282625478593\n",
            "At step: 5899 training error: 0.601356769648724\n",
            "At step: 5900 training error: 0.6009625209325337\n",
            "At step: 5901 training error: 0.5939085378027329\n",
            "At step: 5902 training error: 0.5948418064786456\n",
            "At step: 5903 training error: 0.5969746388442095\n",
            "At step: 5904 training error: 0.5983219245769352\n",
            "At step: 5905 training error: 0.5998482070474941\n",
            "At step: 5906 training error: 0.5979434288847465\n",
            "At step: 5907 training error: 0.5978968344332545\n",
            "At step: 5908 training error: 0.6003760781388843\n",
            "At step: 5909 training error: 0.601804751581622\n",
            "At step: 5910 training error: 0.6015766620016699\n",
            "At step: 5911 training error: 0.6063618001876007\n",
            "At step: 5912 training error: 0.613057258984061\n",
            "At step: 5913 training error: 0.6126618137074398\n",
            "At step: 5914 training error: 0.6117661915172209\n",
            "At step: 5915 training error: 0.6106998401472451\n",
            "At step: 5916 training error: 0.614380164100266\n",
            "At step: 5917 training error: 0.615756021951741\n",
            "At step: 5918 training error: 0.619788675974587\n",
            "At step: 5919 training error: 0.6101903401944965\n",
            "At step: 5920 training error: 0.620013625291451\n",
            "At step: 5921 training error: 0.6179418816747503\n",
            "At step: 5922 training error: 0.6071543919495734\n",
            "At step: 5923 training error: 0.609577698661586\n",
            "At step: 5924 training error: 0.6125836674580325\n",
            "At step: 5925 training error: 0.6105541115632241\n",
            "At step: 5926 training error: 0.6199515348369128\n",
            "At step: 5927 training error: 0.6197191460558306\n",
            "At step: 5928 training error: 0.6201660555486282\n",
            "At step: 5929 training error: 0.614394971150386\n",
            "At step: 5930 training error: 0.6121406493947824\n",
            "At step: 5931 training error: 0.6174921885572439\n",
            "At step: 5932 training error: 0.6157261101348142\n",
            "At step: 5933 training error: 0.6110863048552708\n",
            "At step: 5934 training error: 0.6182468434286249\n",
            "At step: 5935 training error: 0.6237829116821774\n",
            "At step: 5936 training error: 0.6206427450253937\n",
            "At step: 5937 training error: 0.6147125193472192\n",
            "At step: 5938 training error: 0.623070158060716\n",
            "At step: 5939 training error: 0.6158276022192649\n",
            "At step: 5940 training error: 0.6200187853068051\n",
            "At step: 5941 training error: 0.6119860745375018\n",
            "At step: 5942 training error: 0.6088494334300205\n",
            "At step: 5943 training error: 0.6050810831329418\n",
            "At step: 5944 training error: 0.6090614120145618\n",
            "At step: 5945 training error: 0.6173485229273665\n",
            "At step: 5946 training error: 0.6197806786738539\n",
            "At step: 5947 training error: 0.6224280501724889\n",
            "At step: 5948 training error: 0.6232430556061562\n",
            "At step: 5949 training error: 0.6103176983592306\n",
            "At step: 5950 training error: 0.6244403733342663\n",
            "At step: 5951 training error: 0.6183444428342044\n",
            "At step: 5952 training error: 0.6047320427555704\n",
            "At step: 5953 training error: 0.6135136654585428\n",
            "At step: 5954 training error: 0.6073082800349628\n",
            "At step: 5955 training error: 0.6105923440879091\n",
            "At step: 5956 training error: 0.6163482565214816\n",
            "At step: 5957 training error: 0.6129441790695199\n",
            "At step: 5958 training error: 0.6075554449870987\n",
            "At step: 5959 training error: 0.6061565860701574\n",
            "At step: 5960 training error: 0.60518598937258\n",
            "At step: 5961 training error: 0.609710438741463\n",
            "At step: 5962 training error: 0.6106431562636603\n",
            "At step: 5963 training error: 0.6143002600080687\n",
            "At step: 5964 training error: 0.6108027301972636\n",
            "At step: 5965 training error: 0.6066713952570614\n",
            "At step: 5966 training error: 0.600247899814941\n",
            "At step: 5967 training error: 0.61452174097198\n",
            "At step: 5968 training error: 0.6150194134542764\n",
            "At step: 5969 training error: 0.6123969875657604\n",
            "At step: 5970 training error: 0.6145096748402442\n",
            "At step: 5971 training error: 0.6119222169154453\n",
            "At step: 5972 training error: 0.606494645824005\n",
            "At step: 5973 training error: 0.610017782912953\n",
            "At step: 5974 training error: 0.6283424720149462\n",
            "At step: 5975 training error: 0.6298126540722303\n",
            "At step: 5976 training error: 0.6367793209247155\n",
            "At step: 5977 training error: 0.6333872317075793\n",
            "At step: 5978 training error: 0.6348640756026901\n",
            "At step: 5979 training error: 0.6422381071311251\n",
            "At step: 5980 training error: 0.6291317251532224\n",
            "At step: 5981 training error: 0.623050342742982\n",
            "At step: 5982 training error: 0.6332235707128093\n",
            "At step: 5983 training error: 0.6309019586155605\n",
            "At step: 5984 training error: 0.6157008416391788\n",
            "At step: 5985 training error: 0.6023009340281902\n",
            "At step: 5986 training error: 0.6024150198627792\n",
            "At step: 5987 training error: 0.6015963525267469\n",
            "At step: 5988 training error: 0.6086131766875276\n",
            "At step: 5989 training error: 0.6095972746037593\n",
            "At step: 5990 training error: 0.6119175193058272\n",
            "At step: 5991 training error: 0.6062321690385166\n",
            "At step: 5992 training error: 0.6013838040542828\n",
            "At step: 5993 training error: 0.5946093087258533\n",
            "At step: 5994 training error: 0.592228856159952\n",
            "At step: 5995 training error: 0.5894889707213811\n",
            "At step: 5996 training error: 0.5884243617250001\n",
            "At step: 5997 training error: 0.588265351060713\n",
            "At step: 5998 training error: 0.5941651465840526\n",
            "At step: 5999 training error: 0.6078197061529534\n",
            "At step: 6000 training error: 0.6145553829680408\n",
            "At step: 6001 training error: 0.6104460365349662\n",
            "At step: 6002 training error: 0.618224217660374\n",
            "At step: 6003 training error: 0.6186411840447532\n",
            "At step: 6004 training error: 0.6164441673338302\n",
            "At step: 6005 training error: 0.6157003270224961\n",
            "At step: 6006 training error: 0.618182704177469\n",
            "At step: 6007 training error: 0.6223980796723044\n",
            "At step: 6008 training error: 0.6268655352149137\n",
            "At step: 6009 training error: 0.6299841346960636\n",
            "At step: 6010 training error: 0.6266343781858196\n",
            "At step: 6011 training error: 0.621959302851496\n",
            "At step: 6012 training error: 0.630614874124196\n",
            "At step: 6013 training error: 0.6286493513357005\n",
            "At step: 6014 training error: 0.6282718009943058\n",
            "At step: 6015 training error: 0.6252304169602071\n",
            "At step: 6016 training error: 0.6267682881174201\n",
            "At step: 6017 training error: 0.628518183660597\n",
            "At step: 6018 training error: 0.6223357068898893\n",
            "At step: 6019 training error: 0.6175863734058029\n",
            "At step: 6020 training error: 0.6130454893855799\n",
            "At step: 6021 training error: 0.609472813129644\n",
            "At step: 6022 training error: 0.6012523066440595\n",
            "At step: 6023 training error: 0.6063722250084256\n",
            "At step: 6024 training error: 0.6015753179249047\n",
            "At step: 6025 training error: 0.609300211722955\n",
            "At step: 6026 training error: 0.6058919473972579\n",
            "At step: 6027 training error: 0.60114975377935\n",
            "At step: 6028 training error: 0.5953391902718876\n",
            "At step: 6029 training error: 0.6012645329894397\n",
            "At step: 6030 training error: 0.6066003285804547\n",
            "At step: 6031 training error: 0.6033734192104859\n",
            "At step: 6032 training error: 0.6056081159293124\n",
            "At step: 6033 training error: 0.5981679316006147\n",
            "At step: 6034 training error: 0.5928761096434234\n",
            "At step: 6035 training error: 0.5984881633369019\n",
            "At step: 6036 training error: 0.5947474406526398\n",
            "At step: 6037 training error: 0.586702301628541\n",
            "At step: 6038 training error: 0.5842124334829488\n",
            "At step: 6039 training error: 0.585059700533814\n",
            "At step: 6040 training error: 0.5860053178409999\n",
            "At step: 6041 training error: 0.5864155969536939\n",
            "At step: 6042 training error: 0.5857062668140396\n",
            "At step: 6043 training error: 0.5895273149055738\n",
            "At step: 6044 training error: 0.5864319608158325\n",
            "At step: 6045 training error: 0.584427821158256\n",
            "At step: 6046 training error: 0.5980597947171385\n",
            "At step: 6047 training error: 0.6012726814419056\n",
            "At step: 6048 training error: 0.5971518502159274\n",
            "At step: 6049 training error: 0.6010112076962839\n",
            "At step: 6050 training error: 0.6036371267469629\n",
            "At step: 6051 training error: 0.6083399657266211\n",
            "At step: 6052 training error: 0.6105059131501402\n",
            "At step: 6053 training error: 0.6119699300976024\n",
            "At step: 6054 training error: 0.615397305170451\n",
            "At step: 6055 training error: 0.61748488082322\n",
            "At step: 6056 training error: 0.629915564061185\n",
            "At step: 6057 training error: 0.6333324687488268\n",
            "At step: 6058 training error: 0.6324612250371415\n",
            "At step: 6059 training error: 0.6253254374852963\n",
            "At step: 6060 training error: 0.6239021370451328\n",
            "At step: 6061 training error: 0.6143782325593258\n",
            "At step: 6062 training error: 0.6180416827687966\n",
            "At step: 6063 training error: 0.6248199828282377\n",
            "At step: 6064 training error: 0.6193617073473812\n",
            "At step: 6065 training error: 0.6262831251530525\n",
            "At step: 6066 training error: 0.6257032629840482\n",
            "At step: 6067 training error: 0.6210760599047983\n",
            "At step: 6068 training error: 0.6177609133708332\n",
            "At step: 6069 training error: 0.6149478510657291\n",
            "At step: 6070 training error: 0.6171879540737132\n",
            "At step: 6071 training error: 0.6145819193624694\n",
            "At step: 6072 training error: 0.6207319258169476\n",
            "At step: 6073 training error: 0.6198105380013001\n",
            "At step: 6074 training error: 0.607923200099881\n",
            "At step: 6075 training error: 0.6047497700030394\n",
            "At step: 6076 training error: 0.6085998540208906\n",
            "At step: 6077 training error: 0.612086475779367\n",
            "At step: 6078 training error: 0.6026925503651087\n",
            "At step: 6079 training error: 0.6021788338859964\n",
            "At step: 6080 training error: 0.6008850508172049\n",
            "At step: 6081 training error: 0.609392672398291\n",
            "At step: 6082 training error: 0.6073959689675387\n",
            "At step: 6083 training error: 0.5923161421705652\n",
            "At step: 6084 training error: 0.5898161941413971\n",
            "At step: 6085 training error: 0.5783098615259511\n",
            "At step: 6086 training error: 0.5794393512582967\n",
            "At step: 6087 training error: 0.5868724806483563\n",
            "At step: 6088 training error: 0.6001147800568613\n",
            "At step: 6089 training error: 0.6029197338451812\n",
            "At step: 6090 training error: 0.603576400773067\n",
            "At step: 6091 training error: 0.6007986923742775\n",
            "At step: 6092 training error: 0.6048730432286579\n",
            "At step: 6093 training error: 0.6159324239361739\n",
            "At step: 6094 training error: 0.6144158736059063\n",
            "At step: 6095 training error: 0.6115277249880382\n",
            "At step: 6096 training error: 0.6057265104923764\n",
            "At step: 6097 training error: 0.6081480212971904\n",
            "At step: 6098 training error: 0.6139129405652531\n",
            "At step: 6099 training error: 0.6165703551751688\n",
            "At step: 6100 training error: 0.6130104184369587\n",
            "At step: 6101 training error: 0.6091658067188745\n",
            "At step: 6102 training error: 0.6112053520696697\n",
            "At step: 6103 training error: 0.6041249970480748\n",
            "At step: 6104 training error: 0.6068963673815779\n",
            "At step: 6105 training error: 0.6079407597162196\n",
            "At step: 6106 training error: 0.61187954165383\n",
            "At step: 6107 training error: 0.6144685574049977\n",
            "At step: 6108 training error: 0.6107938742569226\n",
            "At step: 6109 training error: 0.6143053520381688\n",
            "At step: 6110 training error: 0.6194150537964577\n",
            "At step: 6111 training error: 0.6158416757653222\n",
            "At step: 6112 training error: 0.6114560065334963\n",
            "At step: 6113 training error: 0.6038281677858829\n",
            "At step: 6114 training error: 0.6060880020034782\n",
            "At step: 6115 training error: 0.6041189241485706\n",
            "At step: 6116 training error: 0.5996830936584809\n",
            "At step: 6117 training error: 0.6088080953495894\n",
            "At step: 6118 training error: 0.6184609837391429\n",
            "At step: 6119 training error: 0.6185218252145097\n",
            "At step: 6120 training error: 0.6219409272306184\n",
            "At step: 6121 training error: 0.6284917109919955\n",
            "At step: 6122 training error: 0.6166715406081752\n",
            "At step: 6123 training error: 0.6111243599510315\n",
            "At step: 6124 training error: 0.6164740416904645\n",
            "At step: 6125 training error: 0.599325117020814\n",
            "At step: 6126 training error: 0.5949106060709278\n",
            "At step: 6127 training error: 0.5903130346103473\n",
            "At step: 6128 training error: 0.5888427105386042\n",
            "At step: 6129 training error: 0.5912044985794949\n",
            "At step: 6130 training error: 0.5910882938614472\n",
            "At step: 6131 training error: 0.5867546636376924\n",
            "At step: 6132 training error: 0.5866350995407594\n",
            "At step: 6133 training error: 0.5861102159312801\n",
            "At step: 6134 training error: 0.5944368040855585\n",
            "At step: 6135 training error: 0.5977458622773659\n",
            "At step: 6136 training error: 0.5985843143947165\n",
            "At step: 6137 training error: 0.6058328322250612\n",
            "At step: 6138 training error: 0.6029337984612622\n",
            "At step: 6139 training error: 0.6008286882830303\n",
            "At step: 6140 training error: 0.6001760215098431\n",
            "At step: 6141 training error: 0.5904611295508962\n",
            "At step: 6142 training error: 0.586319057602728\n",
            "At step: 6143 training error: 0.5886047116344748\n",
            "At step: 6144 training error: 0.5872725533078008\n",
            "At step: 6145 training error: 0.5892848146673801\n",
            "At step: 6146 training error: 0.5887302857508381\n",
            "At step: 6147 training error: 0.5865395130247977\n",
            "At step: 6148 training error: 0.5910665112600162\n",
            "At step: 6149 training error: 0.5980313750215329\n",
            "At step: 6150 training error: 0.5988065042290547\n",
            "At step: 6151 training error: 0.5972711175700604\n",
            "At step: 6152 training error: 0.5993574227509058\n",
            "At step: 6153 training error: 0.5953697505525947\n",
            "At step: 6154 training error: 0.5985322569243111\n",
            "At step: 6155 training error: 0.6146090587430508\n",
            "At step: 6156 training error: 0.6078723443287364\n",
            "At step: 6157 training error: 0.602646113583289\n",
            "At step: 6158 training error: 0.5958666074026362\n",
            "At step: 6159 training error: 0.5909191733156947\n",
            "At step: 6160 training error: 0.5853316865170252\n",
            "At step: 6161 training error: 0.5858161408945057\n",
            "At step: 6162 training error: 0.5931607839520853\n",
            "At step: 6163 training error: 0.5888067272826256\n",
            "At step: 6164 training error: 0.5916612445904647\n",
            "At step: 6165 training error: 0.5921359586460803\n",
            "At step: 6166 training error: 0.5937556568249206\n",
            "At step: 6167 training error: 0.5921131701460278\n",
            "At step: 6168 training error: 0.6021726737551184\n",
            "At step: 6169 training error: 0.5963586272710152\n",
            "At step: 6170 training error: 0.5897054237431856\n",
            "At step: 6171 training error: 0.586098094606976\n",
            "At step: 6172 training error: 0.5858673388738255\n",
            "At step: 6173 training error: 0.5904532767337967\n",
            "At step: 6174 training error: 0.5895959535893672\n",
            "At step: 6175 training error: 0.5952360219929503\n",
            "At step: 6176 training error: 0.5982891403983771\n",
            "At step: 6177 training error: 0.6001609388644243\n",
            "At step: 6178 training error: 0.5952109118010289\n",
            "At step: 6179 training error: 0.5905007616028295\n",
            "At step: 6180 training error: 0.592176961626132\n",
            "At step: 6181 training error: 0.5880595399614774\n",
            "At step: 6182 training error: 0.591448131815865\n",
            "At step: 6183 training error: 0.5968117473934759\n",
            "At step: 6184 training error: 0.5952079261904932\n",
            "At step: 6185 training error: 0.590383012868829\n",
            "At step: 6186 training error: 0.5916291211308723\n",
            "At step: 6187 training error: 0.5947256529638045\n",
            "At step: 6188 training error: 0.599847061553516\n",
            "At step: 6189 training error: 0.6053796809790888\n",
            "At step: 6190 training error: 0.6038170540358254\n",
            "At step: 6191 training error: 0.6002100261057793\n",
            "At step: 6192 training error: 0.5999862146908215\n",
            "At step: 6193 training error: 0.5967109209564532\n",
            "At step: 6194 training error: 0.6038450588090962\n",
            "At step: 6195 training error: 0.6059830222850707\n",
            "At step: 6196 training error: 0.6092501149929868\n",
            "At step: 6197 training error: 0.6125194704646642\n",
            "At step: 6198 training error: 0.6096858587838\n",
            "At step: 6199 training error: 0.6072872135904087\n",
            "At step: 6200 training error: 0.6107878911318293\n",
            "At step: 6201 training error: 0.6109387122958614\n",
            "At step: 6202 training error: 0.5985096097740854\n",
            "At step: 6203 training error: 0.5913802865702701\n",
            "At step: 6204 training error: 0.5962516223010147\n",
            "At step: 6205 training error: 0.6040151292077331\n",
            "At step: 6206 training error: 0.5989773532991879\n",
            "At step: 6207 training error: 0.5930851527539253\n",
            "At step: 6208 training error: 0.5832949814699281\n",
            "At step: 6209 training error: 0.5839759283346334\n",
            "At step: 6210 training error: 0.5810044380894948\n",
            "At step: 6211 training error: 0.583965925469497\n",
            "At step: 6212 training error: 0.5818931985770458\n",
            "At step: 6213 training error: 0.5816165044212457\n",
            "At step: 6214 training error: 0.5858445893876278\n",
            "At step: 6215 training error: 0.5852755704720045\n",
            "At step: 6216 training error: 0.5958043727294827\n",
            "At step: 6217 training error: 0.5846165986549914\n",
            "At step: 6218 training error: 0.5768433418171723\n",
            "At step: 6219 training error: 0.5868633999498847\n",
            "At step: 6220 training error: 0.596954916510069\n",
            "At step: 6221 training error: 0.5939653798215531\n",
            "At step: 6222 training error: 0.6041110603732613\n",
            "At step: 6223 training error: 0.6029820714777214\n",
            "At step: 6224 training error: 0.6121720344936863\n",
            "At step: 6225 training error: 0.6195337245146064\n",
            "At step: 6226 training error: 0.618818743021866\n",
            "At step: 6227 training error: 0.6108121791288845\n",
            "At step: 6228 training error: 0.6154589081800036\n",
            "At step: 6229 training error: 0.6159293159379962\n",
            "At step: 6230 training error: 0.6149885957194383\n",
            "At step: 6231 training error: 0.6103553673747957\n",
            "At step: 6232 training error: 0.609841478749152\n",
            "At step: 6233 training error: 0.6127229072401708\n",
            "At step: 6234 training error: 0.608537656402954\n",
            "At step: 6235 training error: 0.5993856573924188\n",
            "At step: 6236 training error: 0.6058697899559897\n",
            "At step: 6237 training error: 0.6052894185930565\n",
            "At step: 6238 training error: 0.596737727599834\n",
            "At step: 6239 training error: 0.588090804594763\n",
            "At step: 6240 training error: 0.5891190930993198\n",
            "At step: 6241 training error: 0.5942549966794363\n",
            "At step: 6242 training error: 0.5975130272102579\n",
            "At step: 6243 training error: 0.6066902635019854\n",
            "At step: 6244 training error: 0.6084106554070056\n",
            "At step: 6245 training error: 0.612312858395859\n",
            "At step: 6246 training error: 0.6139373657846063\n",
            "At step: 6247 training error: 0.6148248584242201\n",
            "At step: 6248 training error: 0.6158402137296022\n",
            "At step: 6249 training error: 0.6064902141430374\n",
            "At step: 6250 training error: 0.6046755171144679\n",
            "At step: 6251 training error: 0.6112754837937926\n",
            "At step: 6252 training error: 0.6002033752219298\n",
            "At step: 6253 training error: 0.6163946158736502\n",
            "At step: 6254 training error: 0.607151939278659\n",
            "At step: 6255 training error: 0.5993611344738218\n",
            "At step: 6256 training error: 0.6016331900225514\n",
            "At step: 6257 training error: 0.5982195099459761\n",
            "At step: 6258 training error: 0.591777158716359\n",
            "At step: 6259 training error: 0.5965306575812667\n",
            "At step: 6260 training error: 0.5964410810140521\n",
            "At step: 6261 training error: 0.586333836509343\n",
            "At step: 6262 training error: 0.5911589950229997\n",
            "At step: 6263 training error: 0.5964433428874787\n",
            "At step: 6264 training error: 0.5942201245775527\n",
            "At step: 6265 training error: 0.5970601736477881\n",
            "At step: 6266 training error: 0.6046601234605002\n",
            "At step: 6267 training error: 0.5995033878690134\n",
            "At step: 6268 training error: 0.6076773768925596\n",
            "At step: 6269 training error: 0.6045614706353951\n",
            "At step: 6270 training error: 0.603607215558433\n",
            "At step: 6271 training error: 0.6032099035002516\n",
            "At step: 6272 training error: 0.6127368296900042\n",
            "At step: 6273 training error: 0.6124049151309455\n",
            "At step: 6274 training error: 0.6247739950752463\n",
            "At step: 6275 training error: 0.6182824921055637\n",
            "At step: 6276 training error: 0.6138986171667037\n",
            "At step: 6277 training error: 0.6068542065547662\n",
            "At step: 6278 training error: 0.6061705796014177\n",
            "At step: 6279 training error: 0.6011810000008068\n",
            "At step: 6280 training error: 0.6013531990126116\n",
            "At step: 6281 training error: 0.6010641688458505\n",
            "At step: 6282 training error: 0.5962796900183972\n",
            "At step: 6283 training error: 0.5942025410240985\n",
            "At step: 6284 training error: 0.6015672625671855\n",
            "At step: 6285 training error: 0.5946185508535686\n",
            "At step: 6286 training error: 0.5976907477914704\n",
            "At step: 6287 training error: 0.5960783031652176\n",
            "At step: 6288 training error: 0.5877185313439023\n",
            "At step: 6289 training error: 0.5859738577520155\n",
            "At step: 6290 training error: 0.5756817196488886\n",
            "At step: 6291 training error: 0.5842003964996538\n",
            "At step: 6292 training error: 0.5931871717387165\n",
            "At step: 6293 training error: 0.5996474419655919\n",
            "At step: 6294 training error: 0.5896779914702333\n",
            "At step: 6295 training error: 0.5973180759562765\n",
            "At step: 6296 training error: 0.5981895096260628\n",
            "At step: 6297 training error: 0.6054097844727728\n",
            "At step: 6298 training error: 0.6124805517716208\n",
            "At step: 6299 training error: 0.6127277227111233\n",
            "At step: 6300 training error: 0.6152009594816336\n",
            "At step: 6301 training error: 0.6100978413017192\n",
            "At step: 6302 training error: 0.6044466438510687\n",
            "At step: 6303 training error: 0.6159354981249845\n",
            "At step: 6304 training error: 0.6118167417099066\n",
            "At step: 6305 training error: 0.6104719883989713\n",
            "At step: 6306 training error: 0.6015033957163957\n",
            "At step: 6307 training error: 0.6001502388120472\n",
            "At step: 6308 training error: 0.5977960318825845\n",
            "At step: 6309 training error: 0.5897844983559535\n",
            "At step: 6310 training error: 0.5916014343862359\n",
            "At step: 6311 training error: 0.5986440920176936\n",
            "At step: 6312 training error: 0.5977048658487923\n",
            "At step: 6313 training error: 0.59486412539915\n",
            "At step: 6314 training error: 0.5955778519531632\n",
            "At step: 6315 training error: 0.6034647135999126\n",
            "At step: 6316 training error: 0.6071280199052281\n",
            "At step: 6317 training error: 0.600594162369675\n",
            "At step: 6318 training error: 0.6043513754399561\n",
            "At step: 6319 training error: 0.6142140701699031\n",
            "At step: 6320 training error: 0.6109049758687672\n",
            "At step: 6321 training error: 0.6021864807780815\n",
            "At step: 6322 training error: 0.6083550475891073\n",
            "At step: 6323 training error: 0.598726256939767\n",
            "At step: 6324 training error: 0.6032723213496127\n",
            "At step: 6325 training error: 0.6000118374407573\n",
            "At step: 6326 training error: 0.5971089877985756\n",
            "At step: 6327 training error: 0.6029514850373618\n",
            "At step: 6328 training error: 0.6069093959630528\n",
            "At step: 6329 training error: 0.6065948716469873\n",
            "At step: 6330 training error: 0.6006845833815805\n",
            "At step: 6331 training error: 0.5988134785423144\n",
            "At step: 6332 training error: 0.6039101339767289\n",
            "At step: 6333 training error: 0.606227419944292\n",
            "At step: 6334 training error: 0.6104915043243215\n",
            "At step: 6335 training error: 0.6100314510873368\n",
            "At step: 6336 training error: 0.6115569004606095\n",
            "At step: 6337 training error: 0.6031163299498689\n",
            "At step: 6338 training error: 0.6056059627038052\n",
            "At step: 6339 training error: 0.6042765257017244\n",
            "At step: 6340 training error: 0.5982522727018841\n",
            "At step: 6341 training error: 0.60150269077284\n",
            "At step: 6342 training error: 0.5935926239118661\n",
            "At step: 6343 training error: 0.6015473060281163\n",
            "At step: 6344 training error: 0.5993368800157458\n",
            "At step: 6345 training error: 0.596424906078108\n",
            "At step: 6346 training error: 0.5908125016664173\n",
            "At step: 6347 training error: 0.5962822948127998\n",
            "At step: 6348 training error: 0.6012872893445199\n",
            "At step: 6349 training error: 0.5942056612437685\n",
            "At step: 6350 training error: 0.5928128525200917\n",
            "At step: 6351 training error: 0.5896734973548969\n",
            "At step: 6352 training error: 0.5942187673255812\n",
            "At step: 6353 training error: 0.5948083869945864\n",
            "At step: 6354 training error: 0.5866943768680936\n",
            "At step: 6355 training error: 0.5876865303489691\n",
            "At step: 6356 training error: 0.5872832811631198\n",
            "At step: 6357 training error: 0.5934911462048251\n",
            "At step: 6358 training error: 0.592567957270748\n",
            "At step: 6359 training error: 0.5850986647339165\n",
            "At step: 6360 training error: 0.5842736377871249\n",
            "At step: 6361 training error: 0.589620604709181\n",
            "At step: 6362 training error: 0.5927775702587332\n",
            "At step: 6363 training error: 0.5908236597871764\n",
            "At step: 6364 training error: 0.5837098481549737\n",
            "At step: 6365 training error: 0.58249602577405\n",
            "At step: 6366 training error: 0.5828451715803014\n",
            "At step: 6367 training error: 0.5843480533627102\n",
            "At step: 6368 training error: 0.5864345468076607\n",
            "At step: 6369 training error: 0.591270070803632\n",
            "At step: 6370 training error: 0.5953627903512776\n",
            "At step: 6371 training error: 0.5947454065525881\n",
            "At step: 6372 training error: 0.5917831818380025\n",
            "At step: 6373 training error: 0.5932262048659593\n",
            "At step: 6374 training error: 0.5973951195905581\n",
            "At step: 6375 training error: 0.5999620064718185\n",
            "At step: 6376 training error: 0.6009668371970753\n",
            "At step: 6377 training error: 0.5959579230453778\n",
            "At step: 6378 training error: 0.6083962343536016\n",
            "At step: 6379 training error: 0.6085027808930735\n",
            "At step: 6380 training error: 0.5975410050552515\n",
            "At step: 6381 training error: 0.5892766338720766\n",
            "At step: 6382 training error: 0.5898717887828018\n",
            "At step: 6383 training error: 0.5825284329764668\n",
            "At step: 6384 training error: 0.5803712625136607\n",
            "At step: 6385 training error: 0.5867443735567524\n",
            "At step: 6386 training error: 0.5848229567387734\n",
            "At step: 6387 training error: 0.5910968475919178\n",
            "At step: 6388 training error: 0.589193238779452\n",
            "At step: 6389 training error: 0.5732640026795759\n",
            "At step: 6390 training error: 0.5749278789516136\n",
            "At step: 6391 training error: 0.5737690016495237\n",
            "At step: 6392 training error: 0.577607367310527\n",
            "At step: 6393 training error: 0.5733003598752958\n",
            "At step: 6394 training error: 0.5783387081970248\n",
            "At step: 6395 training error: 0.5791934745915684\n",
            "At step: 6396 training error: 0.5677883832001992\n",
            "At step: 6397 training error: 0.5677423777172464\n",
            "At step: 6398 training error: 0.5652133035832018\n",
            "At step: 6399 training error: 0.5700056125375644\n",
            "At step: 6400 training error: 0.5582059964080651\n",
            "At step: 6401 training error: 0.5675152094196396\n",
            "At step: 6402 training error: 0.5787286603285319\n",
            "At step: 6403 training error: 0.5869060091064993\n",
            "At step: 6404 training error: 0.5911895268328081\n",
            "At step: 6405 training error: 0.5824867483429027\n",
            "At step: 6406 training error: 0.5908964830037149\n",
            "At step: 6407 training error: 0.5866488058411773\n",
            "At step: 6408 training error: 0.5931047038612024\n",
            "At step: 6409 training error: 0.5928493374668437\n",
            "At step: 6410 training error: 0.6000493744394914\n",
            "At step: 6411 training error: 0.5909782041762699\n",
            "At step: 6412 training error: 0.5981720507320059\n",
            "At step: 6413 training error: 0.6062729004043327\n",
            "At step: 6414 training error: 0.6002505239463363\n",
            "At step: 6415 training error: 0.5985366095080933\n",
            "At step: 6416 training error: 0.5964510801722013\n",
            "At step: 6417 training error: 0.6042091920084923\n",
            "At step: 6418 training error: 0.6035994391518528\n",
            "At step: 6419 training error: 0.6049591630660899\n",
            "At step: 6420 training error: 0.5959168464250666\n",
            "At step: 6421 training error: 0.590304304148834\n",
            "At step: 6422 training error: 0.5831984836638844\n",
            "At step: 6423 training error: 0.5857816376697558\n",
            "At step: 6424 training error: 0.5857212298416365\n",
            "At step: 6425 training error: 0.5780598436480745\n",
            "At step: 6426 training error: 0.5766631396230361\n",
            "At step: 6427 training error: 0.5793538050524948\n",
            "At step: 6428 training error: 0.5809743548362151\n",
            "At step: 6429 training error: 0.5816627763918051\n",
            "At step: 6430 training error: 0.5848010110665712\n",
            "At step: 6431 training error: 0.5877185565616883\n",
            "At step: 6432 training error: 0.586272285677942\n",
            "At step: 6433 training error: 0.5912365410483479\n",
            "At step: 6434 training error: 0.5880679831140271\n",
            "At step: 6435 training error: 0.5886133531732214\n",
            "At step: 6436 training error: 0.5848756481978652\n",
            "At step: 6437 training error: 0.5857055339856856\n",
            "At step: 6438 training error: 0.584697152956873\n",
            "At step: 6439 training error: 0.5860936420436035\n",
            "At step: 6440 training error: 0.5831464806237735\n",
            "At step: 6441 training error: 0.5863660643655412\n",
            "At step: 6442 training error: 0.5902358154615143\n",
            "At step: 6443 training error: 0.5946799503901454\n",
            "At step: 6444 training error: 0.5966633120992073\n",
            "At step: 6445 training error: 0.5994114937672792\n",
            "At step: 6446 training error: 0.5997569155442597\n",
            "At step: 6447 training error: 0.5983177118521309\n",
            "At step: 6448 training error: 0.5893603627854482\n",
            "At step: 6449 training error: 0.5894477418116872\n",
            "At step: 6450 training error: 0.5918379982883397\n",
            "At step: 6451 training error: 0.5969197692637358\n",
            "At step: 6452 training error: 0.5878501858112544\n",
            "At step: 6453 training error: 0.5817383073402329\n",
            "At step: 6454 training error: 0.5872451177649062\n",
            "At step: 6455 training error: 0.5871317770388207\n",
            "At step: 6456 training error: 0.5991592280041275\n",
            "At step: 6457 training error: 0.5908448293050068\n",
            "At step: 6458 training error: 0.5914753768269485\n",
            "At step: 6459 training error: 0.5815341971089573\n",
            "At step: 6460 training error: 0.5817674246603239\n",
            "At step: 6461 training error: 0.5830823957635992\n",
            "At step: 6462 training error: 0.5866822811318286\n",
            "At step: 6463 training error: 0.5833945899199108\n",
            "At step: 6464 training error: 0.5780792327648033\n",
            "At step: 6465 training error: 0.5843288156769172\n",
            "At step: 6466 training error: 0.5839781076644711\n",
            "At step: 6467 training error: 0.5899858376947973\n",
            "At step: 6468 training error: 0.5876001499545128\n",
            "At step: 6469 training error: 0.5841172770045459\n",
            "At step: 6470 training error: 0.5898066867873014\n",
            "At step: 6471 training error: 0.5961757607450318\n",
            "At step: 6472 training error: 0.5926517105083583\n",
            "At step: 6473 training error: 0.5926464042055403\n",
            "At step: 6474 training error: 0.6070393317010725\n",
            "At step: 6475 training error: 0.6072952969882458\n",
            "At step: 6476 training error: 0.6027231525307758\n",
            "At step: 6477 training error: 0.596734088319593\n",
            "At step: 6478 training error: 0.5937271414609917\n",
            "At step: 6479 training error: 0.5909414622508758\n",
            "At step: 6480 training error: 0.5875515633468339\n",
            "At step: 6481 training error: 0.597820854602227\n",
            "At step: 6482 training error: 0.5980396578231005\n",
            "At step: 6483 training error: 0.5898201642837844\n",
            "At step: 6484 training error: 0.5921862298980582\n",
            "At step: 6485 training error: 0.5881293021454096\n",
            "At step: 6486 training error: 0.5891618712915935\n",
            "At step: 6487 training error: 0.5915836855963991\n",
            "At step: 6488 training error: 0.589029492626342\n",
            "At step: 6489 training error: 0.5969283089322105\n",
            "At step: 6490 training error: 0.6030195292199222\n",
            "At step: 6491 training error: 0.5964328355807569\n",
            "At step: 6492 training error: 0.6021573836168568\n",
            "At step: 6493 training error: 0.6000077188389554\n",
            "At step: 6494 training error: 0.5921217779260696\n",
            "At step: 6495 training error: 0.5947521334842446\n",
            "At step: 6496 training error: 0.5958270585207549\n",
            "At step: 6497 training error: 0.6039623077909247\n",
            "At step: 6498 training error: 0.6087008165259639\n",
            "At step: 6499 training error: 0.5920775912305095\n",
            "At step: 6500 training error: 0.5937099484919937\n",
            "At step: 6501 training error: 0.5961191099373515\n",
            "At step: 6502 training error: 0.5885251956297682\n",
            "At step: 6503 training error: 0.5866745434373294\n",
            "At step: 6504 training error: 0.5904404621293944\n",
            "At step: 6505 training error: 0.5939914934454575\n",
            "At step: 6506 training error: 0.5947268497597908\n",
            "At step: 6507 training error: 0.594595998729615\n",
            "At step: 6508 training error: 0.6020228966318222\n",
            "At step: 6509 training error: 0.604946469556081\n",
            "At step: 6510 training error: 0.6109344511049027\n",
            "At step: 6511 training error: 0.5991282339066168\n",
            "At step: 6512 training error: 0.6077979930280052\n",
            "At step: 6513 training error: 0.6040806092706155\n",
            "At step: 6514 training error: 0.602906313234168\n",
            "At step: 6515 training error: 0.5998278518502993\n",
            "At step: 6516 training error: 0.5905547266341283\n",
            "At step: 6517 training error: 0.5892712937498576\n",
            "At step: 6518 training error: 0.5863021752893228\n",
            "At step: 6519 training error: 0.5842580188140177\n",
            "At step: 6520 training error: 0.586565738211244\n",
            "At step: 6521 training error: 0.5963365498388338\n",
            "At step: 6522 training error: 0.6082243628016185\n",
            "At step: 6523 training error: 0.6075334241663854\n",
            "At step: 6524 training error: 0.6023955888544549\n",
            "At step: 6525 training error: 0.6037553950535959\n",
            "At step: 6526 training error: 0.6020949031527257\n",
            "At step: 6527 training error: 0.604045739123651\n",
            "At step: 6528 training error: 0.5987266268591853\n",
            "At step: 6529 training error: 0.6001715700575586\n",
            "At step: 6530 training error: 0.5981410423539156\n",
            "At step: 6531 training error: 0.5983612366442206\n",
            "At step: 6532 training error: 0.5983911565900449\n",
            "At step: 6533 training error: 0.5953475804564903\n",
            "At step: 6534 training error: 0.5994262314527754\n",
            "At step: 6535 training error: 0.5887442156686092\n",
            "At step: 6536 training error: 0.5784136926791971\n",
            "At step: 6537 training error: 0.5861901661825347\n",
            "At step: 6538 training error: 0.5857798708180446\n",
            "At step: 6539 training error: 0.5827784386833958\n",
            "At step: 6540 training error: 0.5771355405858313\n",
            "At step: 6541 training error: 0.5730106851838301\n",
            "At step: 6542 training error: 0.5655569871473203\n",
            "At step: 6543 training error: 0.5637939596301493\n",
            "At step: 6544 training error: 0.5565239077582643\n",
            "At step: 6545 training error: 0.5683087244058085\n",
            "At step: 6546 training error: 0.580490908510492\n",
            "At step: 6547 training error: 0.586641176549666\n",
            "At step: 6548 training error: 0.5865418157858315\n",
            "At step: 6549 training error: 0.5822608310961382\n",
            "At step: 6550 training error: 0.5879579800704778\n",
            "At step: 6551 training error: 0.5880027040328016\n",
            "At step: 6552 training error: 0.5880396176118016\n",
            "At step: 6553 training error: 0.5983981794294231\n",
            "At step: 6554 training error: 0.592931475454801\n",
            "At step: 6555 training error: 0.5975782989078228\n",
            "At step: 6556 training error: 0.6071708503413862\n",
            "At step: 6557 training error: 0.6076421075289309\n",
            "At step: 6558 training error: 0.6086815610323764\n",
            "At step: 6559 training error: 0.6104503102905017\n",
            "At step: 6560 training error: 0.6129981483762109\n",
            "At step: 6561 training error: 0.6113385988018959\n",
            "At step: 6562 training error: 0.6135563453698273\n",
            "At step: 6563 training error: 0.6153944838332516\n",
            "At step: 6564 training error: 0.6188131344444774\n",
            "At step: 6565 training error: 0.6143434174699536\n",
            "At step: 6566 training error: 0.6169238699212202\n",
            "At step: 6567 training error: 0.6175482285556736\n",
            "At step: 6568 training error: 0.6168315603409233\n",
            "At step: 6569 training error: 0.6140134863373728\n",
            "At step: 6570 training error: 0.609677117130612\n",
            "At step: 6571 training error: 0.6111694653893633\n",
            "At step: 6572 training error: 0.6085365627651068\n",
            "At step: 6573 training error: 0.6149077515627208\n",
            "At step: 6574 training error: 0.6120051540889662\n",
            "At step: 6575 training error: 0.6169882319472735\n",
            "At step: 6576 training error: 0.6188363855887767\n",
            "At step: 6577 training error: 0.6166736212400579\n",
            "At step: 6578 training error: 0.6201469245274261\n",
            "At step: 6579 training error: 0.6146681748598488\n",
            "At step: 6580 training error: 0.612111312696625\n",
            "At step: 6581 training error: 0.6080861012633691\n",
            "At step: 6582 training error: 0.6072515116220248\n",
            "At step: 6583 training error: 0.6042024230584017\n",
            "At step: 6584 training error: 0.603219471572263\n",
            "At step: 6585 training error: 0.6116201061875631\n",
            "At step: 6586 training error: 0.6137993105804592\n",
            "At step: 6587 training error: 0.6099662122839606\n",
            "At step: 6588 training error: 0.6133966837960063\n",
            "At step: 6589 training error: 0.5981536586952156\n",
            "At step: 6590 training error: 0.5977446901248079\n",
            "At step: 6591 training error: 0.5970399183607297\n",
            "At step: 6592 training error: 0.5919137882658985\n",
            "At step: 6593 training error: 0.5903277866176687\n",
            "At step: 6594 training error: 0.5699385105700819\n",
            "At step: 6595 training error: 0.5809038068400403\n",
            "At step: 6596 training error: 0.5725513602547957\n",
            "At step: 6597 training error: 0.5728886181070358\n",
            "At step: 6598 training error: 0.5731153994630449\n",
            "At step: 6599 training error: 0.5765693239939793\n",
            "At step: 6600 training error: 0.5798064804388989\n",
            "At step: 6601 training error: 0.5778684138972306\n",
            "At step: 6602 training error: 0.5722221745356847\n",
            "At step: 6603 training error: 0.5701511975944693\n",
            "At step: 6604 training error: 0.5808006052420487\n",
            "At step: 6605 training error: 0.5814190022352275\n",
            "At step: 6606 training error: 0.589231576764268\n",
            "At step: 6607 training error: 0.5872694306541204\n",
            "At step: 6608 training error: 0.5859593405499355\n",
            "At step: 6609 training error: 0.5904403244190966\n",
            "At step: 6610 training error: 0.5972621653430504\n",
            "At step: 6611 training error: 0.5956128505424829\n",
            "At step: 6612 training error: 0.5942409057069689\n",
            "At step: 6613 training error: 0.5990875108819537\n",
            "At step: 6614 training error: 0.5930225873393764\n",
            "At step: 6615 training error: 0.5887446264834754\n",
            "At step: 6616 training error: 0.5953847222659934\n",
            "At step: 6617 training error: 0.598272484873016\n",
            "At step: 6618 training error: 0.6001532452705407\n",
            "At step: 6619 training error: 0.6016377931972458\n",
            "At step: 6620 training error: 0.5962428983950201\n",
            "At step: 6621 training error: 0.5791568335869778\n",
            "At step: 6622 training error: 0.5815270953008806\n",
            "At step: 6623 training error: 0.5834765360880204\n",
            "At step: 6624 training error: 0.5897729208749575\n",
            "At step: 6625 training error: 0.5834538556663994\n",
            "At step: 6626 training error: 0.5783467603139333\n",
            "At step: 6627 training error: 0.5884776774773877\n",
            "At step: 6628 training error: 0.5930357552153789\n",
            "At step: 6629 training error: 0.5883859455457415\n",
            "At step: 6630 training error: 0.575110825406803\n",
            "At step: 6631 training error: 0.5782344726262187\n",
            "At step: 6632 training error: 0.5874520245007819\n",
            "At step: 6633 training error: 0.5939373787227546\n",
            "At step: 6634 training error: 0.5896397283531257\n",
            "At step: 6635 training error: 0.5872604352448834\n",
            "At step: 6636 training error: 0.5984023261625244\n",
            "At step: 6637 training error: 0.5918921620496389\n",
            "At step: 6638 training error: 0.5956758917102971\n",
            "At step: 6639 training error: 0.5931775976529787\n",
            "At step: 6640 training error: 0.601910756961918\n",
            "At step: 6641 training error: 0.5957223697576209\n",
            "At step: 6642 training error: 0.5986845803735745\n",
            "At step: 6643 training error: 0.6024449593211532\n",
            "At step: 6644 training error: 0.5986716921166751\n",
            "At step: 6645 training error: 0.5887896879886734\n",
            "At step: 6646 training error: 0.588271434727742\n",
            "At step: 6647 training error: 0.577351206186548\n",
            "At step: 6648 training error: 0.588058237513568\n",
            "At step: 6649 training error: 0.5946119261014539\n",
            "At step: 6650 training error: 0.5968798101997819\n",
            "At step: 6651 training error: 0.5983481796977769\n",
            "At step: 6652 training error: 0.5972307426092471\n",
            "At step: 6653 training error: 0.5980730041295796\n",
            "At step: 6654 training error: 0.5942744258534\n",
            "At step: 6655 training error: 0.5910247706858551\n",
            "At step: 6656 training error: 0.5833205157337918\n",
            "At step: 6657 training error: 0.5800580091075132\n",
            "At step: 6658 training error: 0.5854582829493984\n",
            "At step: 6659 training error: 0.5868664221961111\n",
            "At step: 6660 training error: 0.5916374491390486\n",
            "At step: 6661 training error: 0.5854075584696101\n",
            "At step: 6662 training error: 0.583166981471293\n",
            "At step: 6663 training error: 0.6006198687727572\n",
            "At step: 6664 training error: 0.6020154760590575\n",
            "At step: 6665 training error: 0.605374606916697\n",
            "At step: 6666 training error: 0.6050441638648912\n",
            "At step: 6667 training error: 0.60351153602535\n",
            "At step: 6668 training error: 0.5964439585964432\n",
            "At step: 6669 training error: 0.5912274912118481\n",
            "At step: 6670 training error: 0.584657251246612\n",
            "At step: 6671 training error: 0.5926492302812543\n",
            "At step: 6672 training error: 0.5941622072894316\n",
            "At step: 6673 training error: 0.5919504678083329\n",
            "At step: 6674 training error: 0.5941545011178238\n",
            "At step: 6675 training error: 0.5957555111450136\n",
            "At step: 6676 training error: 0.5921511329360747\n",
            "At step: 6677 training error: 0.6031383339862622\n",
            "At step: 6678 training error: 0.6073992892273564\n",
            "At step: 6679 training error: 0.6040476027358785\n",
            "At step: 6680 training error: 0.6039614849775786\n",
            "At step: 6681 training error: 0.6107473043454984\n",
            "At step: 6682 training error: 0.606593432646242\n",
            "At step: 6683 training error: 0.6054443201508649\n",
            "At step: 6684 training error: 0.6098732171436824\n",
            "At step: 6685 training error: 0.6197746081841292\n",
            "At step: 6686 training error: 0.6137104939662554\n",
            "At step: 6687 training error: 0.6230666573171945\n",
            "At step: 6688 training error: 0.6176596100461353\n",
            "At step: 6689 training error: 0.6147550738018798\n",
            "At step: 6690 training error: 0.6141024217570141\n",
            "At step: 6691 training error: 0.6051735934238187\n",
            "At step: 6692 training error: 0.6084933365787574\n",
            "At step: 6693 training error: 0.6058750283352989\n",
            "At step: 6694 training error: 0.598973394972525\n",
            "At step: 6695 training error: 0.5949955237661725\n",
            "At step: 6696 training error: 0.5895102745878303\n",
            "At step: 6697 training error: 0.583243625483922\n",
            "At step: 6698 training error: 0.5909646665072095\n",
            "At step: 6699 training error: 0.5844916149734064\n",
            "At step: 6700 training error: 0.5919919840156531\n",
            "At step: 6701 training error: 0.592648952498643\n",
            "At step: 6702 training error: 0.5962911872998448\n",
            "At step: 6703 training error: 0.5978198318789204\n",
            "At step: 6704 training error: 0.5955140085096199\n",
            "At step: 6705 training error: 0.5941425632288293\n",
            "At step: 6706 training error: 0.5968151560159534\n",
            "At step: 6707 training error: 0.6006036487631747\n",
            "At step: 6708 training error: 0.5961776223819705\n",
            "At step: 6709 training error: 0.5885003780063105\n",
            "At step: 6710 training error: 0.5838617576272446\n",
            "At step: 6711 training error: 0.5707855214771934\n",
            "At step: 6712 training error: 0.565246543630009\n",
            "At step: 6713 training error: 0.570655146394474\n",
            "At step: 6714 training error: 0.5770410197568586\n",
            "At step: 6715 training error: 0.5812434734944131\n",
            "At step: 6716 training error: 0.585941955762702\n",
            "At step: 6717 training error: 0.5805448232289498\n",
            "At step: 6718 training error: 0.5807821702636454\n",
            "At step: 6719 training error: 0.5954712520014236\n",
            "At step: 6720 training error: 0.5891637950260727\n",
            "At step: 6721 training error: 0.5878035441710917\n",
            "At step: 6722 training error: 0.5836932265734504\n",
            "At step: 6723 training error: 0.5911832422336746\n",
            "At step: 6724 training error: 0.5857877310774499\n",
            "At step: 6725 training error: 0.5819151516072492\n",
            "At step: 6726 training error: 0.5792199424578227\n",
            "At step: 6727 training error: 0.5772993201794382\n",
            "At step: 6728 training error: 0.5808987816475137\n",
            "At step: 6729 training error: 0.5835930099119099\n",
            "At step: 6730 training error: 0.5921032851081875\n",
            "At step: 6731 training error: 0.6040652340186445\n",
            "At step: 6732 training error: 0.6015202038183498\n",
            "At step: 6733 training error: 0.6027761120653885\n",
            "At step: 6734 training error: 0.5962161033983726\n",
            "At step: 6735 training error: 0.5976347933982317\n",
            "At step: 6736 training error: 0.5884709777358799\n",
            "At step: 6737 training error: 0.5775095607349294\n",
            "At step: 6738 training error: 0.5856085280842693\n",
            "At step: 6739 training error: 0.5841809200939143\n",
            "At step: 6740 training error: 0.585159876608908\n",
            "At step: 6741 training error: 0.572096555450619\n",
            "At step: 6742 training error: 0.5723972110959248\n",
            "At step: 6743 training error: 0.5746289868214859\n",
            "At step: 6744 training error: 0.5821813258711213\n",
            "At step: 6745 training error: 0.5786722151843168\n",
            "At step: 6746 training error: 0.5817076646662118\n",
            "At step: 6747 training error: 0.5918714434739794\n",
            "At step: 6748 training error: 0.5945916104883298\n",
            "At step: 6749 training error: 0.5936797606260497\n",
            "At step: 6750 training error: 0.59153786188048\n",
            "At step: 6751 training error: 0.5932113811729061\n",
            "At step: 6752 training error: 0.5953460553776371\n",
            "At step: 6753 training error: 0.5873976548353841\n",
            "At step: 6754 training error: 0.5826836157666194\n",
            "At step: 6755 training error: 0.5902887048362879\n",
            "At step: 6756 training error: 0.5937031544836672\n",
            "At step: 6757 training error: 0.5883013168807211\n",
            "At step: 6758 training error: 0.583511733054912\n",
            "At step: 6759 training error: 0.5834649866626325\n",
            "At step: 6760 training error: 0.5894982161647387\n",
            "At step: 6761 training error: 0.5867100468322909\n",
            "At step: 6762 training error: 0.5798697852618842\n",
            "At step: 6763 training error: 0.5744586858829099\n",
            "At step: 6764 training error: 0.5759539896864814\n",
            "At step: 6765 training error: 0.5667744298769597\n",
            "At step: 6766 training error: 0.5594263990707746\n",
            "At step: 6767 training error: 0.5620464971242277\n",
            "At step: 6768 training error: 0.5753604853269851\n",
            "At step: 6769 training error: 0.5782761400096873\n",
            "At step: 6770 training error: 0.5700102194345994\n",
            "At step: 6771 training error: 0.5694033409842457\n",
            "At step: 6772 training error: 0.575711455996637\n",
            "At step: 6773 training error: 0.5766196710254443\n",
            "At step: 6774 training error: 0.5721714712267607\n",
            "At step: 6775 training error: 0.5731615526110769\n",
            "At step: 6776 training error: 0.5803561616258801\n",
            "At step: 6777 training error: 0.574256096079351\n",
            "At step: 6778 training error: 0.5739859622080621\n",
            "At step: 6779 training error: 0.5679466239962799\n",
            "At step: 6780 training error: 0.5670885142804073\n",
            "At step: 6781 training error: 0.5641572306633189\n",
            "At step: 6782 training error: 0.5678069991327531\n",
            "At step: 6783 training error: 0.5662795445976504\n",
            "At step: 6784 training error: 0.5806750345082783\n",
            "At step: 6785 training error: 0.59328562319012\n",
            "At step: 6786 training error: 0.5892044300799925\n",
            "At step: 6787 training error: 0.5907610026751194\n",
            "At step: 6788 training error: 0.5843282841615511\n",
            "At step: 6789 training error: 0.5858596114864605\n",
            "At step: 6790 training error: 0.5785405972868877\n",
            "At step: 6791 training error: 0.5757703989264689\n",
            "At step: 6792 training error: 0.5732870728840458\n",
            "At step: 6793 training error: 0.5786254424938329\n",
            "At step: 6794 training error: 0.5788938607957435\n",
            "At step: 6795 training error: 0.579570326644714\n",
            "At step: 6796 training error: 0.5947084973576022\n",
            "At step: 6797 training error: 0.591388707615415\n",
            "At step: 6798 training error: 0.5876044437549965\n",
            "At step: 6799 training error: 0.5930726515732029\n",
            "At step: 6800 training error: 0.5881966550027772\n",
            "At step: 6801 training error: 0.5804835585003395\n",
            "At step: 6802 training error: 0.586043348265193\n",
            "At step: 6803 training error: 0.598165494263108\n",
            "At step: 6804 training error: 0.5943874463906513\n",
            "At step: 6805 training error: 0.588725478548815\n",
            "At step: 6806 training error: 0.5848611547574307\n",
            "At step: 6807 training error: 0.5859594765485225\n",
            "At step: 6808 training error: 0.5757004953366006\n",
            "At step: 6809 training error: 0.5641739913088886\n",
            "At step: 6810 training error: 0.5768777583331519\n",
            "At step: 6811 training error: 0.5745743432778193\n",
            "At step: 6812 training error: 0.5797516779589216\n",
            "At step: 6813 training error: 0.5816285942351951\n",
            "At step: 6814 training error: 0.5764618536077929\n",
            "At step: 6815 training error: 0.5723428307769125\n",
            "At step: 6816 training error: 0.5736849795628334\n",
            "At step: 6817 training error: 0.5821130378209491\n",
            "At step: 6818 training error: 0.5782174682771863\n",
            "At step: 6819 training error: 0.5825221840578004\n",
            "At step: 6820 training error: 0.5963776863979402\n",
            "At step: 6821 training error: 0.5912011866687512\n",
            "At step: 6822 training error: 0.583407303271464\n",
            "At step: 6823 training error: 0.5990319330739964\n",
            "At step: 6824 training error: 0.5851708080398489\n",
            "At step: 6825 training error: 0.5800700899505915\n",
            "At step: 6826 training error: 0.5777493539298061\n",
            "At step: 6827 training error: 0.5802115124665284\n",
            "At step: 6828 training error: 0.5808492640678863\n",
            "At step: 6829 training error: 0.5826476699661401\n",
            "At step: 6830 training error: 0.59365563344994\n",
            "At step: 6831 training error: 0.589792429692564\n",
            "At step: 6832 training error: 0.5818866700971164\n",
            "At step: 6833 training error: 0.5827924360630949\n",
            "At step: 6834 training error: 0.5783954818916541\n",
            "At step: 6835 training error: 0.5771896036949598\n",
            "At step: 6836 training error: 0.5724649768579223\n",
            "At step: 6837 training error: 0.5818119690989678\n",
            "At step: 6838 training error: 0.5894512687616239\n",
            "At step: 6839 training error: 0.5869417809739013\n",
            "At step: 6840 training error: 0.5972562511001858\n",
            "At step: 6841 training error: 0.6034652453289722\n",
            "At step: 6842 training error: 0.598373602680624\n",
            "At step: 6843 training error: 0.5972851158018896\n",
            "At step: 6844 training error: 0.5917067919812286\n",
            "At step: 6845 training error: 0.5861794904204741\n",
            "At step: 6846 training error: 0.5909262459088642\n",
            "At step: 6847 training error: 0.5887015212043961\n",
            "At step: 6848 training error: 0.5861379817218342\n",
            "At step: 6849 training error: 0.5849575831442281\n",
            "At step: 6850 training error: 0.585814114017957\n",
            "At step: 6851 training error: 0.5815394387012516\n",
            "At step: 6852 training error: 0.5863243440251671\n",
            "At step: 6853 training error: 0.6018205537903556\n",
            "At step: 6854 training error: 0.5961955480467005\n",
            "At step: 6855 training error: 0.6080266799989799\n",
            "At step: 6856 training error: 0.5989626448065032\n",
            "At step: 6857 training error: 0.5900317607603895\n",
            "At step: 6858 training error: 0.5968089565467677\n",
            "At step: 6859 training error: 0.5968736201348711\n",
            "At step: 6860 training error: 0.590945398548979\n",
            "At step: 6861 training error: 0.5793980927718559\n",
            "At step: 6862 training error: 0.5813182830529612\n",
            "At step: 6863 training error: 0.5777765829973172\n",
            "At step: 6864 training error: 0.5756707810132491\n",
            "At step: 6865 training error: 0.5695204374358923\n",
            "At step: 6866 training error: 0.5708050646628373\n",
            "At step: 6867 training error: 0.5747795460593682\n",
            "At step: 6868 training error: 0.5738084057460949\n",
            "At step: 6869 training error: 0.5674748898975815\n",
            "At step: 6870 training error: 0.5678066045867931\n",
            "At step: 6871 training error: 0.5648083732568503\n",
            "At step: 6872 training error: 0.5650104523321349\n",
            "At step: 6873 training error: 0.5555247242740999\n",
            "At step: 6874 training error: 0.5499731854187533\n",
            "At step: 6875 training error: 0.5569207501115934\n",
            "At step: 6876 training error: 0.5590794563172873\n",
            "At step: 6877 training error: 0.5530145362115217\n",
            "At step: 6878 training error: 0.55993883405255\n",
            "At step: 6879 training error: 0.5596331793374374\n",
            "At step: 6880 training error: 0.5601904103692323\n",
            "At step: 6881 training error: 0.5622000563324939\n",
            "At step: 6882 training error: 0.5583068460288494\n",
            "At step: 6883 training error: 0.565291709892807\n",
            "At step: 6884 training error: 0.5704652507741774\n",
            "At step: 6885 training error: 0.573950559990446\n",
            "At step: 6886 training error: 0.5805655675727537\n",
            "At step: 6887 training error: 0.5803680864825449\n",
            "At step: 6888 training error: 0.5695611229791757\n",
            "At step: 6889 training error: 0.5686143024116325\n",
            "At step: 6890 training error: 0.5616645008725987\n",
            "At step: 6891 training error: 0.562888046958519\n",
            "At step: 6892 training error: 0.5739323529894274\n",
            "At step: 6893 training error: 0.5683102841181585\n",
            "At step: 6894 training error: 0.5805469674710025\n",
            "At step: 6895 training error: 0.5816520947407262\n",
            "At step: 6896 training error: 0.575728354885951\n",
            "At step: 6897 training error: 0.5851772664076365\n",
            "At step: 6898 training error: 0.592614951791831\n",
            "At step: 6899 training error: 0.5843560216691265\n",
            "At step: 6900 training error: 0.5937599411712324\n",
            "At step: 6901 training error: 0.5867311482848186\n",
            "At step: 6902 training error: 0.5814105326994812\n",
            "At step: 6903 training error: 0.5776327774554988\n",
            "At step: 6904 training error: 0.5735495115850973\n",
            "At step: 6905 training error: 0.5626779510378366\n",
            "At step: 6906 training error: 0.5549478988590687\n",
            "At step: 6907 training error: 0.5542095459323728\n",
            "At step: 6908 training error: 0.5541955114761594\n",
            "At step: 6909 training error: 0.558161535174218\n",
            "At step: 6910 training error: 0.5536691025636062\n",
            "At step: 6911 training error: 0.5566896677232839\n",
            "At step: 6912 training error: 0.5641037020785251\n",
            "At step: 6913 training error: 0.5678462473737556\n",
            "At step: 6914 training error: 0.5629196276598344\n",
            "At step: 6915 training error: 0.5620126714674781\n",
            "At step: 6916 training error: 0.5449421397960998\n",
            "At step: 6917 training error: 0.5542040035995333\n",
            "At step: 6918 training error: 0.5485842141792578\n",
            "At step: 6919 training error: 0.5564573247914021\n",
            "At step: 6920 training error: 0.5608816582637888\n",
            "At step: 6921 training error: 0.5560352764110621\n",
            "At step: 6922 training error: 0.5612722085380968\n",
            "At step: 6923 training error: 0.5549682501339592\n",
            "At step: 6924 training error: 0.5558681315965565\n",
            "At step: 6925 training error: 0.5500230359055082\n",
            "At step: 6926 training error: 0.5489834757468376\n",
            "At step: 6927 training error: 0.5521945096189526\n",
            "At step: 6928 training error: 0.5493546549199382\n",
            "At step: 6929 training error: 0.5555858220723989\n",
            "At step: 6930 training error: 0.5659097349264864\n",
            "At step: 6931 training error: 0.5718707750168509\n",
            "At step: 6932 training error: 0.5720745417162205\n",
            "At step: 6933 training error: 0.5746529281460945\n",
            "At step: 6934 training error: 0.5696026634524334\n",
            "At step: 6935 training error: 0.5758994368676753\n",
            "At step: 6936 training error: 0.5757633835830541\n",
            "At step: 6937 training error: 0.5831364233346212\n",
            "At step: 6938 training error: 0.5829275822594925\n",
            "At step: 6939 training error: 0.5809355144996021\n",
            "At step: 6940 training error: 0.5890235257793714\n",
            "At step: 6941 training error: 0.5938803114227994\n",
            "At step: 6942 training error: 0.5852387579731987\n",
            "At step: 6943 training error: 0.586959614953816\n",
            "At step: 6944 training error: 0.5863153608670671\n",
            "At step: 6945 training error: 0.5904049501741502\n",
            "At step: 6946 training error: 0.5906746602532617\n",
            "At step: 6947 training error: 0.5937532596107262\n",
            "At step: 6948 training error: 0.5879464671369451\n",
            "At step: 6949 training error: 0.5906744833555366\n",
            "At step: 6950 training error: 0.5894012133244632\n",
            "At step: 6951 training error: 0.5873630110441641\n",
            "At step: 6952 training error: 0.5873654472493075\n",
            "At step: 6953 training error: 0.580146958235974\n",
            "At step: 6954 training error: 0.5779650494787496\n",
            "At step: 6955 training error: 0.5848658395529364\n",
            "At step: 6956 training error: 0.573563100984493\n",
            "At step: 6957 training error: 0.5799191454717193\n",
            "At step: 6958 training error: 0.5842091061741923\n",
            "At step: 6959 training error: 0.5943093918126824\n",
            "At step: 6960 training error: 0.5998601164849668\n",
            "At step: 6961 training error: 0.6037366110983674\n",
            "At step: 6962 training error: 0.6092093466322512\n",
            "At step: 6963 training error: 0.6097897402885066\n",
            "At step: 6964 training error: 0.6023127747873662\n",
            "At step: 6965 training error: 0.6000425076519659\n",
            "At step: 6966 training error: 0.5939028140771122\n",
            "At step: 6967 training error: 0.590775217385756\n",
            "At step: 6968 training error: 0.5897616302761074\n",
            "At step: 6969 training error: 0.5968209560357134\n",
            "At step: 6970 training error: 0.590519567760242\n",
            "At step: 6971 training error: 0.5806091376832839\n",
            "At step: 6972 training error: 0.5852468215477213\n",
            "At step: 6973 training error: 0.569950925915025\n",
            "At step: 6974 training error: 0.5714760028600927\n",
            "At step: 6975 training error: 0.5776706462441238\n",
            "At step: 6976 training error: 0.5827180199033098\n",
            "At step: 6977 training error: 0.5913592099597069\n",
            "At step: 6978 training error: 0.5824284645629105\n",
            "At step: 6979 training error: 0.587334676702305\n",
            "At step: 6980 training error: 0.5906694282808335\n",
            "At step: 6981 training error: 0.5949786111744423\n",
            "At step: 6982 training error: 0.5920707132900996\n",
            "At step: 6983 training error: 0.593950323921943\n",
            "At step: 6984 training error: 0.5879756372603716\n",
            "At step: 6985 training error: 0.5898102195808431\n",
            "At step: 6986 training error: 0.5859708300210869\n",
            "At step: 6987 training error: 0.577198162067466\n",
            "At step: 6988 training error: 0.5692282161931737\n",
            "At step: 6989 training error: 0.5763341000477191\n",
            "At step: 6990 training error: 0.5707724549267419\n",
            "At step: 6991 training error: 0.5694927495465412\n",
            "At step: 6992 training error: 0.569107861956523\n",
            "At step: 6993 training error: 0.5797368472758135\n",
            "At step: 6994 training error: 0.5783586009082409\n",
            "At step: 6995 training error: 0.5743741601482323\n",
            "At step: 6996 training error: 0.57426461324762\n",
            "At step: 6997 training error: 0.5831253392014439\n",
            "At step: 6998 training error: 0.5799112098506846\n",
            "At step: 6999 training error: 0.5769384270312439\n",
            "At step: 7000 training error: 0.5922980601369657\n",
            "At step: 7001 training error: 0.5874594869527379\n",
            "At step: 7002 training error: 0.5914855921693946\n",
            "At step: 7003 training error: 0.5882996506723202\n",
            "At step: 7004 training error: 0.5821984138580399\n",
            "At step: 7005 training error: 0.5740264708320989\n",
            "At step: 7006 training error: 0.5696148980462449\n",
            "At step: 7007 training error: 0.5761524481511637\n",
            "At step: 7008 training error: 0.5824361407732884\n",
            "At step: 7009 training error: 0.5864868779802247\n",
            "At step: 7010 training error: 0.5812867866014206\n",
            "At step: 7011 training error: 0.5726022812699386\n",
            "At step: 7012 training error: 0.5700751921256724\n",
            "At step: 7013 training error: 0.5762782825704049\n",
            "At step: 7014 training error: 0.5825975553326298\n",
            "At step: 7015 training error: 0.5840528636009632\n",
            "At step: 7016 training error: 0.5890641038813234\n",
            "At step: 7017 training error: 0.5840585946325821\n",
            "At step: 7018 training error: 0.5819063238909585\n",
            "At step: 7019 training error: 0.5785192168279261\n",
            "At step: 7020 training error: 0.5894926851277064\n",
            "At step: 7021 training error: 0.5836303046755295\n",
            "At step: 7022 training error: 0.589679738422607\n",
            "At step: 7023 training error: 0.5942821158241214\n",
            "At step: 7024 training error: 0.5838367659110865\n",
            "At step: 7025 training error: 0.5818149492592015\n",
            "At step: 7026 training error: 0.588363629926934\n",
            "At step: 7027 training error: 0.5756955236947726\n",
            "At step: 7028 training error: 0.5665897683573499\n",
            "At step: 7029 training error: 0.5629852460321589\n",
            "At step: 7030 training error: 0.5522755566221141\n",
            "At step: 7031 training error: 0.549115583475412\n",
            "At step: 7032 training error: 0.5508200560858953\n",
            "At step: 7033 training error: 0.5483803804242295\n",
            "At step: 7034 training error: 0.5556333899197617\n",
            "At step: 7035 training error: 0.5496351054840253\n",
            "At step: 7036 training error: 0.5539342514344802\n",
            "At step: 7037 training error: 0.5586362355318208\n",
            "At step: 7038 training error: 0.5520623630199541\n",
            "At step: 7039 training error: 0.5553914331373601\n",
            "At step: 7040 training error: 0.5578551596017143\n",
            "At step: 7041 training error: 0.5699381591506258\n",
            "At step: 7042 training error: 0.5761226866219765\n",
            "At step: 7043 training error: 0.5700351812053642\n",
            "At step: 7044 training error: 0.5612791000349392\n",
            "At step: 7045 training error: 0.5623720667078272\n",
            "At step: 7046 training error: 0.5643376693276106\n",
            "At step: 7047 training error: 0.5644100531151242\n",
            "At step: 7048 training error: 0.5776415642279444\n",
            "At step: 7049 training error: 0.585789648875917\n",
            "At step: 7050 training error: 0.5773971953841752\n",
            "At step: 7051 training error: 0.5647078619621624\n",
            "At step: 7052 training error: 0.5663272605477271\n",
            "At step: 7053 training error: 0.5745402043275771\n",
            "At step: 7054 training error: 0.5775062828047788\n",
            "At step: 7055 training error: 0.5753505159988119\n",
            "At step: 7056 training error: 0.5710467080579419\n",
            "At step: 7057 training error: 0.5606733374817855\n",
            "At step: 7058 training error: 0.5587855594482743\n",
            "At step: 7059 training error: 0.5610282889922571\n",
            "At step: 7060 training error: 0.5571247371624738\n",
            "At step: 7061 training error: 0.5553324400473629\n",
            "At step: 7062 training error: 0.5500839138200775\n",
            "At step: 7063 training error: 0.556420436716289\n",
            "At step: 7064 training error: 0.5649304068128231\n",
            "At step: 7065 training error: 0.5659977791611789\n",
            "At step: 7066 training error: 0.5762962659723907\n",
            "At step: 7067 training error: 0.5804608022065221\n",
            "At step: 7068 training error: 0.572842089664269\n",
            "At step: 7069 training error: 0.5777036083090205\n",
            "At step: 7070 training error: 0.5752547049782942\n",
            "At step: 7071 training error: 0.572889702811998\n",
            "At step: 7072 training error: 0.5790227026021757\n",
            "At step: 7073 training error: 0.5742744780009447\n",
            "At step: 7074 training error: 0.5719476159004045\n",
            "At step: 7075 training error: 0.568839338181751\n",
            "At step: 7076 training error: 0.5719618698285983\n",
            "At step: 7077 training error: 0.5716773600294686\n",
            "At step: 7078 training error: 0.5775741709561719\n",
            "At step: 7079 training error: 0.5649953269732461\n",
            "At step: 7080 training error: 0.571176675200834\n",
            "At step: 7081 training error: 0.5729529147052133\n",
            "At step: 7082 training error: 0.5746251986308144\n",
            "At step: 7083 training error: 0.5716121190141792\n",
            "At step: 7084 training error: 0.5704943234993084\n",
            "At step: 7085 training error: 0.5676907653201604\n",
            "At step: 7086 training error: 0.5679628266166726\n",
            "At step: 7087 training error: 0.5657975280890004\n",
            "At step: 7088 training error: 0.5755313391178104\n",
            "At step: 7089 training error: 0.5842309089484464\n",
            "At step: 7090 training error: 0.5889585360124994\n",
            "At step: 7091 training error: 0.5921526269294483\n",
            "At step: 7092 training error: 0.5880557290686467\n",
            "At step: 7093 training error: 0.5972072339235724\n",
            "At step: 7094 training error: 0.6063455745437613\n",
            "At step: 7095 training error: 0.6138245004942032\n",
            "At step: 7096 training error: 0.6158185787109318\n",
            "At step: 7097 training error: 0.6109908652735756\n",
            "At step: 7098 training error: 0.6001195789726729\n",
            "At step: 7099 training error: 0.5943262575663317\n",
            "At step: 7100 training error: 0.5907382191619758\n",
            "At step: 7101 training error: 0.5937560184646168\n",
            "At step: 7102 training error: 0.5869448921715621\n",
            "At step: 7103 training error: 0.572609243023513\n",
            "At step: 7104 training error: 0.5744879292512384\n",
            "At step: 7105 training error: 0.5877249972783898\n",
            "At step: 7106 training error: 0.5788542292305265\n",
            "At step: 7107 training error: 0.5735099739344479\n",
            "At step: 7108 training error: 0.5654328267029186\n",
            "At step: 7109 training error: 0.55818366910942\n",
            "At step: 7110 training error: 0.557452000906122\n",
            "At step: 7111 training error: 0.5543640753186001\n",
            "At step: 7112 training error: 0.5570328921418407\n",
            "At step: 7113 training error: 0.5595601795638463\n",
            "At step: 7114 training error: 0.5553218655944907\n",
            "At step: 7115 training error: 0.5589084304665123\n",
            "At step: 7116 training error: 0.5731930624760645\n",
            "At step: 7117 training error: 0.5748657071157868\n",
            "At step: 7118 training error: 0.5741343264949026\n",
            "At step: 7119 training error: 0.5797256387473044\n",
            "At step: 7120 training error: 0.5897587143269533\n",
            "At step: 7121 training error: 0.586650226845083\n",
            "At step: 7122 training error: 0.5843096264825866\n",
            "At step: 7123 training error: 0.5812400277579153\n",
            "At step: 7124 training error: 0.5708257508965401\n",
            "At step: 7125 training error: 0.5724741838708576\n",
            "At step: 7126 training error: 0.577357706729983\n",
            "At step: 7127 training error: 0.5792436294098792\n",
            "At step: 7128 training error: 0.5709389542221334\n",
            "At step: 7129 training error: 0.5779321968978919\n",
            "At step: 7130 training error: 0.5771961068416931\n",
            "At step: 7131 training error: 0.593299181970925\n",
            "At step: 7132 training error: 0.6048411361531261\n",
            "At step: 7133 training error: 0.6086654563228238\n",
            "At step: 7134 training error: 0.6032615357208266\n",
            "At step: 7135 training error: 0.6022431702098554\n",
            "At step: 7136 training error: 0.6003151709586257\n",
            "At step: 7137 training error: 0.6035974111139865\n",
            "At step: 7138 training error: 0.6065298680990346\n",
            "At step: 7139 training error: 0.5998121593944442\n",
            "At step: 7140 training error: 0.5864513874745401\n",
            "At step: 7141 training error: 0.5806244939459652\n",
            "At step: 7142 training error: 0.582594945025115\n",
            "At step: 7143 training error: 0.5956628156274035\n",
            "At step: 7144 training error: 0.5968101692655498\n",
            "At step: 7145 training error: 0.5988837970153277\n",
            "At step: 7146 training error: 0.5980251992920984\n",
            "At step: 7147 training error: 0.5886557939041759\n",
            "At step: 7148 training error: 0.5959771838836946\n",
            "At step: 7149 training error: 0.604220469503263\n",
            "At step: 7150 training error: 0.5970481478058973\n",
            "At step: 7151 training error: 0.5853554343006114\n",
            "At step: 7152 training error: 0.5803233767824287\n",
            "At step: 7153 training error: 0.5852795005021263\n",
            "At step: 7154 training error: 0.5841846519981556\n",
            "At step: 7155 training error: 0.5882177623223593\n",
            "At step: 7156 training error: 0.584202068855706\n",
            "At step: 7157 training error: 0.5796123391438441\n",
            "At step: 7158 training error: 0.5827390130210476\n",
            "At step: 7159 training error: 0.5819986744187129\n",
            "At step: 7160 training error: 0.5835515784616624\n",
            "At step: 7161 training error: 0.5841679377035273\n",
            "At step: 7162 training error: 0.585647982484226\n",
            "At step: 7163 training error: 0.5820272261945681\n",
            "At step: 7164 training error: 0.5861190380073927\n",
            "At step: 7165 training error: 0.5780260837150788\n",
            "At step: 7166 training error: 0.5824925273071233\n",
            "At step: 7167 training error: 0.5806699359186068\n",
            "At step: 7168 training error: 0.5768577223781786\n",
            "At step: 7169 training error: 0.5799674419963777\n",
            "At step: 7170 training error: 0.5778192574726312\n",
            "At step: 7171 training error: 0.5825840493113078\n",
            "At step: 7172 training error: 0.5816841586538077\n",
            "At step: 7173 training error: 0.5873940155917131\n",
            "At step: 7174 training error: 0.5920789695856475\n",
            "At step: 7175 training error: 0.5932474046026789\n",
            "At step: 7176 training error: 0.5858145704156741\n",
            "At step: 7177 training error: 0.5918451804269912\n",
            "At step: 7178 training error: 0.5904848850793851\n",
            "At step: 7179 training error: 0.5915441408348897\n",
            "At step: 7180 training error: 0.5873229719512233\n",
            "At step: 7181 training error: 0.5993643601650378\n",
            "At step: 7182 training error: 0.6013849421520227\n",
            "At step: 7183 training error: 0.599082485753875\n",
            "At step: 7184 training error: 0.5930390604866764\n",
            "At step: 7185 training error: 0.5933323787108974\n",
            "At step: 7186 training error: 0.593468486196384\n",
            "At step: 7187 training error: 0.5884160203519937\n",
            "At step: 7188 training error: 0.5788896755414855\n",
            "At step: 7189 training error: 0.5768408132492762\n",
            "At step: 7190 training error: 0.5764784000701217\n",
            "At step: 7191 training error: 0.5769606418506648\n",
            "At step: 7192 training error: 0.5776467139041364\n",
            "At step: 7193 training error: 0.5831338352350751\n",
            "At step: 7194 training error: 0.5928099489333511\n",
            "At step: 7195 training error: 0.5831233589936788\n",
            "At step: 7196 training error: 0.5781043532671293\n",
            "At step: 7197 training error: 0.5711376178757964\n",
            "At step: 7198 training error: 0.5703934358211725\n",
            "At step: 7199 training error: 0.5646136579732096\n",
            "At step: 7200 training error: 0.5667895912623632\n",
            "At step: 7201 training error: 0.5625990211211281\n",
            "At step: 7202 training error: 0.5583706555749036\n",
            "At step: 7203 training error: 0.5667592196820539\n",
            "At step: 7204 training error: 0.5604976818749116\n",
            "At step: 7205 training error: 0.553928975794795\n",
            "At step: 7206 training error: 0.5620085420513654\n",
            "At step: 7207 training error: 0.5675185860316968\n",
            "At step: 7208 training error: 0.5736703425295359\n",
            "At step: 7209 training error: 0.5707297732403789\n",
            "At step: 7210 training error: 0.5705214434932179\n",
            "At step: 7211 training error: 0.569400666340265\n",
            "At step: 7212 training error: 0.5776402220824223\n",
            "At step: 7213 training error: 0.5735333353262716\n",
            "At step: 7214 training error: 0.5639978843396499\n",
            "At step: 7215 training error: 0.5593298142507559\n",
            "At step: 7216 training error: 0.5581938511429614\n",
            "At step: 7217 training error: 0.5635649969412546\n",
            "At step: 7218 training error: 0.568818830338359\n",
            "At step: 7219 training error: 0.5717557055638645\n",
            "At step: 7220 training error: 0.5759150635086484\n",
            "At step: 7221 training error: 0.5796327105909863\n",
            "At step: 7222 training error: 0.5773737924298674\n",
            "At step: 7223 training error: 0.5743279244065321\n",
            "At step: 7224 training error: 0.5714068180324622\n",
            "At step: 7225 training error: 0.5731354197602189\n",
            "At step: 7226 training error: 0.5773475045917575\n",
            "At step: 7227 training error: 0.5816839070567055\n",
            "At step: 7228 training error: 0.585917750817252\n",
            "At step: 7229 training error: 0.5806321014790793\n",
            "At step: 7230 training error: 0.5811640839745678\n",
            "At step: 7231 training error: 0.576708345490976\n",
            "At step: 7232 training error: 0.569357915887073\n",
            "At step: 7233 training error: 0.5850736219962822\n",
            "At step: 7234 training error: 0.5823538110915666\n",
            "At step: 7235 training error: 0.5772340178461394\n",
            "At step: 7236 training error: 0.5736566761655775\n",
            "At step: 7237 training error: 0.5776364404368985\n",
            "At step: 7238 training error: 0.5739617714140806\n",
            "At step: 7239 training error: 0.5776199105784384\n",
            "At step: 7240 training error: 0.5752662793959944\n",
            "At step: 7241 training error: 0.5723798408532508\n",
            "At step: 7242 training error: 0.5753920298593957\n",
            "At step: 7243 training error: 0.5855875014177198\n",
            "At step: 7244 training error: 0.5874885868951989\n",
            "At step: 7245 training error: 0.5872952812576477\n",
            "At step: 7246 training error: 0.5933461949603512\n",
            "At step: 7247 training error: 0.5898846490056953\n",
            "At step: 7248 training error: 0.5825660127326846\n",
            "At step: 7249 training error: 0.573393750991825\n",
            "At step: 7250 training error: 0.573482712947856\n",
            "At step: 7251 training error: 0.5711667493754098\n",
            "At step: 7252 training error: 0.5724147849820553\n",
            "At step: 7253 training error: 0.5685818916231812\n",
            "At step: 7254 training error: 0.5660906674405491\n",
            "At step: 7255 training error: 0.5707340454593713\n",
            "At step: 7256 training error: 0.575166290581437\n",
            "At step: 7257 training error: 0.5776133659939915\n",
            "At step: 7258 training error: 0.5717991385880389\n",
            "At step: 7259 training error: 0.5711128707801297\n",
            "At step: 7260 training error: 0.5639113179905165\n",
            "At step: 7261 training error: 0.5577719018654239\n",
            "At step: 7262 training error: 0.5540039600427147\n",
            "At step: 7263 training error: 0.5545547909636005\n",
            "At step: 7264 training error: 0.5514895136276708\n",
            "At step: 7265 training error: 0.5572246937803522\n",
            "At step: 7266 training error: 0.5543970488236639\n",
            "At step: 7267 training error: 0.5470805179347928\n",
            "At step: 7268 training error: 0.5427448736926447\n",
            "At step: 7269 training error: 0.5365669609956815\n",
            "At step: 7270 training error: 0.5421129007661417\n",
            "At step: 7271 training error: 0.5447844969585038\n",
            "At step: 7272 training error: 0.5387233105153886\n",
            "At step: 7273 training error: 0.5440018911469409\n",
            "At step: 7274 training error: 0.5387686881880137\n",
            "At step: 7275 training error: 0.5335603849328411\n",
            "At step: 7276 training error: 0.5269504397804735\n",
            "At step: 7277 training error: 0.5298982422801561\n",
            "At step: 7278 training error: 0.5342188929784393\n",
            "At step: 7279 training error: 0.5394993353006639\n",
            "At step: 7280 training error: 0.5376648686326231\n",
            "At step: 7281 training error: 0.5389540062025239\n",
            "At step: 7282 training error: 0.5366202687416878\n",
            "At step: 7283 training error: 0.5519255995085957\n",
            "At step: 7284 training error: 0.5655566294674755\n",
            "At step: 7285 training error: 0.5637750666780973\n",
            "At step: 7286 training error: 0.5666519926379731\n",
            "At step: 7287 training error: 0.5688591134400088\n",
            "At step: 7288 training error: 0.5612809973874727\n",
            "At step: 7289 training error: 0.5654602382056407\n",
            "At step: 7290 training error: 0.5764990064988865\n",
            "At step: 7291 training error: 0.5765229175170155\n",
            "At step: 7292 training error: 0.5762419535880521\n",
            "At step: 7293 training error: 0.5774053982927512\n",
            "At step: 7294 training error: 0.5805872573148536\n",
            "At step: 7295 training error: 0.5783403316016915\n",
            "At step: 7296 training error: 0.5660101243684469\n",
            "At step: 7297 training error: 0.5708466661656446\n",
            "At step: 7298 training error: 0.5720270506277809\n",
            "At step: 7299 training error: 0.5797445271164523\n",
            "At step: 7300 training error: 0.5784838495959331\n",
            "At step: 7301 training error: 0.58252446847166\n",
            "At step: 7302 training error: 0.578761253641211\n",
            "At step: 7303 training error: 0.5753277388752979\n",
            "At step: 7304 training error: 0.5808872969124143\n",
            "At step: 7305 training error: 0.5845282937364282\n",
            "At step: 7306 training error: 0.5825536572635337\n",
            "At step: 7307 training error: 0.5813511306371656\n",
            "At step: 7308 training error: 0.5666171595527012\n",
            "At step: 7309 training error: 0.5624010479087026\n",
            "At step: 7310 training error: 0.5576239386796192\n",
            "At step: 7311 training error: 0.5555650896389736\n",
            "At step: 7312 training error: 0.5589369598540577\n",
            "At step: 7313 training error: 0.5638046664463896\n",
            "At step: 7314 training error: 0.5626249074312619\n",
            "At step: 7315 training error: 0.5681130028592444\n",
            "At step: 7316 training error: 0.5641077598177254\n",
            "At step: 7317 training error: 0.5633081162302762\n",
            "At step: 7318 training error: 0.567434725450531\n",
            "At step: 7319 training error: 0.5601250666342277\n",
            "At step: 7320 training error: 0.5607126812753509\n",
            "At step: 7321 training error: 0.5705796829378061\n",
            "At step: 7322 training error: 0.56720243608365\n",
            "At step: 7323 training error: 0.5692508360517211\n",
            "At step: 7324 training error: 0.563360394450867\n",
            "At step: 7325 training error: 0.5718085590164653\n",
            "At step: 7326 training error: 0.5653771240441775\n",
            "At step: 7327 training error: 0.5637798504444774\n",
            "At step: 7328 training error: 0.5655983606014462\n",
            "At step: 7329 training error: 0.5728898187858092\n",
            "At step: 7330 training error: 0.5732377217600118\n",
            "At step: 7331 training error: 0.5752510966438488\n",
            "At step: 7332 training error: 0.5675918983609803\n",
            "At step: 7333 training error: 0.5690594985372845\n",
            "At step: 7334 training error: 0.5737775530072616\n",
            "At step: 7335 training error: 0.5751921103397436\n",
            "At step: 7336 training error: 0.5759567390464515\n",
            "At step: 7337 training error: 0.5772870956475774\n",
            "At step: 7338 training error: 0.5750668801668805\n",
            "At step: 7339 training error: 0.5782157302553627\n",
            "At step: 7340 training error: 0.5737502180938095\n",
            "At step: 7341 training error: 0.566035695784763\n",
            "At step: 7342 training error: 0.5682958624193376\n",
            "At step: 7343 training error: 0.5768232115373128\n",
            "At step: 7344 training error: 0.5740064319813533\n",
            "At step: 7345 training error: 0.5807227556853791\n",
            "At step: 7346 training error: 0.5827710327288229\n",
            "At step: 7347 training error: 0.5831143720911531\n",
            "At step: 7348 training error: 0.5820291215983209\n",
            "At step: 7349 training error: 0.5799967518901905\n",
            "At step: 7350 training error: 0.5724854400689222\n",
            "At step: 7351 training error: 0.5750873679066238\n",
            "At step: 7352 training error: 0.5789906629713241\n",
            "At step: 7353 training error: 0.5784575262013206\n",
            "At step: 7354 training error: 0.5764877085494391\n",
            "At step: 7355 training error: 0.5683093590833688\n",
            "At step: 7356 training error: 0.5641630230733421\n",
            "At step: 7357 training error: 0.5655511152706485\n",
            "At step: 7358 training error: 0.5634155928717248\n",
            "At step: 7359 training error: 0.5775479075251727\n",
            "At step: 7360 training error: 0.569302374346195\n",
            "At step: 7361 training error: 0.5644056767351718\n",
            "At step: 7362 training error: 0.5584533663902109\n",
            "At step: 7363 training error: 0.5566985058293147\n",
            "At step: 7364 training error: 0.5537963436711051\n",
            "At step: 7365 training error: 0.5622386910992532\n",
            "At step: 7366 training error: 0.56239510474343\n",
            "At step: 7367 training error: 0.5700748192439754\n",
            "At step: 7368 training error: 0.5661231908256764\n",
            "At step: 7369 training error: 0.5681850220948359\n",
            "At step: 7370 training error: 0.5650824613789517\n",
            "At step: 7371 training error: 0.5596915526099984\n",
            "At step: 7372 training error: 0.5512830129147142\n",
            "At step: 7373 training error: 0.5482227933478714\n",
            "At step: 7374 training error: 0.5481792094895968\n",
            "At step: 7375 training error: 0.5466851264644639\n",
            "At step: 7376 training error: 0.5528265647386675\n",
            "At step: 7377 training error: 0.5487196391441707\n",
            "At step: 7378 training error: 0.5503452716249596\n",
            "At step: 7379 training error: 0.553310268663109\n",
            "At step: 7380 training error: 0.5564041029701812\n",
            "At step: 7381 training error: 0.5539042014161191\n",
            "At step: 7382 training error: 0.5590186769246611\n",
            "At step: 7383 training error: 0.5583622141861215\n",
            "At step: 7384 training error: 0.554055073894253\n",
            "At step: 7385 training error: 0.5553859537504654\n",
            "At step: 7386 training error: 0.5597937850825314\n",
            "At step: 7387 training error: 0.5598316493167225\n",
            "At step: 7388 training error: 0.5640750371294163\n",
            "At step: 7389 training error: 0.5542202343148942\n",
            "At step: 7390 training error: 0.5583995756548407\n",
            "At step: 7391 training error: 0.5571771717656285\n",
            "At step: 7392 training error: 0.5516127296105481\n",
            "At step: 7393 training error: 0.5663442359866709\n",
            "At step: 7394 training error: 0.5569528807959325\n",
            "At step: 7395 training error: 0.5550720439020898\n",
            "At step: 7396 training error: 0.5508503513086765\n",
            "At step: 7397 training error: 0.5480922126845912\n",
            "At step: 7398 training error: 0.5458776016006941\n",
            "At step: 7399 training error: 0.5431237779203537\n",
            "At step: 7400 training error: 0.5470089008148676\n",
            "At step: 7401 training error: 0.5447404299510425\n",
            "At step: 7402 training error: 0.5327036927802788\n",
            "At step: 7403 training error: 0.535136202561077\n",
            "At step: 7404 training error: 0.5417545337125341\n",
            "At step: 7405 training error: 0.5448085221712635\n",
            "At step: 7406 training error: 0.5453092266709209\n",
            "At step: 7407 training error: 0.5377830989425869\n",
            "At step: 7408 training error: 0.5413695907922458\n",
            "At step: 7409 training error: 0.5463203950724659\n",
            "At step: 7410 training error: 0.5495071970180021\n",
            "At step: 7411 training error: 0.5546327453609563\n",
            "At step: 7412 training error: 0.5538401790850948\n",
            "At step: 7413 training error: 0.5585892499030827\n",
            "At step: 7414 training error: 0.5498698822744955\n",
            "At step: 7415 training error: 0.5502549560878477\n",
            "At step: 7416 training error: 0.5571246029701593\n",
            "At step: 7417 training error: 0.555241147812591\n",
            "At step: 7418 training error: 0.5571829091360012\n",
            "At step: 7419 training error: 0.5644315578663465\n",
            "At step: 7420 training error: 0.5709702870196078\n",
            "At step: 7421 training error: 0.5631603722951416\n",
            "At step: 7422 training error: 0.5679079805738172\n",
            "At step: 7423 training error: 0.5597504239075286\n",
            "At step: 7424 training error: 0.5542863906309895\n",
            "At step: 7425 training error: 0.5676165255862933\n",
            "At step: 7426 training error: 0.5753998781061654\n",
            "At step: 7427 training error: 0.5620755594193351\n",
            "At step: 7428 training error: 0.561959882794975\n",
            "At step: 7429 training error: 0.5567919140105144\n",
            "At step: 7430 training error: 0.5571419199462605\n",
            "At step: 7431 training error: 0.5699075160110729\n",
            "At step: 7432 training error: 0.560851257823743\n",
            "At step: 7433 training error: 0.5598933760510522\n",
            "At step: 7434 training error: 0.5686641603372331\n",
            "At step: 7435 training error: 0.5622980118964692\n",
            "At step: 7436 training error: 0.5595521366284809\n",
            "At step: 7437 training error: 0.5631079232758313\n",
            "At step: 7438 training error: 0.5646952368334275\n",
            "At step: 7439 training error: 0.5596337536410655\n",
            "At step: 7440 training error: 0.559350000652393\n",
            "At step: 7441 training error: 0.5574784388677948\n",
            "At step: 7442 training error: 0.5573745095283156\n",
            "At step: 7443 training error: 0.5600491373948147\n",
            "At step: 7444 training error: 0.5481810650486413\n",
            "At step: 7445 training error: 0.5415086244290299\n",
            "At step: 7446 training error: 0.5348048217247725\n",
            "At step: 7447 training error: 0.5253693053836542\n",
            "At step: 7448 training error: 0.531419076414328\n",
            "At step: 7449 training error: 0.5366820774345152\n",
            "At step: 7450 training error: 0.5430049055286135\n",
            "At step: 7451 training error: 0.5478370809936686\n",
            "At step: 7452 training error: 0.5541344883201039\n",
            "At step: 7453 training error: 0.5550067278807238\n",
            "At step: 7454 training error: 0.5532400263482465\n",
            "At step: 7455 training error: 0.5488231127822976\n",
            "At step: 7456 training error: 0.5479234224782817\n",
            "At step: 7457 training error: 0.54519500896939\n",
            "At step: 7458 training error: 0.5481394234854001\n",
            "At step: 7459 training error: 0.5358442325523937\n",
            "At step: 7460 training error: 0.5463677313768639\n",
            "At step: 7461 training error: 0.5510353146115654\n",
            "At step: 7462 training error: 0.5598928024730265\n",
            "At step: 7463 training error: 0.5557194665677202\n",
            "At step: 7464 training error: 0.5603208758632451\n",
            "At step: 7465 training error: 0.5648233853766222\n",
            "At step: 7466 training error: 0.5669548729046674\n",
            "At step: 7467 training error: 0.5677466441170116\n",
            "At step: 7468 training error: 0.5662344897655139\n",
            "At step: 7469 training error: 0.5684484986022084\n",
            "At step: 7470 training error: 0.5685101398521972\n",
            "At step: 7471 training error: 0.5626899945952138\n",
            "At step: 7472 training error: 0.5673859313651215\n",
            "At step: 7473 training error: 0.5652511075490435\n",
            "At step: 7474 training error: 0.5655165503615424\n",
            "At step: 7475 training error: 0.5694481389851375\n",
            "At step: 7476 training error: 0.5720482494689179\n",
            "At step: 7477 training error: 0.5604445163542027\n",
            "At step: 7478 training error: 0.5710475908103452\n",
            "At step: 7479 training error: 0.5681556907357277\n",
            "At step: 7480 training error: 0.5721275212835174\n",
            "At step: 7481 training error: 0.5752111410925085\n",
            "At step: 7482 training error: 0.5702128359239993\n",
            "At step: 7483 training error: 0.572679808022598\n",
            "At step: 7484 training error: 0.5727571859961781\n",
            "At step: 7485 training error: 0.578879487478314\n",
            "At step: 7486 training error: 0.5775815885028619\n",
            "At step: 7487 training error: 0.5862127293940457\n",
            "At step: 7488 training error: 0.5816695628968818\n",
            "At step: 7489 training error: 0.5889216563404883\n",
            "At step: 7490 training error: 0.5823056593577658\n",
            "At step: 7491 training error: 0.5863918748219846\n",
            "At step: 7492 training error: 0.5882547286077852\n",
            "At step: 7493 training error: 0.5912713779619984\n",
            "At step: 7494 training error: 0.585402361587424\n",
            "At step: 7495 training error: 0.5801561197844993\n",
            "At step: 7496 training error: 0.5804792831261985\n",
            "At step: 7497 training error: 0.5773298241447948\n",
            "At step: 7498 training error: 0.5768427861113198\n",
            "At step: 7499 training error: 0.5698892589245347\n",
            "At step: 7500 training error: 0.569970307986068\n",
            "At step: 7501 training error: 0.5717655198187558\n",
            "At step: 7502 training error: 0.5672088596620132\n",
            "At step: 7503 training error: 0.5739903707343749\n",
            "At step: 7504 training error: 0.5756148897331423\n",
            "At step: 7505 training error: 0.577516326681206\n",
            "At step: 7506 training error: 0.5716368619311454\n",
            "At step: 7507 training error: 0.5767650509658604\n",
            "At step: 7508 training error: 0.5875735390322556\n",
            "At step: 7509 training error: 0.5954314132050035\n",
            "At step: 7510 training error: 0.5898601275217743\n",
            "At step: 7511 training error: 0.5861879733431545\n",
            "At step: 7512 training error: 0.5973443206304365\n",
            "At step: 7513 training error: 0.5999802288006049\n",
            "At step: 7514 training error: 0.5935473123341637\n",
            "At step: 7515 training error: 0.5879509792135555\n",
            "At step: 7516 training error: 0.5776214956480107\n",
            "At step: 7517 training error: 0.5758013894728282\n",
            "At step: 7518 training error: 0.574481149786709\n",
            "At step: 7519 training error: 0.5739010116404271\n",
            "At step: 7520 training error: 0.5703441180939297\n",
            "At step: 7521 training error: 0.5618598756887356\n",
            "At step: 7522 training error: 0.5661923528132756\n",
            "At step: 7523 training error: 0.5689067130404003\n",
            "At step: 7524 training error: 0.5655007325155675\n",
            "At step: 7525 training error: 0.5697951809765132\n",
            "At step: 7526 training error: 0.5698192839364015\n",
            "At step: 7527 training error: 0.5761817936067063\n",
            "At step: 7528 training error: 0.5699921290477413\n",
            "At step: 7529 training error: 0.5644326005647606\n",
            "At step: 7530 training error: 0.5690227534015844\n",
            "At step: 7531 training error: 0.5609534313500343\n",
            "At step: 7532 training error: 0.5546454454480112\n",
            "At step: 7533 training error: 0.563832723878966\n",
            "At step: 7534 training error: 0.5609623375330474\n",
            "At step: 7535 training error: 0.5543535691673391\n",
            "At step: 7536 training error: 0.5622544054015575\n",
            "At step: 7537 training error: 0.571546513389642\n",
            "At step: 7538 training error: 0.573124251511919\n",
            "At step: 7539 training error: 0.5691064254156121\n",
            "At step: 7540 training error: 0.5644452693354457\n",
            "At step: 7541 training error: 0.5620087570269637\n",
            "At step: 7542 training error: 0.5654688950520532\n",
            "At step: 7543 training error: 0.5689468848149798\n",
            "At step: 7544 training error: 0.5675220083325945\n",
            "At step: 7545 training error: 0.5769310758297335\n",
            "At step: 7546 training error: 0.5746710810723737\n",
            "At step: 7547 training error: 0.5794775007288044\n",
            "At step: 7548 training error: 0.5857985337306946\n",
            "At step: 7549 training error: 0.5841057676342978\n",
            "At step: 7550 training error: 0.5939438431543611\n",
            "At step: 7551 training error: 0.5873221203165782\n",
            "At step: 7552 training error: 0.5976451058104497\n",
            "At step: 7553 training error: 0.5902184108822415\n",
            "At step: 7554 training error: 0.5856950662367685\n",
            "At step: 7555 training error: 0.5807817715016458\n",
            "At step: 7556 training error: 0.5849989984392714\n",
            "At step: 7557 training error: 0.5770834073127985\n",
            "At step: 7558 training error: 0.5768151966651553\n",
            "At step: 7559 training error: 0.5757597525292806\n",
            "At step: 7560 training error: 0.5731229028030186\n",
            "At step: 7561 training error: 0.5742919035984243\n",
            "At step: 7562 training error: 0.581407481680017\n",
            "At step: 7563 training error: 0.5708879716700773\n",
            "At step: 7564 training error: 0.5738448093737345\n",
            "At step: 7565 training error: 0.5782581587638017\n",
            "At step: 7566 training error: 0.5820499889266465\n",
            "At step: 7567 training error: 0.576836451682188\n",
            "At step: 7568 training error: 0.5819626802171614\n",
            "At step: 7569 training error: 0.5847092421337905\n",
            "At step: 7570 training error: 0.587570837708977\n",
            "At step: 7571 training error: 0.5757818804055175\n",
            "At step: 7572 training error: 0.5804683963917333\n",
            "At step: 7573 training error: 0.5710591327288437\n",
            "At step: 7574 training error: 0.5641759484477891\n",
            "At step: 7575 training error: 0.5663253566043983\n",
            "At step: 7576 training error: 0.5641586479251854\n",
            "At step: 7577 training error: 0.5545707840488223\n",
            "At step: 7578 training error: 0.5522419037622409\n",
            "At step: 7579 training error: 0.5614889475451481\n",
            "At step: 7580 training error: 0.5642886415675866\n",
            "At step: 7581 training error: 0.5653066396464939\n",
            "At step: 7582 training error: 0.5626452381341289\n",
            "At step: 7583 training error: 0.5594619018700837\n",
            "At step: 7584 training error: 0.5578023107426564\n",
            "At step: 7585 training error: 0.5556256927867385\n",
            "At step: 7586 training error: 0.5591103781440646\n",
            "At step: 7587 training error: 0.5688264886913066\n",
            "At step: 7588 training error: 0.5629619625566957\n",
            "At step: 7589 training error: 0.5578639855476661\n",
            "At step: 7590 training error: 0.5502245854378554\n",
            "At step: 7591 training error: 0.5545261568435905\n",
            "At step: 7592 training error: 0.5580334701116283\n",
            "At step: 7593 training error: 0.5572211989752143\n",
            "At step: 7594 training error: 0.5557733334685115\n",
            "At step: 7595 training error: 0.5587344532455859\n",
            "At step: 7596 training error: 0.5570871653389595\n",
            "At step: 7597 training error: 0.5619957606501687\n",
            "At step: 7598 training error: 0.5667915142353223\n",
            "At step: 7599 training error: 0.5649907263675518\n",
            "At step: 7600 training error: 0.5552544582806849\n",
            "At step: 7601 training error: 0.5529809733462839\n",
            "At step: 7602 training error: 0.5537570566468281\n",
            "At step: 7603 training error: 0.5618238026061677\n",
            "At step: 7604 training error: 0.5610465779726139\n",
            "At step: 7605 training error: 0.5482893987930044\n",
            "At step: 7606 training error: 0.5560498182449068\n",
            "At step: 7607 training error: 0.5661909679413083\n",
            "At step: 7608 training error: 0.5615250047552136\n",
            "At step: 7609 training error: 0.5633571211074051\n",
            "At step: 7610 training error: 0.5739273822969216\n",
            "At step: 7611 training error: 0.5624413734260415\n",
            "At step: 7612 training error: 0.5655014541187231\n",
            "At step: 7613 training error: 0.5575916164995134\n",
            "At step: 7614 training error: 0.5502820788666071\n",
            "At step: 7615 training error: 0.5499633877978872\n",
            "At step: 7616 training error: 0.5442272976165914\n",
            "At step: 7617 training error: 0.5546925218125969\n",
            "At step: 7618 training error: 0.557810264476559\n",
            "At step: 7619 training error: 0.5617528715094153\n",
            "At step: 7620 training error: 0.5592797733361262\n",
            "At step: 7621 training error: 0.5496404300619132\n",
            "At step: 7622 training error: 0.552533964500842\n",
            "At step: 7623 training error: 0.5494158903384208\n",
            "At step: 7624 training error: 0.5397639636970952\n",
            "At step: 7625 training error: 0.5389278000206852\n",
            "At step: 7626 training error: 0.544701766872375\n",
            "At step: 7627 training error: 0.5446481148437514\n",
            "At step: 7628 training error: 0.5382768143082036\n",
            "At step: 7629 training error: 0.5404458626051675\n",
            "At step: 7630 training error: 0.5503410985118412\n",
            "At step: 7631 training error: 0.5546298419579976\n",
            "At step: 7632 training error: 0.5536852998632705\n",
            "At step: 7633 training error: 0.5632845903414778\n",
            "At step: 7634 training error: 0.5658171175636485\n",
            "At step: 7635 training error: 0.5621505703794998\n",
            "At step: 7636 training error: 0.5627318993435881\n",
            "At step: 7637 training error: 0.5707947711107704\n",
            "At step: 7638 training error: 0.5683930548624498\n",
            "At step: 7639 training error: 0.557696207344988\n",
            "At step: 7640 training error: 0.5569985313761895\n",
            "At step: 7641 training error: 0.5565800161047005\n",
            "At step: 7642 training error: 0.5609943840543445\n",
            "At step: 7643 training error: 0.5551794778438596\n",
            "At step: 7644 training error: 0.558573414068425\n",
            "At step: 7645 training error: 0.5587432850315748\n",
            "At step: 7646 training error: 0.5644213916705951\n",
            "At step: 7647 training error: 0.5632697873943365\n",
            "At step: 7648 training error: 0.565196193798508\n",
            "At step: 7649 training error: 0.5594696976207153\n",
            "At step: 7650 training error: 0.5591556076469847\n",
            "At step: 7651 training error: 0.5582758433098145\n",
            "At step: 7652 training error: 0.5647965268417601\n",
            "At step: 7653 training error: 0.5741552632489747\n",
            "At step: 7654 training error: 0.5645341122845464\n",
            "At step: 7655 training error: 0.5671682456115338\n",
            "At step: 7656 training error: 0.5602404912438559\n",
            "At step: 7657 training error: 0.5563042390034821\n",
            "At step: 7658 training error: 0.5521527388816461\n",
            "At step: 7659 training error: 0.5549658647894911\n",
            "At step: 7660 training error: 0.5708296655100494\n",
            "At step: 7661 training error: 0.5603050239264391\n",
            "At step: 7662 training error: 0.5642546527839183\n",
            "At step: 7663 training error: 0.5608418618885025\n",
            "At step: 7664 training error: 0.5575627991203457\n",
            "At step: 7665 training error: 0.5530191560458969\n",
            "At step: 7666 training error: 0.5588134116263728\n",
            "At step: 7667 training error: 0.555317747505646\n",
            "At step: 7668 training error: 0.5616453369034723\n",
            "At step: 7669 training error: 0.5508833703432834\n",
            "At step: 7670 training error: 0.5466663224931037\n",
            "At step: 7671 training error: 0.5573964866703495\n",
            "At step: 7672 training error: 0.5596282226774709\n",
            "At step: 7673 training error: 0.5619420839534839\n",
            "At step: 7674 training error: 0.5550853110252357\n",
            "At step: 7675 training error: 0.5530265682825544\n",
            "At step: 7676 training error: 0.5459991515921248\n",
            "At step: 7677 training error: 0.5492532521608167\n",
            "At step: 7678 training error: 0.5599660282433928\n",
            "At step: 7679 training error: 0.5558942470389003\n",
            "At step: 7680 training error: 0.5561968786289073\n",
            "At step: 7681 training error: 0.5552450191262229\n",
            "At step: 7682 training error: 0.5534498684013545\n",
            "At step: 7683 training error: 0.5653618671516816\n",
            "At step: 7684 training error: 0.5579513855281901\n",
            "At step: 7685 training error: 0.5657312642910334\n",
            "At step: 7686 training error: 0.5756118990422957\n",
            "At step: 7687 training error: 0.5692444879871615\n",
            "At step: 7688 training error: 0.5605177610519929\n",
            "At step: 7689 training error: 0.5643007209556472\n",
            "At step: 7690 training error: 0.5538142296747305\n",
            "At step: 7691 training error: 0.5597957891784684\n",
            "At step: 7692 training error: 0.567247957175144\n",
            "At step: 7693 training error: 0.5711474272784662\n",
            "At step: 7694 training error: 0.5738198999177669\n",
            "At step: 7695 training error: 0.5694693716500644\n",
            "At step: 7696 training error: 0.5574132955068465\n",
            "At step: 7697 training error: 0.5526321618781643\n",
            "At step: 7698 training error: 0.5618728791567061\n",
            "At step: 7699 training error: 0.5619539333119985\n",
            "At step: 7700 training error: 0.5508984644144812\n",
            "At step: 7701 training error: 0.5580228494997891\n",
            "At step: 7702 training error: 0.5567078755284411\n",
            "At step: 7703 training error: 0.5557162032489101\n",
            "At step: 7704 training error: 0.5525787008464887\n",
            "At step: 7705 training error: 0.5610744804321138\n",
            "At step: 7706 training error: 0.5530934369721684\n",
            "At step: 7707 training error: 0.5604556914471089\n",
            "At step: 7708 training error: 0.5639790835915127\n",
            "At step: 7709 training error: 0.5722136530785821\n",
            "At step: 7710 training error: 0.5709250541219602\n",
            "At step: 7711 training error: 0.564921993405106\n",
            "At step: 7712 training error: 0.5615976554067225\n",
            "At step: 7713 training error: 0.5683354800399432\n",
            "At step: 7714 training error: 0.5717397322063958\n",
            "At step: 7715 training error: 0.5763994255246121\n",
            "At step: 7716 training error: 0.5819922129218796\n",
            "At step: 7717 training error: 0.5763512997553145\n",
            "At step: 7718 training error: 0.5785744369694025\n",
            "At step: 7719 training error: 0.5810143728236252\n",
            "At step: 7720 training error: 0.5792048024220874\n",
            "At step: 7721 training error: 0.5658389531783854\n",
            "At step: 7722 training error: 0.5770291378585449\n",
            "At step: 7723 training error: 0.5756719349220257\n",
            "At step: 7724 training error: 0.5712802043339282\n",
            "At step: 7725 training error: 0.5584147835255622\n",
            "At step: 7726 training error: 0.5491780765708749\n",
            "At step: 7727 training error: 0.5526550295515591\n",
            "At step: 7728 training error: 0.5699431824824701\n",
            "At step: 7729 training error: 0.5677380282597149\n",
            "At step: 7730 training error: 0.5612778064350389\n",
            "At step: 7731 training error: 0.5675840592109337\n",
            "At step: 7732 training error: 0.5622403579705486\n",
            "At step: 7733 training error: 0.5588751001047301\n",
            "At step: 7734 training error: 0.5633959725870072\n",
            "At step: 7735 training error: 0.5618298098667007\n",
            "At step: 7736 training error: 0.5627729194064847\n",
            "At step: 7737 training error: 0.557885850184809\n",
            "At step: 7738 training error: 0.5667396724578229\n",
            "At step: 7739 training error: 0.5587595774909854\n",
            "At step: 7740 training error: 0.5556282143924173\n",
            "At step: 7741 training error: 0.5550636056719164\n",
            "At step: 7742 training error: 0.5545208634720894\n",
            "At step: 7743 training error: 0.5483410750542974\n",
            "At step: 7744 training error: 0.5463010195158788\n",
            "At step: 7745 training error: 0.5476700190943665\n",
            "At step: 7746 training error: 0.5504955247494036\n",
            "At step: 7747 training error: 0.5635438611555965\n",
            "At step: 7748 training error: 0.5629613499559816\n",
            "At step: 7749 training error: 0.5574197032681628\n",
            "At step: 7750 training error: 0.5501146458394494\n",
            "At step: 7751 training error: 0.5476844489093118\n",
            "At step: 7752 training error: 0.5522125555535123\n",
            "At step: 7753 training error: 0.5530129688795625\n",
            "At step: 7754 training error: 0.5517472308588549\n",
            "At step: 7755 training error: 0.5581308620563595\n",
            "At step: 7756 training error: 0.5624603251649914\n",
            "At step: 7757 training error: 0.5684098609665739\n",
            "At step: 7758 training error: 0.5766505864276084\n",
            "At step: 7759 training error: 0.5847308420760923\n",
            "At step: 7760 training error: 0.5817894891805121\n",
            "At step: 7761 training error: 0.5903543952860753\n",
            "At step: 7762 training error: 0.5906503729885101\n",
            "At step: 7763 training error: 0.5857908540775031\n",
            "At step: 7764 training error: 0.5773721801570331\n",
            "At step: 7765 training error: 0.5640455147772562\n",
            "At step: 7766 training error: 0.5434458928189746\n",
            "At step: 7767 training error: 0.5437542520578073\n",
            "At step: 7768 training error: 0.5508389304287941\n",
            "At step: 7769 training error: 0.5437721496641282\n",
            "At step: 7770 training error: 0.539366445596048\n",
            "At step: 7771 training error: 0.5456378443566486\n",
            "At step: 7772 training error: 0.5473169734358933\n",
            "At step: 7773 training error: 0.5502796596356788\n",
            "At step: 7774 training error: 0.5407948379806489\n",
            "At step: 7775 training error: 0.5447838435578842\n",
            "At step: 7776 training error: 0.5400201479394786\n",
            "At step: 7777 training error: 0.5511076414172517\n",
            "At step: 7778 training error: 0.5541614212078747\n",
            "At step: 7779 training error: 0.5576211437208766\n",
            "At step: 7780 training error: 0.5521583328484321\n",
            "At step: 7781 training error: 0.5546995051064124\n",
            "At step: 7782 training error: 0.5493052843394879\n",
            "At step: 7783 training error: 0.5487018807409657\n",
            "At step: 7784 training error: 0.553879353423282\n",
            "At step: 7785 training error: 0.5472652559734552\n",
            "At step: 7786 training error: 0.5357561695024499\n",
            "At step: 7787 training error: 0.5292084997122324\n",
            "At step: 7788 training error: 0.535015887641905\n",
            "At step: 7789 training error: 0.5441570944943009\n",
            "At step: 7790 training error: 0.5466183174004091\n",
            "At step: 7791 training error: 0.5473808341572433\n",
            "At step: 7792 training error: 0.5518994749905096\n",
            "At step: 7793 training error: 0.5450292785587678\n",
            "At step: 7794 training error: 0.5487086524842255\n",
            "At step: 7795 training error: 0.5420825135228511\n",
            "At step: 7796 training error: 0.5475147945981366\n",
            "At step: 7797 training error: 0.5511931766916575\n",
            "At step: 7798 training error: 0.5511791981076439\n",
            "At step: 7799 training error: 0.5495005664041415\n",
            "At step: 7800 training error: 0.5458797477469125\n",
            "At step: 7801 training error: 0.5479715222150277\n",
            "At step: 7802 training error: 0.5479133961359897\n",
            "At step: 7803 training error: 0.5465081183839512\n",
            "At step: 7804 training error: 0.5458939325383785\n",
            "At step: 7805 training error: 0.5483815587154782\n",
            "At step: 7806 training error: 0.5514409239660133\n",
            "At step: 7807 training error: 0.5479595846153992\n",
            "At step: 7808 training error: 0.5540064481165468\n",
            "At step: 7809 training error: 0.5530581119540392\n",
            "At step: 7810 training error: 0.561204514131992\n",
            "At step: 7811 training error: 0.5781100579431957\n",
            "At step: 7812 training error: 0.5672811139263135\n",
            "At step: 7813 training error: 0.5730012886570812\n",
            "At step: 7814 training error: 0.569538887192894\n",
            "At step: 7815 training error: 0.5724634996073155\n",
            "At step: 7816 training error: 0.5667045320170329\n",
            "At step: 7817 training error: 0.5692924510053988\n",
            "At step: 7818 training error: 0.5634284792808025\n",
            "At step: 7819 training error: 0.5709187148150461\n",
            "At step: 7820 training error: 0.5798175748264126\n",
            "At step: 7821 training error: 0.5791495787864425\n",
            "At step: 7822 training error: 0.5715629665099319\n",
            "At step: 7823 training error: 0.5687332724902255\n",
            "At step: 7824 training error: 0.5666487481440108\n",
            "At step: 7825 training error: 0.5681279972586094\n",
            "At step: 7826 training error: 0.5617307812931038\n",
            "At step: 7827 training error: 0.5655871695877405\n",
            "At step: 7828 training error: 0.5674896291847721\n",
            "At step: 7829 training error: 0.5558279336611558\n",
            "At step: 7830 training error: 0.5463965408505715\n",
            "At step: 7831 training error: 0.5554825687978101\n",
            "At step: 7832 training error: 0.5555165144811731\n",
            "At step: 7833 training error: 0.5620800211912826\n",
            "At step: 7834 training error: 0.5605171937267746\n",
            "At step: 7835 training error: 0.5587381933842466\n",
            "At step: 7836 training error: 0.5543194357052789\n",
            "At step: 7837 training error: 0.5572147971551024\n",
            "At step: 7838 training error: 0.5660387073227475\n",
            "At step: 7839 training error: 0.5590707992762125\n",
            "At step: 7840 training error: 0.5596456287767178\n",
            "At step: 7841 training error: 0.5578867772703344\n",
            "At step: 7842 training error: 0.55277891754635\n",
            "At step: 7843 training error: 0.5492012843231064\n",
            "At step: 7844 training error: 0.5463015809622151\n",
            "At step: 7845 training error: 0.5398830505561293\n",
            "At step: 7846 training error: 0.5509737556677046\n",
            "At step: 7847 training error: 0.5522284833134927\n",
            "At step: 7848 training error: 0.5493251245483026\n",
            "At step: 7849 training error: 0.5392786531499686\n",
            "At step: 7850 training error: 0.5382357387507208\n",
            "At step: 7851 training error: 0.5504723733787934\n",
            "At step: 7852 training error: 0.557691551657637\n",
            "At step: 7853 training error: 0.5582928617954489\n",
            "At step: 7854 training error: 0.5632801890597777\n",
            "At step: 7855 training error: 0.5651644261139254\n",
            "At step: 7856 training error: 0.5558389392176794\n",
            "At step: 7857 training error: 0.5583655855724278\n",
            "At step: 7858 training error: 0.5460491099399843\n",
            "At step: 7859 training error: 0.5376983080431184\n",
            "At step: 7860 training error: 0.5352699943897634\n",
            "At step: 7861 training error: 0.5344474530588552\n",
            "At step: 7862 training error: 0.5396317054915125\n",
            "At step: 7863 training error: 0.5427497306903571\n",
            "At step: 7864 training error: 0.5349186678941458\n",
            "At step: 7865 training error: 0.5307524795415631\n",
            "At step: 7866 training error: 0.5309920074652211\n",
            "At step: 7867 training error: 0.526353623488043\n",
            "At step: 7868 training error: 0.5275008185002859\n",
            "At step: 7869 training error: 0.5191400521278189\n",
            "At step: 7870 training error: 0.5192090588996847\n",
            "At step: 7871 training error: 0.525052949500535\n",
            "At step: 7872 training error: 0.5316195871117075\n",
            "At step: 7873 training error: 0.5304949716598144\n",
            "At step: 7874 training error: 0.5283651396089535\n",
            "At step: 7875 training error: 0.5309268456535549\n",
            "At step: 7876 training error: 0.541286725134734\n",
            "At step: 7877 training error: 0.5442485513646198\n",
            "At step: 7878 training error: 0.5308414336318279\n",
            "At step: 7879 training error: 0.541191636445796\n",
            "At step: 7880 training error: 0.5557739886611474\n",
            "At step: 7881 training error: 0.5541202866090583\n",
            "At step: 7882 training error: 0.555668047850518\n",
            "At step: 7883 training error: 0.5666494978447738\n",
            "At step: 7884 training error: 0.5578814141850732\n",
            "At step: 7885 training error: 0.5397934692402427\n",
            "At step: 7886 training error: 0.5363405236525733\n",
            "At step: 7887 training error: 0.5346184653201709\n",
            "At step: 7888 training error: 0.5337139471106679\n",
            "At step: 7889 training error: 0.5339786365063108\n",
            "At step: 7890 training error: 0.5367620095206626\n",
            "At step: 7891 training error: 0.5393235243228487\n",
            "At step: 7892 training error: 0.5280867662262579\n",
            "At step: 7893 training error: 0.527566410915972\n",
            "At step: 7894 training error: 0.531951206597652\n",
            "At step: 7895 training error: 0.5307665578911656\n",
            "At step: 7896 training error: 0.5410184528369703\n",
            "At step: 7897 training error: 0.5535756310304002\n",
            "At step: 7898 training error: 0.5605245931245787\n",
            "At step: 7899 training error: 0.5495928663405791\n",
            "At step: 7900 training error: 0.546296867411395\n",
            "At step: 7901 training error: 0.547749722765244\n",
            "At step: 7902 training error: 0.5507555837728757\n",
            "At step: 7903 training error: 0.552845808686358\n",
            "At step: 7904 training error: 0.5430387509466872\n",
            "At step: 7905 training error: 0.5385642594512718\n",
            "At step: 7906 training error: 0.5451395574851475\n",
            "At step: 7907 training error: 0.5533706190191252\n",
            "At step: 7908 training error: 0.5552228482197279\n",
            "At step: 7909 training error: 0.5500134121395822\n",
            "At step: 7910 training error: 0.5542730655909257\n",
            "At step: 7911 training error: 0.5544751100995539\n",
            "At step: 7912 training error: 0.5516464526545926\n",
            "At step: 7913 training error: 0.5615479086192638\n",
            "At step: 7914 training error: 0.5531389003356291\n",
            "At step: 7915 training error: 0.5461344532738597\n",
            "At step: 7916 training error: 0.5463250288291028\n",
            "At step: 7917 training error: 0.5480077982828669\n",
            "At step: 7918 training error: 0.5415987369104966\n",
            "At step: 7919 training error: 0.5535012625897092\n",
            "At step: 7920 training error: 0.5549345498720427\n",
            "At step: 7921 training error: 0.5543692770430504\n",
            "At step: 7922 training error: 0.5650757278298905\n",
            "At step: 7923 training error: 0.5697114424216934\n",
            "At step: 7924 training error: 0.5637384396298106\n",
            "At step: 7925 training error: 0.5603157310764514\n",
            "At step: 7926 training error: 0.5618115062340134\n",
            "At step: 7927 training error: 0.5629170981969436\n",
            "At step: 7928 training error: 0.56454338149807\n",
            "At step: 7929 training error: 0.5633530925416258\n",
            "At step: 7930 training error: 0.5654486942634169\n",
            "At step: 7931 training error: 0.5670891423213382\n",
            "At step: 7932 training error: 0.5670039991904479\n",
            "At step: 7933 training error: 0.5588760977299091\n",
            "At step: 7934 training error: 0.55037207617703\n",
            "At step: 7935 training error: 0.5542252054326803\n",
            "At step: 7936 training error: 0.5480709562626409\n",
            "At step: 7937 training error: 0.55750796868526\n",
            "At step: 7938 training error: 0.5622229184946426\n",
            "At step: 7939 training error: 0.5610254896665654\n",
            "At step: 7940 training error: 0.5586077638930775\n",
            "At step: 7941 training error: 0.568952809749234\n",
            "At step: 7942 training error: 0.5685971630443931\n",
            "At step: 7943 training error: 0.5606630918713618\n",
            "At step: 7944 training error: 0.5557394672637249\n",
            "At step: 7945 training error: 0.5549227819300226\n",
            "At step: 7946 training error: 0.5650933845564383\n",
            "At step: 7947 training error: 0.5757580253797773\n",
            "At step: 7948 training error: 0.5774030102989806\n",
            "At step: 7949 training error: 0.5691561260210294\n",
            "At step: 7950 training error: 0.5690759407708933\n",
            "At step: 7951 training error: 0.5786892659294205\n",
            "At step: 7952 training error: 0.5897383357858457\n",
            "At step: 7953 training error: 0.5749816771961999\n",
            "At step: 7954 training error: 0.5694969892681503\n",
            "At step: 7955 training error: 0.5661776082094822\n",
            "At step: 7956 training error: 0.5652868847047599\n",
            "At step: 7957 training error: 0.5684718949351364\n",
            "At step: 7958 training error: 0.5594234336497985\n",
            "At step: 7959 training error: 0.5534362449230811\n",
            "At step: 7960 training error: 0.5524602491002583\n",
            "At step: 7961 training error: 0.5511762575311286\n",
            "At step: 7962 training error: 0.5605793195734782\n",
            "At step: 7963 training error: 0.5662747039635483\n",
            "At step: 7964 training error: 0.5518415296659984\n",
            "At step: 7965 training error: 0.555268075326719\n",
            "At step: 7966 training error: 0.5658479384873281\n",
            "At step: 7967 training error: 0.565866758643089\n",
            "At step: 7968 training error: 0.5519244882292336\n",
            "At step: 7969 training error: 0.5502479308205435\n",
            "At step: 7970 training error: 0.5483501726090059\n",
            "At step: 7971 training error: 0.5493117088110002\n",
            "At step: 7972 training error: 0.5476957535864246\n",
            "At step: 7973 training error: 0.5479317366078277\n",
            "At step: 7974 training error: 0.5443984799860183\n",
            "At step: 7975 training error: 0.5467940461451721\n",
            "At step: 7976 training error: 0.5452630772178241\n",
            "At step: 7977 training error: 0.551888394858663\n",
            "At step: 7978 training error: 0.5711503842501322\n",
            "At step: 7979 training error: 0.5636137910902828\n",
            "At step: 7980 training error: 0.558929008114421\n",
            "At step: 7981 training error: 0.5572048343404407\n",
            "At step: 7982 training error: 0.5570193534378403\n",
            "At step: 7983 training error: 0.5505125036712495\n",
            "At step: 7984 training error: 0.552878293153384\n",
            "At step: 7985 training error: 0.5509352133936208\n",
            "At step: 7986 training error: 0.5635899821721008\n",
            "At step: 7987 training error: 0.5640637940114297\n",
            "At step: 7988 training error: 0.5548476049528783\n",
            "At step: 7989 training error: 0.5525984961900645\n",
            "At step: 7990 training error: 0.5492571040871345\n",
            "At step: 7991 training error: 0.5573292380187826\n",
            "At step: 7992 training error: 0.5551535790369214\n",
            "At step: 7993 training error: 0.5590565783150008\n",
            "At step: 7994 training error: 0.5610910770625771\n",
            "At step: 7995 training error: 0.5665571100421798\n",
            "At step: 7996 training error: 0.5763631603947593\n",
            "At step: 7997 training error: 0.5649500323865256\n",
            "At step: 7998 training error: 0.5719179581882876\n",
            "At step: 7999 training error: 0.5624016148568799\n",
            "At step: 8000 training error: 0.5569652801643625\n",
            "At step: 8001 training error: 0.5605852433021201\n",
            "At step: 8002 training error: 0.5562067648719846\n",
            "At step: 8003 training error: 0.5588566764768492\n",
            "At step: 8004 training error: 0.5567305341625559\n",
            "At step: 8005 training error: 0.5576849435418836\n",
            "At step: 8006 training error: 0.5500719758329217\n",
            "At step: 8007 training error: 0.5495218569812235\n",
            "At step: 8008 training error: 0.5539030060540866\n",
            "At step: 8009 training error: 0.5623663616139\n",
            "At step: 8010 training error: 0.5617886340124933\n",
            "At step: 8011 training error: 0.5697120530486837\n",
            "At step: 8012 training error: 0.571120288796764\n",
            "At step: 8013 training error: 0.5711173741727538\n",
            "At step: 8014 training error: 0.5644259939096672\n",
            "At step: 8015 training error: 0.5632731339136848\n",
            "At step: 8016 training error: 0.5693205801821639\n",
            "At step: 8017 training error: 0.5706149817692427\n",
            "At step: 8018 training error: 0.5644539849839433\n",
            "At step: 8019 training error: 0.5623283025531348\n",
            "At step: 8020 training error: 0.5715750627656156\n",
            "At step: 8021 training error: 0.5752679162211509\n",
            "At step: 8022 training error: 0.5758236173518395\n",
            "At step: 8023 training error: 0.5795906321154547\n",
            "At step: 8024 training error: 0.5666527363470297\n",
            "At step: 8025 training error: 0.5704946274939151\n",
            "At step: 8026 training error: 0.5791424080948571\n",
            "At step: 8027 training error: 0.5818937407280792\n",
            "At step: 8028 training error: 0.5904083524330211\n",
            "At step: 8029 training error: 0.5779327801879413\n",
            "At step: 8030 training error: 0.569363539319207\n",
            "At step: 8031 training error: 0.5771454031108533\n",
            "At step: 8032 training error: 0.5655447173751206\n",
            "At step: 8033 training error: 0.5551863935292309\n",
            "At step: 8034 training error: 0.5490811689261755\n",
            "At step: 8035 training error: 0.5374628222206124\n",
            "At step: 8036 training error: 0.5473977396560505\n",
            "At step: 8037 training error: 0.5509808356983298\n",
            "At step: 8038 training error: 0.5483970852448158\n",
            "At step: 8039 training error: 0.5498004156779777\n",
            "At step: 8040 training error: 0.5577578696653659\n",
            "At step: 8041 training error: 0.5698207629843172\n",
            "At step: 8042 training error: 0.5653152134467428\n",
            "At step: 8043 training error: 0.5624397658303055\n",
            "At step: 8044 training error: 0.5712026319403899\n",
            "At step: 8045 training error: 0.5603987579317168\n",
            "At step: 8046 training error: 0.5619096156818365\n",
            "At step: 8047 training error: 0.5578621254311796\n",
            "At step: 8048 training error: 0.5464156347066322\n",
            "At step: 8049 training error: 0.5446138395208431\n",
            "At step: 8050 training error: 0.5377781755400892\n",
            "At step: 8051 training error: 0.5346311831203558\n",
            "At step: 8052 training error: 0.5427717479846835\n",
            "At step: 8053 training error: 0.5484104414300606\n",
            "At step: 8054 training error: 0.553056910494313\n",
            "At step: 8055 training error: 0.5363645890973994\n",
            "At step: 8056 training error: 0.5356886920217574\n",
            "At step: 8057 training error: 0.539470800123381\n",
            "At step: 8058 training error: 0.5418634899452656\n",
            "At step: 8059 training error: 0.5466548472049243\n",
            "At step: 8060 training error: 0.5432647717744618\n",
            "At step: 8061 training error: 0.5429129463795175\n",
            "At step: 8062 training error: 0.5434496885524022\n",
            "At step: 8063 training error: 0.5459439594777358\n",
            "At step: 8064 training error: 0.5452720277443752\n",
            "At step: 8065 training error: 0.5454896248520613\n",
            "At step: 8066 training error: 0.5313493162937045\n",
            "At step: 8067 training error: 0.5432446710133257\n",
            "At step: 8068 training error: 0.5479371814493493\n",
            "At step: 8069 training error: 0.5547598152614213\n",
            "At step: 8070 training error: 0.555384328547853\n",
            "At step: 8071 training error: 0.5576380955226631\n",
            "At step: 8072 training error: 0.5586469975966235\n",
            "At step: 8073 training error: 0.5579802975673601\n",
            "At step: 8074 training error: 0.5669093434079677\n",
            "At step: 8075 training error: 0.5596549789159403\n",
            "At step: 8076 training error: 0.5525095260626389\n",
            "At step: 8077 training error: 0.5622417341115216\n",
            "At step: 8078 training error: 0.5622705507920951\n",
            "At step: 8079 training error: 0.5658851220770292\n",
            "At step: 8080 training error: 0.5684050427840232\n",
            "At step: 8081 training error: 0.5769909198558678\n",
            "At step: 8082 training error: 0.584772332738421\n",
            "At step: 8083 training error: 0.5869117350199006\n",
            "At step: 8084 training error: 0.5785062862451215\n",
            "At step: 8085 training error: 0.5777571931206769\n",
            "At step: 8086 training error: 0.5573649488861427\n",
            "At step: 8087 training error: 0.5579949150607338\n",
            "At step: 8088 training error: 0.5458532758476908\n",
            "At step: 8089 training error: 0.5441666835922817\n",
            "At step: 8090 training error: 0.5404897377426768\n",
            "At step: 8091 training error: 0.5381428121249874\n",
            "At step: 8092 training error: 0.532341054141235\n",
            "At step: 8093 training error: 0.5293480059780854\n",
            "At step: 8094 training error: 0.5426276292267039\n",
            "At step: 8095 training error: 0.5394797734403358\n",
            "At step: 8096 training error: 0.5543434262864407\n",
            "At step: 8097 training error: 0.5499465606587737\n",
            "At step: 8098 training error: 0.5458553675200102\n",
            "At step: 8099 training error: 0.5491074027717483\n",
            "At step: 8100 training error: 0.5485629399632286\n",
            "At step: 8101 training error: 0.5545550365779685\n",
            "At step: 8102 training error: 0.5548204348201513\n",
            "At step: 8103 training error: 0.5546801966432189\n",
            "At step: 8104 training error: 0.5498948172575467\n",
            "At step: 8105 training error: 0.5424589763046485\n",
            "At step: 8106 training error: 0.5487227008555002\n",
            "At step: 8107 training error: 0.5434204712919952\n",
            "At step: 8108 training error: 0.5481283967920425\n",
            "At step: 8109 training error: 0.5562963121475368\n",
            "At step: 8110 training error: 0.5585837356133516\n",
            "At step: 8111 training error: 0.5527658516813797\n",
            "At step: 8112 training error: 0.5522150101667418\n",
            "At step: 8113 training error: 0.5531271370749142\n",
            "At step: 8114 training error: 0.5539229654744019\n",
            "At step: 8115 training error: 0.5516085723309844\n",
            "At step: 8116 training error: 0.5549087538476141\n",
            "At step: 8117 training error: 0.5426766915292167\n",
            "At step: 8118 training error: 0.5365576628622675\n",
            "At step: 8119 training error: 0.5358778930357536\n",
            "At step: 8120 training error: 0.5308023725593032\n",
            "At step: 8121 training error: 0.5359546603853432\n",
            "At step: 8122 training error: 0.5372476440474301\n",
            "At step: 8123 training error: 0.5331954331955622\n",
            "At step: 8124 training error: 0.5311707627042958\n",
            "At step: 8125 training error: 0.5282702314908072\n",
            "At step: 8126 training error: 0.5237030060044461\n",
            "At step: 8127 training error: 0.5249006272996503\n",
            "At step: 8128 training error: 0.5209090227928621\n",
            "At step: 8129 training error: 0.5337198618997713\n",
            "At step: 8130 training error: 0.5384071565651168\n",
            "At step: 8131 training error: 0.547194214899851\n",
            "At step: 8132 training error: 0.5460731257588751\n",
            "At step: 8133 training error: 0.5420332724555504\n",
            "At step: 8134 training error: 0.5434786796536285\n",
            "At step: 8135 training error: 0.5443068502204591\n",
            "At step: 8136 training error: 0.5332744991326659\n",
            "At step: 8137 training error: 0.522488778925034\n",
            "At step: 8138 training error: 0.5216306598461207\n",
            "At step: 8139 training error: 0.5162280678386091\n",
            "At step: 8140 training error: 0.5235321528464358\n",
            "At step: 8141 training error: 0.5234078105384261\n",
            "At step: 8142 training error: 0.530122015632602\n",
            "At step: 8143 training error: 0.5413755658404903\n",
            "At step: 8144 training error: 0.5411609922787456\n",
            "At step: 8145 training error: 0.5315615644533405\n",
            "At step: 8146 training error: 0.5273739718486885\n",
            "At step: 8147 training error: 0.5265631959780486\n",
            "At step: 8148 training error: 0.5294669048394068\n",
            "At step: 8149 training error: 0.5336478431534434\n",
            "At step: 8150 training error: 0.5390083298417946\n",
            "At step: 8151 training error: 0.5374986108239521\n",
            "At step: 8152 training error: 0.5378987858704618\n",
            "At step: 8153 training error: 0.5333693364656233\n",
            "At step: 8154 training error: 0.5319025690549587\n",
            "At step: 8155 training error: 0.529152946755846\n",
            "At step: 8156 training error: 0.5315835563913641\n",
            "At step: 8157 training error: 0.5368668751880359\n",
            "At step: 8158 training error: 0.5508986595132391\n",
            "At step: 8159 training error: 0.5495391238248846\n",
            "At step: 8160 training error: 0.5449476037830367\n",
            "At step: 8161 training error: 0.556387656334569\n",
            "At step: 8162 training error: 0.5604464124164987\n",
            "At step: 8163 training error: 0.5548314308129247\n",
            "At step: 8164 training error: 0.549477422594135\n",
            "At step: 8165 training error: 0.5593556260220403\n",
            "At step: 8166 training error: 0.5600047071881025\n",
            "At step: 8167 training error: 0.566759742776616\n",
            "At step: 8168 training error: 0.5629074596007061\n",
            "At step: 8169 training error: 0.5600292178252142\n",
            "At step: 8170 training error: 0.5489732240249798\n",
            "At step: 8171 training error: 0.5518865449783793\n",
            "At step: 8172 training error: 0.5470508738092288\n",
            "At step: 8173 training error: 0.5467383730895257\n",
            "At step: 8174 training error: 0.5483600782531046\n",
            "At step: 8175 training error: 0.5481441583102501\n",
            "At step: 8176 training error: 0.5551284603771636\n",
            "At step: 8177 training error: 0.5524861167099999\n",
            "At step: 8178 training error: 0.5550650360518227\n",
            "At step: 8179 training error: 0.5575430537692094\n",
            "At step: 8180 training error: 0.5646497246685502\n",
            "At step: 8181 training error: 0.5656792692335476\n",
            "At step: 8182 training error: 0.5664382700334023\n",
            "At step: 8183 training error: 0.5787794531609726\n",
            "At step: 8184 training error: 0.5839498240963219\n",
            "At step: 8185 training error: 0.580599589061982\n",
            "At step: 8186 training error: 0.5832172244857969\n",
            "At step: 8187 training error: 0.5920962946067564\n",
            "At step: 8188 training error: 0.5731117658245116\n",
            "At step: 8189 training error: 0.5853633861954534\n",
            "At step: 8190 training error: 0.584844828083505\n",
            "At step: 8191 training error: 0.5788978737044074\n",
            "At step: 8192 training error: 0.5765433485648368\n",
            "At step: 8193 training error: 0.585739836775447\n",
            "At step: 8194 training error: 0.5715958854191144\n",
            "At step: 8195 training error: 0.5670733345694907\n",
            "At step: 8196 training error: 0.5667730502132822\n",
            "At step: 8197 training error: 0.5681901662427379\n",
            "At step: 8198 training error: 0.5683782559562319\n",
            "At step: 8199 training error: 0.5632967994819826\n",
            "At step: 8200 training error: 0.5512364766356128\n",
            "At step: 8201 training error: 0.5483205368363194\n",
            "At step: 8202 training error: 0.5532319608145649\n",
            "At step: 8203 training error: 0.5593246794331619\n",
            "At step: 8204 training error: 0.5647971679766594\n",
            "At step: 8205 training error: 0.5682849740896171\n",
            "At step: 8206 training error: 0.5699156650158606\n",
            "At step: 8207 training error: 0.5811167274910362\n",
            "At step: 8208 training error: 0.5698978196023121\n",
            "At step: 8209 training error: 0.5580701750075616\n",
            "At step: 8210 training error: 0.5580156429697304\n",
            "At step: 8211 training error: 0.5497360202588926\n",
            "At step: 8212 training error: 0.5552429503992252\n",
            "At step: 8213 training error: 0.5505660819788565\n",
            "At step: 8214 training error: 0.5514570877209455\n",
            "At step: 8215 training error: 0.5459789590906037\n",
            "At step: 8216 training error: 0.5533828498694999\n",
            "At step: 8217 training error: 0.5615869805537709\n",
            "At step: 8218 training error: 0.5661887648374477\n",
            "At step: 8219 training error: 0.5634057471809784\n",
            "At step: 8220 training error: 0.5594243892210333\n",
            "At step: 8221 training error: 0.5660330936716763\n",
            "At step: 8222 training error: 0.571002195472679\n",
            "At step: 8223 training error: 0.5632902482847284\n",
            "At step: 8224 training error: 0.5635273279267378\n",
            "At step: 8225 training error: 0.5563094437294923\n",
            "At step: 8226 training error: 0.5596246820327859\n",
            "At step: 8227 training error: 0.5557086740108929\n",
            "At step: 8228 training error: 0.5589173500448952\n",
            "At step: 8229 training error: 0.5666942274962833\n",
            "At step: 8230 training error: 0.5679850121506009\n",
            "At step: 8231 training error: 0.5798746360092719\n",
            "At step: 8232 training error: 0.5795507873178055\n",
            "At step: 8233 training error: 0.5827168221959752\n",
            "At step: 8234 training error: 0.5743016731000264\n",
            "At step: 8235 training error: 0.5641834505778709\n",
            "At step: 8236 training error: 0.5520263533814306\n",
            "At step: 8237 training error: 0.5548176735768896\n",
            "At step: 8238 training error: 0.5532246013372913\n",
            "At step: 8239 training error: 0.5437291026026817\n",
            "At step: 8240 training error: 0.543701166300272\n",
            "At step: 8241 training error: 0.5406496869879976\n",
            "At step: 8242 training error: 0.550886247504343\n",
            "At step: 8243 training error: 0.5547831722542802\n",
            "At step: 8244 training error: 0.558942730336027\n",
            "At step: 8245 training error: 0.5525204849338266\n",
            "At step: 8246 training error: 0.5521548826062675\n",
            "At step: 8247 training error: 0.5418131823933219\n",
            "At step: 8248 training error: 0.5398788921612772\n",
            "At step: 8249 training error: 0.5479132120301726\n",
            "At step: 8250 training error: 0.5484342364512369\n",
            "At step: 8251 training error: 0.5502578619139947\n",
            "At step: 8252 training error: 0.5476370771596905\n",
            "At step: 8253 training error: 0.5495185772040274\n",
            "At step: 8254 training error: 0.5418190148184301\n",
            "At step: 8255 training error: 0.5388728640817821\n",
            "At step: 8256 training error: 0.5329045152587373\n",
            "At step: 8257 training error: 0.5391120105879468\n",
            "At step: 8258 training error: 0.531482105942641\n",
            "At step: 8259 training error: 0.5234848136312085\n",
            "At step: 8260 training error: 0.5281977338177773\n",
            "At step: 8261 training error: 0.5383752888554862\n",
            "At step: 8262 training error: 0.546834068236537\n",
            "At step: 8263 training error: 0.5502500572392656\n",
            "At step: 8264 training error: 0.5430055832820472\n",
            "At step: 8265 training error: 0.5473501787092485\n",
            "At step: 8266 training error: 0.5429773169058636\n",
            "At step: 8267 training error: 0.5462297301680196\n",
            "At step: 8268 training error: 0.5428471130877839\n",
            "At step: 8269 training error: 0.5487543427326319\n",
            "At step: 8270 training error: 0.5539556747969573\n",
            "At step: 8271 training error: 0.5499359264443661\n",
            "At step: 8272 training error: 0.5533044566581617\n",
            "At step: 8273 training error: 0.5510289115993514\n",
            "At step: 8274 training error: 0.5428747326872732\n",
            "At step: 8275 training error: 0.545995670870988\n",
            "At step: 8276 training error: 0.5442111501937907\n",
            "At step: 8277 training error: 0.5350254875761519\n",
            "At step: 8278 training error: 0.5252424642742032\n",
            "At step: 8279 training error: 0.5300775516621843\n",
            "At step: 8280 training error: 0.534803985880433\n",
            "At step: 8281 training error: 0.5360004273556083\n",
            "At step: 8282 training error: 0.5325653911274849\n",
            "At step: 8283 training error: 0.5283892439899074\n",
            "At step: 8284 training error: 0.5330726876638531\n",
            "At step: 8285 training error: 0.5423286691580862\n",
            "At step: 8286 training error: 0.546809415683708\n",
            "At step: 8287 training error: 0.5500820911529084\n",
            "At step: 8288 training error: 0.5588417106129048\n",
            "At step: 8289 training error: 0.5486193413360664\n",
            "At step: 8290 training error: 0.5521496059729292\n",
            "At step: 8291 training error: 0.5440253469048435\n",
            "At step: 8292 training error: 0.5462335258410944\n",
            "At step: 8293 training error: 0.5519908025102236\n",
            "At step: 8294 training error: 0.5597642977967753\n",
            "At step: 8295 training error: 0.5513335566015487\n",
            "At step: 8296 training error: 0.5462902701327949\n",
            "At step: 8297 training error: 0.5503603126926927\n",
            "At step: 8298 training error: 0.5508797123429306\n",
            "At step: 8299 training error: 0.5555673459492677\n",
            "At step: 8300 training error: 0.5524205881018882\n",
            "At step: 8301 training error: 0.5509464777627533\n",
            "At step: 8302 training error: 0.5600956525403553\n",
            "At step: 8303 training error: 0.5601749206243605\n",
            "At step: 8304 training error: 0.551236506405128\n",
            "At step: 8305 training error: 0.5521232567864764\n",
            "At step: 8306 training error: 0.5562789095674651\n",
            "At step: 8307 training error: 0.547928287479241\n",
            "At step: 8308 training error: 0.5502758838534957\n",
            "At step: 8309 training error: 0.5559479072622632\n",
            "At step: 8310 training error: 0.5446014734287443\n",
            "At step: 8311 training error: 0.5456557184332178\n",
            "At step: 8312 training error: 0.5338869963812907\n",
            "At step: 8313 training error: 0.5541732858303005\n",
            "At step: 8314 training error: 0.5424739661143216\n",
            "At step: 8315 training error: 0.5583725791519644\n",
            "At step: 8316 training error: 0.5616735584798975\n",
            "At step: 8317 training error: 0.552621155993494\n",
            "At step: 8318 training error: 0.5439184601396254\n",
            "At step: 8319 training error: 0.5417561935192114\n",
            "At step: 8320 training error: 0.5352888717808449\n",
            "At step: 8321 training error: 0.5359991701067199\n",
            "At step: 8322 training error: 0.534844438913609\n",
            "At step: 8323 training error: 0.5255812859004793\n",
            "At step: 8324 training error: 0.517895530487783\n",
            "At step: 8325 training error: 0.5150448041677995\n",
            "At step: 8326 training error: 0.5203904693551211\n",
            "At step: 8327 training error: 0.524088199055325\n",
            "At step: 8328 training error: 0.5267979624406255\n",
            "At step: 8329 training error: 0.5197428784432438\n",
            "At step: 8330 training error: 0.5245472460199152\n",
            "At step: 8331 training error: 0.528476245009703\n",
            "At step: 8332 training error: 0.5340283793897435\n",
            "At step: 8333 training error: 0.5315458637294859\n",
            "At step: 8334 training error: 0.5260262408573948\n",
            "At step: 8335 training error: 0.541573705413348\n",
            "At step: 8336 training error: 0.5436572292173795\n",
            "At step: 8337 training error: 0.5497802953636148\n",
            "At step: 8338 training error: 0.5487323593882056\n",
            "At step: 8339 training error: 0.5483598287374174\n",
            "At step: 8340 training error: 0.5493211603801501\n",
            "At step: 8341 training error: 0.5392888654307632\n",
            "At step: 8342 training error: 0.5484673646226802\n",
            "At step: 8343 training error: 0.5475818061937514\n",
            "At step: 8344 training error: 0.5568293661054095\n",
            "At step: 8345 training error: 0.5663567337738493\n",
            "At step: 8346 training error: 0.5783321574081398\n",
            "At step: 8347 training error: 0.5784723765585782\n",
            "At step: 8348 training error: 0.5813433820982165\n",
            "At step: 8349 training error: 0.5696168324399173\n",
            "At step: 8350 training error: 0.5765106764556263\n",
            "At step: 8351 training error: 0.575105247817572\n",
            "At step: 8352 training error: 0.5700699993257868\n",
            "At step: 8353 training error: 0.5734457302696755\n",
            "At step: 8354 training error: 0.5598618516097422\n",
            "At step: 8355 training error: 0.56073249723568\n",
            "At step: 8356 training error: 0.5518150820975136\n",
            "At step: 8357 training error: 0.5538252220612133\n",
            "At step: 8358 training error: 0.5579260623211635\n",
            "At step: 8359 training error: 0.555362041590916\n",
            "At step: 8360 training error: 0.5497987843293184\n",
            "At step: 8361 training error: 0.5477050910269481\n",
            "At step: 8362 training error: 0.5503350184052958\n",
            "At step: 8363 training error: 0.5608168634424509\n",
            "At step: 8364 training error: 0.5596925629154452\n",
            "At step: 8365 training error: 0.5544570728691148\n",
            "At step: 8366 training error: 0.5452553648330275\n",
            "At step: 8367 training error: 0.5390513990530205\n",
            "At step: 8368 training error: 0.5346849620529979\n",
            "At step: 8369 training error: 0.5352849324902142\n",
            "At step: 8370 training error: 0.5499601410937784\n",
            "At step: 8371 training error: 0.5346656420971332\n",
            "At step: 8372 training error: 0.5541354097811361\n",
            "At step: 8373 training error: 0.5476477278870651\n",
            "At step: 8374 training error: 0.5584305522709438\n",
            "At step: 8375 training error: 0.5658222131265219\n",
            "At step: 8376 training error: 0.5623938621651036\n",
            "At step: 8377 training error: 0.5635469802540045\n",
            "At step: 8378 training error: 0.5604367674135174\n",
            "At step: 8379 training error: 0.5476121212618967\n",
            "At step: 8380 training error: 0.5515901250728845\n",
            "At step: 8381 training error: 0.5617063206039771\n",
            "At step: 8382 training error: 0.551610847075357\n",
            "At step: 8383 training error: 0.5439668976621991\n",
            "At step: 8384 training error: 0.5434178785849019\n",
            "At step: 8385 training error: 0.543231244680153\n",
            "At step: 8386 training error: 0.5430194996462275\n",
            "At step: 8387 training error: 0.5549317607952916\n",
            "At step: 8388 training error: 0.5611879231956602\n",
            "At step: 8389 training error: 0.5564620145436733\n",
            "At step: 8390 training error: 0.5569670603550008\n",
            "At step: 8391 training error: 0.5583300358658192\n",
            "At step: 8392 training error: 0.5544675847772863\n",
            "At step: 8393 training error: 0.551776467284395\n",
            "At step: 8394 training error: 0.5561130767917506\n",
            "At step: 8395 training error: 0.5610166630193468\n",
            "At step: 8396 training error: 0.5618013388219488\n",
            "At step: 8397 training error: 0.5618481792988205\n",
            "At step: 8398 training error: 0.5645013800657811\n",
            "At step: 8399 training error: 0.559686579514666\n",
            "At step: 8400 training error: 0.5546371438724175\n",
            "At step: 8401 training error: 0.5456615541939516\n",
            "At step: 8402 training error: 0.5394079059851564\n",
            "At step: 8403 training error: 0.535177835925655\n",
            "At step: 8404 training error: 0.5336240584238651\n",
            "At step: 8405 training error: 0.5341541759258527\n",
            "At step: 8406 training error: 0.5280048670695084\n",
            "At step: 8407 training error: 0.5201285539332677\n",
            "At step: 8408 training error: 0.5214349348175884\n",
            "At step: 8409 training error: 0.5307119242991197\n",
            "At step: 8410 training error: 0.5247581964255509\n",
            "At step: 8411 training error: 0.5305764022779874\n",
            "At step: 8412 training error: 0.5168953358235666\n",
            "At step: 8413 training error: 0.512913049695096\n",
            "At step: 8414 training error: 0.5152748425160045\n",
            "At step: 8415 training error: 0.5194927403721626\n",
            "At step: 8416 training error: 0.5239258069606878\n",
            "At step: 8417 training error: 0.5214781660253142\n",
            "At step: 8418 training error: 0.5171610781721088\n",
            "At step: 8419 training error: 0.5190921890143114\n",
            "At step: 8420 training error: 0.5129949270494919\n",
            "At step: 8421 training error: 0.5202740046508686\n",
            "At step: 8422 training error: 0.5277892239290283\n",
            "At step: 8423 training error: 0.5288320072523893\n",
            "At step: 8424 training error: 0.5193084610779239\n",
            "At step: 8425 training error: 0.5193747224219837\n",
            "At step: 8426 training error: 0.5206232024325379\n",
            "At step: 8427 training error: 0.5214190114999867\n",
            "At step: 8428 training error: 0.5323142920854116\n",
            "At step: 8429 training error: 0.5250310209922205\n",
            "At step: 8430 training error: 0.5234758702077522\n",
            "At step: 8431 training error: 0.526699796347019\n",
            "At step: 8432 training error: 0.5310939234349935\n",
            "At step: 8433 training error: 0.523996638998758\n",
            "At step: 8434 training error: 0.528358752351241\n",
            "At step: 8435 training error: 0.5231170202032446\n",
            "At step: 8436 training error: 0.5164783022233403\n",
            "At step: 8437 training error: 0.5096769624093186\n",
            "At step: 8438 training error: 0.5110429610969748\n",
            "At step: 8439 training error: 0.5174398471578001\n",
            "At step: 8440 training error: 0.520814093914339\n",
            "At step: 8441 training error: 0.5241051033989965\n",
            "At step: 8442 training error: 0.5292453307353565\n",
            "At step: 8443 training error: 0.5215450436948013\n",
            "At step: 8444 training error: 0.525371482074771\n",
            "At step: 8445 training error: 0.5408479106836096\n",
            "At step: 8446 training error: 0.539894605784516\n",
            "At step: 8447 training error: 0.5389942961069327\n",
            "At step: 8448 training error: 0.5418070785576845\n",
            "At step: 8449 training error: 0.5332735115044118\n",
            "At step: 8450 training error: 0.5430800773234543\n",
            "At step: 8451 training error: 0.5463174174390583\n",
            "At step: 8452 training error: 0.5403736816383438\n",
            "At step: 8453 training error: 0.5331796205478366\n",
            "At step: 8454 training error: 0.5322838174120322\n",
            "At step: 8455 training error: 0.5243803746852831\n",
            "At step: 8456 training error: 0.5286230239217404\n",
            "At step: 8457 training error: 0.5269738440628151\n",
            "At step: 8458 training error: 0.5303825595650148\n",
            "At step: 8459 training error: 0.5310470072890048\n",
            "At step: 8460 training error: 0.5437591586793242\n",
            "At step: 8461 training error: 0.5487741892015479\n",
            "At step: 8462 training error: 0.5653217276369148\n",
            "At step: 8463 training error: 0.5557565287866817\n",
            "At step: 8464 training error: 0.5531548839300008\n",
            "At step: 8465 training error: 0.5435574098781996\n",
            "At step: 8466 training error: 0.5428466759147733\n",
            "At step: 8467 training error: 0.5357421828200903\n",
            "At step: 8468 training error: 0.5286378244185171\n",
            "At step: 8469 training error: 0.5327242706922718\n",
            "At step: 8470 training error: 0.528145865433743\n",
            "At step: 8471 training error: 0.5166782002390737\n",
            "At step: 8472 training error: 0.5268538669471525\n",
            "At step: 8473 training error: 0.5271904287803795\n",
            "At step: 8474 training error: 0.533135698134148\n",
            "At step: 8475 training error: 0.5337166805600311\n",
            "At step: 8476 training error: 0.5261100438702475\n",
            "At step: 8477 training error: 0.5254688671646914\n",
            "At step: 8478 training error: 0.531049350882578\n",
            "At step: 8479 training error: 0.5318222292873789\n",
            "At step: 8480 training error: 0.534452494936655\n",
            "At step: 8481 training error: 0.5309053270303077\n",
            "At step: 8482 training error: 0.5277609775500559\n",
            "At step: 8483 training error: 0.5185390202265777\n",
            "At step: 8484 training error: 0.5193381497755296\n",
            "At step: 8485 training error: 0.5311012177447811\n",
            "At step: 8486 training error: 0.5299011897371446\n",
            "At step: 8487 training error: 0.5380286340970031\n",
            "At step: 8488 training error: 0.5426036898919088\n",
            "At step: 8489 training error: 0.5442625091898392\n",
            "At step: 8490 training error: 0.544385774923752\n",
            "At step: 8491 training error: 0.5403773653857143\n",
            "At step: 8492 training error: 0.5498227646856229\n",
            "At step: 8493 training error: 0.5418996533520742\n",
            "At step: 8494 training error: 0.5383536080261123\n",
            "At step: 8495 training error: 0.5404690696577189\n",
            "At step: 8496 training error: 0.5408119236243882\n",
            "At step: 8497 training error: 0.5399003400203906\n",
            "At step: 8498 training error: 0.53947843815013\n",
            "At step: 8499 training error: 0.5380895875084217\n",
            "At step: 8500 training error: 0.5429200145184245\n",
            "At step: 8501 training error: 0.5466685383486443\n",
            "At step: 8502 training error: 0.5415870328907563\n",
            "At step: 8503 training error: 0.5496218604145686\n",
            "At step: 8504 training error: 0.5463708216863095\n",
            "At step: 8505 training error: 0.542957189884782\n",
            "At step: 8506 training error: 0.5518825414303568\n",
            "At step: 8507 training error: 0.544261038192213\n",
            "At step: 8508 training error: 0.5410844433136565\n",
            "At step: 8509 training error: 0.5329738229778932\n",
            "At step: 8510 training error: 0.5402855902272605\n",
            "At step: 8511 training error: 0.5403118185011038\n",
            "At step: 8512 training error: 0.5505782805021318\n",
            "At step: 8513 training error: 0.5557328620542802\n",
            "At step: 8514 training error: 0.5601392600781334\n",
            "At step: 8515 training error: 0.5570031566146492\n",
            "At step: 8516 training error: 0.5599800498504817\n",
            "At step: 8517 training error: 0.5569363692095335\n",
            "At step: 8518 training error: 0.5495629684743514\n",
            "At step: 8519 training error: 0.5493111090536685\n",
            "At step: 8520 training error: 0.5359838960627787\n",
            "At step: 8521 training error: 0.5317203753954932\n",
            "At step: 8522 training error: 0.5268797505909913\n",
            "At step: 8523 training error: 0.5360845592164395\n",
            "At step: 8524 training error: 0.5271853299418344\n",
            "At step: 8525 training error: 0.5273413662257698\n",
            "At step: 8526 training error: 0.5249690905022624\n",
            "At step: 8527 training error: 0.5253162209075111\n",
            "At step: 8528 training error: 0.531179271722505\n",
            "At step: 8529 training error: 0.5378850132743052\n",
            "At step: 8530 training error: 0.5318965053819013\n",
            "At step: 8531 training error: 0.5367298917219644\n",
            "At step: 8532 training error: 0.5336698886353328\n",
            "At step: 8533 training error: 0.5394375401758973\n",
            "At step: 8534 training error: 0.5400395142847858\n",
            "At step: 8535 training error: 0.5468327468314256\n",
            "At step: 8536 training error: 0.5500163831627576\n",
            "At step: 8537 training error: 0.5569927788758914\n",
            "At step: 8538 training error: 0.5505437825150604\n",
            "At step: 8539 training error: 0.5431867698699787\n",
            "At step: 8540 training error: 0.5462698922172852\n",
            "At step: 8541 training error: 0.5437898424722384\n",
            "At step: 8542 training error: 0.5561152157623707\n",
            "At step: 8543 training error: 0.5466569857291064\n",
            "At step: 8544 training error: 0.5526614110049655\n",
            "At step: 8545 training error: 0.5467211314914078\n",
            "At step: 8546 training error: 0.549103591953699\n",
            "At step: 8547 training error: 0.5590789502119087\n",
            "At step: 8548 training error: 0.5512454208011587\n",
            "At step: 8549 training error: 0.5431160987353225\n",
            "At step: 8550 training error: 0.5384846903788258\n",
            "At step: 8551 training error: 0.5416694413144572\n",
            "At step: 8552 training error: 0.5408261998837953\n",
            "At step: 8553 training error: 0.5551659925558348\n",
            "At step: 8554 training error: 0.5527863644165212\n",
            "At step: 8555 training error: 0.5489560968037792\n",
            "At step: 8556 training error: 0.5379368600100708\n",
            "At step: 8557 training error: 0.5318951240456291\n",
            "At step: 8558 training error: 0.531317186962058\n",
            "At step: 8559 training error: 0.525187064638736\n",
            "At step: 8560 training error: 0.5222308371807391\n",
            "At step: 8561 training error: 0.5228263594256021\n",
            "At step: 8562 training error: 0.5320779830418552\n",
            "At step: 8563 training error: 0.5406037594483968\n",
            "At step: 8564 training error: 0.5353305854329324\n",
            "At step: 8565 training error: 0.5284529190168135\n",
            "At step: 8566 training error: 0.5328101990632851\n",
            "At step: 8567 training error: 0.5382689329467032\n",
            "At step: 8568 training error: 0.5453504530392741\n",
            "At step: 8569 training error: 0.5503658721977872\n",
            "At step: 8570 training error: 0.5358554844419936\n",
            "At step: 8571 training error: 0.522056299422158\n",
            "At step: 8572 training error: 0.5196390523327005\n",
            "At step: 8573 training error: 0.5163220020149809\n",
            "At step: 8574 training error: 0.5213592567307224\n",
            "At step: 8575 training error: 0.5204638576438658\n",
            "At step: 8576 training error: 0.5311840116124713\n",
            "At step: 8577 training error: 0.5352099502035865\n",
            "At step: 8578 training error: 0.537710608599741\n",
            "At step: 8579 training error: 0.5405417094799411\n",
            "At step: 8580 training error: 0.5376358116152209\n",
            "At step: 8581 training error: 0.5357445266280628\n",
            "At step: 8582 training error: 0.5369872671055135\n",
            "At step: 8583 training error: 0.5458133738919133\n",
            "At step: 8584 training error: 0.5280962010779179\n",
            "At step: 8585 training error: 0.5308399173340125\n",
            "At step: 8586 training error: 0.5249589650330416\n",
            "At step: 8587 training error: 0.5315099953133791\n",
            "At step: 8588 training error: 0.5281628729951755\n",
            "At step: 8589 training error: 0.5322045013829334\n",
            "At step: 8590 training error: 0.5274788580047747\n",
            "At step: 8591 training error: 0.5356556676809946\n",
            "At step: 8592 training error: 0.541094857870198\n",
            "At step: 8593 training error: 0.5478914663405943\n",
            "At step: 8594 training error: 0.5388525321080228\n",
            "At step: 8595 training error: 0.5384496541644017\n",
            "At step: 8596 training error: 0.5363130966247162\n",
            "At step: 8597 training error: 0.5378501923028727\n",
            "At step: 8598 training error: 0.5408664313812136\n",
            "At step: 8599 training error: 0.54002151980745\n",
            "At step: 8600 training error: 0.5375098861551973\n",
            "At step: 8601 training error: 0.5472881210088968\n",
            "At step: 8602 training error: 0.5423199372194871\n",
            "At step: 8603 training error: 0.5535344109102371\n",
            "At step: 8604 training error: 0.5518287158547773\n",
            "At step: 8605 training error: 0.5527587488645359\n",
            "At step: 8606 training error: 0.5505305828311552\n",
            "At step: 8607 training error: 0.5560015923128399\n",
            "At step: 8608 training error: 0.5551792694549965\n",
            "At step: 8609 training error: 0.5500829177655755\n",
            "At step: 8610 training error: 0.5441557748023721\n",
            "At step: 8611 training error: 0.5314982179079103\n",
            "At step: 8612 training error: 0.5347346612423868\n",
            "At step: 8613 training error: 0.5298819239152852\n",
            "At step: 8614 training error: 0.5334581497375476\n",
            "At step: 8615 training error: 0.5254347037491507\n",
            "At step: 8616 training error: 0.5282801690307559\n",
            "At step: 8617 training error: 0.5227423545852121\n",
            "At step: 8618 training error: 0.5240514444286135\n",
            "At step: 8619 training error: 0.5367970516428843\n",
            "At step: 8620 training error: 0.5406854900417666\n",
            "At step: 8621 training error: 0.5441018637153077\n",
            "At step: 8622 training error: 0.5407951939502827\n",
            "At step: 8623 training error: 0.549044600514598\n",
            "At step: 8624 training error: 0.550373171680969\n",
            "At step: 8625 training error: 0.5479491278630825\n",
            "At step: 8626 training error: 0.5450956491049563\n",
            "At step: 8627 training error: 0.5381057183934111\n",
            "At step: 8628 training error: 0.5388328103413446\n",
            "At step: 8629 training error: 0.5309741585076083\n",
            "At step: 8630 training error: 0.5226128095427511\n",
            "At step: 8631 training error: 0.5294854533212632\n",
            "At step: 8632 training error: 0.5418703629185447\n",
            "At step: 8633 training error: 0.543966438578042\n",
            "At step: 8634 training error: 0.5422884524016713\n",
            "At step: 8635 training error: 0.539105129867443\n",
            "At step: 8636 training error: 0.5416519821272713\n",
            "At step: 8637 training error: 0.5321683621595092\n",
            "At step: 8638 training error: 0.5361908957659719\n",
            "At step: 8639 training error: 0.5429892076565421\n",
            "At step: 8640 training error: 0.5414975642236476\n",
            "At step: 8641 training error: 0.5465820457492845\n",
            "At step: 8642 training error: 0.5373493699904159\n",
            "At step: 8643 training error: 0.5352951593515461\n",
            "At step: 8644 training error: 0.5411278943996982\n",
            "At step: 8645 training error: 0.5435647156302634\n",
            "At step: 8646 training error: 0.5473895946498792\n",
            "At step: 8647 training error: 0.5581744022946148\n",
            "At step: 8648 training error: 0.5578573878834245\n",
            "At step: 8649 training error: 0.552044717368038\n",
            "At step: 8650 training error: 0.5436138751528561\n",
            "At step: 8651 training error: 0.5441788076665124\n",
            "At step: 8652 training error: 0.5436484188496138\n",
            "At step: 8653 training error: 0.5482009234561107\n",
            "At step: 8654 training error: 0.5417969677245237\n",
            "At step: 8655 training error: 0.5300283775587586\n",
            "At step: 8656 training error: 0.5247741126071132\n",
            "At step: 8657 training error: 0.5187540303187606\n",
            "At step: 8658 training error: 0.5169542507142618\n",
            "At step: 8659 training error: 0.5127170619259581\n",
            "At step: 8660 training error: 0.5185379024473993\n",
            "At step: 8661 training error: 0.5321254791744063\n",
            "At step: 8662 training error: 0.5262093855531693\n",
            "At step: 8663 training error: 0.526264700792252\n",
            "At step: 8664 training error: 0.5212913992461983\n",
            "At step: 8665 training error: 0.51430015588374\n",
            "At step: 8666 training error: 0.5185089565867987\n",
            "At step: 8667 training error: 0.5278005336354875\n",
            "At step: 8668 training error: 0.5254069190934079\n",
            "At step: 8669 training error: 0.5201149451608569\n",
            "At step: 8670 training error: 0.5178795584640324\n",
            "At step: 8671 training error: 0.5212652644910791\n",
            "At step: 8672 training error: 0.5222498509352183\n",
            "At step: 8673 training error: 0.5225247263825662\n",
            "At step: 8674 training error: 0.5204317798936332\n",
            "At step: 8675 training error: 0.5244679575731218\n",
            "At step: 8676 training error: 0.5250079535553076\n",
            "At step: 8677 training error: 0.526202623722423\n",
            "At step: 8678 training error: 0.5154824046050182\n",
            "At step: 8679 training error: 0.512806963259563\n",
            "At step: 8680 training error: 0.5186415280700456\n",
            "At step: 8681 training error: 0.5210129384715494\n",
            "At step: 8682 training error: 0.5184842760445498\n",
            "At step: 8683 training error: 0.5156693876807544\n",
            "At step: 8684 training error: 0.5019962819312074\n",
            "At step: 8685 training error: 0.49934997098553496\n",
            "At step: 8686 training error: 0.49739888029847623\n",
            "At step: 8687 training error: 0.5027073897251876\n",
            "At step: 8688 training error: 0.5060559492341429\n",
            "At step: 8689 training error: 0.5183472211730487\n",
            "At step: 8690 training error: 0.5163234583440076\n",
            "At step: 8691 training error: 0.5087234788786409\n",
            "At step: 8692 training error: 0.5165380424720273\n",
            "At step: 8693 training error: 0.5120528127290888\n",
            "At step: 8694 training error: 0.5127782497080365\n",
            "At step: 8695 training error: 0.5172067368848732\n",
            "At step: 8696 training error: 0.527070031972375\n",
            "At step: 8697 training error: 0.5329689803920803\n",
            "At step: 8698 training error: 0.5326660730514278\n",
            "At step: 8699 training error: 0.5412731575073542\n",
            "At step: 8700 training error: 0.5346263572548139\n",
            "At step: 8701 training error: 0.5289358734629407\n",
            "At step: 8702 training error: 0.5355918514273215\n",
            "At step: 8703 training error: 0.5314866369542645\n",
            "At step: 8704 training error: 0.5202783507925057\n",
            "At step: 8705 training error: 0.5251402948866042\n",
            "At step: 8706 training error: 0.5223988701984008\n",
            "At step: 8707 training error: 0.5284465095910205\n",
            "At step: 8708 training error: 0.5243715624053686\n",
            "At step: 8709 training error: 0.5422043455667194\n",
            "At step: 8710 training error: 0.552915387846063\n",
            "At step: 8711 training error: 0.5462631517265869\n",
            "At step: 8712 training error: 0.548386329054913\n",
            "At step: 8713 training error: 0.5519313180419696\n",
            "At step: 8714 training error: 0.553404568893932\n",
            "At step: 8715 training error: 0.5593284185287777\n",
            "At step: 8716 training error: 0.5553514644894205\n",
            "At step: 8717 training error: 0.5419380255889231\n",
            "At step: 8718 training error: 0.537647240684299\n",
            "At step: 8719 training error: 0.5303329947197266\n",
            "At step: 8720 training error: 0.5307364016281896\n",
            "At step: 8721 training error: 0.5321333149735284\n",
            "At step: 8722 training error: 0.5282364720143127\n",
            "At step: 8723 training error: 0.5166600765497958\n",
            "At step: 8724 training error: 0.5117160863206773\n",
            "At step: 8725 training error: 0.5122191544920588\n",
            "At step: 8726 training error: 0.5166174099864463\n",
            "At step: 8727 training error: 0.5185779482000613\n",
            "At step: 8728 training error: 0.5179467550854331\n",
            "At step: 8729 training error: 0.5092488761238108\n",
            "At step: 8730 training error: 0.51487988134878\n",
            "At step: 8731 training error: 0.5238282333527197\n",
            "At step: 8732 training error: 0.5191951463736959\n",
            "At step: 8733 training error: 0.5187538936867928\n",
            "At step: 8734 training error: 0.5168133945198602\n",
            "At step: 8735 training error: 0.5177477596733562\n",
            "At step: 8736 training error: 0.5269118263549366\n",
            "At step: 8737 training error: 0.5186919859601372\n",
            "At step: 8738 training error: 0.5294686285482271\n",
            "At step: 8739 training error: 0.529036122804533\n",
            "At step: 8740 training error: 0.528889231851464\n",
            "At step: 8741 training error: 0.5287943993539913\n",
            "At step: 8742 training error: 0.5293567043030861\n",
            "At step: 8743 training error: 0.5218434731382283\n",
            "At step: 8744 training error: 0.5268842201029778\n",
            "At step: 8745 training error: 0.5256571433180725\n",
            "At step: 8746 training error: 0.5258963805101685\n",
            "At step: 8747 training error: 0.5280780128645997\n",
            "At step: 8748 training error: 0.5387985049852435\n",
            "At step: 8749 training error: 0.5370984167631487\n",
            "At step: 8750 training error: 0.5420684238971432\n",
            "At step: 8751 training error: 0.5394663208357702\n",
            "At step: 8752 training error: 0.540609952542516\n",
            "At step: 8753 training error: 0.5437813226943091\n",
            "At step: 8754 training error: 0.5452663516126645\n",
            "At step: 8755 training error: 0.5515533746007916\n",
            "At step: 8756 training error: 0.5446847970706347\n",
            "At step: 8757 training error: 0.5471271492053763\n",
            "At step: 8758 training error: 0.5422983269779732\n",
            "At step: 8759 training error: 0.5272381375121791\n",
            "At step: 8760 training error: 0.5400958174001189\n",
            "At step: 8761 training error: 0.545479993759539\n",
            "At step: 8762 training error: 0.5364736825926613\n",
            "At step: 8763 training error: 0.5285770501469337\n",
            "At step: 8764 training error: 0.5250783885485623\n",
            "At step: 8765 training error: 0.5278157594290243\n",
            "At step: 8766 training error: 0.520546050511577\n",
            "At step: 8767 training error: 0.5151280289112349\n",
            "At step: 8768 training error: 0.513103432334118\n",
            "At step: 8769 training error: 0.5142968204827625\n",
            "At step: 8770 training error: 0.5102336198349339\n",
            "At step: 8771 training error: 0.5134112404263418\n",
            "At step: 8772 training error: 0.5119725993757543\n",
            "At step: 8773 training error: 0.5131359161814715\n",
            "At step: 8774 training error: 0.5176328457045909\n",
            "At step: 8775 training error: 0.515595817498161\n",
            "At step: 8776 training error: 0.5248789615644203\n",
            "At step: 8777 training error: 0.5243963549079352\n",
            "At step: 8778 training error: 0.532857714088463\n",
            "At step: 8779 training error: 0.5290668754712042\n",
            "At step: 8780 training error: 0.5305425433355846\n",
            "At step: 8781 training error: 0.5248421184882957\n",
            "At step: 8782 training error: 0.5196846334211274\n",
            "At step: 8783 training error: 0.5178986637594337\n",
            "At step: 8784 training error: 0.5121822088175703\n",
            "At step: 8785 training error: 0.5075506945672594\n",
            "At step: 8786 training error: 0.5131348469412553\n",
            "At step: 8787 training error: 0.5139918427104622\n",
            "At step: 8788 training error: 0.5194827925886436\n",
            "At step: 8789 training error: 0.5174245880847722\n",
            "At step: 8790 training error: 0.5211832716426071\n",
            "At step: 8791 training error: 0.5305123394245609\n",
            "At step: 8792 training error: 0.5268919571256624\n",
            "At step: 8793 training error: 0.5311398721142158\n",
            "At step: 8794 training error: 0.5338534305737227\n",
            "At step: 8795 training error: 0.5314483833948461\n",
            "At step: 8796 training error: 0.5379565068488178\n",
            "At step: 8797 training error: 0.539604795075357\n",
            "At step: 8798 training error: 0.5397314786134128\n",
            "At step: 8799 training error: 0.5463739245348775\n",
            "At step: 8800 training error: 0.5456853206604125\n",
            "At step: 8801 training error: 0.5515931302202806\n",
            "At step: 8802 training error: 0.5534546638038251\n",
            "At step: 8803 training error: 0.5471619269877441\n",
            "At step: 8804 training error: 0.5392887739196672\n",
            "At step: 8805 training error: 0.5456906470012428\n",
            "At step: 8806 training error: 0.5478175138786409\n",
            "At step: 8807 training error: 0.5589253049645337\n",
            "At step: 8808 training error: 0.5481977735135976\n",
            "At step: 8809 training error: 0.5426838588115729\n",
            "At step: 8810 training error: 0.5514731335799029\n",
            "At step: 8811 training error: 0.5501384261563919\n",
            "At step: 8812 training error: 0.5425842268033644\n",
            "At step: 8813 training error: 0.5458669544810765\n",
            "At step: 8814 training error: 0.5399432269489469\n",
            "At step: 8815 training error: 0.5451747155921051\n",
            "At step: 8816 training error: 0.5437534524401471\n",
            "At step: 8817 training error: 0.5333446374088693\n",
            "At step: 8818 training error: 0.530971615998655\n",
            "At step: 8819 training error: 0.5240520395134427\n",
            "At step: 8820 training error: 0.5182371314428708\n",
            "At step: 8821 training error: 0.5238199250582687\n",
            "At step: 8822 training error: 0.5206149612877291\n",
            "At step: 8823 training error: 0.5232373598347531\n",
            "At step: 8824 training error: 0.5302333223421045\n",
            "At step: 8825 training error: 0.5299180941728437\n",
            "At step: 8826 training error: 0.5296032433855651\n",
            "At step: 8827 training error: 0.5308507503849679\n",
            "At step: 8828 training error: 0.5329756807021019\n",
            "At step: 8829 training error: 0.5370191893483235\n",
            "At step: 8830 training error: 0.5391056115346957\n",
            "At step: 8831 training error: 0.5375080387188113\n",
            "At step: 8832 training error: 0.5412736882928396\n",
            "At step: 8833 training error: 0.5340147314547065\n",
            "At step: 8834 training error: 0.5396119035202572\n",
            "At step: 8835 training error: 0.5297137535149863\n",
            "At step: 8836 training error: 0.5336494333024037\n",
            "At step: 8837 training error: 0.5272471493263721\n",
            "At step: 8838 training error: 0.5266451549089947\n",
            "At step: 8839 training error: 0.5218933330817601\n",
            "At step: 8840 training error: 0.5295912205116735\n",
            "At step: 8841 training error: 0.5295780477166415\n",
            "At step: 8842 training error: 0.5217909542430857\n",
            "At step: 8843 training error: 0.5318834570187083\n",
            "At step: 8844 training error: 0.5274727979988412\n",
            "At step: 8845 training error: 0.5393092786799704\n",
            "At step: 8846 training error: 0.5324491121421693\n",
            "At step: 8847 training error: 0.5426252927852087\n",
            "At step: 8848 training error: 0.5476529740879994\n",
            "At step: 8849 training error: 0.5393764932072395\n",
            "At step: 8850 training error: 0.5373516575888941\n",
            "At step: 8851 training error: 0.5318932799949013\n",
            "At step: 8852 training error: 0.5201410093939212\n",
            "At step: 8853 training error: 0.5173721759909318\n",
            "At step: 8854 training error: 0.5233438516893849\n",
            "At step: 8855 training error: 0.5127587211040356\n",
            "At step: 8856 training error: 0.5171303286404612\n",
            "At step: 8857 training error: 0.5244617008675514\n",
            "At step: 8858 training error: 0.5196069351622699\n",
            "At step: 8859 training error: 0.5226658603076563\n",
            "At step: 8860 training error: 0.5246705293804946\n",
            "At step: 8861 training error: 0.5279110880010358\n",
            "At step: 8862 training error: 0.523986718292129\n",
            "At step: 8863 training error: 0.5251135674577284\n",
            "At step: 8864 training error: 0.5215368188233771\n",
            "At step: 8865 training error: 0.5261681923971278\n",
            "At step: 8866 training error: 0.5118602143977543\n",
            "At step: 8867 training error: 0.509730018973806\n",
            "At step: 8868 training error: 0.5133238441415358\n",
            "At step: 8869 training error: 0.5094763905459756\n",
            "At step: 8870 training error: 0.51747371370746\n",
            "At step: 8871 training error: 0.5171200470566981\n",
            "At step: 8872 training error: 0.5172792899686524\n",
            "At step: 8873 training error: 0.5229203238403631\n",
            "At step: 8874 training error: 0.5277884387938103\n",
            "At step: 8875 training error: 0.5385974167345703\n",
            "At step: 8876 training error: 0.5470691902617223\n",
            "At step: 8877 training error: 0.5326312720571402\n",
            "At step: 8878 training error: 0.5334719111317532\n",
            "At step: 8879 training error: 0.532766858105758\n",
            "At step: 8880 training error: 0.5191519114219398\n",
            "At step: 8881 training error: 0.5188359582905092\n",
            "At step: 8882 training error: 0.5129746045562542\n",
            "At step: 8883 training error: 0.5060909676510195\n",
            "At step: 8884 training error: 0.5122540178678259\n",
            "At step: 8885 training error: 0.5140157348545917\n",
            "At step: 8886 training error: 0.5161189906781386\n",
            "At step: 8887 training error: 0.5197647510804689\n",
            "At step: 8888 training error: 0.5140907729865068\n",
            "At step: 8889 training error: 0.5200235989527443\n",
            "At step: 8890 training error: 0.5269753136898448\n",
            "At step: 8891 training error: 0.5195204844947092\n",
            "At step: 8892 training error: 0.5304699878017068\n",
            "At step: 8893 training error: 0.5356246386708472\n",
            "At step: 8894 training error: 0.5364939159354879\n",
            "At step: 8895 training error: 0.5286355200315636\n",
            "At step: 8896 training error: 0.525681901629884\n",
            "At step: 8897 training error: 0.5341877725304705\n",
            "At step: 8898 training error: 0.5334700929944804\n",
            "At step: 8899 training error: 0.5314523214193181\n",
            "At step: 8900 training error: 0.5398144068911751\n",
            "At step: 8901 training error: 0.5360797821238409\n",
            "At step: 8902 training error: 0.5344031903920115\n",
            "At step: 8903 training error: 0.5266511924174946\n",
            "At step: 8904 training error: 0.5277965263882991\n",
            "At step: 8905 training error: 0.5311585442495134\n",
            "At step: 8906 training error: 0.5429087700932138\n",
            "At step: 8907 training error: 0.5413074302393456\n",
            "At step: 8908 training error: 0.5409357876266178\n",
            "At step: 8909 training error: 0.5364823638442119\n",
            "At step: 8910 training error: 0.5315485210437267\n",
            "At step: 8911 training error: 0.5272296912736993\n",
            "At step: 8912 training error: 0.5375139426878792\n",
            "At step: 8913 training error: 0.5358320188097868\n",
            "At step: 8914 training error: 0.5280296678235614\n",
            "At step: 8915 training error: 0.5309478100308576\n",
            "At step: 8916 training error: 0.5202108813122123\n",
            "At step: 8917 training error: 0.5218855934640236\n",
            "At step: 8918 training error: 0.5185404255289976\n",
            "At step: 8919 training error: 0.5205476396290805\n",
            "At step: 8920 training error: 0.5212478657351097\n",
            "At step: 8921 training error: 0.5180499561072813\n",
            "At step: 8922 training error: 0.5141184642040525\n",
            "At step: 8923 training error: 0.502774122009771\n",
            "At step: 8924 training error: 0.5116447941386367\n",
            "At step: 8925 training error: 0.514553590399805\n",
            "At step: 8926 training error: 0.5213805095510705\n",
            "At step: 8927 training error: 0.5255034020931353\n",
            "At step: 8928 training error: 0.5189191281682333\n",
            "At step: 8929 training error: 0.5198150961506165\n",
            "At step: 8930 training error: 0.5244309591757261\n",
            "At step: 8931 training error: 0.5353371066997824\n",
            "At step: 8932 training error: 0.5364196218476517\n",
            "At step: 8933 training error: 0.5406971124697763\n",
            "At step: 8934 training error: 0.5497479911434627\n",
            "At step: 8935 training error: 0.5458632587071472\n",
            "At step: 8936 training error: 0.5395015396668518\n",
            "At step: 8937 training error: 0.5501481644539185\n",
            "At step: 8938 training error: 0.5359251737669685\n",
            "At step: 8939 training error: 0.5380141379404147\n",
            "At step: 8940 training error: 0.5291385265851768\n",
            "At step: 8941 training error: 0.527701180786708\n",
            "At step: 8942 training error: 0.5306544420571808\n",
            "At step: 8943 training error: 0.5370225498378997\n",
            "At step: 8944 training error: 0.5383923518501962\n",
            "At step: 8945 training error: 0.5326614893306316\n",
            "At step: 8946 training error: 0.5312501476886236\n",
            "At step: 8947 training error: 0.5347359324088201\n",
            "At step: 8948 training error: 0.5317326755812574\n",
            "At step: 8949 training error: 0.5316095655993711\n",
            "At step: 8950 training error: 0.5301681502282849\n",
            "At step: 8951 training error: 0.5386294286042894\n",
            "At step: 8952 training error: 0.535739480410406\n",
            "At step: 8953 training error: 0.5404777793278444\n",
            "At step: 8954 training error: 0.5459653324253242\n",
            "At step: 8955 training error: 0.5425340914384618\n",
            "At step: 8956 training error: 0.5398171806431732\n",
            "At step: 8957 training error: 0.5357368005533508\n",
            "At step: 8958 training error: 0.5403936072373616\n",
            "At step: 8959 training error: 0.543926649474293\n",
            "At step: 8960 training error: 0.5498825522890562\n",
            "At step: 8961 training error: 0.5489850072802253\n",
            "At step: 8962 training error: 0.5515270528994307\n",
            "At step: 8963 training error: 0.5596927067732483\n",
            "At step: 8964 training error: 0.5562583014993068\n",
            "At step: 8965 training error: 0.5510012659177639\n",
            "At step: 8966 training error: 0.5522297869254911\n",
            "At step: 8967 training error: 0.5432310505443741\n",
            "At step: 8968 training error: 0.5419691972786573\n",
            "At step: 8969 training error: 0.5497206153575662\n",
            "At step: 8970 training error: 0.5411627760759884\n",
            "At step: 8971 training error: 0.5427020443825334\n",
            "At step: 8972 training error: 0.5379096413248526\n",
            "At step: 8973 training error: 0.5552836441953809\n",
            "At step: 8974 training error: 0.554543808890138\n",
            "At step: 8975 training error: 0.5491751231362749\n",
            "At step: 8976 training error: 0.5479145493887976\n",
            "At step: 8977 training error: 0.5524165701047673\n",
            "At step: 8978 training error: 0.5515250554119111\n",
            "At step: 8979 training error: 0.5494977651973834\n",
            "At step: 8980 training error: 0.5272667618231642\n",
            "At step: 8981 training error: 0.5263177898395949\n",
            "At step: 8982 training error: 0.52786788249057\n",
            "At step: 8983 training error: 0.5324494936025531\n",
            "At step: 8984 training error: 0.5311266563445349\n",
            "At step: 8985 training error: 0.5256075930649632\n",
            "At step: 8986 training error: 0.5223667415150258\n",
            "At step: 8987 training error: 0.5305886777257302\n",
            "At step: 8988 training error: 0.5331066746143981\n",
            "At step: 8989 training error: 0.5392834856464922\n",
            "At step: 8990 training error: 0.5400881928307313\n",
            "At step: 8991 training error: 0.5383717667603866\n",
            "At step: 8992 training error: 0.5478343634466117\n",
            "At step: 8993 training error: 0.5442439099809757\n",
            "At step: 8994 training error: 0.5402760842452871\n",
            "At step: 8995 training error: 0.5374586091371243\n",
            "At step: 8996 training error: 0.5344060897804365\n",
            "At step: 8997 training error: 0.5332096769051241\n",
            "At step: 8998 training error: 0.5300659425287759\n",
            "At step: 8999 training error: 0.5282308116341721\n",
            "At step: 9000 training error: 0.530280621336079\n",
            "At step: 9001 training error: 0.5336787508470617\n",
            "At step: 9002 training error: 0.535369415051969\n",
            "At step: 9003 training error: 0.5234729528657954\n",
            "At step: 9004 training error: 0.5277646609796672\n",
            "At step: 9005 training error: 0.5231948237851419\n",
            "At step: 9006 training error: 0.5209334994109389\n",
            "At step: 9007 training error: 0.5243821652413496\n",
            "At step: 9008 training error: 0.5205109325087848\n",
            "At step: 9009 training error: 0.5184257596897539\n",
            "At step: 9010 training error: 0.5036516571206286\n",
            "At step: 9011 training error: 0.5008576086786561\n",
            "At step: 9012 training error: 0.5136892650610806\n",
            "At step: 9013 training error: 0.5060398412341194\n",
            "At step: 9014 training error: 0.4997816029434602\n",
            "At step: 9015 training error: 0.5017010906434358\n",
            "At step: 9016 training error: 0.5056403827393416\n",
            "At step: 9017 training error: 0.5021965928969461\n",
            "At step: 9018 training error: 0.511737301346653\n",
            "At step: 9019 training error: 0.5096353292032381\n",
            "At step: 9020 training error: 0.5078507148092737\n",
            "At step: 9021 training error: 0.510642470201214\n",
            "At step: 9022 training error: 0.5095291375742882\n",
            "At step: 9023 training error: 0.510082701953537\n",
            "At step: 9024 training error: 0.5178435277500548\n",
            "At step: 9025 training error: 0.5208235891019344\n",
            "At step: 9026 training error: 0.5182275224491502\n",
            "At step: 9027 training error: 0.5273219443427722\n",
            "At step: 9028 training error: 0.5334184316018927\n",
            "At step: 9029 training error: 0.5324701267172881\n",
            "At step: 9030 training error: 0.530945803818628\n",
            "At step: 9031 training error: 0.5307436408544091\n",
            "At step: 9032 training error: 0.5369873043241988\n",
            "At step: 9033 training error: 0.5393148709564941\n",
            "At step: 9034 training error: 0.535875341971701\n",
            "At step: 9035 training error: 0.5415178172741163\n",
            "At step: 9036 training error: 0.5395963788815802\n",
            "At step: 9037 training error: 0.5398262515353901\n",
            "At step: 9038 training error: 0.5284731105009173\n",
            "At step: 9039 training error: 0.5312215442820368\n",
            "At step: 9040 training error: 0.5255931715370021\n",
            "At step: 9041 training error: 0.5305768060998352\n",
            "At step: 9042 training error: 0.5356094290751481\n",
            "At step: 9043 training error: 0.5349771947088461\n",
            "At step: 9044 training error: 0.5297652022443748\n",
            "At step: 9045 training error: 0.5310978013644576\n",
            "At step: 9046 training error: 0.5297904686089072\n",
            "At step: 9047 training error: 0.5271666231080098\n",
            "At step: 9048 training error: 0.5333176625713505\n",
            "At step: 9049 training error: 0.5210621999528899\n",
            "At step: 9050 training error: 0.5340363587073652\n",
            "At step: 9051 training error: 0.530043998066434\n",
            "At step: 9052 training error: 0.525557873494618\n",
            "At step: 9053 training error: 0.5276180187520233\n",
            "At step: 9054 training error: 0.5357615402222156\n",
            "At step: 9055 training error: 0.5389944311702735\n",
            "At step: 9056 training error: 0.5378554590128286\n",
            "At step: 9057 training error: 0.533316443137101\n",
            "At step: 9058 training error: 0.5229685284044245\n",
            "At step: 9059 training error: 0.5215225034349588\n",
            "At step: 9060 training error: 0.514693782532884\n",
            "At step: 9061 training error: 0.5136003590885942\n",
            "At step: 9062 training error: 0.5104232716035988\n",
            "At step: 9063 training error: 0.511581514710999\n",
            "At step: 9064 training error: 0.5221353031877571\n",
            "At step: 9065 training error: 0.5225255228490094\n",
            "At step: 9066 training error: 0.5319779001141052\n",
            "At step: 9067 training error: 0.5352560196265175\n",
            "At step: 9068 training error: 0.5291521590253795\n",
            "At step: 9069 training error: 0.5331607704145269\n",
            "At step: 9070 training error: 0.5307000448508342\n",
            "At step: 9071 training error: 0.531683525039818\n",
            "At step: 9072 training error: 0.5407929705480995\n",
            "At step: 9073 training error: 0.5279751358968713\n",
            "At step: 9074 training error: 0.5273989353161995\n",
            "At step: 9075 training error: 0.5412010522009454\n",
            "At step: 9076 training error: 0.541481189138941\n",
            "At step: 9077 training error: 0.52987434550119\n",
            "At step: 9078 training error: 0.5163178647972851\n",
            "At step: 9079 training error: 0.5161402643407148\n",
            "At step: 9080 training error: 0.5134841675389787\n",
            "At step: 9081 training error: 0.5248867207320771\n",
            "At step: 9082 training error: 0.5258024767899272\n",
            "At step: 9083 training error: 0.5246987216683083\n",
            "At step: 9084 training error: 0.5242140590479656\n",
            "At step: 9085 training error: 0.5172268083498877\n",
            "At step: 9086 training error: 0.5098618049630709\n",
            "At step: 9087 training error: 0.5096618779645942\n",
            "At step: 9088 training error: 0.5163053710174947\n",
            "At step: 9089 training error: 0.5289464117398257\n",
            "At step: 9090 training error: 0.5323854402606841\n",
            "At step: 9091 training error: 0.5278226745497548\n",
            "At step: 9092 training error: 0.5200340053648002\n",
            "At step: 9093 training error: 0.5307754348716522\n",
            "At step: 9094 training error: 0.5250888143196117\n",
            "At step: 9095 training error: 0.513791771564671\n",
            "At step: 9096 training error: 0.5132827154425674\n",
            "At step: 9097 training error: 0.5221618889223002\n",
            "At step: 9098 training error: 0.51972796928175\n",
            "At step: 9099 training error: 0.5133990741295987\n",
            "At step: 9100 training error: 0.510170301198378\n",
            "At step: 9101 training error: 0.5138863306016747\n",
            "At step: 9102 training error: 0.5123523844164377\n",
            "At step: 9103 training error: 0.5074227116546143\n",
            "At step: 9104 training error: 0.49419752685546997\n",
            "At step: 9105 training error: 0.49118016119926294\n",
            "At step: 9106 training error: 0.4997987579693973\n",
            "At step: 9107 training error: 0.5031983062640367\n",
            "At step: 9108 training error: 0.5034591993860612\n",
            "At step: 9109 training error: 0.5008256994879564\n",
            "At step: 9110 training error: 0.5015354322376354\n",
            "At step: 9111 training error: 0.5105855550047803\n",
            "At step: 9112 training error: 0.5186257370428954\n",
            "At step: 9113 training error: 0.5235362691673744\n",
            "At step: 9114 training error: 0.5330880180167379\n",
            "At step: 9115 training error: 0.5241934013458203\n",
            "At step: 9116 training error: 0.5173814051022058\n",
            "At step: 9117 training error: 0.5172232850211868\n",
            "At step: 9118 training error: 0.5130499483836767\n",
            "At step: 9119 training error: 0.5166379594751516\n",
            "At step: 9120 training error: 0.5239203017579719\n",
            "At step: 9121 training error: 0.5232376956630527\n",
            "At step: 9122 training error: 0.5202795956688175\n",
            "At step: 9123 training error: 0.5221244112720245\n",
            "At step: 9124 training error: 0.5366480801017746\n",
            "At step: 9125 training error: 0.5398374363413863\n",
            "At step: 9126 training error: 0.5331201174186759\n",
            "At step: 9127 training error: 0.5299667127311711\n",
            "At step: 9128 training error: 0.5321259853909422\n",
            "At step: 9129 training error: 0.5320185249482721\n",
            "At step: 9130 training error: 0.5368363245320831\n",
            "At step: 9131 training error: 0.5426124362222599\n",
            "At step: 9132 training error: 0.5379302253516962\n",
            "At step: 9133 training error: 0.5339999972050611\n",
            "At step: 9134 training error: 0.530027333932134\n",
            "At step: 9135 training error: 0.5205511305410553\n",
            "At step: 9136 training error: 0.5184447461691051\n",
            "At step: 9137 training error: 0.5281701204094442\n",
            "At step: 9138 training error: 0.5279896480854971\n",
            "At step: 9139 training error: 0.53107153135822\n",
            "At step: 9140 training error: 0.5366820131304529\n",
            "At step: 9141 training error: 0.5428395058890578\n",
            "At step: 9142 training error: 0.5378197389441428\n",
            "At step: 9143 training error: 0.5300722062362282\n",
            "At step: 9144 training error: 0.5264359741083688\n",
            "At step: 9145 training error: 0.5304682236280127\n",
            "At step: 9146 training error: 0.5291113275867428\n",
            "At step: 9147 training error: 0.5376876699694151\n",
            "At step: 9148 training error: 0.5319089204420396\n",
            "At step: 9149 training error: 0.5365133549211631\n",
            "At step: 9150 training error: 0.5325613314953745\n",
            "At step: 9151 training error: 0.5401780412106219\n",
            "At step: 9152 training error: 0.5464470359146198\n",
            "At step: 9153 training error: 0.5418523162327109\n",
            "At step: 9154 training error: 0.5548334406344453\n",
            "At step: 9155 training error: 0.5473417446287612\n",
            "At step: 9156 training error: 0.5542926827665497\n",
            "At step: 9157 training error: 0.5493141747834368\n",
            "At step: 9158 training error: 0.5504900543576188\n",
            "At step: 9159 training error: 0.5384202569089666\n",
            "At step: 9160 training error: 0.5348343634255887\n",
            "At step: 9161 training error: 0.5294514388502314\n",
            "At step: 9162 training error: 0.539727378243727\n",
            "At step: 9163 training error: 0.5320194155625396\n",
            "At step: 9164 training error: 0.5218836176425236\n",
            "At step: 9165 training error: 0.5244381116916079\n",
            "At step: 9166 training error: 0.5167271146365834\n",
            "At step: 9167 training error: 0.5181087244894438\n",
            "At step: 9168 training error: 0.525278372712817\n",
            "At step: 9169 training error: 0.521399574709272\n",
            "At step: 9170 training error: 0.5243849643017412\n",
            "At step: 9171 training error: 0.5359066047716664\n",
            "At step: 9172 training error: 0.5415433916532906\n",
            "At step: 9173 training error: 0.5394656765503507\n",
            "At step: 9174 training error: 0.5381949027211\n",
            "At step: 9175 training error: 0.5281302764634376\n",
            "At step: 9176 training error: 0.5262058891553986\n",
            "At step: 9177 training error: 0.531387575551197\n",
            "At step: 9178 training error: 0.5300265759004936\n",
            "At step: 9179 training error: 0.5301341070395755\n",
            "At step: 9180 training error: 0.5409787070067332\n",
            "At step: 9181 training error: 0.5432828391147542\n",
            "At step: 9182 training error: 0.5425839904503866\n",
            "At step: 9183 training error: 0.543253544418006\n",
            "At step: 9184 training error: 0.5353092517197866\n",
            "At step: 9185 training error: 0.5351558278676876\n",
            "At step: 9186 training error: 0.5338382560696117\n",
            "At step: 9187 training error: 0.5242924475399572\n",
            "At step: 9188 training error: 0.530095261543159\n",
            "At step: 9189 training error: 0.5361641104592143\n",
            "At step: 9190 training error: 0.5379782842126124\n",
            "At step: 9191 training error: 0.5266677642348581\n",
            "At step: 9192 training error: 0.515062199676851\n",
            "At step: 9193 training error: 0.5158770399017387\n",
            "At step: 9194 training error: 0.5203313509054883\n",
            "At step: 9195 training error: 0.5281580406145003\n",
            "At step: 9196 training error: 0.5285848085124072\n",
            "At step: 9197 training error: 0.5456658548171427\n",
            "At step: 9198 training error: 0.5480288160635807\n",
            "At step: 9199 training error: 0.5390727104992225\n",
            "At step: 9200 training error: 0.5350381570187368\n",
            "At step: 9201 training error: 0.5415376976337882\n",
            "At step: 9202 training error: 0.5418618755642663\n",
            "At step: 9203 training error: 0.5323667155005877\n",
            "At step: 9204 training error: 0.5353056706322132\n",
            "At step: 9205 training error: 0.5371491743734482\n",
            "At step: 9206 training error: 0.5360937350572372\n",
            "At step: 9207 training error: 0.5434438645285994\n",
            "At step: 9208 training error: 0.5599903668062092\n",
            "At step: 9209 training error: 0.5644844131786426\n",
            "At step: 9210 training error: 0.5592351760146506\n",
            "At step: 9211 training error: 0.5429585308157006\n",
            "At step: 9212 training error: 0.5523323893293458\n",
            "At step: 9213 training error: 0.5492482515734645\n",
            "At step: 9214 training error: 0.5364456296874283\n",
            "At step: 9215 training error: 0.5375794050897604\n",
            "At step: 9216 training error: 0.5389114196731203\n",
            "At step: 9217 training error: 0.5441476205421962\n",
            "At step: 9218 training error: 0.5434921964277183\n",
            "At step: 9219 training error: 0.5391131406708776\n",
            "At step: 9220 training error: 0.5389290895689494\n",
            "At step: 9221 training error: 0.5291711120043295\n",
            "At step: 9222 training error: 0.5298073459950297\n",
            "At step: 9223 training error: 0.5332169720039761\n",
            "At step: 9224 training error: 0.5325663080334864\n",
            "At step: 9225 training error: 0.5295804777681111\n",
            "At step: 9226 training error: 0.5331099592404738\n",
            "At step: 9227 training error: 0.5281672511652041\n",
            "At step: 9228 training error: 0.5242168189059376\n",
            "At step: 9229 training error: 0.5326566921648554\n",
            "At step: 9230 training error: 0.5309576076200861\n",
            "At step: 9231 training error: 0.5370057301694794\n",
            "At step: 9232 training error: 0.5335437974983784\n",
            "At step: 9233 training error: 0.5345299528820269\n",
            "At step: 9234 training error: 0.5265214879272349\n",
            "At step: 9235 training error: 0.5258952313640339\n",
            "At step: 9236 training error: 0.523299057238036\n",
            "At step: 9237 training error: 0.5335295944843722\n",
            "At step: 9238 training error: 0.5271192787810112\n",
            "At step: 9239 training error: 0.527613147431439\n",
            "At step: 9240 training error: 0.5327301718656472\n",
            "At step: 9241 training error: 0.5232847325238619\n",
            "At step: 9242 training error: 0.525402662565992\n",
            "At step: 9243 training error: 0.5227602900247672\n",
            "At step: 9244 training error: 0.5223473177694197\n",
            "At step: 9245 training error: 0.5305912541621305\n",
            "At step: 9246 training error: 0.5339346945743895\n",
            "At step: 9247 training error: 0.5301465291539277\n",
            "At step: 9248 training error: 0.5300472468727346\n",
            "At step: 9249 training error: 0.5257058618712133\n",
            "At step: 9250 training error: 0.5172767868815894\n",
            "At step: 9251 training error: 0.5080446661488927\n",
            "At step: 9252 training error: 0.5249080240977829\n",
            "At step: 9253 training error: 0.5304708213532876\n",
            "At step: 9254 training error: 0.5226471777264949\n",
            "At step: 9255 training error: 0.5115316020608022\n",
            "At step: 9256 training error: 0.5114904681049391\n",
            "At step: 9257 training error: 0.5101602593892843\n",
            "At step: 9258 training error: 0.49801181710241105\n",
            "At step: 9259 training error: 0.49622216895689275\n",
            "At step: 9260 training error: 0.4939937295284871\n",
            "At step: 9261 training error: 0.49639136273241824\n",
            "At step: 9262 training error: 0.5030256266056352\n",
            "At step: 9263 training error: 0.49543627476716584\n",
            "At step: 9264 training error: 0.5013149224009531\n",
            "At step: 9265 training error: 0.5019061161599028\n",
            "At step: 9266 training error: 0.5013596146652632\n",
            "At step: 9267 training error: 0.51779679715673\n",
            "At step: 9268 training error: 0.5181351348493831\n",
            "At step: 9269 training error: 0.5110772387022482\n",
            "At step: 9270 training error: 0.5036124234777469\n",
            "At step: 9271 training error: 0.5151733230022834\n",
            "At step: 9272 training error: 0.5212698351226933\n",
            "At step: 9273 training error: 0.5168230591594708\n",
            "At step: 9274 training error: 0.5139511855215888\n",
            "At step: 9275 training error: 0.5179445105000684\n",
            "At step: 9276 training error: 0.5194751436628413\n",
            "At step: 9277 training error: 0.5198625967300651\n",
            "At step: 9278 training error: 0.5148455183376022\n",
            "At step: 9279 training error: 0.5267817517683134\n",
            "At step: 9280 training error: 0.5214128949642111\n",
            "At step: 9281 training error: 0.5258068568954224\n",
            "At step: 9282 training error: 0.5247500555731542\n",
            "At step: 9283 training error: 0.5251286074796888\n",
            "At step: 9284 training error: 0.5186235367250446\n",
            "At step: 9285 training error: 0.5140164613052228\n",
            "At step: 9286 training error: 0.5151263322530971\n",
            "At step: 9287 training error: 0.51365865932553\n",
            "At step: 9288 training error: 0.5214050066392426\n",
            "At step: 9289 training error: 0.5201328674890395\n",
            "At step: 9290 training error: 0.5223480842371389\n",
            "At step: 9291 training error: 0.5183463528055079\n",
            "At step: 9292 training error: 0.5210508860726344\n",
            "At step: 9293 training error: 0.5189216330922926\n",
            "At step: 9294 training error: 0.5236539594799987\n",
            "At step: 9295 training error: 0.5301459853424328\n",
            "At step: 9296 training error: 0.5227663273056651\n",
            "At step: 9297 training error: 0.5284851703157604\n",
            "At step: 9298 training error: 0.524703237859965\n",
            "At step: 9299 training error: 0.5159557776449712\n",
            "At step: 9300 training error: 0.5118709525338517\n",
            "At step: 9301 training error: 0.50852698059248\n",
            "At step: 9302 training error: 0.517564744028874\n",
            "At step: 9303 training error: 0.5145339720934632\n",
            "At step: 9304 training error: 0.5056371585511729\n",
            "At step: 9305 training error: 0.5158407815875461\n",
            "At step: 9306 training error: 0.5230128258801083\n",
            "At step: 9307 training error: 0.5239587601978211\n",
            "At step: 9308 training error: 0.5101900816340075\n",
            "At step: 9309 training error: 0.5077307269498335\n",
            "At step: 9310 training error: 0.5062678238626623\n",
            "At step: 9311 training error: 0.5056587565858436\n",
            "At step: 9312 training error: 0.5005303411180861\n",
            "At step: 9313 training error: 0.5063590908358043\n",
            "At step: 9314 training error: 0.5060031393770283\n",
            "At step: 9315 training error: 0.4938253685611514\n",
            "At step: 9316 training error: 0.49529230531993346\n",
            "At step: 9317 training error: 0.49919836537914347\n",
            "At step: 9318 training error: 0.4990891262838009\n",
            "At step: 9319 training error: 0.5017332514361408\n",
            "At step: 9320 training error: 0.5058129737036681\n",
            "At step: 9321 training error: 0.506062277857789\n",
            "At step: 9322 training error: 0.5061759614249797\n",
            "At step: 9323 training error: 0.4987589077379586\n",
            "At step: 9324 training error: 0.500504184089889\n",
            "At step: 9325 training error: 0.5018542923293193\n",
            "At step: 9326 training error: 0.5033858492795983\n",
            "At step: 9327 training error: 0.4961900863817289\n",
            "At step: 9328 training error: 0.4963892349209132\n",
            "At step: 9329 training error: 0.5024245120532059\n",
            "At step: 9330 training error: 0.5008180381004742\n",
            "At step: 9331 training error: 0.4898060682658125\n",
            "At step: 9332 training error: 0.49714057583468824\n",
            "At step: 9333 training error: 0.5011198923074143\n",
            "At step: 9334 training error: 0.49243703995296095\n",
            "At step: 9335 training error: 0.49036755623101824\n",
            "At step: 9336 training error: 0.49000175661599216\n",
            "At step: 9337 training error: 0.48661283493904467\n",
            "At step: 9338 training error: 0.48046225552244765\n",
            "At step: 9339 training error: 0.4896036148558573\n",
            "At step: 9340 training error: 0.4992269150151928\n",
            "At step: 9341 training error: 0.5064004134006415\n",
            "At step: 9342 training error: 0.5095395745414921\n",
            "At step: 9343 training error: 0.5145465227777666\n",
            "At step: 9344 training error: 0.5122397604718805\n",
            "At step: 9345 training error: 0.507249464824451\n",
            "At step: 9346 training error: 0.511244442234358\n",
            "At step: 9347 training error: 0.5115060714943337\n",
            "At step: 9348 training error: 0.5205296554509351\n",
            "At step: 9349 training error: 0.520442228096601\n",
            "At step: 9350 training error: 0.5265010681163524\n",
            "At step: 9351 training error: 0.5259429588492965\n",
            "At step: 9352 training error: 0.5172529178126072\n",
            "At step: 9353 training error: 0.5147928451964195\n",
            "At step: 9354 training error: 0.5184917460990295\n",
            "At step: 9355 training error: 0.5116491301051117\n",
            "At step: 9356 training error: 0.5052190468065436\n",
            "At step: 9357 training error: 0.5146015814342679\n",
            "At step: 9358 training error: 0.512359979719185\n",
            "At step: 9359 training error: 0.5087676273586501\n",
            "At step: 9360 training error: 0.5109519940570607\n",
            "At step: 9361 training error: 0.5065777268624151\n",
            "At step: 9362 training error: 0.5069472132472087\n",
            "At step: 9363 training error: 0.5029036350854383\n",
            "At step: 9364 training error: 0.5100259017702496\n",
            "At step: 9365 training error: 0.5188446306031997\n",
            "At step: 9366 training error: 0.5173461531005148\n",
            "At step: 9367 training error: 0.5211090360328458\n",
            "At step: 9368 training error: 0.5199935727666949\n",
            "At step: 9369 training error: 0.5321930323122713\n",
            "At step: 9370 training error: 0.5267139654730179\n",
            "At step: 9371 training error: 0.5259700334539561\n",
            "At step: 9372 training error: 0.5255951765484894\n",
            "At step: 9373 training error: 0.5311762068028436\n",
            "At step: 9374 training error: 0.5368508913263855\n",
            "At step: 9375 training error: 0.5330832478400415\n",
            "At step: 9376 training error: 0.5303693201928084\n",
            "At step: 9377 training error: 0.524316386380068\n",
            "At step: 9378 training error: 0.5259415591167844\n",
            "At step: 9379 training error: 0.5192936564029292\n",
            "At step: 9380 training error: 0.5116800512427901\n",
            "At step: 9381 training error: 0.5087641521354156\n",
            "At step: 9382 training error: 0.5126624795671517\n",
            "At step: 9383 training error: 0.5240443046518198\n",
            "At step: 9384 training error: 0.5212101788070728\n",
            "At step: 9385 training error: 0.520190699077806\n",
            "At step: 9386 training error: 0.523898836349074\n",
            "At step: 9387 training error: 0.5167059627954556\n",
            "At step: 9388 training error: 0.5162080593187409\n",
            "At step: 9389 training error: 0.5189091513798465\n",
            "At step: 9390 training error: 0.518921140242474\n",
            "At step: 9391 training error: 0.5151628193111225\n",
            "At step: 9392 training error: 0.5188145201500588\n",
            "At step: 9393 training error: 0.511549235995725\n",
            "At step: 9394 training error: 0.5139584295473949\n",
            "At step: 9395 training error: 0.5204859991896739\n",
            "At step: 9396 training error: 0.5275690542173231\n",
            "At step: 9397 training error: 0.5308103383803418\n",
            "At step: 9398 training error: 0.5203663243905743\n",
            "At step: 9399 training error: 0.5252268553418927\n",
            "At step: 9400 training error: 0.5159478018892432\n",
            "At step: 9401 training error: 0.511681321749888\n",
            "At step: 9402 training error: 0.5063057439944303\n",
            "At step: 9403 training error: 0.5042854984037518\n",
            "At step: 9404 training error: 0.4969147980433727\n",
            "At step: 9405 training error: 0.4977313663596686\n",
            "At step: 9406 training error: 0.494057073747142\n",
            "At step: 9407 training error: 0.49532237352025005\n",
            "At step: 9408 training error: 0.49555010095312635\n",
            "At step: 9409 training error: 0.49512091876367703\n",
            "At step: 9410 training error: 0.5046701525479385\n",
            "At step: 9411 training error: 0.5205122381928032\n",
            "At step: 9412 training error: 0.5132534224598584\n",
            "At step: 9413 training error: 0.5119256599115891\n",
            "At step: 9414 training error: 0.5149745305876497\n",
            "At step: 9415 training error: 0.5208966197201748\n",
            "At step: 9416 training error: 0.5202093321752981\n",
            "At step: 9417 training error: 0.5278635085111937\n",
            "At step: 9418 training error: 0.5311953641630801\n",
            "At step: 9419 training error: 0.5283510113297769\n",
            "At step: 9420 training error: 0.5290049186398003\n",
            "At step: 9421 training error: 0.5346000204246876\n",
            "At step: 9422 training error: 0.5366385005374815\n",
            "At step: 9423 training error: 0.5378524650146036\n",
            "At step: 9424 training error: 0.541341242009714\n",
            "At step: 9425 training error: 0.5394515469144396\n",
            "At step: 9426 training error: 0.5346580714356315\n",
            "At step: 9427 training error: 0.5387592450563616\n",
            "At step: 9428 training error: 0.5351663296283398\n",
            "At step: 9429 training error: 0.5267806455717629\n",
            "At step: 9430 training error: 0.5173982483304171\n",
            "At step: 9431 training error: 0.5259934807600424\n",
            "At step: 9432 training error: 0.5390174185419339\n",
            "At step: 9433 training error: 0.5509256990463545\n",
            "At step: 9434 training error: 0.5472121352941645\n",
            "At step: 9435 training error: 0.5419517379432156\n",
            "At step: 9436 training error: 0.5342110138784503\n",
            "At step: 9437 training error: 0.542796489984662\n",
            "At step: 9438 training error: 0.5348179522139364\n",
            "At step: 9439 training error: 0.5415519017778049\n",
            "At step: 9440 training error: 0.5284739164787164\n",
            "At step: 9441 training error: 0.5252759028348368\n",
            "At step: 9442 training error: 0.5221272692784088\n",
            "At step: 9443 training error: 0.5153382122804504\n",
            "At step: 9444 training error: 0.5159529533299796\n",
            "At step: 9445 training error: 0.5162949738375627\n",
            "At step: 9446 training error: 0.512158983001641\n",
            "At step: 9447 training error: 0.517221981666583\n",
            "At step: 9448 training error: 0.5146217578772395\n",
            "At step: 9449 training error: 0.510957584111461\n",
            "At step: 9450 training error: 0.5073285606383803\n",
            "At step: 9451 training error: 0.5071493492466274\n",
            "At step: 9452 training error: 0.5195942277364838\n",
            "At step: 9453 training error: 0.5151711925329043\n",
            "At step: 9454 training error: 0.5214628634665877\n",
            "At step: 9455 training error: 0.5253844745773322\n",
            "At step: 9456 training error: 0.5374197613736055\n",
            "At step: 9457 training error: 0.5211910643229024\n",
            "At step: 9458 training error: 0.5316416885022539\n",
            "At step: 9459 training error: 0.5319490149390101\n",
            "At step: 9460 training error: 0.5228207192921516\n",
            "At step: 9461 training error: 0.5213052411672042\n",
            "At step: 9462 training error: 0.5225312444208143\n",
            "At step: 9463 training error: 0.5218703811233738\n",
            "At step: 9464 training error: 0.5189816757602881\n",
            "At step: 9465 training error: 0.512786002956379\n",
            "At step: 9466 training error: 0.5141676620196263\n",
            "At step: 9467 training error: 0.5188837299190613\n",
            "At step: 9468 training error: 0.5163085373796668\n",
            "At step: 9469 training error: 0.5144215809024166\n",
            "At step: 9470 training error: 0.5216439565057239\n",
            "At step: 9471 training error: 0.5266226469965127\n",
            "At step: 9472 training error: 0.5303055928989873\n",
            "At step: 9473 training error: 0.517206455113727\n",
            "At step: 9474 training error: 0.5203529509575939\n",
            "At step: 9475 training error: 0.525411115531641\n",
            "At step: 9476 training error: 0.5398377836842857\n",
            "At step: 9477 training error: 0.5370721949469128\n",
            "At step: 9478 training error: 0.5409513622309933\n",
            "At step: 9479 training error: 0.5355472385135231\n",
            "At step: 9480 training error: 0.5284452746457109\n",
            "At step: 9481 training error: 0.5308704366595928\n",
            "At step: 9482 training error: 0.5290299911961437\n",
            "At step: 9483 training error: 0.5260782109717018\n",
            "At step: 9484 training error: 0.543206105253121\n",
            "At step: 9485 training error: 0.5378051478133471\n",
            "At step: 9486 training error: 0.5308122524676102\n",
            "At step: 9487 training error: 0.5312956684922205\n",
            "At step: 9488 training error: 0.5387916532217387\n",
            "At step: 9489 training error: 0.5457506296521487\n",
            "At step: 9490 training error: 0.539085236855344\n",
            "At step: 9491 training error: 0.5381456024362785\n",
            "At step: 9492 training error: 0.5342262001648863\n",
            "At step: 9493 training error: 0.5319384442657128\n",
            "At step: 9494 training error: 0.5307102818291306\n",
            "At step: 9495 training error: 0.5245033855551547\n",
            "At step: 9496 training error: 0.5171596595981526\n",
            "At step: 9497 training error: 0.5227338814035039\n",
            "At step: 9498 training error: 0.5150895803697861\n",
            "At step: 9499 training error: 0.5087634758037058\n",
            "At step: 9500 training error: 0.5148877661162083\n",
            "At step: 9501 training error: 0.516472784303208\n",
            "At step: 9502 training error: 0.5140525764186067\n",
            "At step: 9503 training error: 0.5150189371827288\n",
            "At step: 9504 training error: 0.5098177405232258\n",
            "At step: 9505 training error: 0.5145017086001316\n",
            "At step: 9506 training error: 0.5087638653316633\n",
            "At step: 9507 training error: 0.5088490258785676\n",
            "At step: 9508 training error: 0.5074253452011431\n",
            "At step: 9509 training error: 0.5044849297986564\n",
            "At step: 9510 training error: 0.5112781517019424\n",
            "At step: 9511 training error: 0.5063448199999419\n",
            "At step: 9512 training error: 0.5007480611544922\n",
            "At step: 9513 training error: 0.4992988034798333\n",
            "At step: 9514 training error: 0.508221309402983\n",
            "At step: 9515 training error: 0.4956711545637439\n",
            "At step: 9516 training error: 0.493845844255083\n",
            "At step: 9517 training error: 0.4983835828879465\n",
            "At step: 9518 training error: 0.5041927046659436\n",
            "At step: 9519 training error: 0.5004233423653\n",
            "At step: 9520 training error: 0.5101552058664433\n",
            "At step: 9521 training error: 0.5153527281782289\n",
            "At step: 9522 training error: 0.5155203961673668\n",
            "At step: 9523 training error: 0.5170470119410275\n",
            "At step: 9524 training error: 0.517044907030624\n",
            "At step: 9525 training error: 0.5158637504258315\n",
            "At step: 9526 training error: 0.5158209331618366\n",
            "At step: 9527 training error: 0.5179306465678646\n",
            "At step: 9528 training error: 0.5157980984588194\n",
            "At step: 9529 training error: 0.5132102309212987\n",
            "At step: 9530 training error: 0.5183001410370252\n",
            "At step: 9531 training error: 0.5166982308667586\n",
            "At step: 9532 training error: 0.5221331618431032\n",
            "At step: 9533 training error: 0.5190370043867054\n",
            "At step: 9534 training error: 0.5200151881638198\n",
            "At step: 9535 training error: 0.5294826237623944\n",
            "At step: 9536 training error: 0.5320099670277553\n",
            "At step: 9537 training error: 0.5344772658547188\n",
            "At step: 9538 training error: 0.5338918078619976\n",
            "At step: 9539 training error: 0.5401808862479608\n",
            "At step: 9540 training error: 0.5310285248494457\n",
            "At step: 9541 training error: 0.5313329257496081\n",
            "At step: 9542 training error: 0.5349510112928102\n",
            "At step: 9543 training error: 0.5392899568782135\n",
            "At step: 9544 training error: 0.5383386951064972\n",
            "At step: 9545 training error: 0.5372066581358479\n",
            "At step: 9546 training error: 0.5339558719580291\n",
            "At step: 9547 training error: 0.5347480896361829\n",
            "At step: 9548 training error: 0.542282372094942\n",
            "At step: 9549 training error: 0.5385009572961319\n",
            "At step: 9550 training error: 0.5353273805543577\n",
            "At step: 9551 training error: 0.5387867442191209\n",
            "At step: 9552 training error: 0.5483292535140252\n",
            "At step: 9553 training error: 0.5407299457616388\n",
            "At step: 9554 training error: 0.5348510132021548\n",
            "At step: 9555 training error: 0.5244676642131929\n",
            "At step: 9556 training error: 0.515562336182369\n",
            "At step: 9557 training error: 0.5131503171966151\n",
            "At step: 9558 training error: 0.5123821253132148\n",
            "At step: 9559 training error: 0.5132199689007584\n",
            "At step: 9560 training error: 0.5167289680890437\n",
            "At step: 9561 training error: 0.5128358443353247\n",
            "At step: 9562 training error: 0.515169138036694\n",
            "At step: 9563 training error: 0.5255440455997973\n",
            "At step: 9564 training error: 0.5244879198816029\n",
            "At step: 9565 training error: 0.51996309733587\n",
            "At step: 9566 training error: 0.525403092772279\n",
            "At step: 9567 training error: 0.5254638723506684\n",
            "At step: 9568 training error: 0.5268448835020567\n",
            "At step: 9569 training error: 0.5245360053001141\n",
            "At step: 9570 training error: 0.5248088730157646\n",
            "At step: 9571 training error: 0.5200073563224986\n",
            "At step: 9572 training error: 0.5127532684236792\n",
            "At step: 9573 training error: 0.5144623582620809\n",
            "At step: 9574 training error: 0.514581778537645\n",
            "At step: 9575 training error: 0.5102569368572865\n",
            "At step: 9576 training error: 0.5123571133484748\n",
            "At step: 9577 training error: 0.5181554825697147\n",
            "At step: 9578 training error: 0.5211099897469158\n",
            "At step: 9579 training error: 0.5204342771657395\n",
            "At step: 9580 training error: 0.515694555589092\n",
            "At step: 9581 training error: 0.5063856542618971\n",
            "At step: 9582 training error: 0.5068309621299357\n",
            "At step: 9583 training error: 0.5021027082881595\n",
            "At step: 9584 training error: 0.5033833190944087\n",
            "At step: 9585 training error: 0.5125065554112485\n",
            "At step: 9586 training error: 0.5062627377188859\n",
            "At step: 9587 training error: 0.5042589055781104\n",
            "At step: 9588 training error: 0.501670037099964\n",
            "At step: 9589 training error: 0.5066866518372516\n",
            "At step: 9590 training error: 0.5144167262617659\n",
            "At step: 9591 training error: 0.5287261040072735\n",
            "At step: 9592 training error: 0.5191778540903584\n",
            "At step: 9593 training error: 0.5100240975762452\n",
            "At step: 9594 training error: 0.5156548485675133\n",
            "At step: 9595 training error: 0.5133109969403465\n",
            "At step: 9596 training error: 0.5120680250281857\n",
            "At step: 9597 training error: 0.522038788269845\n",
            "At step: 9598 training error: 0.5194619837764407\n",
            "At step: 9599 training error: 0.5143506867066319\n",
            "At step: 9600 training error: 0.5029023348306176\n",
            "At step: 9601 training error: 0.5194187296502483\n",
            "At step: 9602 training error: 0.5234014420683902\n",
            "At step: 9603 training error: 0.5301969480693323\n",
            "At step: 9604 training error: 0.5177688608353558\n",
            "At step: 9605 training error: 0.5219639789861887\n",
            "At step: 9606 training error: 0.5173435247994617\n",
            "At step: 9607 training error: 0.5270392744626182\n",
            "At step: 9608 training error: 0.5186607679009749\n",
            "At step: 9609 training error: 0.5183711668877627\n",
            "At step: 9610 training error: 0.5227860025252589\n",
            "At step: 9611 training error: 0.5240834791303698\n",
            "At step: 9612 training error: 0.5255184022310588\n",
            "At step: 9613 training error: 0.5326843190754417\n",
            "At step: 9614 training error: 0.5320920019582316\n",
            "At step: 9615 training error: 0.5222380720624812\n",
            "At step: 9616 training error: 0.5138541695969777\n",
            "At step: 9617 training error: 0.518864399280877\n",
            "At step: 9618 training error: 0.5176890173602495\n",
            "At step: 9619 training error: 0.5093780374310637\n",
            "At step: 9620 training error: 0.5040198552990985\n",
            "At step: 9621 training error: 0.4901937379174227\n",
            "At step: 9622 training error: 0.49769259251521253\n",
            "At step: 9623 training error: 0.49221564011977104\n",
            "At step: 9624 training error: 0.4931713896398764\n",
            "At step: 9625 training error: 0.4996052191717445\n",
            "At step: 9626 training error: 0.49991165650320557\n",
            "At step: 9627 training error: 0.5011824671793197\n",
            "At step: 9628 training error: 0.498005081497073\n",
            "At step: 9629 training error: 0.49655018439044857\n",
            "At step: 9630 training error: 0.5082946829548525\n",
            "At step: 9631 training error: 0.5036337472187684\n",
            "At step: 9632 training error: 0.5068427154376062\n",
            "At step: 9633 training error: 0.5111356412641043\n",
            "At step: 9634 training error: 0.5044210981638694\n",
            "At step: 9635 training error: 0.507496077120638\n",
            "At step: 9636 training error: 0.5105917088788837\n",
            "At step: 9637 training error: 0.5075862437857049\n",
            "At step: 9638 training error: 0.5045389376421667\n",
            "At step: 9639 training error: 0.502093086958459\n",
            "At step: 9640 training error: 0.5032779064408793\n",
            "At step: 9641 training error: 0.4910746273608761\n",
            "At step: 9642 training error: 0.5024281230780074\n",
            "At step: 9643 training error: 0.5042126247693368\n",
            "At step: 9644 training error: 0.4982924775621509\n",
            "At step: 9645 training error: 0.49966669136945274\n",
            "At step: 9646 training error: 0.49935695207042297\n",
            "At step: 9647 training error: 0.49386639611217387\n",
            "At step: 9648 training error: 0.4946417735904969\n",
            "At step: 9649 training error: 0.49761536043087795\n",
            "At step: 9650 training error: 0.4986110753009891\n",
            "At step: 9651 training error: 0.5028347797526598\n",
            "At step: 9652 training error: 0.5111985496566684\n",
            "At step: 9653 training error: 0.5125009498316305\n",
            "At step: 9654 training error: 0.5176675869574726\n",
            "At step: 9655 training error: 0.5216523608888568\n",
            "At step: 9656 training error: 0.5172076013803089\n",
            "At step: 9657 training error: 0.5134934145277708\n",
            "At step: 9658 training error: 0.5112331925576282\n",
            "At step: 9659 training error: 0.5173041140595365\n",
            "At step: 9660 training error: 0.5172856614824397\n",
            "At step: 9661 training error: 0.5141428341466482\n",
            "At step: 9662 training error: 0.5214987593258343\n",
            "At step: 9663 training error: 0.5366044842727555\n",
            "At step: 9664 training error: 0.5424455246873797\n",
            "At step: 9665 training error: 0.5383330710709455\n",
            "At step: 9666 training error: 0.5310460667158298\n",
            "At step: 9667 training error: 0.5288275083075531\n",
            "At step: 9668 training error: 0.5240622654092941\n",
            "At step: 9669 training error: 0.5356156688208453\n",
            "At step: 9670 training error: 0.5306313208477381\n",
            "At step: 9671 training error: 0.5371217131175436\n",
            "At step: 9672 training error: 0.5318168548943896\n",
            "At step: 9673 training error: 0.530793475329161\n",
            "At step: 9674 training error: 0.5197927699748174\n",
            "At step: 9675 training error: 0.5212319312033196\n",
            "At step: 9676 training error: 0.518413972118897\n",
            "At step: 9677 training error: 0.5123057670599176\n",
            "At step: 9678 training error: 0.5190394308047505\n",
            "At step: 9679 training error: 0.5191708163884586\n",
            "At step: 9680 training error: 0.5125548373723182\n",
            "At step: 9681 training error: 0.5118365913489189\n",
            "At step: 9682 training error: 0.5010108453990312\n",
            "At step: 9683 training error: 0.5041020141359825\n",
            "At step: 9684 training error: 0.49937354841122267\n",
            "At step: 9685 training error: 0.4981291348476796\n",
            "At step: 9686 training error: 0.5061699351040164\n",
            "At step: 9687 training error: 0.5010364642800119\n",
            "At step: 9688 training error: 0.5075248358834812\n",
            "At step: 9689 training error: 0.4990610453556142\n",
            "At step: 9690 training error: 0.49085225302694835\n",
            "At step: 9691 training error: 0.49161868938057635\n",
            "At step: 9692 training error: 0.49425684795024516\n",
            "At step: 9693 training error: 0.49820491151359425\n",
            "At step: 9694 training error: 0.49324566931329383\n",
            "At step: 9695 training error: 0.48805181625779875\n",
            "At step: 9696 training error: 0.48894416502174537\n",
            "At step: 9697 training error: 0.49750433232737573\n",
            "At step: 9698 training error: 0.4973630620525053\n",
            "At step: 9699 training error: 0.5010771032061088\n",
            "At step: 9700 training error: 0.4992942436012115\n",
            "At step: 9701 training error: 0.5027917195667112\n",
            "At step: 9702 training error: 0.49554805455081513\n",
            "At step: 9703 training error: 0.492127934769119\n",
            "At step: 9704 training error: 0.5043857178633245\n",
            "At step: 9705 training error: 0.503902177816252\n",
            "At step: 9706 training error: 0.5024523647675263\n",
            "At step: 9707 training error: 0.5056538343918107\n",
            "At step: 9708 training error: 0.5117756864402672\n",
            "At step: 9709 training error: 0.5088520835118139\n",
            "At step: 9710 training error: 0.5016788790982193\n",
            "At step: 9711 training error: 0.4996013404206134\n",
            "At step: 9712 training error: 0.5094353987344418\n",
            "At step: 9713 training error: 0.5156579267769493\n",
            "At step: 9714 training error: 0.5210906325920073\n",
            "At step: 9715 training error: 0.5233160530694743\n",
            "At step: 9716 training error: 0.5197333947179658\n",
            "At step: 9717 training error: 0.5229378276873193\n",
            "At step: 9718 training error: 0.5202620259818898\n",
            "At step: 9719 training error: 0.5238019998997347\n",
            "At step: 9720 training error: 0.547811447341814\n",
            "At step: 9721 training error: 0.5418629578439854\n",
            "At step: 9722 training error: 0.5315677852722575\n",
            "At step: 9723 training error: 0.5382993978796027\n",
            "At step: 9724 training error: 0.5264605059759603\n",
            "At step: 9725 training error: 0.5211677125750404\n",
            "At step: 9726 training error: 0.5128224029158119\n",
            "At step: 9727 training error: 0.5062191031230697\n",
            "At step: 9728 training error: 0.5140155874123112\n",
            "At step: 9729 training error: 0.5191641632926877\n",
            "At step: 9730 training error: 0.519655634228472\n",
            "At step: 9731 training error: 0.5169787903749601\n",
            "At step: 9732 training error: 0.5142962725287635\n",
            "At step: 9733 training error: 0.5246427047241069\n",
            "At step: 9734 training error: 0.5158563923391533\n",
            "At step: 9735 training error: 0.5241558824492383\n",
            "At step: 9736 training error: 0.5290464817388912\n",
            "At step: 9737 training error: 0.5193425503449137\n",
            "At step: 9738 training error: 0.5144296078355249\n",
            "At step: 9739 training error: 0.5132174076417774\n",
            "At step: 9740 training error: 0.5128704200479483\n",
            "At step: 9741 training error: 0.5152703529236147\n",
            "At step: 9742 training error: 0.5192383478479515\n",
            "At step: 9743 training error: 0.5189043830497749\n",
            "At step: 9744 training error: 0.520064091369454\n",
            "At step: 9745 training error: 0.5058860508864715\n",
            "At step: 9746 training error: 0.5137598052719892\n",
            "At step: 9747 training error: 0.506649119577469\n",
            "At step: 9748 training error: 0.5101794534459367\n",
            "At step: 9749 training error: 0.5119124737738587\n",
            "At step: 9750 training error: 0.5102726963006743\n",
            "At step: 9751 training error: 0.5260921396265238\n",
            "At step: 9752 training error: 0.5137127402254684\n",
            "At step: 9753 training error: 0.5199769725827319\n",
            "At step: 9754 training error: 0.5144657071783456\n",
            "At step: 9755 training error: 0.5132860238188466\n",
            "At step: 9756 training error: 0.5153380385448982\n",
            "At step: 9757 training error: 0.5129134897011444\n",
            "At step: 9758 training error: 0.5119012046470295\n",
            "At step: 9759 training error: 0.5045514552586705\n",
            "At step: 9760 training error: 0.5128664738015231\n",
            "At step: 9761 training error: 0.5051033243485069\n",
            "At step: 9762 training error: 0.5166769451521118\n",
            "At step: 9763 training error: 0.5143372757323413\n",
            "At step: 9764 training error: 0.5064707045618634\n",
            "At step: 9765 training error: 0.5077326031644838\n",
            "At step: 9766 training error: 0.5097556684453816\n",
            "At step: 9767 training error: 0.5066741541654629\n",
            "At step: 9768 training error: 0.5084973119460041\n",
            "At step: 9769 training error: 0.5195493614453411\n",
            "At step: 9770 training error: 0.5197518039507231\n",
            "At step: 9771 training error: 0.5074580530429593\n",
            "At step: 9772 training error: 0.5112027297704934\n",
            "At step: 9773 training error: 0.5021454598043027\n",
            "At step: 9774 training error: 0.5000460693015673\n",
            "At step: 9775 training error: 0.5036570689483835\n",
            "At step: 9776 training error: 0.5100960621469979\n",
            "At step: 9777 training error: 0.5126447093596924\n",
            "At step: 9778 training error: 0.515512704299936\n",
            "At step: 9779 training error: 0.5225821603229146\n",
            "At step: 9780 training error: 0.5190814561530132\n",
            "At step: 9781 training error: 0.5139368582738597\n",
            "At step: 9782 training error: 0.5046994892185548\n",
            "At step: 9783 training error: 0.5083197615978982\n",
            "At step: 9784 training error: 0.5217622516874325\n",
            "At step: 9785 training error: 0.5231194662891787\n",
            "At step: 9786 training error: 0.5137178727064179\n",
            "At step: 9787 training error: 0.5109659656786708\n",
            "At step: 9788 training error: 0.5133969639956775\n",
            "At step: 9789 training error: 0.5094886033866656\n",
            "At step: 9790 training error: 0.4971791964670465\n",
            "At step: 9791 training error: 0.49515711714037164\n",
            "At step: 9792 training error: 0.5023461515207701\n",
            "At step: 9793 training error: 0.49337419031115687\n",
            "At step: 9794 training error: 0.49160411160078743\n",
            "At step: 9795 training error: 0.48787032157125715\n",
            "At step: 9796 training error: 0.4794328339353698\n",
            "At step: 9797 training error: 0.4812230220819675\n",
            "At step: 9798 training error: 0.4704270384126611\n",
            "At step: 9799 training error: 0.4635037651757884\n",
            "At step: 9800 training error: 0.4711241707265384\n",
            "At step: 9801 training error: 0.47098545601962993\n",
            "At step: 9802 training error: 0.48625378905999356\n",
            "At step: 9803 training error: 0.49161517200852967\n",
            "At step: 9804 training error: 0.5019309308105112\n",
            "At step: 9805 training error: 0.4899568874610824\n",
            "At step: 9806 training error: 0.4870907591487993\n",
            "At step: 9807 training error: 0.4792448389739614\n",
            "At step: 9808 training error: 0.482256203091275\n",
            "At step: 9809 training error: 0.4819729585988193\n",
            "At step: 9810 training error: 0.48214208113961077\n",
            "At step: 9811 training error: 0.4919066740840885\n",
            "At step: 9812 training error: 0.4927120088495375\n",
            "At step: 9813 training error: 0.49830590100765687\n",
            "At step: 9814 training error: 0.5015473909234779\n",
            "At step: 9815 training error: 0.5015067110750645\n",
            "At step: 9816 training error: 0.5030119289372639\n",
            "At step: 9817 training error: 0.5035871915538854\n",
            "At step: 9818 training error: 0.4995463243459059\n",
            "At step: 9819 training error: 0.5063533358443691\n",
            "At step: 9820 training error: 0.501946479784418\n",
            "At step: 9821 training error: 0.5065241760542419\n",
            "At step: 9822 training error: 0.5092641537435955\n",
            "At step: 9823 training error: 0.5151497266875296\n",
            "At step: 9824 training error: 0.5199261743645222\n",
            "At step: 9825 training error: 0.5182155228289314\n",
            "At step: 9826 training error: 0.5166281058192901\n",
            "At step: 9827 training error: 0.5146462145318097\n",
            "At step: 9828 training error: 0.5070034496863731\n",
            "At step: 9829 training error: 0.5052110867987615\n",
            "At step: 9830 training error: 0.5149520257168971\n",
            "At step: 9831 training error: 0.5110502535507501\n",
            "At step: 9832 training error: 0.5092998874902228\n",
            "At step: 9833 training error: 0.5070768467222769\n",
            "At step: 9834 training error: 0.512385594459363\n",
            "At step: 9835 training error: 0.5165962290262103\n",
            "At step: 9836 training error: 0.5147160410623961\n",
            "At step: 9837 training error: 0.508815641979011\n",
            "At step: 9838 training error: 0.5120111394832868\n",
            "At step: 9839 training error: 0.514961235066109\n",
            "At step: 9840 training error: 0.50678561305865\n",
            "At step: 9841 training error: 0.5028766535962065\n",
            "At step: 9842 training error: 0.5104700587550827\n",
            "At step: 9843 training error: 0.5064147779786108\n",
            "At step: 9844 training error: 0.5032460935529681\n",
            "At step: 9845 training error: 0.5092432072201456\n",
            "At step: 9846 training error: 0.5072160733080411\n",
            "At step: 9847 training error: 0.514877804060081\n",
            "At step: 9848 training error: 0.5077850359696777\n",
            "At step: 9849 training error: 0.503402904987188\n",
            "At step: 9850 training error: 0.5028248850159769\n",
            "At step: 9851 training error: 0.501105539177954\n",
            "At step: 9852 training error: 0.5027540380384197\n",
            "At step: 9853 training error: 0.49990032529665707\n",
            "At step: 9854 training error: 0.5151994624750734\n",
            "At step: 9855 training error: 0.5113283568463036\n",
            "At step: 9856 training error: 0.501745187015102\n",
            "At step: 9857 training error: 0.5042236244247441\n",
            "At step: 9858 training error: 0.5053354892906424\n",
            "At step: 9859 training error: 0.5018977423076869\n",
            "At step: 9860 training error: 0.49529304948628905\n",
            "At step: 9861 training error: 0.48887785099483855\n",
            "At step: 9862 training error: 0.4878887808027782\n",
            "At step: 9863 training error: 0.492830595574261\n",
            "At step: 9864 training error: 0.4991364486341831\n",
            "At step: 9865 training error: 0.5035830962196874\n",
            "At step: 9866 training error: 0.5090954350849112\n",
            "At step: 9867 training error: 0.5110828542975904\n",
            "At step: 9868 training error: 0.49403375094941576\n",
            "At step: 9869 training error: 0.49252042059824697\n",
            "At step: 9870 training error: 0.49699022605484605\n",
            "At step: 9871 training error: 0.49964496980806616\n",
            "At step: 9872 training error: 0.49749985823967857\n",
            "At step: 9873 training error: 0.5041399866638814\n",
            "At step: 9874 training error: 0.49565092218939594\n",
            "At step: 9875 training error: 0.4978157176186545\n",
            "At step: 9876 training error: 0.5047862139069692\n",
            "At step: 9877 training error: 0.5172363902664452\n",
            "At step: 9878 training error: 0.5117891494244629\n",
            "At step: 9879 training error: 0.5175727051783424\n",
            "At step: 9880 training error: 0.5229285542905885\n",
            "At step: 9881 training error: 0.5214221202552531\n",
            "At step: 9882 training error: 0.5131222438403865\n",
            "At step: 9883 training error: 0.5113525977256853\n",
            "At step: 9884 training error: 0.5110024451383953\n",
            "At step: 9885 training error: 0.5177798152014229\n",
            "At step: 9886 training error: 0.5186214486497985\n",
            "At step: 9887 training error: 0.5128084338654226\n",
            "At step: 9888 training error: 0.5158614979493384\n",
            "At step: 9889 training error: 0.5146252028921838\n",
            "At step: 9890 training error: 0.5108425705017299\n",
            "At step: 9891 training error: 0.520040683384948\n",
            "At step: 9892 training error: 0.5209594005767186\n",
            "At step: 9893 training error: 0.5170076821871838\n",
            "At step: 9894 training error: 0.5154728893837979\n",
            "At step: 9895 training error: 0.5152259751092203\n",
            "At step: 9896 training error: 0.5081984101220918\n",
            "At step: 9897 training error: 0.5125869042174683\n",
            "At step: 9898 training error: 0.5197075513167131\n",
            "At step: 9899 training error: 0.5185628685893785\n",
            "At step: 9900 training error: 0.5094651892891\n",
            "At step: 9901 training error: 0.50982264548035\n",
            "At step: 9902 training error: 0.5126323471345213\n",
            "At step: 9903 training error: 0.5066116835457966\n",
            "At step: 9904 training error: 0.5073618360596932\n",
            "At step: 9905 training error: 0.5009655792070985\n",
            "At step: 9906 training error: 0.4978159826743151\n",
            "At step: 9907 training error: 0.5114846092106198\n",
            "At step: 9908 training error: 0.5119648451817846\n",
            "At step: 9909 training error: 0.5097873746893545\n",
            "At step: 9910 training error: 0.5079761852363076\n",
            "At step: 9911 training error: 0.5041219787824259\n",
            "At step: 9912 training error: 0.4971643800084526\n",
            "At step: 9913 training error: 0.4954025376168059\n",
            "At step: 9914 training error: 0.4872113123628599\n",
            "At step: 9915 training error: 0.4963050508430853\n",
            "At step: 9916 training error: 0.5046578374269157\n",
            "At step: 9917 training error: 0.5157864451450744\n",
            "At step: 9918 training error: 0.5044326937436155\n",
            "At step: 9919 training error: 0.5107487085199273\n",
            "At step: 9920 training error: 0.498779118662531\n",
            "At step: 9921 training error: 0.5015557562872011\n",
            "At step: 9922 training error: 0.5053597275432328\n",
            "At step: 9923 training error: 0.5024007681013174\n",
            "At step: 9924 training error: 0.49925032983770923\n",
            "At step: 9925 training error: 0.5105720721177021\n",
            "At step: 9926 training error: 0.5039472500357254\n",
            "At step: 9927 training error: 0.5096586162335812\n",
            "At step: 9928 training error: 0.5185327836682374\n",
            "At step: 9929 training error: 0.5162612266468016\n",
            "At step: 9930 training error: 0.5119318023862649\n",
            "At step: 9931 training error: 0.5109291292461696\n",
            "At step: 9932 training error: 0.5039344833303628\n",
            "At step: 9933 training error: 0.5094236485389763\n",
            "At step: 9934 training error: 0.5038659200232611\n",
            "At step: 9935 training error: 0.5038498868073178\n",
            "At step: 9936 training error: 0.5139040585242532\n",
            "At step: 9937 training error: 0.5106051070540683\n",
            "At step: 9938 training error: 0.5000525060325883\n",
            "At step: 9939 training error: 0.4935312750068729\n",
            "At step: 9940 training error: 0.49489186820500597\n",
            "At step: 9941 training error: 0.4881676973094422\n",
            "At step: 9942 training error: 0.4895324399834118\n",
            "At step: 9943 training error: 0.4920001504710129\n",
            "At step: 9944 training error: 0.49265140470909685\n",
            "At step: 9945 training error: 0.49919347046803375\n",
            "At step: 9946 training error: 0.49287124311271535\n",
            "At step: 9947 training error: 0.4909237367664988\n",
            "At step: 9948 training error: 0.4847863800502437\n",
            "At step: 9949 training error: 0.4950395747887582\n",
            "At step: 9950 training error: 0.5003325805032282\n",
            "At step: 9951 training error: 0.4919781868245259\n",
            "At step: 9952 training error: 0.492724414081753\n",
            "At step: 9953 training error: 0.49166705994379073\n",
            "At step: 9954 training error: 0.4823402396893408\n",
            "At step: 9955 training error: 0.47645724193481975\n",
            "At step: 9956 training error: 0.49223939508831693\n",
            "At step: 9957 training error: 0.49452379853322465\n",
            "At step: 9958 training error: 0.4869130306652063\n",
            "At step: 9959 training error: 0.4772995527291792\n",
            "At step: 9960 training error: 0.46834211438221096\n",
            "At step: 9961 training error: 0.47597693760851395\n",
            "At step: 9962 training error: 0.48616921186199596\n",
            "At step: 9963 training error: 0.4865506370602615\n",
            "At step: 9964 training error: 0.49407849706975504\n",
            "At step: 9965 training error: 0.48604276843019645\n",
            "At step: 9966 training error: 0.4905219259230215\n",
            "At step: 9967 training error: 0.4931135339903761\n",
            "At step: 9968 training error: 0.49225899832167536\n",
            "At step: 9969 training error: 0.49300047808408376\n",
            "At step: 9970 training error: 0.5148501078611534\n",
            "At step: 9971 training error: 0.5224560918567388\n",
            "At step: 9972 training error: 0.5300757564025274\n",
            "At step: 9973 training error: 0.5359723467187406\n",
            "At step: 9974 training error: 0.5306287417180833\n",
            "At step: 9975 training error: 0.5257965447368947\n",
            "At step: 9976 training error: 0.5280115837195521\n",
            "At step: 9977 training error: 0.5182855129559161\n",
            "At step: 9978 training error: 0.50750420952333\n",
            "At step: 9979 training error: 0.5154390050551959\n",
            "At step: 9980 training error: 0.5204014201056605\n",
            "At step: 9981 training error: 0.5283412045962977\n",
            "At step: 9982 training error: 0.5317584106082692\n",
            "At step: 9983 training error: 0.5298671749553461\n",
            "At step: 9984 training error: 0.5340524590889051\n",
            "At step: 9985 training error: 0.5320154295129365\n",
            "At step: 9986 training error: 0.5134700140417918\n",
            "At step: 9987 training error: 0.5092084781058982\n",
            "At step: 9988 training error: 0.5107531734345523\n",
            "At step: 9989 training error: 0.5053215701593027\n",
            "At step: 9990 training error: 0.5076801307421053\n",
            "At step: 9991 training error: 0.511360287597626\n",
            "At step: 9992 training error: 0.5044703257256817\n",
            "At step: 9993 training error: 0.5025576969047305\n",
            "At step: 9994 training error: 0.504147721032244\n",
            "At step: 9995 training error: 0.5020367456498882\n",
            "At step: 9996 training error: 0.49964879999564893\n",
            "At step: 9997 training error: 0.5029104770829131\n",
            "At step: 9998 training error: 0.49603991793203195\n",
            "At step: 9999 training error: 0.4948210835599093\n",
            "At Epoch 0, validation error: 0.057496060330757055, validation accuracy 0.6245\n",
            "At step: 0 training error: 0.427391748709561\n",
            "At step: 1 training error: 0.4348974276268863\n",
            "At step: 2 training error: 0.43853162472289375\n",
            "At step: 3 training error: 0.4434613514588017\n",
            "At step: 4 training error: 0.45347817264416784\n",
            "At step: 5 training error: 0.46608820667433704\n",
            "At step: 6 training error: 0.4686264476048456\n",
            "At step: 7 training error: 0.47715909070872464\n",
            "At step: 8 training error: 0.4910679682427883\n",
            "At step: 9 training error: 0.48924179902617887\n",
            "At step: 10 training error: 0.4827353809662898\n",
            "At step: 11 training error: 0.491477857018169\n",
            "At step: 12 training error: 0.482626632161858\n",
            "At step: 13 training error: 0.48944740071169274\n",
            "At step: 14 training error: 0.4949958534807588\n",
            "At step: 15 training error: 0.48382762791089634\n",
            "At step: 16 training error: 0.4799248615106888\n",
            "At step: 17 training error: 0.4827529263393985\n",
            "At step: 18 training error: 0.4933514272043154\n",
            "At step: 19 training error: 0.48114339653300414\n",
            "At step: 20 training error: 0.48176035699150566\n",
            "At step: 21 training error: 0.478203360834406\n",
            "At step: 22 training error: 0.48954825671067637\n",
            "At step: 23 training error: 0.5064895414129265\n",
            "At step: 24 training error: 0.5131143024911818\n",
            "At step: 25 training error: 0.5140034640619404\n",
            "At step: 26 training error: 0.5121996188147457\n",
            "At step: 27 training error: 0.5031613743148655\n",
            "At step: 28 training error: 0.5045794007571476\n",
            "At step: 29 training error: 0.5011477950043851\n",
            "At step: 30 training error: 0.5009513414448432\n",
            "At step: 31 training error: 0.5009600264958869\n",
            "At step: 32 training error: 0.5177207184859589\n",
            "At step: 33 training error: 0.5151349546570381\n",
            "At step: 34 training error: 0.513017847335835\n",
            "At step: 35 training error: 0.516263987390433\n",
            "At step: 36 training error: 0.5205386917527327\n",
            "At step: 37 training error: 0.5118010925948966\n",
            "At step: 38 training error: 0.5155365033785138\n",
            "At step: 39 training error: 0.5172055948030718\n",
            "At step: 40 training error: 0.5325827435609\n",
            "At step: 41 training error: 0.5269292075958947\n",
            "At step: 42 training error: 0.5220645415725559\n",
            "At step: 43 training error: 0.5245690780088588\n",
            "At step: 44 training error: 0.5242744979354708\n",
            "At step: 45 training error: 0.5286019832317341\n",
            "At step: 46 training error: 0.5364956208117049\n",
            "At step: 47 training error: 0.5383050103484399\n",
            "At step: 48 training error: 0.5218229047339454\n",
            "At step: 49 training error: 0.5195292253886539\n",
            "At step: 50 training error: 0.5164019916772866\n",
            "At step: 51 training error: 0.5137606501636185\n",
            "At step: 52 training error: 0.5159302104391689\n",
            "At step: 53 training error: 0.5186193075965089\n",
            "At step: 54 training error: 0.5272552320016151\n",
            "At step: 55 training error: 0.532067531973947\n",
            "At step: 56 training error: 0.5274662329486384\n",
            "At step: 57 training error: 0.5178282880316473\n",
            "At step: 58 training error: 0.5195626340145423\n",
            "At step: 59 training error: 0.513289429845124\n",
            "At step: 60 training error: 0.5204731881708187\n",
            "At step: 61 training error: 0.5173173888135072\n",
            "At step: 62 training error: 0.522898252697081\n",
            "At step: 63 training error: 0.512737194756569\n",
            "At step: 64 training error: 0.5186935573825189\n",
            "At step: 65 training error: 0.5123334457784015\n",
            "At step: 66 training error: 0.5097626311079656\n",
            "At step: 67 training error: 0.5334415349639048\n",
            "At step: 68 training error: 0.5404815059190642\n",
            "At step: 69 training error: 0.5276270799305565\n",
            "At step: 70 training error: 0.5236729787719805\n",
            "At step: 71 training error: 0.5273803269976799\n",
            "At step: 72 training error: 0.5187435911365208\n",
            "At step: 73 training error: 0.5096024177823875\n",
            "At step: 74 training error: 0.5103101989808948\n",
            "At step: 75 training error: 0.5108477222448603\n",
            "At step: 76 training error: 0.5071784432706549\n",
            "At step: 77 training error: 0.5060668080296733\n",
            "At step: 78 training error: 0.49800671613450354\n",
            "At step: 79 training error: 0.494223703874824\n",
            "At step: 80 training error: 0.49422343239961597\n",
            "At step: 81 training error: 0.48733988474084144\n",
            "At step: 82 training error: 0.48749952426722615\n",
            "At step: 83 training error: 0.48975659113709546\n",
            "At step: 84 training error: 0.4901881714491297\n",
            "At step: 85 training error: 0.49264883712757923\n",
            "At step: 86 training error: 0.4915168506669596\n",
            "At step: 87 training error: 0.507256988416326\n",
            "At step: 88 training error: 0.5134926265505545\n",
            "At step: 89 training error: 0.5105597060243399\n",
            "At step: 90 training error: 0.5150693330416469\n",
            "At step: 91 training error: 0.5063344455436828\n",
            "At step: 92 training error: 0.5016880972366011\n",
            "At step: 93 training error: 0.4876423565637257\n",
            "At step: 94 training error: 0.48343704766687823\n",
            "At step: 95 training error: 0.4909412654054936\n",
            "At step: 96 training error: 0.48842006334022\n",
            "At step: 97 training error: 0.49066220498078444\n",
            "At step: 98 training error: 0.4976109898227222\n",
            "At step: 99 training error: 0.49537997590554744\n",
            "At step: 100 training error: 0.4906345347735478\n",
            "At step: 101 training error: 0.4920843461606795\n",
            "At step: 102 training error: 0.5049581610854275\n",
            "At step: 103 training error: 0.5088373576195511\n",
            "At step: 104 training error: 0.5142589456875569\n",
            "At step: 105 training error: 0.5149242767441194\n",
            "At step: 106 training error: 0.5080322930349732\n",
            "At step: 107 training error: 0.4979423993808604\n",
            "At step: 108 training error: 0.49541532803210825\n",
            "At step: 109 training error: 0.49183960492535195\n",
            "At step: 110 training error: 0.4904101130907432\n",
            "At step: 111 training error: 0.48306867349990684\n",
            "At step: 112 training error: 0.4814866299803766\n",
            "At step: 113 training error: 0.48866080508207344\n",
            "At step: 114 training error: 0.49370881370319103\n",
            "At step: 115 training error: 0.4961508093796828\n",
            "At step: 116 training error: 0.5032406305431394\n",
            "At step: 117 training error: 0.4973190579463457\n",
            "At step: 118 training error: 0.4930414207670947\n",
            "At step: 119 training error: 0.5078155550882433\n",
            "At step: 120 training error: 0.5075159163400504\n",
            "At step: 121 training error: 0.49961426734790765\n",
            "At step: 122 training error: 0.4875704734266741\n",
            "At step: 123 training error: 0.48873546467032686\n",
            "At step: 124 training error: 0.48159311392538307\n",
            "At step: 125 training error: 0.4859704853176454\n",
            "At step: 126 training error: 0.4972564338282795\n",
            "At step: 127 training error: 0.4920381088245852\n",
            "At step: 128 training error: 0.5084440986972978\n",
            "At step: 129 training error: 0.5115515452377304\n",
            "At step: 130 training error: 0.5130035916055238\n",
            "At step: 131 training error: 0.5091871071648657\n",
            "At step: 132 training error: 0.5188929525330006\n",
            "At step: 133 training error: 0.5165481346157974\n",
            "At step: 134 training error: 0.5143984880351142\n",
            "At step: 135 training error: 0.5205250569778302\n",
            "At step: 136 training error: 0.5122011765674561\n",
            "At step: 137 training error: 0.5042791290545258\n",
            "At step: 138 training error: 0.5107088924119607\n",
            "At step: 139 training error: 0.509443504252422\n",
            "At step: 140 training error: 0.512357166933644\n",
            "At step: 141 training error: 0.5281203651226675\n",
            "At step: 142 training error: 0.5248717117672151\n",
            "At step: 143 training error: 0.5143541549666467\n",
            "At step: 144 training error: 0.5172108126144692\n",
            "At step: 145 training error: 0.5134420783831115\n",
            "At step: 146 training error: 0.522358871442231\n",
            "At step: 147 training error: 0.5253998058017624\n",
            "At step: 148 training error: 0.5109941537194621\n",
            "At step: 149 training error: 0.5056824432590968\n",
            "At step: 150 training error: 0.5010049783830249\n",
            "At step: 151 training error: 0.49884826835617\n",
            "At step: 152 training error: 0.49766238177156874\n",
            "At step: 153 training error: 0.5037188910127829\n",
            "At step: 154 training error: 0.50346569311631\n",
            "At step: 155 training error: 0.5013177476931835\n",
            "At step: 156 training error: 0.502652836538357\n",
            "At step: 157 training error: 0.5034586400488938\n",
            "At step: 158 training error: 0.49834916836416715\n",
            "At step: 159 training error: 0.5032412728455786\n",
            "At step: 160 training error: 0.5029377297019849\n",
            "At step: 161 training error: 0.5071571897754614\n",
            "At step: 162 training error: 0.5061994618584824\n",
            "At step: 163 training error: 0.5026133562938726\n",
            "At step: 164 training error: 0.4933819256511939\n",
            "At step: 165 training error: 0.49928253048880755\n",
            "At step: 166 training error: 0.5006729931116947\n",
            "At step: 167 training error: 0.5005614299468815\n",
            "At step: 168 training error: 0.5097442832641687\n",
            "At step: 169 training error: 0.5040960380420687\n",
            "At step: 170 training error: 0.5049533031044136\n",
            "At step: 171 training error: 0.5077109686203395\n",
            "At step: 172 training error: 0.4979067155039557\n",
            "At step: 173 training error: 0.5054706905797614\n",
            "At step: 174 training error: 0.5106631651545084\n",
            "At step: 175 training error: 0.5127991855745344\n",
            "At step: 176 training error: 0.5141709746288291\n",
            "At step: 177 training error: 0.5195544010168816\n",
            "At step: 178 training error: 0.5068979664650897\n",
            "At step: 179 training error: 0.5101967528647123\n",
            "At step: 180 training error: 0.5091660884933279\n",
            "At step: 181 training error: 0.5163959671871587\n",
            "At step: 182 training error: 0.5079340394964926\n",
            "At step: 183 training error: 0.5051855578022332\n",
            "At step: 184 training error: 0.5052330138881257\n",
            "At step: 185 training error: 0.5025012853982335\n",
            "At step: 186 training error: 0.49841322927440745\n",
            "At step: 187 training error: 0.498327459585806\n",
            "At step: 188 training error: 0.4944293011447401\n",
            "At step: 189 training error: 0.5020583253833792\n",
            "At step: 190 training error: 0.5063820749404838\n",
            "At step: 191 training error: 0.51628475781846\n",
            "At step: 192 training error: 0.5135258800779922\n",
            "At step: 193 training error: 0.5140769602860031\n",
            "At step: 194 training error: 0.5127858251672559\n",
            "At step: 195 training error: 0.509655565734677\n",
            "At step: 196 training error: 0.5042651111177199\n",
            "At step: 197 training error: 0.5040931670110568\n",
            "At step: 198 training error: 0.504220166648786\n",
            "At step: 199 training error: 0.5021307933601866\n",
            "At step: 200 training error: 0.5001388078421474\n",
            "At step: 201 training error: 0.5069506291466725\n",
            "At step: 202 training error: 0.5030404012899428\n",
            "At step: 203 training error: 0.4997099768543701\n",
            "At step: 204 training error: 0.5173256449917348\n",
            "At step: 205 training error: 0.5151092788058599\n",
            "At step: 206 training error: 0.5074510813811771\n",
            "At step: 207 training error: 0.5006835946608135\n",
            "At step: 208 training error: 0.5075685673695987\n",
            "At step: 209 training error: 0.5187195970394896\n",
            "At step: 210 training error: 0.520778488763336\n",
            "At step: 211 training error: 0.5148642699237279\n",
            "At step: 212 training error: 0.5109740505680969\n",
            "At step: 213 training error: 0.5072879905080004\n",
            "At step: 214 training error: 0.5019125270080478\n",
            "At step: 215 training error: 0.5054440314189217\n",
            "At step: 216 training error: 0.5102187402879194\n",
            "At step: 217 training error: 0.5044334155290783\n",
            "At step: 218 training error: 0.5153302782771487\n",
            "At step: 219 training error: 0.5091133582809817\n",
            "At step: 220 training error: 0.4913593154426706\n",
            "At step: 221 training error: 0.49891835645247445\n",
            "At step: 222 training error: 0.4870217273776169\n",
            "At step: 223 training error: 0.4905955125162783\n",
            "At step: 224 training error: 0.48647242027458765\n",
            "At step: 225 training error: 0.4891497095978012\n",
            "At step: 226 training error: 0.5025878791098065\n",
            "At step: 227 training error: 0.5044428474735747\n",
            "At step: 228 training error: 0.5031859999915548\n",
            "At step: 229 training error: 0.4999524188702583\n",
            "At step: 230 training error: 0.505893202263032\n",
            "At step: 231 training error: 0.5064793977550164\n",
            "At step: 232 training error: 0.5090999090259835\n",
            "At step: 233 training error: 0.5138964358231224\n",
            "At step: 234 training error: 0.5031506925559782\n",
            "At step: 235 training error: 0.49807115542150626\n",
            "At step: 236 training error: 0.4976366776018355\n",
            "At step: 237 training error: 0.4919113967678689\n",
            "At step: 238 training error: 0.49232177350720097\n",
            "At step: 239 training error: 0.4914360177630181\n",
            "At step: 240 training error: 0.4938260905345604\n",
            "At step: 241 training error: 0.4958375730487946\n",
            "At step: 242 training error: 0.4930535043506098\n",
            "At step: 243 training error: 0.49489711454547963\n",
            "At step: 244 training error: 0.5033879344585961\n",
            "At step: 245 training error: 0.5045112000175338\n",
            "At step: 246 training error: 0.5070437331506917\n",
            "At step: 247 training error: 0.5101655135985582\n",
            "At step: 248 training error: 0.525540012707114\n",
            "At step: 249 training error: 0.518593468941652\n",
            "At step: 250 training error: 0.5126550947327276\n",
            "At step: 251 training error: 0.5093090459140105\n",
            "At step: 252 training error: 0.509288483159318\n",
            "At step: 253 training error: 0.508784416395127\n",
            "At step: 254 training error: 0.5082834347888266\n",
            "At step: 255 training error: 0.5050707659948981\n",
            "At step: 256 training error: 0.5048003173539742\n",
            "At step: 257 training error: 0.4993589798648309\n",
            "At step: 258 training error: 0.48306480920497535\n",
            "At step: 259 training error: 0.48788502050009885\n",
            "At step: 260 training error: 0.48271683493567885\n",
            "At step: 261 training error: 0.4981401732329141\n",
            "At step: 262 training error: 0.4877359654329133\n",
            "At step: 263 training error: 0.49526946917300474\n",
            "At step: 264 training error: 0.503566657113505\n",
            "At step: 265 training error: 0.489728924508795\n",
            "At step: 266 training error: 0.4956628748436885\n",
            "At step: 267 training error: 0.5055562334302988\n",
            "At step: 268 training error: 0.5025891990445652\n",
            "At step: 269 training error: 0.4899654376521534\n",
            "At step: 270 training error: 0.4885002258708884\n",
            "At step: 271 training error: 0.49328908296892326\n",
            "At step: 272 training error: 0.4911193666887701\n",
            "At step: 273 training error: 0.49485593667480976\n",
            "At step: 274 training error: 0.4916638714569888\n",
            "At step: 275 training error: 0.4989867792369576\n",
            "At step: 276 training error: 0.4876836293914179\n",
            "At step: 277 training error: 0.4860091605745536\n",
            "At step: 278 training error: 0.478518615886649\n",
            "At step: 279 training error: 0.48663849820298416\n",
            "At step: 280 training error: 0.49097734460086123\n",
            "At step: 281 training error: 0.48849931104871813\n",
            "At step: 282 training error: 0.4830686907219143\n",
            "At step: 283 training error: 0.4989709855632754\n",
            "At step: 284 training error: 0.4976751243047182\n",
            "At step: 285 training error: 0.5042485807032442\n",
            "At step: 286 training error: 0.5083684823620992\n",
            "At step: 287 training error: 0.5090362353442277\n",
            "At step: 288 training error: 0.5142343519758072\n",
            "At step: 289 training error: 0.5204711494315657\n",
            "At step: 290 training error: 0.528498430347244\n",
            "At step: 291 training error: 0.5276783723780909\n",
            "At step: 292 training error: 0.5312117502049436\n",
            "At step: 293 training error: 0.5263028487044568\n",
            "At step: 294 training error: 0.5193685006520756\n",
            "At step: 295 training error: 0.5216800562844247\n",
            "At step: 296 training error: 0.5194469109657703\n",
            "At step: 297 training error: 0.5116214819605462\n",
            "At step: 298 training error: 0.511177983859111\n",
            "At step: 299 training error: 0.5010498628263416\n",
            "At step: 300 training error: 0.4962657685833396\n",
            "At step: 301 training error: 0.4963622496485094\n",
            "At step: 302 training error: 0.49403898182952155\n",
            "At step: 303 training error: 0.5000750991466741\n",
            "At step: 304 training error: 0.49810480918379507\n",
            "At step: 305 training error: 0.5007771411354887\n",
            "At step: 306 training error: 0.5051126313690041\n",
            "At step: 307 training error: 0.5007136195723599\n",
            "At step: 308 training error: 0.503998621033472\n",
            "At step: 309 training error: 0.5015677626114433\n",
            "At step: 310 training error: 0.48865410661981046\n",
            "At step: 311 training error: 0.497745746055147\n",
            "At step: 312 training error: 0.49706129784348785\n",
            "At step: 313 training error: 0.4939759803264691\n",
            "At step: 314 training error: 0.4958104849400357\n",
            "At step: 315 training error: 0.5023029688968716\n",
            "At step: 316 training error: 0.5072673600138348\n",
            "At step: 317 training error: 0.515030453247542\n",
            "At step: 318 training error: 0.5097532045080303\n",
            "At step: 319 training error: 0.5096416679065949\n",
            "At step: 320 training error: 0.5041876524479789\n",
            "At step: 321 training error: 0.49940591831371417\n",
            "At step: 322 training error: 0.4997738805262327\n",
            "At step: 323 training error: 0.4951368051903575\n",
            "At step: 324 training error: 0.4867983008241104\n",
            "At step: 325 training error: 0.49142737819507387\n",
            "At step: 326 training error: 0.5011880952247874\n",
            "At step: 327 training error: 0.5017049958735595\n",
            "At step: 328 training error: 0.4939653292775903\n",
            "At step: 329 training error: 0.48585862748980774\n",
            "At step: 330 training error: 0.48581608981509095\n",
            "At step: 331 training error: 0.4820755083947511\n",
            "At step: 332 training error: 0.4776400196751778\n",
            "At step: 333 training error: 0.48725239061595926\n",
            "At step: 334 training error: 0.481953718468181\n",
            "At step: 335 training error: 0.4888544806444699\n",
            "At step: 336 training error: 0.485127589472931\n",
            "At step: 337 training error: 0.48649402087681126\n",
            "At step: 338 training error: 0.4929511120800154\n",
            "At step: 339 training error: 0.49717462490608516\n",
            "At step: 340 training error: 0.4892392881787885\n",
            "At step: 341 training error: 0.49466967650198207\n",
            "At step: 342 training error: 0.4917941848944728\n",
            "At step: 343 training error: 0.49331229428433643\n",
            "At step: 344 training error: 0.49079031033250786\n",
            "At step: 345 training error: 0.49304514166426566\n",
            "At step: 346 training error: 0.48452477534311933\n",
            "At step: 347 training error: 0.5041366190454957\n",
            "At step: 348 training error: 0.5021270716906228\n",
            "At step: 349 training error: 0.49766726442769726\n",
            "At step: 350 training error: 0.5015801213905202\n",
            "At step: 351 training error: 0.4942835168854164\n",
            "At step: 352 training error: 0.48692688565238856\n",
            "At step: 353 training error: 0.4805535437345467\n",
            "At step: 354 training error: 0.4910613635776625\n",
            "At step: 355 training error: 0.5019717390666386\n",
            "At step: 356 training error: 0.49842169997030367\n",
            "At step: 357 training error: 0.4982778789103984\n",
            "At step: 358 training error: 0.4906241980950245\n",
            "At step: 359 training error: 0.48614646098873904\n",
            "At step: 360 training error: 0.484242333029296\n",
            "At step: 361 training error: 0.4856798983104391\n",
            "At step: 362 training error: 0.47938005389788757\n",
            "At step: 363 training error: 0.48182121845942266\n",
            "At step: 364 training error: 0.4883750466553311\n",
            "At step: 365 training error: 0.49451057321137215\n",
            "At step: 366 training error: 0.4935674478685399\n",
            "At step: 367 training error: 0.49703287696375453\n",
            "At step: 368 training error: 0.49178353870187175\n",
            "At step: 369 training error: 0.48352741473592553\n",
            "At step: 370 training error: 0.4885100131936408\n",
            "At step: 371 training error: 0.4818128518717036\n",
            "At step: 372 training error: 0.4758980505690751\n",
            "At step: 373 training error: 0.47561480577839915\n",
            "At step: 374 training error: 0.4860287147169759\n",
            "At step: 375 training error: 0.4807406831930474\n",
            "At step: 376 training error: 0.47367722762814696\n",
            "At step: 377 training error: 0.4810322067841409\n",
            "At step: 378 training error: 0.4837053176431257\n",
            "At step: 379 training error: 0.47925346042908507\n",
            "At step: 380 training error: 0.48056280103361826\n",
            "At step: 381 training error: 0.48265495514034523\n",
            "At step: 382 training error: 0.49034030846957427\n",
            "At step: 383 training error: 0.49858257137216566\n",
            "At step: 384 training error: 0.49477065763172734\n",
            "At step: 385 training error: 0.49526823710509493\n",
            "At step: 386 training error: 0.48526992198282387\n",
            "At step: 387 training error: 0.48940565343188336\n",
            "At step: 388 training error: 0.4867220946195259\n",
            "At step: 389 training error: 0.4791098999152813\n",
            "At step: 390 training error: 0.4773420061342466\n",
            "At step: 391 training error: 0.4751408198905578\n",
            "At step: 392 training error: 0.4806757703420559\n",
            "At step: 393 training error: 0.48496925924475603\n",
            "At step: 394 training error: 0.48888592448390533\n",
            "At step: 395 training error: 0.49174345369074096\n",
            "At step: 396 training error: 0.4927469089457604\n",
            "At step: 397 training error: 0.4983335481258946\n",
            "At step: 398 training error: 0.4861287102226947\n",
            "At step: 399 training error: 0.49022181371469875\n",
            "At step: 400 training error: 0.4920894714023672\n",
            "At step: 401 training error: 0.4983585724977968\n",
            "At step: 402 training error: 0.504563645896515\n",
            "At step: 403 training error: 0.5209547315166747\n",
            "At step: 404 training error: 0.5162583603201346\n",
            "At step: 405 training error: 0.5131461019286774\n",
            "At step: 406 training error: 0.5148843705844094\n",
            "At step: 407 training error: 0.5061442169952897\n",
            "At step: 408 training error: 0.5107315304525737\n",
            "At step: 409 training error: 0.5091467499581204\n",
            "At step: 410 training error: 0.5072953098966237\n",
            "At step: 411 training error: 0.4978981194462529\n",
            "At step: 412 training error: 0.49368959191618034\n",
            "At step: 413 training error: 0.49171745858294136\n",
            "At step: 414 training error: 0.4909724317465438\n",
            "At step: 415 training error: 0.4917667425171304\n",
            "At step: 416 training error: 0.497362368494343\n",
            "At step: 417 training error: 0.4925434027536934\n",
            "At step: 418 training error: 0.4974454449983982\n",
            "At step: 419 training error: 0.5099793232285297\n",
            "At step: 420 training error: 0.5092158378537974\n",
            "At step: 421 training error: 0.5066381408882272\n",
            "At step: 422 training error: 0.4983150942298844\n",
            "At step: 423 training error: 0.4900186181147133\n",
            "At step: 424 training error: 0.5026021513697261\n",
            "At step: 425 training error: 0.5086186930769369\n",
            "At step: 426 training error: 0.508172995615023\n",
            "At step: 427 training error: 0.5014959063482748\n",
            "At step: 428 training error: 0.5092112605136931\n",
            "At step: 429 training error: 0.5107371770865989\n",
            "At step: 430 training error: 0.5093929514369124\n",
            "At step: 431 training error: 0.5064331309770513\n",
            "At step: 432 training error: 0.5175026283182808\n",
            "At step: 433 training error: 0.5122335213234506\n",
            "At step: 434 training error: 0.5073940147453031\n",
            "At step: 435 training error: 0.506083296510554\n",
            "At step: 436 training error: 0.5112848443493854\n",
            "At step: 437 training error: 0.5016169951546452\n",
            "At step: 438 training error: 0.5038062280370945\n",
            "At step: 439 training error: 0.4936695034046734\n",
            "At step: 440 training error: 0.49847692426281437\n",
            "At step: 441 training error: 0.5053958675808572\n",
            "At step: 442 training error: 0.49678063577353604\n",
            "At step: 443 training error: 0.49961754175683876\n",
            "At step: 444 training error: 0.49419100202609056\n",
            "At step: 445 training error: 0.49678554441301165\n",
            "At step: 446 training error: 0.5062298665365234\n",
            "At step: 447 training error: 0.5073772321493093\n",
            "At step: 448 training error: 0.5110892836808306\n",
            "At step: 449 training error: 0.5112008801788455\n",
            "At step: 450 training error: 0.5134395648787595\n",
            "At step: 451 training error: 0.5126986737973462\n",
            "At step: 452 training error: 0.5198196116401577\n",
            "At step: 453 training error: 0.5251712303169112\n",
            "At step: 454 training error: 0.527573025664322\n",
            "At step: 455 training error: 0.5289623462685343\n",
            "At step: 456 training error: 0.518557105493523\n",
            "At step: 457 training error: 0.5163616890980736\n",
            "At step: 458 training error: 0.5163236293321218\n",
            "At step: 459 training error: 0.511744272327077\n",
            "At step: 460 training error: 0.519704363144027\n",
            "At step: 461 training error: 0.514485324033376\n",
            "At step: 462 training error: 0.5158031841447185\n",
            "At step: 463 training error: 0.5113771128065527\n",
            "At step: 464 training error: 0.5059988762935299\n",
            "At step: 465 training error: 0.510114368979458\n",
            "At step: 466 training error: 0.5152267243000804\n",
            "At step: 467 training error: 0.5092966714515753\n",
            "At step: 468 training error: 0.5067469901406051\n",
            "At step: 469 training error: 0.5037211911471979\n",
            "At step: 470 training error: 0.5054343875241165\n",
            "At step: 471 training error: 0.5061891822121866\n",
            "At step: 472 training error: 0.49869761576309124\n",
            "At step: 473 training error: 0.507870507181725\n",
            "At step: 474 training error: 0.5083460527321744\n",
            "At step: 475 training error: 0.49376358140782756\n",
            "At step: 476 training error: 0.4915793843168591\n",
            "At step: 477 training error: 0.49285703617768273\n",
            "At step: 478 training error: 0.4969143213734232\n",
            "At step: 479 training error: 0.49498463522875075\n",
            "At step: 480 training error: 0.5037918200335347\n",
            "At step: 481 training error: 0.5058809749137286\n",
            "At step: 482 training error: 0.504183990479211\n",
            "At step: 483 training error: 0.5026718590603352\n",
            "At step: 484 training error: 0.5079863347392302\n",
            "At step: 485 training error: 0.5146421649802916\n",
            "At step: 486 training error: 0.5086279373751725\n",
            "At step: 487 training error: 0.5090284176924197\n",
            "At step: 488 training error: 0.5017348403305067\n",
            "At step: 489 training error: 0.5059583276494897\n",
            "At step: 490 training error: 0.5067150339181334\n",
            "At step: 491 training error: 0.5116886400874887\n",
            "At step: 492 training error: 0.5113119532492149\n",
            "At step: 493 training error: 0.5134205920593833\n",
            "At step: 494 training error: 0.49868613098430464\n",
            "At step: 495 training error: 0.4960450230250743\n",
            "At step: 496 training error: 0.4835427610232844\n",
            "At step: 497 training error: 0.48639003767319444\n",
            "At step: 498 training error: 0.4939993124964079\n",
            "At step: 499 training error: 0.4888358495569112\n",
            "At step: 500 training error: 0.4980769724830778\n",
            "At step: 501 training error: 0.49672803786161857\n",
            "At step: 502 training error: 0.4975551975564368\n",
            "At step: 503 training error: 0.5043893170213877\n",
            "At step: 504 training error: 0.5094371585213088\n",
            "At step: 505 training error: 0.5117973799488145\n",
            "At step: 506 training error: 0.508500868267211\n",
            "At step: 507 training error: 0.5103424499682776\n",
            "At step: 508 training error: 0.5059159771167427\n",
            "At step: 509 training error: 0.5003597260860376\n",
            "At step: 510 training error: 0.5012646969899192\n",
            "At step: 511 training error: 0.4883498462164709\n",
            "At step: 512 training error: 0.48847108616847945\n",
            "At step: 513 training error: 0.48938828552676417\n",
            "At step: 514 training error: 0.4894165593254633\n",
            "At step: 515 training error: 0.49314298186502586\n",
            "At step: 516 training error: 0.49985647065269473\n",
            "At step: 517 training error: 0.49998255174638434\n",
            "At step: 518 training error: 0.49342522588792104\n",
            "At step: 519 training error: 0.49906337063948286\n",
            "At step: 520 training error: 0.5071489378032502\n",
            "At step: 521 training error: 0.50078956700178\n",
            "At step: 522 training error: 0.48942806140980977\n",
            "At step: 523 training error: 0.4929632242838369\n",
            "At step: 524 training error: 0.4891129128997258\n",
            "At step: 525 training error: 0.49609953738955725\n",
            "At step: 526 training error: 0.5025316554884209\n",
            "At step: 527 training error: 0.5034273666098004\n",
            "At step: 528 training error: 0.4973799974487203\n",
            "At step: 529 training error: 0.49393343533533474\n",
            "At step: 530 training error: 0.49318424205273487\n",
            "At step: 531 training error: 0.4913217401412692\n",
            "At step: 532 training error: 0.4827014778669456\n",
            "At step: 533 training error: 0.4849180633142186\n",
            "At step: 534 training error: 0.4855803172642382\n",
            "At step: 535 training error: 0.4888733851418658\n",
            "At step: 536 training error: 0.4886836165078489\n",
            "At step: 537 training error: 0.4924541206625143\n",
            "At step: 538 training error: 0.4863719398299948\n",
            "At step: 539 training error: 0.491283471408151\n",
            "At step: 540 training error: 0.4954296055429513\n",
            "At step: 541 training error: 0.4952902916356347\n",
            "At step: 542 training error: 0.4996489928080623\n",
            "At step: 543 training error: 0.5000166425688607\n",
            "At step: 544 training error: 0.509446107146047\n",
            "At step: 545 training error: 0.5139000040992223\n",
            "At step: 546 training error: 0.5135636842118302\n",
            "At step: 547 training error: 0.5111164683694129\n",
            "At step: 548 training error: 0.5112908347935641\n",
            "At step: 549 training error: 0.5026652120281413\n",
            "At step: 550 training error: 0.49883234987856684\n",
            "At step: 551 training error: 0.49367814472862964\n",
            "At step: 552 training error: 0.5082733974844434\n",
            "At step: 553 training error: 0.5049381204295272\n",
            "At step: 554 training error: 0.4999358647007035\n",
            "At step: 555 training error: 0.49429211581234683\n",
            "At step: 556 training error: 0.49485332039810853\n",
            "At step: 557 training error: 0.5009986425908808\n",
            "At step: 558 training error: 0.4882784804326975\n",
            "At step: 559 training error: 0.484621128216142\n",
            "At step: 560 training error: 0.4890028744233453\n",
            "At step: 561 training error: 0.49552789063011315\n",
            "At step: 562 training error: 0.48708852617634435\n",
            "At step: 563 training error: 0.4711746695865849\n",
            "At step: 564 training error: 0.46467024078963254\n",
            "At step: 565 training error: 0.4754114908258567\n",
            "At step: 566 training error: 0.47722150219353804\n",
            "At step: 567 training error: 0.47033343114545134\n",
            "At step: 568 training error: 0.4637016135234193\n",
            "At step: 569 training error: 0.46720596701394645\n",
            "At step: 570 training error: 0.4697944044185918\n",
            "At step: 571 training error: 0.4710047223517391\n",
            "At step: 572 training error: 0.479849130364392\n",
            "At step: 573 training error: 0.4830559852823043\n",
            "At step: 574 training error: 0.47549320378261967\n",
            "At step: 575 training error: 0.48572915258871835\n",
            "At step: 576 training error: 0.4878674443408954\n",
            "At step: 577 training error: 0.4803502911301022\n",
            "At step: 578 training error: 0.49140241355042663\n",
            "At step: 579 training error: 0.4882674925091326\n",
            "At step: 580 training error: 0.481570845237019\n",
            "At step: 581 training error: 0.4983902605273789\n",
            "At step: 582 training error: 0.5040578847242426\n",
            "At step: 583 training error: 0.4939422615248824\n",
            "At step: 584 training error: 0.49514996683115403\n",
            "At step: 585 training error: 0.49771996615900815\n",
            "At step: 586 training error: 0.4886465110161109\n",
            "At step: 587 training error: 0.4919486116429346\n",
            "At step: 588 training error: 0.5050567943772617\n",
            "At step: 589 training error: 0.512637879086751\n",
            "At step: 590 training error: 0.5156190128639271\n",
            "At step: 591 training error: 0.5245500688406248\n",
            "At step: 592 training error: 0.5089865633135957\n",
            "At step: 593 training error: 0.4986232397019521\n",
            "At step: 594 training error: 0.5006107433868202\n",
            "At step: 595 training error: 0.4997840589479587\n",
            "At step: 596 training error: 0.49482525818062084\n",
            "At step: 597 training error: 0.49247861802532056\n",
            "At step: 598 training error: 0.5014697055055003\n",
            "At step: 599 training error: 0.49738987144252667\n",
            "At step: 600 training error: 0.49116031204358856\n",
            "At step: 601 training error: 0.4882684234131991\n",
            "At step: 602 training error: 0.49774817991164577\n",
            "At step: 603 training error: 0.5010090281537974\n",
            "At step: 604 training error: 0.5022354506413917\n",
            "At step: 605 training error: 0.5058306275995615\n",
            "At step: 606 training error: 0.5022002082739011\n",
            "At step: 607 training error: 0.4940563210576743\n",
            "At step: 608 training error: 0.49868855636308784\n",
            "At step: 609 training error: 0.508662893354177\n",
            "At step: 610 training error: 0.5058590145958586\n",
            "At step: 611 training error: 0.5068829827219365\n",
            "At step: 612 training error: 0.511000450408516\n",
            "At step: 613 training error: 0.5054446953319444\n",
            "At step: 614 training error: 0.49671338281575383\n",
            "At step: 615 training error: 0.49858624115837646\n",
            "At step: 616 training error: 0.4975987558092232\n",
            "At step: 617 training error: 0.5104537767723192\n",
            "At step: 618 training error: 0.5001924789514254\n",
            "At step: 619 training error: 0.5029851082695606\n",
            "At step: 620 training error: 0.4989853593724697\n",
            "At step: 621 training error: 0.5057166980395872\n",
            "At step: 622 training error: 0.49674205692043966\n",
            "At step: 623 training error: 0.4898699058484136\n",
            "At step: 624 training error: 0.4817092081303551\n",
            "At step: 625 training error: 0.47184956044482196\n",
            "At step: 626 training error: 0.4779025696951351\n",
            "At step: 627 training error: 0.4727658611713195\n",
            "At step: 628 training error: 0.4707584763831004\n",
            "At step: 629 training error: 0.4675253633193175\n",
            "At step: 630 training error: 0.46931720160674784\n",
            "At step: 631 training error: 0.4696578601174981\n",
            "At step: 632 training error: 0.47169198779127697\n",
            "At step: 633 training error: 0.4786142886627994\n",
            "At step: 634 training error: 0.4823903163724194\n",
            "At step: 635 training error: 0.5007226929187882\n",
            "At step: 636 training error: 0.4946452759282991\n",
            "At step: 637 training error: 0.49750073455595384\n",
            "At step: 638 training error: 0.4929801650863677\n",
            "At step: 639 training error: 0.4922290809389885\n",
            "At step: 640 training error: 0.49349744979544585\n",
            "At step: 641 training error: 0.49595907780541826\n",
            "At step: 642 training error: 0.49739057987029356\n",
            "At step: 643 training error: 0.4871962731730306\n",
            "At step: 644 training error: 0.4862576153268172\n",
            "At step: 645 training error: 0.4949478679784329\n",
            "At step: 646 training error: 0.49296317266111817\n",
            "At step: 647 training error: 0.496374546705137\n",
            "At step: 648 training error: 0.4937737891679269\n",
            "At step: 649 training error: 0.4881170473012293\n",
            "At step: 650 training error: 0.49015712468888356\n",
            "At step: 651 training error: 0.5011287922017272\n",
            "At step: 652 training error: 0.49281598802387194\n",
            "At step: 653 training error: 0.49483301330115637\n",
            "At step: 654 training error: 0.49593814457490654\n",
            "At step: 655 training error: 0.49336786427873963\n",
            "At step: 656 training error: 0.4901751221424299\n",
            "At step: 657 training error: 0.4842983249958286\n",
            "At step: 658 training error: 0.4763247094025051\n",
            "At step: 659 training error: 0.4811775600783761\n",
            "At step: 660 training error: 0.4716997569682958\n",
            "At step: 661 training error: 0.47108951295321744\n",
            "At step: 662 training error: 0.4747695052910362\n",
            "At step: 663 training error: 0.4891849964213213\n",
            "At step: 664 training error: 0.48132868854803856\n",
            "At step: 665 training error: 0.4724823410610221\n",
            "At step: 666 training error: 0.47526142130082205\n",
            "At step: 667 training error: 0.47240957740985945\n",
            "At step: 668 training error: 0.480301089536238\n",
            "At step: 669 training error: 0.4701138456573186\n",
            "At step: 670 training error: 0.4695334755450388\n",
            "At step: 671 training error: 0.47357818231631443\n",
            "At step: 672 training error: 0.4850527765476721\n",
            "At step: 673 training error: 0.48634710967417516\n",
            "At step: 674 training error: 0.4951556915789747\n",
            "At step: 675 training error: 0.49688556805076284\n",
            "At step: 676 training error: 0.49367730681021516\n",
            "At step: 677 training error: 0.4935382735645155\n",
            "At step: 678 training error: 0.4887593453611735\n",
            "At step: 679 training error: 0.49308009587780827\n",
            "At step: 680 training error: 0.482975202336911\n",
            "At step: 681 training error: 0.47837317889905057\n",
            "At step: 682 training error: 0.46408354877329966\n",
            "At step: 683 training error: 0.45805214543328876\n",
            "At step: 684 training error: 0.4661245642626139\n",
            "At step: 685 training error: 0.4695144443919719\n",
            "At step: 686 training error: 0.4856843827525202\n",
            "At step: 687 training error: 0.4839064789816204\n",
            "At step: 688 training error: 0.4911011423168177\n",
            "At step: 689 training error: 0.4839773904304409\n",
            "At step: 690 training error: 0.4764541582827686\n",
            "At step: 691 training error: 0.4825762475300363\n",
            "At step: 692 training error: 0.4937459579386027\n",
            "At step: 693 training error: 0.4824157503371594\n",
            "At step: 694 training error: 0.4919712927776913\n",
            "At step: 695 training error: 0.4877918968520473\n",
            "At step: 696 training error: 0.48536727243174443\n",
            "At step: 697 training error: 0.48983082486287566\n",
            "At step: 698 training error: 0.48265992345670444\n",
            "At step: 699 training error: 0.4822276691452176\n",
            "At step: 700 training error: 0.480083181317304\n",
            "At step: 701 training error: 0.4778741127673164\n",
            "At step: 702 training error: 0.479088342407918\n",
            "At step: 703 training error: 0.4904970518636408\n",
            "At step: 704 training error: 0.48092046534422017\n",
            "At step: 705 training error: 0.48767853179532217\n",
            "At step: 706 training error: 0.4871041636798793\n",
            "At step: 707 training error: 0.49498993781057693\n",
            "At step: 708 training error: 0.48775763865745103\n",
            "At step: 709 training error: 0.49050277648762186\n",
            "At step: 710 training error: 0.4829775467128291\n",
            "At step: 711 training error: 0.48245692618136693\n",
            "At step: 712 training error: 0.48167323725662625\n",
            "At step: 713 training error: 0.484116741243514\n",
            "At step: 714 training error: 0.4868466440017745\n",
            "At step: 715 training error: 0.49045911049019697\n",
            "At step: 716 training error: 0.489886423871822\n",
            "At step: 717 training error: 0.5069507704122024\n",
            "At step: 718 training error: 0.49983630072544477\n",
            "At step: 719 training error: 0.5003600091367782\n",
            "At step: 720 training error: 0.4956519218147721\n",
            "At step: 721 training error: 0.49717390442609877\n",
            "At step: 722 training error: 0.495657456389976\n",
            "At step: 723 training error: 0.49519547630996447\n",
            "At step: 724 training error: 0.493262494041012\n",
            "At step: 725 training error: 0.49110506368092527\n",
            "At step: 726 training error: 0.49469955404300636\n",
            "At step: 727 training error: 0.5000430728715308\n",
            "At step: 728 training error: 0.5017748155104613\n",
            "At step: 729 training error: 0.5065075034569531\n",
            "At step: 730 training error: 0.5091609957631738\n",
            "At step: 731 training error: 0.5110851035047139\n",
            "At step: 732 training error: 0.5182661732010346\n",
            "At step: 733 training error: 0.5156935810403012\n",
            "At step: 734 training error: 0.5184513522072437\n",
            "At step: 735 training error: 0.5199597267627462\n",
            "At step: 736 training error: 0.5125284487517903\n",
            "At step: 737 training error: 0.5148132223969082\n",
            "At step: 738 training error: 0.5127482812722717\n",
            "At step: 739 training error: 0.507658244874471\n",
            "At step: 740 training error: 0.5038469742044863\n",
            "At step: 741 training error: 0.506712185450612\n",
            "At step: 742 training error: 0.5000717888052156\n",
            "At step: 743 training error: 0.4999009856516239\n",
            "At step: 744 training error: 0.4945805700929737\n",
            "At step: 745 training error: 0.4944693231750863\n",
            "At step: 746 training error: 0.4963556859348581\n",
            "At step: 747 training error: 0.488056283095361\n",
            "At step: 748 training error: 0.4797259396357755\n",
            "At step: 749 training error: 0.47370283363757765\n",
            "At step: 750 training error: 0.47351487518868773\n",
            "At step: 751 training error: 0.47703085299697395\n",
            "At step: 752 training error: 0.4835512075741524\n",
            "At step: 753 training error: 0.48862703709168415\n",
            "At step: 754 training error: 0.48492997922195813\n",
            "At step: 755 training error: 0.4867257665622059\n",
            "At step: 756 training error: 0.481871908171081\n",
            "At step: 757 training error: 0.4871447303925658\n",
            "At step: 758 training error: 0.49086985080450574\n",
            "At step: 759 training error: 0.4893951438399029\n",
            "At step: 760 training error: 0.4921811761474624\n",
            "At step: 761 training error: 0.49316943980542577\n",
            "At step: 762 training error: 0.4919292073666348\n",
            "At step: 763 training error: 0.49222711334185604\n",
            "At step: 764 training error: 0.4987423408092407\n",
            "At step: 765 training error: 0.4919589068712837\n",
            "At step: 766 training error: 0.5068103465729612\n",
            "At step: 767 training error: 0.502869205656003\n",
            "At step: 768 training error: 0.5049505131852878\n",
            "At step: 769 training error: 0.5026207303304626\n",
            "At step: 770 training error: 0.506997352742688\n",
            "At step: 771 training error: 0.5079458962552218\n",
            "At step: 772 training error: 0.514322464178452\n",
            "At step: 773 training error: 0.5089902480114578\n",
            "At step: 774 training error: 0.49417561313106456\n",
            "At step: 775 training error: 0.49873589506649096\n",
            "At step: 776 training error: 0.5089975376305936\n",
            "At step: 777 training error: 0.5098338502879239\n",
            "At step: 778 training error: 0.511893462301854\n",
            "At step: 779 training error: 0.5128253451995499\n",
            "At step: 780 training error: 0.5117371504615393\n",
            "At step: 781 training error: 0.4955007160420755\n",
            "At step: 782 training error: 0.4999916344294244\n",
            "At step: 783 training error: 0.4974792920854927\n",
            "At step: 784 training error: 0.493933203625953\n",
            "At step: 785 training error: 0.4961202862871468\n",
            "At step: 786 training error: 0.5024150863521905\n",
            "At step: 787 training error: 0.5010775135402252\n",
            "At step: 788 training error: 0.5029532730032703\n",
            "At step: 789 training error: 0.5043889812712552\n",
            "At step: 790 training error: 0.5025781629148642\n",
            "At step: 791 training error: 0.5000696521979958\n",
            "At step: 792 training error: 0.4975017765696419\n",
            "At step: 793 training error: 0.4848401106833964\n",
            "At step: 794 training error: 0.48442202080776675\n",
            "At step: 795 training error: 0.48330093320973166\n",
            "At step: 796 training error: 0.47739540690795373\n",
            "At step: 797 training error: 0.4760438038580987\n",
            "At step: 798 training error: 0.4930367391787664\n",
            "At step: 799 training error: 0.48785581673284023\n",
            "At step: 800 training error: 0.4894372143758513\n",
            "At step: 801 training error: 0.5048801244515349\n",
            "At step: 802 training error: 0.5051015214243699\n",
            "At step: 803 training error: 0.5046233444376438\n",
            "At step: 804 training error: 0.49384767009297936\n",
            "At step: 805 training error: 0.49746811776171995\n",
            "At step: 806 training error: 0.4978410882032604\n",
            "At step: 807 training error: 0.49859369599129033\n",
            "At step: 808 training error: 0.4962800513997946\n",
            "At step: 809 training error: 0.4907483794905574\n",
            "At step: 810 training error: 0.5027201377388055\n",
            "At step: 811 training error: 0.5105634893571677\n",
            "At step: 812 training error: 0.5025263146774696\n",
            "At step: 813 training error: 0.5103887215007312\n",
            "At step: 814 training error: 0.4992528744306477\n",
            "At step: 815 training error: 0.5020305660484492\n",
            "At step: 816 training error: 0.4917901623232278\n",
            "At step: 817 training error: 0.495131179673988\n",
            "At step: 818 training error: 0.5125950344706108\n",
            "At step: 819 training error: 0.49922212812032535\n",
            "At step: 820 training error: 0.49637200664787784\n",
            "At step: 821 training error: 0.5059020090727132\n",
            "At step: 822 training error: 0.49352000285572734\n",
            "At step: 823 training error: 0.493505546788399\n",
            "At step: 824 training error: 0.4854992676601079\n",
            "At step: 825 training error: 0.49087623178806117\n",
            "At step: 826 training error: 0.4936455460418302\n",
            "At step: 827 training error: 0.48605119977450983\n",
            "At step: 828 training error: 0.49136163328186266\n",
            "At step: 829 training error: 0.490879628035365\n",
            "At step: 830 training error: 0.484927258790628\n",
            "At step: 831 training error: 0.4877596340635179\n",
            "At step: 832 training error: 0.4749634322048756\n",
            "At step: 833 training error: 0.4680272889528561\n",
            "At step: 834 training error: 0.4662264836932415\n",
            "At step: 835 training error: 0.4770281927035882\n",
            "At step: 836 training error: 0.47085409611296464\n",
            "At step: 837 training error: 0.47693334426967154\n",
            "At step: 838 training error: 0.4692124869618023\n",
            "At step: 839 training error: 0.4754665107868296\n",
            "At step: 840 training error: 0.4785963784417474\n",
            "At step: 841 training error: 0.4794451801840187\n",
            "At step: 842 training error: 0.4838301564910195\n",
            "At step: 843 training error: 0.4721768773157593\n",
            "At step: 844 training error: 0.46890062346630923\n",
            "At step: 845 training error: 0.46824134083678803\n",
            "At step: 846 training error: 0.46527197317751057\n",
            "At step: 847 training error: 0.4692087925002396\n",
            "At step: 848 training error: 0.4653234194389634\n",
            "At step: 849 training error: 0.4723529949403128\n",
            "At step: 850 training error: 0.47603179367572873\n",
            "At step: 851 training error: 0.4739362318173898\n",
            "At step: 852 training error: 0.4784636074851889\n",
            "At step: 853 training error: 0.4832706349173781\n",
            "At step: 854 training error: 0.49332124053904225\n",
            "At step: 855 training error: 0.4859567017208274\n",
            "At step: 856 training error: 0.48215953463319927\n",
            "At step: 857 training error: 0.4750443599005526\n",
            "At step: 858 training error: 0.47686098045383174\n",
            "At step: 859 training error: 0.4811718834287517\n",
            "At step: 860 training error: 0.4828616217756139\n",
            "At step: 861 training error: 0.4867328049267152\n",
            "At step: 862 training error: 0.4877621128372242\n",
            "At step: 863 training error: 0.4882360952929075\n",
            "At step: 864 training error: 0.4890459059043197\n",
            "At step: 865 training error: 0.4940159065430361\n",
            "At step: 866 training error: 0.4862804991916245\n",
            "At step: 867 training error: 0.48451092269498997\n",
            "At step: 868 training error: 0.48894227171204785\n",
            "At step: 869 training error: 0.4786110873597481\n",
            "At step: 870 training error: 0.4764837731397704\n",
            "At step: 871 training error: 0.4829504410261856\n",
            "At step: 872 training error: 0.48986902607432087\n",
            "At step: 873 training error: 0.49844356145723934\n",
            "At step: 874 training error: 0.4949812764665395\n",
            "At step: 875 training error: 0.5043939067199268\n",
            "At step: 876 training error: 0.5056448783580033\n",
            "At step: 877 training error: 0.5091226010674382\n",
            "At step: 878 training error: 0.5140310867784963\n",
            "At step: 879 training error: 0.502727725822492\n",
            "At step: 880 training error: 0.4926480935072035\n",
            "At step: 881 training error: 0.488051321992925\n",
            "At step: 882 training error: 0.49868222283045527\n",
            "At step: 883 training error: 0.5096806037356908\n",
            "At step: 884 training error: 0.5111145746456546\n",
            "At step: 885 training error: 0.515198767663792\n",
            "At step: 886 training error: 0.5088863628661033\n",
            "At step: 887 training error: 0.5116629976545556\n",
            "At step: 888 training error: 0.519347206668215\n",
            "At step: 889 training error: 0.515529232646437\n",
            "At step: 890 training error: 0.5201004515879949\n",
            "At step: 891 training error: 0.5190628905974701\n",
            "At step: 892 training error: 0.5183160543009043\n",
            "At step: 893 training error: 0.5179014099121564\n",
            "At step: 894 training error: 0.5224771074415698\n",
            "At step: 895 training error: 0.5180952985595714\n",
            "At step: 896 training error: 0.5139741501558192\n",
            "At step: 897 training error: 0.49843022991597685\n",
            "At step: 898 training error: 0.5017173719324963\n",
            "At step: 899 training error: 0.4996022038637314\n",
            "At step: 900 training error: 0.5065287945379534\n",
            "At step: 901 training error: 0.5003455128810841\n",
            "At step: 902 training error: 0.5002022639500804\n",
            "At step: 903 training error: 0.5007796667665717\n",
            "At step: 904 training error: 0.49605593425655287\n",
            "At step: 905 training error: 0.48617728092473766\n",
            "At step: 906 training error: 0.4897126355385226\n",
            "At step: 907 training error: 0.49702618767349765\n",
            "At step: 908 training error: 0.49588713876212276\n",
            "At step: 909 training error: 0.4856651311860487\n",
            "At step: 910 training error: 0.4872857060531109\n",
            "At step: 911 training error: 0.483766174963746\n",
            "At step: 912 training error: 0.49239107271683186\n",
            "At step: 913 training error: 0.4930018163783324\n",
            "At step: 914 training error: 0.5001130851059848\n",
            "At step: 915 training error: 0.4989996058260777\n",
            "At step: 916 training error: 0.5050361969890559\n",
            "At step: 917 training error: 0.4982759876936693\n",
            "At step: 918 training error: 0.49993000377876345\n",
            "At step: 919 training error: 0.48994367475598477\n",
            "At step: 920 training error: 0.49522132331802543\n",
            "At step: 921 training error: 0.49721345146248896\n",
            "At step: 922 training error: 0.4944500395838192\n",
            "At step: 923 training error: 0.491145631368794\n",
            "At step: 924 training error: 0.48220257177082443\n",
            "At step: 925 training error: 0.4835685846221251\n",
            "At step: 926 training error: 0.4862117136261876\n",
            "At step: 927 training error: 0.47655350312481165\n",
            "At step: 928 training error: 0.46937593847763637\n",
            "At step: 929 training error: 0.48171574256207\n",
            "At step: 930 training error: 0.47762198213516777\n",
            "At step: 931 training error: 0.474609039157687\n",
            "At step: 932 training error: 0.4751374342303116\n",
            "At step: 933 training error: 0.47853825234147945\n",
            "At step: 934 training error: 0.48374281029810423\n",
            "At step: 935 training error: 0.48981824483470177\n",
            "At step: 936 training error: 0.4844344125293132\n",
            "At step: 937 training error: 0.4930367470818797\n",
            "At step: 938 training error: 0.48699414794165585\n",
            "At step: 939 training error: 0.4792241549143977\n",
            "At step: 940 training error: 0.48139428813193724\n",
            "At step: 941 training error: 0.47288638839242875\n",
            "At step: 942 training error: 0.47546608363393184\n",
            "At step: 943 training error: 0.4860195682659775\n",
            "At step: 944 training error: 0.48981217375742025\n",
            "At step: 945 training error: 0.49826923682231045\n",
            "At step: 946 training error: 0.49406236027493494\n",
            "At step: 947 training error: 0.48463768815376584\n",
            "At step: 948 training error: 0.4793777165911288\n",
            "At step: 949 training error: 0.477224957977177\n",
            "At step: 950 training error: 0.4667347804499625\n",
            "At step: 951 training error: 0.4718466450730096\n",
            "At step: 952 training error: 0.46705842359443284\n",
            "At step: 953 training error: 0.47347866431229835\n",
            "At step: 954 training error: 0.4769147854480965\n",
            "At step: 955 training error: 0.4733745684903011\n",
            "At step: 956 training error: 0.4761608582645298\n",
            "At step: 957 training error: 0.495866284403217\n",
            "At step: 958 training error: 0.49988811976923375\n",
            "At step: 959 training error: 0.48995825894577033\n",
            "At step: 960 training error: 0.49154940632185423\n",
            "At step: 961 training error: 0.4812499897757791\n",
            "At step: 962 training error: 0.4870554902239858\n",
            "At step: 963 training error: 0.49637195598573747\n",
            "At step: 964 training error: 0.50310956224806\n",
            "At step: 965 training error: 0.5029345278862355\n",
            "At step: 966 training error: 0.5037073505115232\n",
            "At step: 967 training error: 0.5014261995240642\n",
            "At step: 968 training error: 0.4888128367491522\n",
            "At step: 969 training error: 0.4932686550123263\n",
            "At step: 970 training error: 0.4973775454694424\n",
            "At step: 971 training error: 0.4937508262922316\n",
            "At step: 972 training error: 0.5054729503022426\n",
            "At step: 973 training error: 0.5028662825088961\n",
            "At step: 974 training error: 0.4999839440383792\n",
            "At step: 975 training error: 0.4961562761032032\n",
            "At step: 976 training error: 0.49863025550017515\n",
            "At step: 977 training error: 0.4947042755902398\n",
            "At step: 978 training error: 0.49590766215424154\n",
            "At step: 979 training error: 0.49471108250278234\n",
            "At step: 980 training error: 0.47524546707174037\n",
            "At step: 981 training error: 0.47385688499962275\n",
            "At step: 982 training error: 0.4711315487991601\n",
            "At step: 983 training error: 0.4702564732490159\n",
            "At step: 984 training error: 0.47900555512582293\n",
            "At step: 985 training error: 0.4845315526293336\n",
            "At step: 986 training error: 0.47655921782862554\n",
            "At step: 987 training error: 0.47406413016464255\n",
            "At step: 988 training error: 0.478580732513101\n",
            "At step: 989 training error: 0.47214063654421257\n",
            "At step: 990 training error: 0.4748797393165159\n",
            "At step: 991 training error: 0.4755399636305063\n",
            "At step: 992 training error: 0.4833534121434136\n",
            "At step: 993 training error: 0.47785945787875744\n",
            "At step: 994 training error: 0.48072690336411517\n",
            "At step: 995 training error: 0.47134470815650986\n",
            "At step: 996 training error: 0.47095828898142444\n",
            "At step: 997 training error: 0.46866822829177984\n",
            "At step: 998 training error: 0.4664743177543217\n",
            "At step: 999 training error: 0.46494908414004854\n",
            "At step: 1000 training error: 0.4606127050493184\n",
            "At step: 1001 training error: 0.4643921265273398\n",
            "At step: 1002 training error: 0.481515848099933\n",
            "At step: 1003 training error: 0.47192445230735475\n",
            "At step: 1004 training error: 0.45974139570660516\n",
            "At step: 1005 training error: 0.4585150482369489\n",
            "At step: 1006 training error: 0.45714399379558174\n",
            "At step: 1007 training error: 0.4591731349958167\n",
            "At step: 1008 training error: 0.4650339214285697\n",
            "At step: 1009 training error: 0.47147145042406513\n",
            "At step: 1010 training error: 0.4732268115418591\n",
            "At step: 1011 training error: 0.47833079145314183\n",
            "At step: 1012 training error: 0.470329006339992\n",
            "At step: 1013 training error: 0.4797202032798344\n",
            "At step: 1014 training error: 0.48017348674565863\n",
            "At step: 1015 training error: 0.4910716691784702\n",
            "At step: 1016 training error: 0.48301741887371125\n",
            "At step: 1017 training error: 0.47819769086382335\n",
            "At step: 1018 training error: 0.47484197818758556\n",
            "At step: 1019 training error: 0.4769381238885908\n",
            "At step: 1020 training error: 0.47578093257461895\n",
            "At step: 1021 training error: 0.4719330365108448\n",
            "At step: 1022 training error: 0.4748995045954093\n",
            "At step: 1023 training error: 0.47169189842059883\n",
            "At step: 1024 training error: 0.4818508394551584\n",
            "At step: 1025 training error: 0.4784288760301405\n",
            "At step: 1026 training error: 0.48175087289016766\n",
            "At step: 1027 training error: 0.47693581734574547\n",
            "At step: 1028 training error: 0.4840777898567704\n",
            "At step: 1029 training error: 0.48007035140425675\n",
            "At step: 1030 training error: 0.4894139844509626\n",
            "At step: 1031 training error: 0.4877372749666236\n",
            "At step: 1032 training error: 0.48578478074551845\n",
            "At step: 1033 training error: 0.47521546707812945\n",
            "At step: 1034 training error: 0.4683992199681737\n",
            "At step: 1035 training error: 0.47414645099333647\n",
            "At step: 1036 training error: 0.47169095552981233\n",
            "At step: 1037 training error: 0.47380236343417315\n",
            "At step: 1038 training error: 0.4755036105126723\n",
            "At step: 1039 training error: 0.48139229726665617\n",
            "At step: 1040 training error: 0.4752401730964762\n",
            "At step: 1041 training error: 0.47918968450204935\n",
            "At step: 1042 training error: 0.4757605378178781\n",
            "At step: 1043 training error: 0.48063843080561747\n",
            "At step: 1044 training error: 0.48408962471532946\n",
            "At step: 1045 training error: 0.4908475333350585\n",
            "At step: 1046 training error: 0.4980746900128748\n",
            "At step: 1047 training error: 0.4949656194364524\n",
            "At step: 1048 training error: 0.499967895069077\n",
            "At step: 1049 training error: 0.5029340228665143\n",
            "At step: 1050 training error: 0.4972142664590529\n",
            "At step: 1051 training error: 0.49407447323679954\n",
            "At step: 1052 training error: 0.4895940395212841\n",
            "At step: 1053 training error: 0.49396777657554697\n",
            "At step: 1054 training error: 0.49897659084234675\n",
            "At step: 1055 training error: 0.50687593668099\n",
            "At step: 1056 training error: 0.501556456022448\n",
            "At step: 1057 training error: 0.4883378812899556\n",
            "At step: 1058 training error: 0.4834056878303693\n",
            "At step: 1059 training error: 0.48478669775410493\n",
            "At step: 1060 training error: 0.49055742095633753\n",
            "At step: 1061 training error: 0.4992495492860753\n",
            "At step: 1062 training error: 0.49577323685773655\n",
            "At step: 1063 training error: 0.4917064362171503\n",
            "At step: 1064 training error: 0.49205863421933155\n",
            "At step: 1065 training error: 0.48788651626968177\n",
            "At step: 1066 training error: 0.48847559559390646\n",
            "At step: 1067 training error: 0.48210556034404406\n",
            "At step: 1068 training error: 0.48615771406714253\n",
            "At step: 1069 training error: 0.4856112005768804\n",
            "At step: 1070 training error: 0.47700563321131284\n",
            "At step: 1071 training error: 0.4760736981296211\n",
            "At step: 1072 training error: 0.4745527927590249\n",
            "At step: 1073 training error: 0.4646737001243886\n",
            "At step: 1074 training error: 0.47008975551938476\n",
            "At step: 1075 training error: 0.47509170760528335\n",
            "At step: 1076 training error: 0.4792326540546061\n",
            "At step: 1077 training error: 0.47331321982278635\n",
            "At step: 1078 training error: 0.4684859971874666\n",
            "At step: 1079 training error: 0.46456046851430577\n",
            "At step: 1080 training error: 0.4543084196643378\n",
            "At step: 1081 training error: 0.4555185171158973\n",
            "At step: 1082 training error: 0.46092604775955237\n",
            "At step: 1083 training error: 0.46088813529948874\n",
            "At step: 1084 training error: 0.45490627211403\n",
            "At step: 1085 training error: 0.4594097280427687\n",
            "At step: 1086 training error: 0.4532273736234241\n",
            "At step: 1087 training error: 0.45284605122174837\n",
            "At step: 1088 training error: 0.4605777806181598\n",
            "At step: 1089 training error: 0.46545189137780374\n",
            "At step: 1090 training error: 0.4581639479533463\n",
            "At step: 1091 training error: 0.4718016565128858\n",
            "At step: 1092 training error: 0.4640438973022726\n",
            "At step: 1093 training error: 0.4695794397968632\n",
            "At step: 1094 training error: 0.4666660366286468\n",
            "At step: 1095 training error: 0.4724946717078202\n",
            "At step: 1096 training error: 0.4669096610629616\n",
            "At step: 1097 training error: 0.4778525515836419\n",
            "At step: 1098 training error: 0.47934080854868577\n",
            "At step: 1099 training error: 0.47651971177311414\n",
            "At step: 1100 training error: 0.4764661079294084\n",
            "At step: 1101 training error: 0.4853906985442426\n",
            "At step: 1102 training error: 0.4848106092014978\n",
            "At step: 1103 training error: 0.4825158198920096\n",
            "At step: 1104 training error: 0.4805490776508222\n",
            "At step: 1105 training error: 0.4801955118115096\n",
            "At step: 1106 training error: 0.48575471899549366\n",
            "At step: 1107 training error: 0.4857342292480066\n",
            "At step: 1108 training error: 0.48624709368398567\n",
            "At step: 1109 training error: 0.4820111652241167\n",
            "At step: 1110 training error: 0.47562248968845783\n",
            "At step: 1111 training error: 0.47301343966480897\n",
            "At step: 1112 training error: 0.47780696869297684\n",
            "At step: 1113 training error: 0.4820360979317406\n",
            "At step: 1114 training error: 0.4816182800406686\n",
            "At step: 1115 training error: 0.4815743081233515\n",
            "At step: 1116 training error: 0.47878365543114926\n",
            "At step: 1117 training error: 0.47181016747321575\n",
            "At step: 1118 training error: 0.4751104870975177\n",
            "At step: 1119 training error: 0.46053806278211895\n",
            "At step: 1120 training error: 0.46209403481139344\n",
            "At step: 1121 training error: 0.47118730095729416\n",
            "At step: 1122 training error: 0.4682214362077014\n",
            "At step: 1123 training error: 0.4652636598741232\n",
            "At step: 1124 training error: 0.46929755630609093\n",
            "At step: 1125 training error: 0.4608973082113014\n",
            "At step: 1126 training error: 0.4761749793050806\n",
            "At step: 1127 training error: 0.482213037928977\n",
            "At step: 1128 training error: 0.48146428207161696\n",
            "At step: 1129 training error: 0.4822952733724571\n",
            "At step: 1130 training error: 0.47997350761105173\n",
            "At step: 1131 training error: 0.4969679071846515\n",
            "At step: 1132 training error: 0.49957288953688644\n",
            "At step: 1133 training error: 0.5156151847740179\n",
            "At step: 1134 training error: 0.4979721409459502\n",
            "At step: 1135 training error: 0.4871958579941268\n",
            "At step: 1136 training error: 0.4900880082527179\n",
            "At step: 1137 training error: 0.48848351090967645\n",
            "At step: 1138 training error: 0.4892330691741854\n",
            "At step: 1139 training error: 0.48500221289199447\n",
            "At step: 1140 training error: 0.4874795641468558\n",
            "At step: 1141 training error: 0.4893927329687666\n",
            "At step: 1142 training error: 0.4875881898509976\n",
            "At step: 1143 training error: 0.4793493091196493\n",
            "At step: 1144 training error: 0.48571584650595323\n",
            "At step: 1145 training error: 0.47654358201939157\n",
            "At step: 1146 training error: 0.48739096012043637\n",
            "At step: 1147 training error: 0.4916631090491116\n",
            "At step: 1148 training error: 0.496898827292865\n",
            "At step: 1149 training error: 0.4989788230385882\n",
            "At step: 1150 training error: 0.49325944346376505\n",
            "At step: 1151 training error: 0.49348555411202116\n",
            "At step: 1152 training error: 0.4949039314954204\n",
            "At step: 1153 training error: 0.4991057306982307\n",
            "At step: 1154 training error: 0.5103352862075652\n",
            "At step: 1155 training error: 0.49834820592547835\n",
            "At step: 1156 training error: 0.5022675642246598\n",
            "At step: 1157 training error: 0.491497151247369\n",
            "At step: 1158 training error: 0.49417759097434766\n",
            "At step: 1159 training error: 0.4852427897036603\n",
            "At step: 1160 training error: 0.47636980130180356\n",
            "At step: 1161 training error: 0.4701062055813111\n",
            "At step: 1162 training error: 0.4591542655498655\n",
            "At step: 1163 training error: 0.4573050453043853\n",
            "At step: 1164 training error: 0.45672726808161757\n",
            "At step: 1165 training error: 0.4553430597406162\n",
            "At step: 1166 training error: 0.45693051405647916\n",
            "At step: 1167 training error: 0.45440936328207326\n",
            "At step: 1168 training error: 0.44821509534485976\n",
            "At step: 1169 training error: 0.4586163298802897\n",
            "At step: 1170 training error: 0.4615660205812574\n",
            "At step: 1171 training error: 0.46390078866808765\n",
            "At step: 1172 training error: 0.4686579433379691\n",
            "At step: 1173 training error: 0.47948023637441267\n",
            "At step: 1174 training error: 0.47391112417123116\n",
            "At step: 1175 training error: 0.46305258704803576\n",
            "At step: 1176 training error: 0.4853107145120825\n",
            "At step: 1177 training error: 0.49586894016830596\n",
            "At step: 1178 training error: 0.49209334808422134\n",
            "At step: 1179 training error: 0.4936831354615747\n",
            "At step: 1180 training error: 0.48573151605816384\n",
            "At step: 1181 training error: 0.49642116147474624\n",
            "At step: 1182 training error: 0.5056120141747545\n",
            "At step: 1183 training error: 0.5013344939642546\n",
            "At step: 1184 training error: 0.505293030167682\n",
            "At step: 1185 training error: 0.4990781717635768\n",
            "At step: 1186 training error: 0.4904719476745507\n",
            "At step: 1187 training error: 0.47857367410350854\n",
            "At step: 1188 training error: 0.4690608505980087\n",
            "At step: 1189 training error: 0.476496348583982\n",
            "At step: 1190 training error: 0.47818210632453906\n",
            "At step: 1191 training error: 0.48458209685014714\n",
            "At step: 1192 training error: 0.4965444898250855\n",
            "At step: 1193 training error: 0.49424546386232987\n",
            "At step: 1194 training error: 0.49628388725996275\n",
            "At step: 1195 training error: 0.5055383700824414\n",
            "At step: 1196 training error: 0.5049431907596262\n",
            "At step: 1197 training error: 0.5021274507374325\n",
            "At step: 1198 training error: 0.5030721307911901\n",
            "At step: 1199 training error: 0.4982875349436908\n",
            "At step: 1200 training error: 0.49377970406666755\n",
            "At step: 1201 training error: 0.49225216273276184\n",
            "At step: 1202 training error: 0.49539502962668613\n",
            "At step: 1203 training error: 0.5088053222629028\n",
            "At step: 1204 training error: 0.5139003288018787\n",
            "At step: 1205 training error: 0.5190597352306036\n",
            "At step: 1206 training error: 0.515415799167852\n",
            "At step: 1207 training error: 0.5163712099128397\n",
            "At step: 1208 training error: 0.5125962439412687\n",
            "At step: 1209 training error: 0.5033256095477624\n",
            "At step: 1210 training error: 0.5075293094804801\n",
            "At step: 1211 training error: 0.5070954895691621\n",
            "At step: 1212 training error: 0.5037683430216087\n",
            "At step: 1213 training error: 0.5078252120035651\n",
            "At step: 1214 training error: 0.5081339119644718\n",
            "At step: 1215 training error: 0.5043311591129522\n",
            "At step: 1216 training error: 0.5059540634049292\n",
            "At step: 1217 training error: 0.5044269342280507\n",
            "At step: 1218 training error: 0.49517065480988\n",
            "At step: 1219 training error: 0.49516267083734555\n",
            "At step: 1220 training error: 0.5012801478668787\n",
            "At step: 1221 training error: 0.5030293544227785\n",
            "At step: 1222 training error: 0.5114231871450297\n",
            "At step: 1223 training error: 0.5040263031168326\n",
            "At step: 1224 training error: 0.5046641208079042\n",
            "At step: 1225 training error: 0.51610794173811\n",
            "At step: 1226 training error: 0.5161958498828125\n",
            "At step: 1227 training error: 0.5140703583537116\n",
            "At step: 1228 training error: 0.526670474818851\n",
            "At step: 1229 training error: 0.5159520640641817\n",
            "At step: 1230 training error: 0.5042920204241491\n",
            "At step: 1231 training error: 0.5010023159519914\n",
            "At step: 1232 training error: 0.4978611078871533\n",
            "At step: 1233 training error: 0.49002872896981065\n",
            "At step: 1234 training error: 0.4961198127194912\n",
            "At step: 1235 training error: 0.49675081589147446\n",
            "At step: 1236 training error: 0.4895039493228935\n",
            "At step: 1237 training error: 0.48267938552051315\n",
            "At step: 1238 training error: 0.47615209284376664\n",
            "At step: 1239 training error: 0.48573116106750563\n",
            "At step: 1240 training error: 0.4980657186291092\n",
            "At step: 1241 training error: 0.4956965610261806\n",
            "At step: 1242 training error: 0.4909763225625071\n",
            "At step: 1243 training error: 0.4941383434972594\n",
            "At step: 1244 training error: 0.48924350483788026\n",
            "At step: 1245 training error: 0.48012024162523403\n",
            "At step: 1246 training error: 0.47988102234524815\n",
            "At step: 1247 training error: 0.46918072504380526\n",
            "At step: 1248 training error: 0.4736810154503919\n",
            "At step: 1249 training error: 0.4780576803622213\n",
            "At step: 1250 training error: 0.4800211593060041\n",
            "At step: 1251 training error: 0.4867300900883947\n",
            "At step: 1252 training error: 0.49232522832248315\n",
            "At step: 1253 training error: 0.4927248536867458\n",
            "At step: 1254 training error: 0.49318576745085607\n",
            "At step: 1255 training error: 0.48610878097486976\n",
            "At step: 1256 training error: 0.4801700615161628\n",
            "At step: 1257 training error: 0.4870344237525095\n",
            "At step: 1258 training error: 0.4839843498804026\n",
            "At step: 1259 training error: 0.48565434700315024\n",
            "At step: 1260 training error: 0.4875142866527877\n",
            "At step: 1261 training error: 0.4847572039050462\n",
            "At step: 1262 training error: 0.47406819355509733\n",
            "At step: 1263 training error: 0.4775777341324969\n",
            "At step: 1264 training error: 0.48032732713096543\n",
            "At step: 1265 training error: 0.47720889599774774\n",
            "At step: 1266 training error: 0.4740500195344499\n",
            "At step: 1267 training error: 0.47271564233204616\n",
            "At step: 1268 training error: 0.4749535887052683\n",
            "At step: 1269 training error: 0.47509907233440263\n",
            "At step: 1270 training error: 0.4758426206783919\n",
            "At step: 1271 training error: 0.4688783365217996\n",
            "At step: 1272 training error: 0.47365573834069685\n",
            "At step: 1273 training error: 0.4679660723157277\n",
            "At step: 1274 training error: 0.4689434565853385\n",
            "At step: 1275 training error: 0.47427037787021786\n",
            "At step: 1276 training error: 0.4733568083189442\n",
            "At step: 1277 training error: 0.46997411092839303\n",
            "At step: 1278 training error: 0.4675572030185541\n",
            "At step: 1279 training error: 0.4656476091126195\n",
            "At step: 1280 training error: 0.4802515700352369\n",
            "At step: 1281 training error: 0.4760053848525138\n",
            "At step: 1282 training error: 0.4799603731910324\n",
            "At step: 1283 training error: 0.4809078230899063\n",
            "At step: 1284 training error: 0.471485104100445\n",
            "At step: 1285 training error: 0.4708425100192497\n",
            "At step: 1286 training error: 0.4562331315044082\n",
            "At step: 1287 training error: 0.4604089926040832\n",
            "At step: 1288 training error: 0.4593027179000665\n",
            "At step: 1289 training error: 0.45101883818985283\n",
            "At step: 1290 training error: 0.45110954557611954\n",
            "At step: 1291 training error: 0.4465721194149037\n",
            "At step: 1292 training error: 0.4586564573678429\n",
            "At step: 1293 training error: 0.4592717804062282\n",
            "At step: 1294 training error: 0.45975107155079264\n",
            "At step: 1295 training error: 0.4632397440824337\n",
            "At step: 1296 training error: 0.46419437951084486\n",
            "At step: 1297 training error: 0.47150894907399776\n",
            "At step: 1298 training error: 0.4839573674772658\n",
            "At step: 1299 training error: 0.4831906087224787\n",
            "At step: 1300 training error: 0.48775273377251366\n",
            "At step: 1301 training error: 0.48531929468881274\n",
            "At step: 1302 training error: 0.477927720610701\n",
            "At step: 1303 training error: 0.474169888180463\n",
            "At step: 1304 training error: 0.47202513353631353\n",
            "At step: 1305 training error: 0.46869760924960635\n",
            "At step: 1306 training error: 0.46350940770800475\n",
            "At step: 1307 training error: 0.46385333579503374\n",
            "At step: 1308 training error: 0.4638026526524562\n",
            "At step: 1309 training error: 0.46040405269884976\n",
            "At step: 1310 training error: 0.4720333167770454\n",
            "At step: 1311 training error: 0.4697762472150242\n",
            "At step: 1312 training error: 0.4779360617414314\n",
            "At step: 1313 training error: 0.47661895032129975\n",
            "At step: 1314 training error: 0.47105682513952324\n",
            "At step: 1315 training error: 0.46693738132133944\n",
            "At step: 1316 training error: 0.45820857404772763\n",
            "At step: 1317 training error: 0.4585748725812437\n",
            "At step: 1318 training error: 0.4474690922215368\n",
            "At step: 1319 training error: 0.44728118764207636\n",
            "At step: 1320 training error: 0.4436203768297816\n",
            "At step: 1321 training error: 0.4503525661418545\n",
            "At step: 1322 training error: 0.46179910412298897\n",
            "At step: 1323 training error: 0.46505051260980274\n",
            "At step: 1324 training error: 0.46860996193778326\n",
            "At step: 1325 training error: 0.49115317479330106\n",
            "At step: 1326 training error: 0.4988253921381747\n",
            "At step: 1327 training error: 0.4964517113130643\n",
            "At step: 1328 training error: 0.49760891552448744\n",
            "At step: 1329 training error: 0.5006671937361027\n",
            "At step: 1330 training error: 0.5032481190602414\n",
            "At step: 1331 training error: 0.49922473786702837\n",
            "At step: 1332 training error: 0.48815350376283295\n",
            "At step: 1333 training error: 0.48561454666333115\n",
            "At step: 1334 training error: 0.47934642022461815\n",
            "At step: 1335 training error: 0.4764019814862455\n",
            "At step: 1336 training error: 0.4731529298885744\n",
            "At step: 1337 training error: 0.4673476545812176\n",
            "At step: 1338 training error: 0.4757240337776164\n",
            "At step: 1339 training error: 0.4740827394301156\n",
            "At step: 1340 training error: 0.4753848506738617\n",
            "At step: 1341 training error: 0.4829705329130028\n",
            "At step: 1342 training error: 0.48326336708588974\n",
            "At step: 1343 training error: 0.4832962938160512\n",
            "At step: 1344 training error: 0.4779090603899371\n",
            "At step: 1345 training error: 0.4785787093021308\n",
            "At step: 1346 training error: 0.4747868861301034\n",
            "At step: 1347 training error: 0.47767013901451916\n",
            "At step: 1348 training error: 0.4873400716369245\n",
            "At step: 1349 training error: 0.4964639447758462\n",
            "At step: 1350 training error: 0.5010948057362067\n",
            "At step: 1351 training error: 0.49913985093506336\n",
            "At step: 1352 training error: 0.48744715580760223\n",
            "At step: 1353 training error: 0.4901145539859098\n",
            "At step: 1354 training error: 0.4888262600154325\n",
            "At step: 1355 training error: 0.4840052640902569\n",
            "At step: 1356 training error: 0.4838214420745359\n",
            "At step: 1357 training error: 0.4817901110693954\n",
            "At step: 1358 training error: 0.4692293208702804\n",
            "At step: 1359 training error: 0.47198745111291157\n",
            "At step: 1360 training error: 0.48274504619521924\n",
            "At step: 1361 training error: 0.4859066120400691\n",
            "At step: 1362 training error: 0.48733561446897056\n",
            "At step: 1363 training error: 0.48601291876010205\n",
            "At step: 1364 training error: 0.49089817018760223\n",
            "At step: 1365 training error: 0.4963791871307833\n",
            "At step: 1366 training error: 0.4958084489047562\n",
            "At step: 1367 training error: 0.4912271033175148\n",
            "At step: 1368 training error: 0.4973305980797328\n",
            "At step: 1369 training error: 0.5080934178985361\n",
            "At step: 1370 training error: 0.5001152535941717\n",
            "At step: 1371 training error: 0.49395058702030853\n",
            "At step: 1372 training error: 0.4880760147583479\n",
            "At step: 1373 training error: 0.4834914603082064\n",
            "At step: 1374 training error: 0.47771868135591766\n",
            "At step: 1375 training error: 0.48763569467153994\n",
            "At step: 1376 training error: 0.48789357877434514\n",
            "At step: 1377 training error: 0.491566795685382\n",
            "At step: 1378 training error: 0.48685353069292986\n",
            "At step: 1379 training error: 0.48296594258155556\n",
            "At step: 1380 training error: 0.487252126001489\n",
            "At step: 1381 training error: 0.4888444304416335\n",
            "At step: 1382 training error: 0.4925605843902752\n",
            "At step: 1383 training error: 0.4938750994295312\n",
            "At step: 1384 training error: 0.48716100393979656\n",
            "At step: 1385 training error: 0.4992131186291148\n",
            "At step: 1386 training error: 0.4936922165791009\n",
            "At step: 1387 training error: 0.5004790965348836\n",
            "At step: 1388 training error: 0.5030741615457818\n",
            "At step: 1389 training error: 0.49732116416671246\n",
            "At step: 1390 training error: 0.49591092834516604\n",
            "At step: 1391 training error: 0.4972072504005289\n",
            "At step: 1392 training error: 0.49484985454786135\n",
            "At step: 1393 training error: 0.48578225364069866\n",
            "At step: 1394 training error: 0.48473997586084167\n",
            "At step: 1395 training error: 0.48340727033077213\n",
            "At step: 1396 training error: 0.4860271909392076\n",
            "At step: 1397 training error: 0.4846245283006907\n",
            "At step: 1398 training error: 0.48243990893051775\n",
            "At step: 1399 training error: 0.47605524839193464\n",
            "At step: 1400 training error: 0.4704322523268157\n",
            "At step: 1401 training error: 0.4668460674884931\n",
            "At step: 1402 training error: 0.46484749987078067\n",
            "At step: 1403 training error: 0.46838159523196676\n",
            "At step: 1404 training error: 0.4683528453211014\n",
            "At step: 1405 training error: 0.46988173693487\n",
            "At step: 1406 training error: 0.46870292832744054\n",
            "At step: 1407 training error: 0.4564324129076078\n",
            "At step: 1408 training error: 0.4603847125208739\n",
            "At step: 1409 training error: 0.4680109362333851\n",
            "At step: 1410 training error: 0.48116247986488875\n",
            "At step: 1411 training error: 0.48235620742793883\n",
            "At step: 1412 training error: 0.49182374641598925\n",
            "At step: 1413 training error: 0.4917405760417914\n",
            "At step: 1414 training error: 0.48492138912688526\n",
            "At step: 1415 training error: 0.49503776716629844\n",
            "At step: 1416 training error: 0.487204510810759\n",
            "At step: 1417 training error: 0.4797023004996367\n",
            "At step: 1418 training error: 0.47902725399637436\n",
            "At step: 1419 training error: 0.4799193017968709\n",
            "At step: 1420 training error: 0.47233996877950857\n",
            "At step: 1421 training error: 0.4783051515249326\n",
            "At step: 1422 training error: 0.4744899228118796\n",
            "At step: 1423 training error: 0.4640877455890765\n",
            "At step: 1424 training error: 0.45858262808032624\n",
            "At step: 1425 training error: 0.4524703575146488\n",
            "At step: 1426 training error: 0.4508741715729085\n",
            "At step: 1427 training error: 0.44735953466852496\n",
            "At step: 1428 training error: 0.4483842425911963\n",
            "At step: 1429 training error: 0.4559539582070398\n",
            "At step: 1430 training error: 0.45950465166799526\n",
            "At step: 1431 training error: 0.4511104982542162\n",
            "At step: 1432 training error: 0.46751996397235085\n",
            "At step: 1433 training error: 0.4541105460547735\n",
            "At step: 1434 training error: 0.4531457276542391\n",
            "At step: 1435 training error: 0.4612020571037208\n",
            "At step: 1436 training error: 0.4602939174945503\n",
            "At step: 1437 training error: 0.4677178330555435\n",
            "At step: 1438 training error: 0.464372193236851\n",
            "At step: 1439 training error: 0.4625900343984244\n",
            "At step: 1440 training error: 0.4545606108304802\n",
            "At step: 1441 training error: 0.4604598794485719\n",
            "At step: 1442 training error: 0.45868953484090447\n",
            "At step: 1443 training error: 0.46540682902908354\n",
            "At step: 1444 training error: 0.4591130625788706\n",
            "At step: 1445 training error: 0.4631148742746741\n",
            "At step: 1446 training error: 0.47467014115283357\n",
            "At step: 1447 training error: 0.468208907441\n",
            "At step: 1448 training error: 0.4698743892200109\n",
            "At step: 1449 training error: 0.4792162934094146\n",
            "At step: 1450 training error: 0.4707681168670057\n",
            "At step: 1451 training error: 0.46683226813409007\n",
            "At step: 1452 training error: 0.4604371224725039\n",
            "At step: 1453 training error: 0.4547058787481001\n",
            "At step: 1454 training error: 0.4530711056273882\n",
            "At step: 1455 training error: 0.45818496607945514\n",
            "At step: 1456 training error: 0.4748141579722544\n",
            "At step: 1457 training error: 0.4725840006289507\n",
            "At step: 1458 training error: 0.48327017522050514\n",
            "At step: 1459 training error: 0.47578600741319943\n",
            "At step: 1460 training error: 0.4802846207012547\n",
            "At step: 1461 training error: 0.47508721973526113\n",
            "At step: 1462 training error: 0.47549878954971303\n",
            "At step: 1463 training error: 0.4741197661940221\n",
            "At step: 1464 training error: 0.4772203776444206\n",
            "At step: 1465 training error: 0.46641776320396877\n",
            "At step: 1466 training error: 0.4619634201526699\n",
            "At step: 1467 training error: 0.4564536694035264\n",
            "At step: 1468 training error: 0.46126080941205505\n",
            "At step: 1469 training error: 0.4580107373655438\n",
            "At step: 1470 training error: 0.46625131394650726\n",
            "At step: 1471 training error: 0.47331252307090854\n",
            "At step: 1472 training error: 0.468418000386044\n",
            "At step: 1473 training error: 0.46764924126688756\n",
            "At step: 1474 training error: 0.4683439063403687\n",
            "At step: 1475 training error: 0.46151391678235437\n",
            "At step: 1476 training error: 0.4634463179483461\n",
            "At step: 1477 training error: 0.4603572160939716\n",
            "At step: 1478 training error: 0.45458601212411937\n",
            "At step: 1479 training error: 0.46963833097868507\n",
            "At step: 1480 training error: 0.4700760972287385\n",
            "At step: 1481 training error: 0.45243456677580773\n",
            "At step: 1482 training error: 0.447584605022561\n",
            "At step: 1483 training error: 0.45061148409563995\n",
            "At step: 1484 training error: 0.45027207179681406\n",
            "At step: 1485 training error: 0.45512159465563357\n",
            "At step: 1486 training error: 0.4609774956517202\n",
            "At step: 1487 training error: 0.46062538130047764\n",
            "At step: 1488 training error: 0.4515171241991889\n",
            "At step: 1489 training error: 0.447010827404375\n",
            "At step: 1490 training error: 0.43763531507211045\n",
            "At step: 1491 training error: 0.4505647647402622\n",
            "At step: 1492 training error: 0.45033700651494035\n",
            "At step: 1493 training error: 0.45009312108748295\n",
            "At step: 1494 training error: 0.4588568815525718\n",
            "At step: 1495 training error: 0.45580736804041133\n",
            "At step: 1496 training error: 0.45290315632788375\n",
            "At step: 1497 training error: 0.45615485165978864\n",
            "At step: 1498 training error: 0.45878231415159937\n",
            "At step: 1499 training error: 0.46026650657256973\n",
            "At step: 1500 training error: 0.47132416642174246\n",
            "At step: 1501 training error: 0.4820138981236278\n",
            "At step: 1502 training error: 0.48031518554994196\n",
            "At step: 1503 training error: 0.47752924442211603\n",
            "At step: 1504 training error: 0.4839016015454246\n",
            "At step: 1505 training error: 0.48133094021294626\n",
            "At step: 1506 training error: 0.4796462829689043\n",
            "At step: 1507 training error: 0.4725275177128035\n",
            "At step: 1508 training error: 0.47964431058083823\n",
            "At step: 1509 training error: 0.4796414405032241\n",
            "At step: 1510 training error: 0.4639679280600795\n",
            "At step: 1511 training error: 0.46821756139996873\n",
            "At step: 1512 training error: 0.46563438336085006\n",
            "At step: 1513 training error: 0.46620685286470565\n",
            "At step: 1514 training error: 0.46793608434789835\n",
            "At step: 1515 training error: 0.4719302492655422\n",
            "At step: 1516 training error: 0.4672969072048818\n",
            "At step: 1517 training error: 0.45705095158486986\n",
            "At step: 1518 training error: 0.46453700543763776\n",
            "At step: 1519 training error: 0.46892738255779376\n",
            "At step: 1520 training error: 0.4706971806094924\n",
            "At step: 1521 training error: 0.4609718408287711\n",
            "At step: 1522 training error: 0.4664016972092546\n",
            "At step: 1523 training error: 0.47066333510849556\n",
            "At step: 1524 training error: 0.4755016047934377\n",
            "At step: 1525 training error: 0.4630256978371112\n",
            "At step: 1526 training error: 0.46645118857545165\n",
            "At step: 1527 training error: 0.467124451649156\n",
            "At step: 1528 training error: 0.46409661914423056\n",
            "At step: 1529 training error: 0.45762924929715265\n",
            "At step: 1530 training error: 0.4584129884856374\n",
            "At step: 1531 training error: 0.46098213909270314\n",
            "At step: 1532 training error: 0.4634977462449239\n",
            "At step: 1533 training error: 0.46044649903802265\n",
            "At step: 1534 training error: 0.4697852160316078\n",
            "At step: 1535 training error: 0.46233056018231417\n",
            "At step: 1536 training error: 0.4563369418834806\n",
            "At step: 1537 training error: 0.4466144846170778\n",
            "At step: 1538 training error: 0.4440977960655735\n",
            "At step: 1539 training error: 0.438277619315636\n",
            "At step: 1540 training error: 0.43451684114584954\n",
            "At step: 1541 training error: 0.4398782658929248\n",
            "At step: 1542 training error: 0.4444175445648601\n",
            "At step: 1543 training error: 0.4565491213004157\n",
            "At step: 1544 training error: 0.4634468014506176\n",
            "At step: 1545 training error: 0.4592833526728483\n",
            "At step: 1546 training error: 0.4613977863823036\n",
            "At step: 1547 training error: 0.46095939301791605\n",
            "At step: 1548 training error: 0.45215580957317963\n",
            "At step: 1549 training error: 0.44959846901979067\n",
            "At step: 1550 training error: 0.44909795431487126\n",
            "At step: 1551 training error: 0.4474896815998174\n",
            "At step: 1552 training error: 0.4614748704541143\n",
            "At step: 1553 training error: 0.4628130122227279\n",
            "At step: 1554 training error: 0.46540533595032757\n",
            "At step: 1555 training error: 0.46999465293203035\n",
            "At step: 1556 training error: 0.4709251053190834\n",
            "At step: 1557 training error: 0.46488283743353764\n",
            "At step: 1558 training error: 0.4695130999477813\n",
            "At step: 1559 training error: 0.4723382467909482\n",
            "At step: 1560 training error: 0.47494320677669005\n",
            "At step: 1561 training error: 0.4570455549046449\n",
            "At step: 1562 training error: 0.45626175570831695\n",
            "At step: 1563 training error: 0.4626640063324949\n",
            "At step: 1564 training error: 0.4609950195730201\n",
            "At step: 1565 training error: 0.46081046483015264\n",
            "At step: 1566 training error: 0.46813511574658273\n",
            "At step: 1567 training error: 0.46244069984347874\n",
            "At step: 1568 training error: 0.46825787839194755\n",
            "At step: 1569 training error: 0.473754895339975\n",
            "At step: 1570 training error: 0.4725790432916832\n",
            "At step: 1571 training error: 0.4755079879245164\n",
            "At step: 1572 training error: 0.4724385591606997\n",
            "At step: 1573 training error: 0.46689716619470634\n",
            "At step: 1574 training error: 0.4667508441781155\n",
            "At step: 1575 training error: 0.46104410279720426\n",
            "At step: 1576 training error: 0.4576994114899278\n",
            "At step: 1577 training error: 0.4629968745668929\n",
            "At step: 1578 training error: 0.45502580657881697\n",
            "At step: 1579 training error: 0.4565255658735656\n",
            "At step: 1580 training error: 0.45728384343026085\n",
            "At step: 1581 training error: 0.4697974607939981\n",
            "At step: 1582 training error: 0.4658210365743977\n",
            "At step: 1583 training error: 0.46528454350915943\n",
            "At step: 1584 training error: 0.4627473508087822\n",
            "At step: 1585 training error: 0.4662054213207851\n",
            "At step: 1586 training error: 0.46630616336991615\n",
            "At step: 1587 training error: 0.4647620740999748\n",
            "At step: 1588 training error: 0.46478963081498237\n",
            "At step: 1589 training error: 0.469774756668496\n",
            "At step: 1590 training error: 0.47141354319652923\n",
            "At step: 1591 training error: 0.47016262678854465\n",
            "At step: 1592 training error: 0.4610566379412504\n",
            "At step: 1593 training error: 0.46287042969194647\n",
            "At step: 1594 training error: 0.4571482490719332\n",
            "At step: 1595 training error: 0.4616653258122083\n",
            "At step: 1596 training error: 0.4639504016582034\n",
            "At step: 1597 training error: 0.46007626152453723\n",
            "At step: 1598 training error: 0.46500678903232184\n",
            "At step: 1599 training error: 0.4654110297712378\n",
            "At step: 1600 training error: 0.46746030426902946\n",
            "At step: 1601 training error: 0.47839220724014386\n",
            "At step: 1602 training error: 0.48167359530737897\n",
            "At step: 1603 training error: 0.48260003246476235\n",
            "At step: 1604 training error: 0.4745842130503825\n",
            "At step: 1605 training error: 0.4661046337404605\n",
            "At step: 1606 training error: 0.4638064958265388\n",
            "At step: 1607 training error: 0.46119394011175185\n",
            "At step: 1608 training error: 0.47061507446106077\n",
            "At step: 1609 training error: 0.46942081515702155\n",
            "At step: 1610 training error: 0.46861619418757877\n",
            "At step: 1611 training error: 0.46895151956938685\n",
            "At step: 1612 training error: 0.47945795145272696\n",
            "At step: 1613 training error: 0.4745941379908444\n",
            "At step: 1614 training error: 0.4807082812845731\n",
            "At step: 1615 training error: 0.48077890046666927\n",
            "At step: 1616 training error: 0.4853272207700625\n",
            "At step: 1617 training error: 0.4872301542629528\n",
            "At step: 1618 training error: 0.48039682069177225\n",
            "At step: 1619 training error: 0.4793244073274037\n",
            "At step: 1620 training error: 0.4869870489034478\n",
            "At step: 1621 training error: 0.48021444100279176\n",
            "At step: 1622 training error: 0.47852789618193814\n",
            "At step: 1623 training error: 0.46657231111777075\n",
            "At step: 1624 training error: 0.46880030180224846\n",
            "At step: 1625 training error: 0.47049490530028426\n",
            "At step: 1626 training error: 0.4676693039363992\n",
            "At step: 1627 training error: 0.455169355034171\n",
            "At step: 1628 training error: 0.45611780025454485\n",
            "At step: 1629 training error: 0.45875740929382136\n",
            "At step: 1630 training error: 0.45892920838991647\n",
            "At step: 1631 training error: 0.4644208113254818\n",
            "At step: 1632 training error: 0.46895253322895775\n",
            "At step: 1633 training error: 0.4783568639676316\n",
            "At step: 1634 training error: 0.4705994631441325\n",
            "At step: 1635 training error: 0.47132193851848525\n",
            "At step: 1636 training error: 0.46800235043446275\n",
            "At step: 1637 training error: 0.4728960104707984\n",
            "At step: 1638 training error: 0.46449589105925393\n",
            "At step: 1639 training error: 0.46810616636663055\n",
            "At step: 1640 training error: 0.4732068942405074\n",
            "At step: 1641 training error: 0.47316856064359164\n",
            "At step: 1642 training error: 0.48200424986043483\n",
            "At step: 1643 training error: 0.4847231144028284\n",
            "At step: 1644 training error: 0.48347378037641886\n",
            "At step: 1645 training error: 0.4899923075312637\n",
            "At step: 1646 training error: 0.4917522386507828\n",
            "At step: 1647 training error: 0.4945894520466732\n",
            "At step: 1648 training error: 0.49678343073459746\n",
            "At step: 1649 training error: 0.49378081026336595\n",
            "At step: 1650 training error: 0.48937605136871565\n",
            "At step: 1651 training error: 0.4828145525724606\n",
            "At step: 1652 training error: 0.4869596156578754\n",
            "At step: 1653 training error: 0.48327694889858547\n",
            "At step: 1654 training error: 0.48450254012253535\n",
            "At step: 1655 training error: 0.4755414972212908\n",
            "At step: 1656 training error: 0.4751083152748887\n",
            "At step: 1657 training error: 0.4720999162343556\n",
            "At step: 1658 training error: 0.4697852604704642\n",
            "At step: 1659 training error: 0.46625740546846206\n",
            "At step: 1660 training error: 0.4685188555508793\n",
            "At step: 1661 training error: 0.47156555708999937\n",
            "At step: 1662 training error: 0.46161408024864997\n",
            "At step: 1663 training error: 0.466662125897178\n",
            "At step: 1664 training error: 0.46731687817364476\n",
            "At step: 1665 training error: 0.4649886578267581\n",
            "At step: 1666 training error: 0.48269267654144776\n",
            "At step: 1667 training error: 0.4792677697363956\n",
            "At step: 1668 training error: 0.47504369504087696\n",
            "At step: 1669 training error: 0.48344306050447294\n",
            "At step: 1670 training error: 0.482092334575445\n",
            "At step: 1671 training error: 0.48821234784818945\n",
            "At step: 1672 training error: 0.47010253824124604\n",
            "At step: 1673 training error: 0.4788810761172302\n",
            "At step: 1674 training error: 0.4743022605276244\n",
            "At step: 1675 training error: 0.4731698051450682\n",
            "At step: 1676 training error: 0.47587452483223974\n",
            "At step: 1677 training error: 0.49029815991228265\n",
            "At step: 1678 training error: 0.480552405976943\n",
            "At step: 1679 training error: 0.47178674958426425\n",
            "At step: 1680 training error: 0.47829918327143417\n",
            "At step: 1681 training error: 0.4793401832803599\n",
            "At step: 1682 training error: 0.4775320123884551\n",
            "At step: 1683 training error: 0.4770804767918352\n",
            "At step: 1684 training error: 0.4768657604073913\n",
            "At step: 1685 training error: 0.4705726509358693\n",
            "At step: 1686 training error: 0.47417524999840444\n",
            "At step: 1687 training error: 0.4721876383495407\n",
            "At step: 1688 training error: 0.47532180296963605\n",
            "At step: 1689 training error: 0.4814697261504841\n",
            "At step: 1690 training error: 0.4957396267076606\n",
            "At step: 1691 training error: 0.49503473018502836\n",
            "At step: 1692 training error: 0.4892612112256961\n",
            "At step: 1693 training error: 0.4982618147189368\n",
            "At step: 1694 training error: 0.49617817616004184\n",
            "At step: 1695 training error: 0.49531298613930824\n",
            "At step: 1696 training error: 0.4889254611572796\n",
            "At step: 1697 training error: 0.49542010008968584\n",
            "At step: 1698 training error: 0.49836019973545786\n",
            "At step: 1699 training error: 0.49292255447025857\n",
            "At step: 1700 training error: 0.4934236839499587\n",
            "At step: 1701 training error: 0.4826696369667385\n",
            "At step: 1702 training error: 0.47744861257055876\n",
            "At step: 1703 training error: 0.48797201516003297\n",
            "At step: 1704 training error: 0.4929912160254217\n",
            "At step: 1705 training error: 0.4995004405820244\n",
            "At step: 1706 training error: 0.49544004204337294\n",
            "At step: 1707 training error: 0.4867559918418019\n",
            "At step: 1708 training error: 0.4965801492601274\n",
            "At step: 1709 training error: 0.4954253001598019\n",
            "At step: 1710 training error: 0.49658807038361763\n",
            "At step: 1711 training error: 0.4916675219759877\n",
            "At step: 1712 training error: 0.49339246355408717\n",
            "At step: 1713 training error: 0.4884350174277153\n",
            "At step: 1714 training error: 0.48034067991805995\n",
            "At step: 1715 training error: 0.47743767723509073\n",
            "At step: 1716 training error: 0.47351665353844063\n",
            "At step: 1717 training error: 0.4766074778235177\n",
            "At step: 1718 training error: 0.4796299155207706\n",
            "At step: 1719 training error: 0.4702748214899535\n",
            "At step: 1720 training error: 0.47387784386324905\n",
            "At step: 1721 training error: 0.47918563901247246\n",
            "At step: 1722 training error: 0.4711861815941258\n",
            "At step: 1723 training error: 0.47107712883451636\n",
            "At step: 1724 training error: 0.4780134384056885\n",
            "At step: 1725 training error: 0.46728822023259664\n",
            "At step: 1726 training error: 0.4778553601650063\n",
            "At step: 1727 training error: 0.47089295402431774\n",
            "At step: 1728 training error: 0.479983734257569\n",
            "At step: 1729 training error: 0.47377990259005365\n",
            "At step: 1730 training error: 0.4745765280325555\n",
            "At step: 1731 training error: 0.47824541881652355\n",
            "At step: 1732 training error: 0.4752951011259732\n",
            "At step: 1733 training error: 0.4814751148348232\n",
            "At step: 1734 training error: 0.4785953332615117\n",
            "At step: 1735 training error: 0.47989962576599127\n",
            "At step: 1736 training error: 0.4689215038132046\n",
            "At step: 1737 training error: 0.47437890330679333\n",
            "At step: 1738 training error: 0.4727036302893489\n",
            "At step: 1739 training error: 0.46789961725612983\n",
            "At step: 1740 training error: 0.46230112618848135\n",
            "At step: 1741 training error: 0.46856671600426464\n",
            "At step: 1742 training error: 0.47738506118548796\n",
            "At step: 1743 training error: 0.46868415565141747\n",
            "At step: 1744 training error: 0.4633429648675998\n",
            "At step: 1745 training error: 0.45603993717130376\n",
            "At step: 1746 training error: 0.4494778278452093\n",
            "At step: 1747 training error: 0.45643220204696994\n",
            "At step: 1748 training error: 0.44889805206395916\n",
            "At step: 1749 training error: 0.4452497691243425\n",
            "At step: 1750 training error: 0.452371137289642\n",
            "At step: 1751 training error: 0.46872285405815906\n",
            "At step: 1752 training error: 0.4629855465859827\n",
            "At step: 1753 training error: 0.46006678509067855\n",
            "At step: 1754 training error: 0.453685038784072\n",
            "At step: 1755 training error: 0.45289507421616876\n",
            "At step: 1756 training error: 0.44169704341773475\n",
            "At step: 1757 training error: 0.4543221853180912\n",
            "At step: 1758 training error: 0.455607598209295\n",
            "At step: 1759 training error: 0.4594227656236547\n",
            "At step: 1760 training error: 0.4645232211063744\n",
            "At step: 1761 training error: 0.4695402899215869\n",
            "At step: 1762 training error: 0.4632361048675978\n",
            "At step: 1763 training error: 0.46957329984761115\n",
            "At step: 1764 training error: 0.47905041008869975\n",
            "At step: 1765 training error: 0.48336166492903776\n",
            "At step: 1766 training error: 0.4833872387070034\n",
            "At step: 1767 training error: 0.4835652776152623\n",
            "At step: 1768 training error: 0.4816436033846977\n",
            "At step: 1769 training error: 0.48300824654036645\n",
            "At step: 1770 training error: 0.4767167485623887\n",
            "At step: 1771 training error: 0.4868888324197526\n",
            "At step: 1772 training error: 0.4953214285500802\n",
            "At step: 1773 training error: 0.48689702464016543\n",
            "At step: 1774 training error: 0.4856915707253944\n",
            "At step: 1775 training error: 0.47516596369724456\n",
            "At step: 1776 training error: 0.4749867483514378\n",
            "At step: 1777 training error: 0.46721083387176304\n",
            "At step: 1778 training error: 0.47344395332842176\n",
            "At step: 1779 training error: 0.4840876011439563\n",
            "At step: 1780 training error: 0.4838563465439375\n",
            "At step: 1781 training error: 0.4815845727450471\n",
            "At step: 1782 training error: 0.48761284430616364\n",
            "At step: 1783 training error: 0.47761149309740175\n",
            "At step: 1784 training error: 0.47558148271605966\n",
            "At step: 1785 training error: 0.46970968449844885\n",
            "At step: 1786 training error: 0.4781395378552902\n",
            "At step: 1787 training error: 0.47438022390128837\n",
            "At step: 1788 training error: 0.4692564511018309\n",
            "At step: 1789 training error: 0.469793783156967\n",
            "At step: 1790 training error: 0.47051198916286496\n",
            "At step: 1791 training error: 0.46519232950183054\n",
            "At step: 1792 training error: 0.46151642269618254\n",
            "At step: 1793 training error: 0.4597895546640086\n",
            "At step: 1794 training error: 0.4558735244258703\n",
            "At step: 1795 training error: 0.4552595247775046\n",
            "At step: 1796 training error: 0.45301996273510775\n",
            "At step: 1797 training error: 0.45097901727362094\n",
            "At step: 1798 training error: 0.45874676453253554\n",
            "At step: 1799 training error: 0.46665794753659173\n",
            "At step: 1800 training error: 0.466295192751375\n",
            "At step: 1801 training error: 0.4645055034494996\n",
            "At step: 1802 training error: 0.46719204911088824\n",
            "At step: 1803 training error: 0.4612096593809228\n",
            "At step: 1804 training error: 0.4611704626663247\n",
            "At step: 1805 training error: 0.45765255309787345\n",
            "At step: 1806 training error: 0.4513141903639732\n",
            "At step: 1807 training error: 0.4546676052656951\n",
            "At step: 1808 training error: 0.4424074481783308\n",
            "At step: 1809 training error: 0.4397466846568962\n",
            "At step: 1810 training error: 0.444504538178402\n",
            "At step: 1811 training error: 0.45017678378043047\n",
            "At step: 1812 training error: 0.4686775168566471\n",
            "At step: 1813 training error: 0.4710621840537307\n",
            "At step: 1814 training error: 0.46458804609772764\n",
            "At step: 1815 training error: 0.46700234024796566\n",
            "At step: 1816 training error: 0.47432811300593325\n",
            "At step: 1817 training error: 0.4725648495549928\n",
            "At step: 1818 training error: 0.468326914528618\n",
            "At step: 1819 training error: 0.46316568664096214\n",
            "At step: 1820 training error: 0.4582102606636735\n",
            "At step: 1821 training error: 0.4532925952352833\n",
            "At step: 1822 training error: 0.452469208649296\n",
            "At step: 1823 training error: 0.4628700796109084\n",
            "At step: 1824 training error: 0.46001249819340945\n",
            "At step: 1825 training error: 0.4680088368155584\n",
            "At step: 1826 training error: 0.47390003966877586\n",
            "At step: 1827 training error: 0.47704559288581244\n",
            "At step: 1828 training error: 0.4797022559954426\n",
            "At step: 1829 training error: 0.47597539477397804\n",
            "At step: 1830 training error: 0.47996696806022604\n",
            "At step: 1831 training error: 0.48493060451512693\n",
            "At step: 1832 training error: 0.48401324612287505\n",
            "At step: 1833 training error: 0.4778872183267272\n",
            "At step: 1834 training error: 0.4832398807016457\n",
            "At step: 1835 training error: 0.47143398765905753\n",
            "At step: 1836 training error: 0.4581995065548336\n",
            "At step: 1837 training error: 0.4639209922525134\n",
            "At step: 1838 training error: 0.46121141027900275\n",
            "At step: 1839 training error: 0.46315786920885244\n",
            "At step: 1840 training error: 0.46670306569563574\n",
            "At step: 1841 training error: 0.47723673060116945\n",
            "At step: 1842 training error: 0.4760644537063279\n",
            "At step: 1843 training error: 0.47223295049150665\n",
            "At step: 1844 training error: 0.4734794746438559\n",
            "At step: 1845 training error: 0.47144531134417245\n",
            "At step: 1846 training error: 0.4821129485507021\n",
            "At step: 1847 training error: 0.47283594771582216\n",
            "At step: 1848 training error: 0.4764709440271341\n",
            "At step: 1849 training error: 0.4826999995079809\n",
            "At step: 1850 training error: 0.4830894604474969\n",
            "At step: 1851 training error: 0.4900157342376894\n",
            "At step: 1852 training error: 0.4833848906858749\n",
            "At step: 1853 training error: 0.47456861033817566\n",
            "At step: 1854 training error: 0.47481328650580285\n",
            "At step: 1855 training error: 0.46709501468006115\n",
            "At step: 1856 training error: 0.4597258942394554\n",
            "At step: 1857 training error: 0.4507057134375141\n",
            "At step: 1858 training error: 0.45099195280060494\n",
            "At step: 1859 training error: 0.44827808665795693\n",
            "At step: 1860 training error: 0.4630215860847449\n",
            "At step: 1861 training error: 0.45808859937870045\n",
            "At step: 1862 training error: 0.4620193913287748\n",
            "At step: 1863 training error: 0.46232978539596903\n",
            "At step: 1864 training error: 0.4745905296839414\n",
            "At step: 1865 training error: 0.4622372380897956\n",
            "At step: 1866 training error: 0.4639329262748652\n",
            "At step: 1867 training error: 0.4675923404686652\n",
            "At step: 1868 training error: 0.4715424884593094\n",
            "At step: 1869 training error: 0.4644220855052473\n",
            "At step: 1870 training error: 0.4609768533276155\n",
            "At step: 1871 training error: 0.45940290448051513\n",
            "At step: 1872 training error: 0.46354143794122804\n",
            "At step: 1873 training error: 0.4606468721219571\n",
            "At step: 1874 training error: 0.462776378467886\n",
            "At step: 1875 training error: 0.4583528775993563\n",
            "At step: 1876 training error: 0.46676116137423285\n",
            "At step: 1877 training error: 0.4710442934481543\n",
            "At step: 1878 training error: 0.4742017518500239\n",
            "At step: 1879 training error: 0.4847081594009989\n",
            "At step: 1880 training error: 0.495231145573997\n",
            "At step: 1881 training error: 0.5047961902722545\n",
            "At step: 1882 training error: 0.5115508813069831\n",
            "At step: 1883 training error: 0.49986766802157717\n",
            "At step: 1884 training error: 0.47976511053473564\n",
            "At step: 1885 training error: 0.4738805560738244\n",
            "At step: 1886 training error: 0.477224094866151\n",
            "At step: 1887 training error: 0.4840320792060038\n",
            "At step: 1888 training error: 0.47172254863146523\n",
            "At step: 1889 training error: 0.4604923856969869\n",
            "At step: 1890 training error: 0.4591492374450611\n",
            "At step: 1891 training error: 0.4550461902861701\n",
            "At step: 1892 training error: 0.45726296752927453\n",
            "At step: 1893 training error: 0.4578734472740188\n",
            "At step: 1894 training error: 0.46164201019309287\n",
            "At step: 1895 training error: 0.4724328370026664\n",
            "At step: 1896 training error: 0.47671137281644665\n",
            "At step: 1897 training error: 0.4720895470612032\n",
            "At step: 1898 training error: 0.4751354981098091\n",
            "At step: 1899 training error: 0.467253831624324\n",
            "At step: 1900 training error: 0.4627930774110059\n",
            "At step: 1901 training error: 0.46636877311774094\n",
            "At step: 1902 training error: 0.4606506665452811\n",
            "At step: 1903 training error: 0.4578242405046711\n",
            "At step: 1904 training error: 0.4556334148908053\n",
            "At step: 1905 training error: 0.45231713092569487\n",
            "At step: 1906 training error: 0.44826044675029414\n",
            "At step: 1907 training error: 0.4461042138205926\n",
            "At step: 1908 training error: 0.4515698387321651\n",
            "At step: 1909 training error: 0.45162443461318846\n",
            "At step: 1910 training error: 0.44539235632886565\n",
            "At step: 1911 training error: 0.4490143800300803\n",
            "At step: 1912 training error: 0.4498358120410594\n",
            "At step: 1913 training error: 0.44804265198724086\n",
            "At step: 1914 training error: 0.4449501721340535\n",
            "At step: 1915 training error: 0.43348724855899595\n",
            "At step: 1916 training error: 0.43539015316842994\n",
            "At step: 1917 training error: 0.43421739002801923\n",
            "At step: 1918 training error: 0.4276409565021798\n",
            "At step: 1919 training error: 0.4347649383430761\n",
            "At step: 1920 training error: 0.42861180191140524\n",
            "At step: 1921 training error: 0.4312667954998121\n",
            "At step: 1922 training error: 0.43215924452585236\n",
            "At step: 1923 training error: 0.437690561945841\n",
            "At step: 1924 training error: 0.4315299089208219\n",
            "At step: 1925 training error: 0.4334517225838687\n",
            "At step: 1926 training error: 0.4344867136746392\n",
            "At step: 1927 training error: 0.4284212666113354\n",
            "At step: 1928 training error: 0.43162675964634367\n",
            "At step: 1929 training error: 0.43506284688748553\n",
            "At step: 1930 training error: 0.4377811405548356\n",
            "At step: 1931 training error: 0.44611425716560754\n",
            "At step: 1932 training error: 0.4555427945160793\n",
            "At step: 1933 training error: 0.4528771944971266\n",
            "At step: 1934 training error: 0.4582013090484389\n",
            "At step: 1935 training error: 0.46309172065201\n",
            "At step: 1936 training error: 0.46797618951690967\n",
            "At step: 1937 training error: 0.4683919061785027\n",
            "At step: 1938 training error: 0.4678828453889565\n",
            "At step: 1939 training error: 0.476803077821604\n",
            "At step: 1940 training error: 0.4744224106074706\n",
            "At step: 1941 training error: 0.4695762910898729\n",
            "At step: 1942 training error: 0.47676995198860067\n",
            "At step: 1943 training error: 0.4659672233037958\n",
            "At step: 1944 training error: 0.4706226536567734\n",
            "At step: 1945 training error: 0.47280748124329797\n",
            "At step: 1946 training error: 0.47297912201018716\n",
            "At step: 1947 training error: 0.48329268974386974\n",
            "At step: 1948 training error: 0.48052976715779144\n",
            "At step: 1949 training error: 0.47756661250424226\n",
            "At step: 1950 training error: 0.4777361794810028\n",
            "At step: 1951 training error: 0.46821208561205685\n",
            "At step: 1952 training error: 0.46880730229314993\n",
            "At step: 1953 training error: 0.4667353592737852\n",
            "At step: 1954 training error: 0.471097403074263\n",
            "At step: 1955 training error: 0.4646490807612007\n",
            "At step: 1956 training error: 0.46104614078945183\n",
            "At step: 1957 training error: 0.46857037803392737\n",
            "At step: 1958 training error: 0.47160174959797796\n",
            "At step: 1959 training error: 0.4810949933975071\n",
            "At step: 1960 training error: 0.4799596910015867\n",
            "At step: 1961 training error: 0.47125166282753234\n",
            "At step: 1962 training error: 0.48050984192809276\n",
            "At step: 1963 training error: 0.48330223210563494\n",
            "At step: 1964 training error: 0.47693545049878033\n",
            "At step: 1965 training error: 0.47590383255483737\n",
            "At step: 1966 training error: 0.47746302687021575\n",
            "At step: 1967 training error: 0.4726171387386728\n",
            "At step: 1968 training error: 0.4856820144796673\n",
            "At step: 1969 training error: 0.48347066502462044\n",
            "At step: 1970 training error: 0.4692316267926757\n",
            "At step: 1971 training error: 0.4664617198897842\n",
            "At step: 1972 training error: 0.47023943174502003\n",
            "At step: 1973 training error: 0.46576433601704986\n",
            "At step: 1974 training error: 0.4718153876886816\n",
            "At step: 1975 training error: 0.4681406642503808\n",
            "At step: 1976 training error: 0.4759849799484262\n",
            "At step: 1977 training error: 0.48365269693990176\n",
            "At step: 1978 training error: 0.4783493569494633\n",
            "At step: 1979 training error: 0.47132690608495553\n",
            "At step: 1980 training error: 0.4624063468416162\n",
            "At step: 1981 training error: 0.46115465547012735\n",
            "At step: 1982 training error: 0.45680669607246865\n",
            "At step: 1983 training error: 0.454699870394376\n",
            "At step: 1984 training error: 0.4511520806445646\n",
            "At step: 1985 training error: 0.45616372796308746\n",
            "At step: 1986 training error: 0.457803968944388\n",
            "At step: 1987 training error: 0.46035374722366706\n",
            "At step: 1988 training error: 0.46245857718473626\n",
            "At step: 1989 training error: 0.46169067436951333\n",
            "At step: 1990 training error: 0.46017576156938633\n",
            "At step: 1991 training error: 0.4593545293737029\n",
            "At step: 1992 training error: 0.4707789727736331\n",
            "At step: 1993 training error: 0.475687789132201\n",
            "At step: 1994 training error: 0.481754777209758\n",
            "At step: 1995 training error: 0.47277494337085246\n",
            "At step: 1996 training error: 0.46839799781237573\n",
            "At step: 1997 training error: 0.4622823373541732\n",
            "At step: 1998 training error: 0.4526181014412023\n",
            "At step: 1999 training error: 0.4560344337365387\n",
            "At step: 2000 training error: 0.46250120678046897\n",
            "At step: 2001 training error: 0.4636169697638116\n",
            "At step: 2002 training error: 0.46537610879064545\n",
            "At step: 2003 training error: 0.46357738687721434\n",
            "At step: 2004 training error: 0.4549165164835205\n",
            "At step: 2005 training error: 0.4596113197913405\n",
            "At step: 2006 training error: 0.4588891856355813\n",
            "At step: 2007 training error: 0.454110165947863\n",
            "At step: 2008 training error: 0.4452475347486853\n",
            "At step: 2009 training error: 0.4592744693577265\n",
            "At step: 2010 training error: 0.4548594853724679\n",
            "At step: 2011 training error: 0.45026059137724406\n",
            "At step: 2012 training error: 0.4457558101827318\n",
            "At step: 2013 training error: 0.45330246606126834\n",
            "At step: 2014 training error: 0.45540212891669957\n",
            "At step: 2015 training error: 0.4589941331151183\n",
            "At step: 2016 training error: 0.45476672112499633\n",
            "At step: 2017 training error: 0.45202465340197556\n",
            "At step: 2018 training error: 0.46665888329438243\n",
            "At step: 2019 training error: 0.47384515667217075\n",
            "At step: 2020 training error: 0.47244535084373834\n",
            "At step: 2021 training error: 0.4816145376747966\n",
            "At step: 2022 training error: 0.49033826444384077\n",
            "At step: 2023 training error: 0.48620575671189015\n",
            "At step: 2024 training error: 0.48825314404128384\n",
            "At step: 2025 training error: 0.4864600820771111\n",
            "At step: 2026 training error: 0.48988125232955215\n",
            "At step: 2027 training error: 0.4807104172664631\n",
            "At step: 2028 training error: 0.47572557976728047\n",
            "At step: 2029 training error: 0.4679868971206617\n",
            "At step: 2030 training error: 0.46298020513860755\n",
            "At step: 2031 training error: 0.4622436927012742\n",
            "At step: 2032 training error: 0.4703681482106411\n",
            "At step: 2033 training error: 0.4705972756816315\n",
            "At step: 2034 training error: 0.48016289183641014\n",
            "At step: 2035 training error: 0.47274568994356797\n",
            "At step: 2036 training error: 0.4745631069980277\n",
            "At step: 2037 training error: 0.469672974927883\n",
            "At step: 2038 training error: 0.46756814841392363\n",
            "At step: 2039 training error: 0.4613504990752451\n",
            "At step: 2040 training error: 0.45324505671662174\n",
            "At step: 2041 training error: 0.4558871658831382\n",
            "At step: 2042 training error: 0.4470485235129689\n",
            "At step: 2043 training error: 0.45258244956288995\n",
            "At step: 2044 training error: 0.456466775594282\n",
            "At step: 2045 training error: 0.46492239420432624\n",
            "At step: 2046 training error: 0.4506815214330983\n",
            "At step: 2047 training error: 0.4567583811802732\n",
            "At step: 2048 training error: 0.4551252361597031\n",
            "At step: 2049 training error: 0.463753966893876\n",
            "At step: 2050 training error: 0.46698546889519454\n",
            "At step: 2051 training error: 0.46785674037770175\n",
            "At step: 2052 training error: 0.46165398594506873\n",
            "At step: 2053 training error: 0.45146189348152843\n",
            "At step: 2054 training error: 0.4515402977739393\n",
            "At step: 2055 training error: 0.4497518638271314\n",
            "At step: 2056 training error: 0.4575757341885814\n",
            "At step: 2057 training error: 0.4555231193112186\n",
            "At step: 2058 training error: 0.44404103501349146\n",
            "At step: 2059 training error: 0.4596445983802384\n",
            "At step: 2060 training error: 0.4672417594620317\n",
            "At step: 2061 training error: 0.4594120633910342\n",
            "At step: 2062 training error: 0.45192464017270917\n",
            "At step: 2063 training error: 0.45554667884441136\n",
            "At step: 2064 training error: 0.45589892828559786\n",
            "At step: 2065 training error: 0.46655395418026063\n",
            "At step: 2066 training error: 0.45778287902129117\n",
            "At step: 2067 training error: 0.4622368500413875\n",
            "At step: 2068 training error: 0.46266488733032574\n",
            "At step: 2069 training error: 0.4634777508383789\n",
            "At step: 2070 training error: 0.45431963843586737\n",
            "At step: 2071 training error: 0.45980878979338513\n",
            "At step: 2072 training error: 0.4621929366224376\n",
            "At step: 2073 training error: 0.4638651004512065\n",
            "At step: 2074 training error: 0.46733910968950654\n",
            "At step: 2075 training error: 0.45926215990924085\n",
            "At step: 2076 training error: 0.4623628211345614\n",
            "At step: 2077 training error: 0.46993801939479857\n",
            "At step: 2078 training error: 0.4590267016272646\n",
            "At step: 2079 training error: 0.4664452583310626\n",
            "At step: 2080 training error: 0.47787477878838514\n",
            "At step: 2081 training error: 0.48333790838031343\n",
            "At step: 2082 training error: 0.47497871620990045\n",
            "At step: 2083 training error: 0.4699151326390826\n",
            "At step: 2084 training error: 0.47177340975636317\n",
            "At step: 2085 training error: 0.46175760555612416\n",
            "At step: 2086 training error: 0.4633406036138971\n",
            "At step: 2087 training error: 0.4616208830292009\n",
            "At step: 2088 training error: 0.4642540373561593\n",
            "At step: 2089 training error: 0.46686683164849635\n",
            "At step: 2090 training error: 0.4696587959998421\n",
            "At step: 2091 training error: 0.4601555307087357\n",
            "At step: 2092 training error: 0.45587262743318957\n",
            "At step: 2093 training error: 0.45938021867243334\n",
            "At step: 2094 training error: 0.46754112859530356\n",
            "At step: 2095 training error: 0.4752451567425957\n",
            "At step: 2096 training error: 0.4799564163764628\n",
            "At step: 2097 training error: 0.474490285458174\n",
            "At step: 2098 training error: 0.471301813085365\n",
            "At step: 2099 training error: 0.46455917743878256\n",
            "At step: 2100 training error: 0.46284853414473914\n",
            "At step: 2101 training error: 0.4705532482512738\n",
            "At step: 2102 training error: 0.4600622402575682\n",
            "At step: 2103 training error: 0.4692336108299573\n",
            "At step: 2104 training error: 0.4673304626348608\n",
            "At step: 2105 training error: 0.4584771707063233\n",
            "At step: 2106 training error: 0.4529615527281599\n",
            "At step: 2107 training error: 0.4470182135876867\n",
            "At step: 2108 training error: 0.4494663503426283\n",
            "At step: 2109 training error: 0.44422354342855785\n",
            "At step: 2110 training error: 0.45577544226438826\n",
            "At step: 2111 training error: 0.4574375038483038\n",
            "At step: 2112 training error: 0.4489663533087487\n",
            "At step: 2113 training error: 0.4558190544638198\n",
            "At step: 2114 training error: 0.4553783360194036\n",
            "At step: 2115 training error: 0.4597399287213672\n",
            "At step: 2116 training error: 0.4553200979364549\n",
            "At step: 2117 training error: 0.4545419787543545\n",
            "At step: 2118 training error: 0.45231816453514656\n",
            "At step: 2119 training error: 0.4575043877122679\n",
            "At step: 2120 training error: 0.4643486035055166\n",
            "At step: 2121 training error: 0.4653047363113554\n",
            "At step: 2122 training error: 0.47016705019671257\n",
            "At step: 2123 training error: 0.46329497637377104\n",
            "At step: 2124 training error: 0.47565071551544474\n",
            "At step: 2125 training error: 0.4777760796633509\n",
            "At step: 2126 training error: 0.484983052743609\n",
            "At step: 2127 training error: 0.4818270481833783\n",
            "At step: 2128 training error: 0.48625864157016857\n",
            "At step: 2129 training error: 0.4781729612574399\n",
            "At step: 2130 training error: 0.4719470787218043\n",
            "At step: 2131 training error: 0.47598975719921655\n",
            "At step: 2132 training error: 0.4702563152971402\n",
            "At step: 2133 training error: 0.46453517287152984\n",
            "At step: 2134 training error: 0.46623929616687826\n",
            "At step: 2135 training error: 0.45760228013620247\n",
            "At step: 2136 training error: 0.45103351523481516\n",
            "At step: 2137 training error: 0.4475489672791985\n",
            "At step: 2138 training error: 0.45708589660225557\n",
            "At step: 2139 training error: 0.45639758800797803\n",
            "At step: 2140 training error: 0.45096168794532815\n",
            "At step: 2141 training error: 0.46420752035174173\n",
            "At step: 2142 training error: 0.4577293578999167\n",
            "At step: 2143 training error: 0.46490649560638087\n",
            "At step: 2144 training error: 0.45933431254368107\n",
            "At step: 2145 training error: 0.46466775414574096\n",
            "At step: 2146 training error: 0.46245839666390776\n",
            "At step: 2147 training error: 0.47967194505705657\n",
            "At step: 2148 training error: 0.4770640921116613\n",
            "At step: 2149 training error: 0.4729972383447768\n",
            "At step: 2150 training error: 0.4693834874365361\n",
            "At step: 2151 training error: 0.46231626987605934\n",
            "At step: 2152 training error: 0.46669256533925846\n",
            "At step: 2153 training error: 0.46760988869240433\n",
            "At step: 2154 training error: 0.47097867603791377\n",
            "At step: 2155 training error: 0.4706910225642418\n",
            "At step: 2156 training error: 0.4630377128037804\n",
            "At step: 2157 training error: 0.46842705777816773\n",
            "At step: 2158 training error: 0.46731542368703993\n",
            "At step: 2159 training error: 0.47575303400498825\n",
            "At step: 2160 training error: 0.46845920452833234\n",
            "At step: 2161 training error: 0.46783510050742866\n",
            "At step: 2162 training error: 0.4583075409630263\n",
            "At step: 2163 training error: 0.4591182167872986\n",
            "At step: 2164 training error: 0.46709715542347147\n",
            "At step: 2165 training error: 0.46926542656845005\n",
            "At step: 2166 training error: 0.4803916066639264\n",
            "At step: 2167 training error: 0.472313006935015\n",
            "At step: 2168 training error: 0.47643635207542595\n",
            "At step: 2169 training error: 0.4715776007521685\n",
            "At step: 2170 training error: 0.46621146361795857\n",
            "At step: 2171 training error: 0.47987452258748003\n",
            "At step: 2172 training error: 0.47265807771424473\n",
            "At step: 2173 training error: 0.4718946703119977\n",
            "At step: 2174 training error: 0.4681818025110274\n",
            "At step: 2175 training error: 0.4643456632724246\n",
            "At step: 2176 training error: 0.4616031089231064\n",
            "At step: 2177 training error: 0.46811677717466704\n",
            "At step: 2178 training error: 0.4700159169066465\n",
            "At step: 2179 training error: 0.46170526857968164\n",
            "At step: 2180 training error: 0.4554164943900451\n",
            "At step: 2181 training error: 0.4593665819418872\n",
            "At step: 2182 training error: 0.45404481017095055\n",
            "At step: 2183 training error: 0.4527188261245177\n",
            "At step: 2184 training error: 0.4493455321955467\n",
            "At step: 2185 training error: 0.44862947454494906\n",
            "At step: 2186 training error: 0.45170295171554353\n",
            "At step: 2187 training error: 0.4664201367599644\n",
            "At step: 2188 training error: 0.4594841529836765\n",
            "At step: 2189 training error: 0.45527777032035477\n",
            "At step: 2190 training error: 0.45203101972674087\n",
            "At step: 2191 training error: 0.4559232160803227\n",
            "At step: 2192 training error: 0.4585170510390512\n",
            "At step: 2193 training error: 0.46588456539459033\n",
            "At step: 2194 training error: 0.45654188987421335\n",
            "At step: 2195 training error: 0.45419586268168627\n",
            "At step: 2196 training error: 0.444917504657788\n",
            "At step: 2197 training error: 0.44472803768701735\n",
            "At step: 2198 training error: 0.44168541707155173\n",
            "At step: 2199 training error: 0.43388651525987354\n",
            "At step: 2200 training error: 0.4445209146480385\n",
            "At step: 2201 training error: 0.45452240452445924\n",
            "At step: 2202 training error: 0.45646065600012975\n",
            "At step: 2203 training error: 0.4600037831360785\n",
            "At step: 2204 training error: 0.46283696193014634\n",
            "At step: 2205 training error: 0.46935661738928847\n",
            "At step: 2206 training error: 0.4685864385999252\n",
            "At step: 2207 training error: 0.4723754223848714\n",
            "At step: 2208 training error: 0.4751702171871008\n",
            "At step: 2209 training error: 0.4722019429105588\n",
            "At step: 2210 training error: 0.4788913678324215\n",
            "At step: 2211 training error: 0.47176001509905224\n",
            "At step: 2212 training error: 0.4718700757520303\n",
            "At step: 2213 training error: 0.47612152566697663\n",
            "At step: 2214 training error: 0.47551539197340464\n",
            "At step: 2215 training error: 0.47516363046312027\n",
            "At step: 2216 training error: 0.47297615874893767\n",
            "At step: 2217 training error: 0.4765745634376785\n",
            "At step: 2218 training error: 0.4665452933012622\n",
            "At step: 2219 training error: 0.4812059870550214\n",
            "At step: 2220 training error: 0.47878190714346736\n",
            "At step: 2221 training error: 0.4775242569029713\n",
            "At step: 2222 training error: 0.48560566017992374\n",
            "At step: 2223 training error: 0.48082875785474904\n",
            "At step: 2224 training error: 0.469084053784992\n",
            "At step: 2225 training error: 0.4667330601116335\n",
            "At step: 2226 training error: 0.4688265572854346\n",
            "At step: 2227 training error: 0.45655281825793237\n",
            "At step: 2228 training error: 0.4623549490689929\n",
            "At step: 2229 training error: 0.4780777250737611\n",
            "At step: 2230 training error: 0.47347199741766155\n",
            "At step: 2231 training error: 0.4762553999092373\n",
            "At step: 2232 training error: 0.47347429276522696\n",
            "At step: 2233 training error: 0.4742570129328944\n",
            "At step: 2234 training error: 0.46736477290121364\n",
            "At step: 2235 training error: 0.4546082283918113\n",
            "At step: 2236 training error: 0.45406208961919947\n",
            "At step: 2237 training error: 0.4440581843752714\n",
            "At step: 2238 training error: 0.4442151837074898\n",
            "At step: 2239 training error: 0.4446643044629031\n",
            "At step: 2240 training error: 0.45263741141159053\n",
            "At step: 2241 training error: 0.45248910445881707\n",
            "At step: 2242 training error: 0.4625901951422488\n",
            "At step: 2243 training error: 0.4644206450620605\n",
            "At step: 2244 training error: 0.4669457220124404\n",
            "At step: 2245 training error: 0.46151147153300875\n",
            "At step: 2246 training error: 0.4580189520866154\n",
            "At step: 2247 training error: 0.4611524160849558\n",
            "At step: 2248 training error: 0.4623584664615256\n",
            "At step: 2249 training error: 0.4640010603112434\n",
            "At step: 2250 training error: 0.4803418979213372\n",
            "At step: 2251 training error: 0.47863747465451345\n",
            "At step: 2252 training error: 0.4832291079380663\n",
            "At step: 2253 training error: 0.482179939470106\n",
            "At step: 2254 training error: 0.46928854175333984\n",
            "At step: 2255 training error: 0.4641628466808453\n",
            "At step: 2256 training error: 0.4481203108662344\n",
            "At step: 2257 training error: 0.43853432995196\n",
            "At step: 2258 training error: 0.44207899444534227\n",
            "At step: 2259 training error: 0.43952965531385124\n",
            "At step: 2260 training error: 0.4492466091342413\n",
            "At step: 2261 training error: 0.44735294193096764\n",
            "At step: 2262 training error: 0.4481555299235437\n",
            "At step: 2263 training error: 0.44859094126911203\n",
            "At step: 2264 training error: 0.451447600979363\n",
            "At step: 2265 training error: 0.4420532775055638\n",
            "At step: 2266 training error: 0.4447741350447104\n",
            "At step: 2267 training error: 0.4476162406117633\n",
            "At step: 2268 training error: 0.4485117969872446\n",
            "At step: 2269 training error: 0.4621759694558249\n",
            "At step: 2270 training error: 0.4727768770442915\n",
            "At step: 2271 training error: 0.4609587991770359\n",
            "At step: 2272 training error: 0.46537951413950496\n",
            "At step: 2273 training error: 0.46804518758149166\n",
            "At step: 2274 training error: 0.45663246557414755\n",
            "At step: 2275 training error: 0.4552003378639391\n",
            "At step: 2276 training error: 0.45788356467809227\n",
            "At step: 2277 training error: 0.4610625739328383\n",
            "At step: 2278 training error: 0.45891687385999985\n",
            "At step: 2279 training error: 0.4805171283123121\n",
            "At step: 2280 training error: 0.4747359560131181\n",
            "At step: 2281 training error: 0.4726514394391171\n",
            "At step: 2282 training error: 0.4705317446381919\n",
            "At step: 2283 training error: 0.47664086426690266\n",
            "At step: 2284 training error: 0.4782966547108866\n",
            "At step: 2285 training error: 0.481520993310589\n",
            "At step: 2286 training error: 0.47884709292318817\n",
            "At step: 2287 training error: 0.4669990381885641\n",
            "At step: 2288 training error: 0.4600172368591118\n",
            "At step: 2289 training error: 0.45238345405716257\n",
            "At step: 2290 training error: 0.44922246442314606\n",
            "At step: 2291 training error: 0.43487364860845323\n",
            "At step: 2292 training error: 0.4373425683417568\n",
            "At step: 2293 training error: 0.436168075112662\n",
            "At step: 2294 training error: 0.43510510809138037\n",
            "At step: 2295 training error: 0.4395052341631011\n",
            "At step: 2296 training error: 0.45224629575076725\n",
            "At step: 2297 training error: 0.44482822121073823\n",
            "At step: 2298 training error: 0.44732289618334514\n",
            "At step: 2299 training error: 0.45013958188181924\n",
            "At step: 2300 training error: 0.45070791871742727\n",
            "At step: 2301 training error: 0.45332162156203276\n",
            "At step: 2302 training error: 0.45829292389405224\n",
            "At step: 2303 training error: 0.46346423797972036\n",
            "At step: 2304 training error: 0.44658225748061825\n",
            "At step: 2305 training error: 0.4408670128298546\n",
            "At step: 2306 training error: 0.43984540004036704\n",
            "At step: 2307 training error: 0.448381961959574\n",
            "At step: 2308 training error: 0.44955583448749914\n",
            "At step: 2309 training error: 0.4532415467619483\n",
            "At step: 2310 training error: 0.4501370982592835\n",
            "At step: 2311 training error: 0.445979695113433\n",
            "At step: 2312 training error: 0.44460483025585146\n",
            "At step: 2313 training error: 0.44854583362079375\n",
            "At step: 2314 training error: 0.446242332407661\n",
            "At step: 2315 training error: 0.4399038750788059\n",
            "At step: 2316 training error: 0.4440343292788956\n",
            "At step: 2317 training error: 0.45270804824958744\n",
            "At step: 2318 training error: 0.4410262340068214\n",
            "At step: 2319 training error: 0.4490121886880867\n",
            "At step: 2320 training error: 0.44611072126320594\n",
            "At step: 2321 training error: 0.4413123028507099\n",
            "At step: 2322 training error: 0.44157423512012584\n",
            "At step: 2323 training error: 0.4436423213466183\n",
            "At step: 2324 training error: 0.4559519368153021\n",
            "At step: 2325 training error: 0.45445377639544093\n",
            "At step: 2326 training error: 0.4574127669926903\n",
            "At step: 2327 training error: 0.4532622928905983\n",
            "At step: 2328 training error: 0.4495281855133148\n",
            "At step: 2329 training error: 0.46578974957754354\n",
            "At step: 2330 training error: 0.45990940825103555\n",
            "At step: 2331 training error: 0.47635222594878956\n",
            "At step: 2332 training error: 0.46536816963490546\n",
            "At step: 2333 training error: 0.46548953622503436\n",
            "At step: 2334 training error: 0.46747046285509714\n",
            "At step: 2335 training error: 0.4745559723895134\n",
            "At step: 2336 training error: 0.47464888653581727\n",
            "At step: 2337 training error: 0.4656100427453402\n",
            "At step: 2338 training error: 0.47340103307826564\n",
            "At step: 2339 training error: 0.4799270961888025\n",
            "At step: 2340 training error: 0.4681613821017485\n",
            "At step: 2341 training error: 0.4640947730625639\n",
            "At step: 2342 training error: 0.46890546997267524\n",
            "At step: 2343 training error: 0.4711403722003011\n",
            "At step: 2344 training error: 0.47462828348960245\n",
            "At step: 2345 training error: 0.4818102018078936\n",
            "At step: 2346 training error: 0.4826139282831283\n",
            "At step: 2347 training error: 0.48885312472010695\n",
            "At step: 2348 training error: 0.48142809432048017\n",
            "At step: 2349 training error: 0.4800452773892555\n",
            "At step: 2350 training error: 0.4749474789219486\n",
            "At step: 2351 training error: 0.47779553609224856\n",
            "At step: 2352 training error: 0.47117063268672493\n",
            "At step: 2353 training error: 0.46600108132626394\n",
            "At step: 2354 training error: 0.4619942256374323\n",
            "At step: 2355 training error: 0.48074338958929386\n",
            "At step: 2356 training error: 0.4782125773498187\n",
            "At step: 2357 training error: 0.4807630057416591\n",
            "At step: 2358 training error: 0.48325208212705695\n",
            "At step: 2359 training error: 0.4847929923371142\n",
            "At step: 2360 training error: 0.47675731527431253\n",
            "At step: 2361 training error: 0.47057641990249083\n",
            "At step: 2362 training error: 0.4752592676545457\n",
            "At step: 2363 training error: 0.480181126433586\n",
            "At step: 2364 training error: 0.4792263816669778\n",
            "At step: 2365 training error: 0.47396806997718643\n",
            "At step: 2366 training error: 0.46859550487706403\n",
            "At step: 2367 training error: 0.46786800907506926\n",
            "At step: 2368 training error: 0.47835012840355484\n",
            "At step: 2369 training error: 0.4764913777613179\n",
            "At step: 2370 training error: 0.47693857266643\n",
            "At step: 2371 training error: 0.48035884314948\n",
            "At step: 2372 training error: 0.47454031241032846\n",
            "At step: 2373 training error: 0.46662986441048515\n",
            "At step: 2374 training error: 0.4647878393937094\n",
            "At step: 2375 training error: 0.46337648657024677\n",
            "At step: 2376 training error: 0.4599303078088474\n",
            "At step: 2377 training error: 0.4506559853437464\n",
            "At step: 2378 training error: 0.43900114393544415\n",
            "At step: 2379 training error: 0.4463248366273814\n",
            "At step: 2380 training error: 0.4495991493512839\n",
            "At step: 2381 training error: 0.4501522967778029\n",
            "At step: 2382 training error: 0.4641366621081091\n",
            "At step: 2383 training error: 0.46871165904265816\n",
            "At step: 2384 training error: 0.46401449695293334\n",
            "At step: 2385 training error: 0.4617827703057404\n",
            "At step: 2386 training error: 0.45413958988725567\n",
            "At step: 2387 training error: 0.44963492311411635\n",
            "At step: 2388 training error: 0.45121696153059776\n",
            "At step: 2389 training error: 0.45550315272970004\n",
            "At step: 2390 training error: 0.4528167308519852\n",
            "At step: 2391 training error: 0.45507039843855607\n",
            "At step: 2392 training error: 0.46444209554497085\n",
            "At step: 2393 training error: 0.466169701604867\n",
            "At step: 2394 training error: 0.4746543550030071\n",
            "At step: 2395 training error: 0.482658964591134\n",
            "At step: 2396 training error: 0.4829057469007878\n",
            "At step: 2397 training error: 0.4759186984421522\n",
            "At step: 2398 training error: 0.4634135722123861\n",
            "At step: 2399 training error: 0.45593598089205856\n",
            "At step: 2400 training error: 0.4492170534663702\n",
            "At step: 2401 training error: 0.4442401352878226\n",
            "At step: 2402 training error: 0.44407450297343976\n",
            "At step: 2403 training error: 0.4454370066841574\n",
            "At step: 2404 training error: 0.44194654547507184\n",
            "At step: 2405 training error: 0.4453301132576617\n",
            "At step: 2406 training error: 0.44642440407364836\n",
            "At step: 2407 training error: 0.4584924373532745\n",
            "At step: 2408 training error: 0.4674129688359605\n",
            "At step: 2409 training error: 0.46819606653371765\n",
            "At step: 2410 training error: 0.4586619008444911\n",
            "At step: 2411 training error: 0.4550352831600796\n",
            "At step: 2412 training error: 0.4589958795517053\n",
            "At step: 2413 training error: 0.4592967220112379\n",
            "At step: 2414 training error: 0.4551108710588581\n",
            "At step: 2415 training error: 0.4529309731185079\n",
            "At step: 2416 training error: 0.4548425966292648\n",
            "At step: 2417 training error: 0.46101447580491167\n",
            "At step: 2418 training error: 0.4622858426180235\n",
            "At step: 2419 training error: 0.4669274472964429\n",
            "At step: 2420 training error: 0.46647958740624396\n",
            "At step: 2421 training error: 0.4644671241363982\n",
            "At step: 2422 training error: 0.4594793380175021\n",
            "At step: 2423 training error: 0.46719959146175394\n",
            "At step: 2424 training error: 0.4722207982177607\n",
            "At step: 2425 training error: 0.4682707113774173\n",
            "At step: 2426 training error: 0.45888392320576954\n",
            "At step: 2427 training error: 0.4576250736208469\n",
            "At step: 2428 training error: 0.4532992535246806\n",
            "At step: 2429 training error: 0.4646254698240752\n",
            "At step: 2430 training error: 0.46285538394889597\n",
            "At step: 2431 training error: 0.466305008516071\n",
            "At step: 2432 training error: 0.4698209635439999\n",
            "At step: 2433 training error: 0.4819281430163235\n",
            "At step: 2434 training error: 0.48163293241913074\n",
            "At step: 2435 training error: 0.4847628741515515\n",
            "At step: 2436 training error: 0.4738034827035024\n",
            "At step: 2437 training error: 0.4674375033935032\n",
            "At step: 2438 training error: 0.470266902605086\n",
            "At step: 2439 training error: 0.47158034263939386\n",
            "At step: 2440 training error: 0.4669182190501069\n",
            "At step: 2441 training error: 0.4676229584558775\n",
            "At step: 2442 training error: 0.4569010549264219\n",
            "At step: 2443 training error: 0.45940696606522147\n",
            "At step: 2444 training error: 0.46249773735837346\n",
            "At step: 2445 training error: 0.453602009000511\n",
            "At step: 2446 training error: 0.45518502420553025\n",
            "At step: 2447 training error: 0.4520597328128413\n",
            "At step: 2448 training error: 0.45286910972118627\n",
            "At step: 2449 training error: 0.453564307227179\n",
            "At step: 2450 training error: 0.45467561446551935\n",
            "At step: 2451 training error: 0.4606357040172159\n",
            "At step: 2452 training error: 0.4609529317173587\n",
            "At step: 2453 training error: 0.4679267984812009\n",
            "At step: 2454 training error: 0.46911816735548656\n",
            "At step: 2455 training error: 0.47115071784998885\n",
            "At step: 2456 training error: 0.4697810885566016\n",
            "At step: 2457 training error: 0.4668281908613286\n",
            "At step: 2458 training error: 0.45893319655774434\n",
            "At step: 2459 training error: 0.4623708897496122\n",
            "At step: 2460 training error: 0.46020701776091844\n",
            "At step: 2461 training error: 0.45335767973093877\n",
            "At step: 2462 training error: 0.4555945267095268\n",
            "At step: 2463 training error: 0.46441367524615834\n",
            "At step: 2464 training error: 0.45698984194289627\n",
            "At step: 2465 training error: 0.4554648337523693\n",
            "At step: 2466 training error: 0.45522253681388153\n",
            "At step: 2467 training error: 0.44600804622062495\n",
            "At step: 2468 training error: 0.4495031662393766\n",
            "At step: 2469 training error: 0.4695021967537313\n",
            "At step: 2470 training error: 0.4778851916265358\n",
            "At step: 2471 training error: 0.4745179344895789\n",
            "At step: 2472 training error: 0.47673781770978096\n",
            "At step: 2473 training error: 0.46523440366252417\n",
            "At step: 2474 training error: 0.47089291182781473\n",
            "At step: 2475 training error: 0.4767914759562549\n",
            "At step: 2476 training error: 0.4734462955708556\n",
            "At step: 2477 training error: 0.47067431208050675\n",
            "At step: 2478 training error: 0.47812263170656005\n",
            "At step: 2479 training error: 0.477468438457732\n",
            "At step: 2480 training error: 0.4705446936756622\n",
            "At step: 2481 training error: 0.4677618688126748\n",
            "At step: 2482 training error: 0.46376892125005753\n",
            "At step: 2483 training error: 0.46227482686534155\n",
            "At step: 2484 training error: 0.4559708304231531\n",
            "At step: 2485 training error: 0.452966743522768\n",
            "At step: 2486 training error: 0.4578197358701647\n",
            "At step: 2487 training error: 0.4434470508401782\n",
            "At step: 2488 training error: 0.4513251226109462\n",
            "At step: 2489 training error: 0.4452146849107315\n",
            "At step: 2490 training error: 0.45974778806596694\n",
            "At step: 2491 training error: 0.4593872787608423\n",
            "At step: 2492 training error: 0.45844367443472067\n",
            "At step: 2493 training error: 0.47203712752701243\n",
            "At step: 2494 training error: 0.47530034796493137\n",
            "At step: 2495 training error: 0.46672894963171585\n",
            "At step: 2496 training error: 0.4683100241385392\n",
            "At step: 2497 training error: 0.4634503151092414\n",
            "At step: 2498 training error: 0.4540696310646293\n",
            "At step: 2499 training error: 0.46441229140514\n",
            "At step: 2500 training error: 0.462826540301676\n",
            "At step: 2501 training error: 0.4526172246381733\n",
            "At step: 2502 training error: 0.45291915800670013\n",
            "At step: 2503 training error: 0.45247081322337\n",
            "At step: 2504 training error: 0.4644212537885053\n",
            "At step: 2505 training error: 0.46148349501501057\n",
            "At step: 2506 training error: 0.4636258672494067\n",
            "At step: 2507 training error: 0.4539257539967523\n",
            "At step: 2508 training error: 0.45266763663187803\n",
            "At step: 2509 training error: 0.4576060796333536\n",
            "At step: 2510 training error: 0.45677515623842657\n",
            "At step: 2511 training error: 0.45127236988021346\n",
            "At step: 2512 training error: 0.4463394177069686\n",
            "At step: 2513 training error: 0.45830064907869966\n",
            "At step: 2514 training error: 0.4508013417297888\n",
            "At step: 2515 training error: 0.45798907916512965\n",
            "At step: 2516 training error: 0.4641088449133507\n",
            "At step: 2517 training error: 0.46707246071165204\n",
            "At step: 2518 training error: 0.46653264584339127\n",
            "At step: 2519 training error: 0.46844241646923956\n",
            "At step: 2520 training error: 0.4807231333634888\n",
            "At step: 2521 training error: 0.5021049454649157\n",
            "At step: 2522 training error: 0.49635936031466876\n",
            "At step: 2523 training error: 0.4734371901438836\n",
            "At step: 2524 training error: 0.46337659761550076\n",
            "At step: 2525 training error: 0.4702283713202453\n",
            "At step: 2526 training error: 0.45687341916108193\n",
            "At step: 2527 training error: 0.4536098786715859\n",
            "At step: 2528 training error: 0.45588049107403367\n",
            "At step: 2529 training error: 0.45335106175109813\n",
            "At step: 2530 training error: 0.46050406036133323\n",
            "At step: 2531 training error: 0.4627444570269213\n",
            "At step: 2532 training error: 0.46884291315917914\n",
            "At step: 2533 training error: 0.47179470069755136\n",
            "At step: 2534 training error: 0.4711704869520295\n",
            "At step: 2535 training error: 0.4656562595304974\n",
            "At step: 2536 training error: 0.4655520764895279\n",
            "At step: 2537 training error: 0.4638612395322636\n",
            "At step: 2538 training error: 0.4641894983945955\n",
            "At step: 2539 training error: 0.46345086006472175\n",
            "At step: 2540 training error: 0.46845022068032993\n",
            "At step: 2541 training error: 0.47178626353865577\n",
            "At step: 2542 training error: 0.47843659381056647\n",
            "At step: 2543 training error: 0.4755313620231581\n",
            "At step: 2544 training error: 0.46868415750478\n",
            "At step: 2545 training error: 0.4788881188984239\n",
            "At step: 2546 training error: 0.4714163383368036\n",
            "At step: 2547 training error: 0.47402430818619545\n",
            "At step: 2548 training error: 0.4779604749642079\n",
            "At step: 2549 training error: 0.4612696542914877\n",
            "At step: 2550 training error: 0.4539896144696154\n",
            "At step: 2551 training error: 0.45486482361483416\n",
            "At step: 2552 training error: 0.46754038215514826\n",
            "At step: 2553 training error: 0.46391408337439244\n",
            "At step: 2554 training error: 0.47284096310609147\n",
            "At step: 2555 training error: 0.4663314200421884\n",
            "At step: 2556 training error: 0.4684931336539402\n",
            "At step: 2557 training error: 0.4719479248417791\n",
            "At step: 2558 training error: 0.47509067928046395\n",
            "At step: 2559 training error: 0.47377882126829135\n",
            "At step: 2560 training error: 0.4750352100832709\n",
            "At step: 2561 training error: 0.4807128817422709\n",
            "At step: 2562 training error: 0.4833440686339212\n",
            "At step: 2563 training error: 0.4704592257737263\n",
            "At step: 2564 training error: 0.48155915676803485\n",
            "At step: 2565 training error: 0.4768718062425984\n",
            "At step: 2566 training error: 0.4824768773090112\n",
            "At step: 2567 training error: 0.47837243084555403\n",
            "At step: 2568 training error: 0.47068399846680586\n",
            "At step: 2569 training error: 0.4597726435210826\n",
            "At step: 2570 training error: 0.45804280318525536\n",
            "At step: 2571 training error: 0.45585431071467014\n",
            "At step: 2572 training error: 0.44894505199655915\n",
            "At step: 2573 training error: 0.4490850825188645\n",
            "At step: 2574 training error: 0.44714763076428843\n",
            "At step: 2575 training error: 0.4553461420331287\n",
            "At step: 2576 training error: 0.4523362924651606\n",
            "At step: 2577 training error: 0.4522429842192228\n",
            "At step: 2578 training error: 0.4456205990640023\n",
            "At step: 2579 training error: 0.45051536704129047\n",
            "At step: 2580 training error: 0.46109367072518437\n",
            "At step: 2581 training error: 0.4564073623206867\n",
            "At step: 2582 training error: 0.4516786667477732\n",
            "At step: 2583 training error: 0.44776093829715574\n",
            "At step: 2584 training error: 0.4519177569438708\n",
            "At step: 2585 training error: 0.45597726325103705\n",
            "At step: 2586 training error: 0.4518173794565748\n",
            "At step: 2587 training error: 0.44061012896174684\n",
            "At step: 2588 training error: 0.450551308359294\n",
            "At step: 2589 training error: 0.4462707508282651\n",
            "At step: 2590 training error: 0.4438654685583598\n",
            "At step: 2591 training error: 0.4467367321548891\n",
            "At step: 2592 training error: 0.44386932972938103\n",
            "At step: 2593 training error: 0.44637843543893513\n",
            "At step: 2594 training error: 0.43166088437890976\n",
            "At step: 2595 training error: 0.43927550986642583\n",
            "At step: 2596 training error: 0.43626253717961416\n",
            "At step: 2597 training error: 0.43644216303853683\n",
            "At step: 2598 training error: 0.4398517639374647\n",
            "At step: 2599 training error: 0.4445378400879322\n",
            "At step: 2600 training error: 0.44309666956115024\n",
            "At step: 2601 training error: 0.43896418588427394\n",
            "At step: 2602 training error: 0.45087322977484784\n",
            "At step: 2603 training error: 0.45562570373733685\n",
            "At step: 2604 training error: 0.4590016568553719\n",
            "At step: 2605 training error: 0.46043355195075003\n",
            "At step: 2606 training error: 0.45950222196734614\n",
            "At step: 2607 training error: 0.44930634320051405\n",
            "At step: 2608 training error: 0.4497954243864133\n",
            "At step: 2609 training error: 0.445318867823814\n",
            "At step: 2610 training error: 0.4340482446854094\n",
            "At step: 2611 training error: 0.43228831674932766\n",
            "At step: 2612 training error: 0.43784723347626014\n",
            "At step: 2613 training error: 0.43303528387633383\n",
            "At step: 2614 training error: 0.4363705266002246\n",
            "At step: 2615 training error: 0.438398025811345\n",
            "At step: 2616 training error: 0.44945583565555935\n",
            "At step: 2617 training error: 0.44489262493123993\n",
            "At step: 2618 training error: 0.4452604834263606\n",
            "At step: 2619 training error: 0.45469064787407076\n",
            "At step: 2620 training error: 0.4570369792843608\n",
            "At step: 2621 training error: 0.4581126412818932\n",
            "At step: 2622 training error: 0.461283456508748\n",
            "At step: 2623 training error: 0.4635811514347784\n",
            "At step: 2624 training error: 0.4687821841333176\n",
            "At step: 2625 training error: 0.4673324749622572\n",
            "At step: 2626 training error: 0.46482493180912066\n",
            "At step: 2627 training error: 0.4565073100629261\n",
            "At step: 2628 training error: 0.45299915110618344\n",
            "At step: 2629 training error: 0.4534615876741678\n",
            "At step: 2630 training error: 0.4582902798508969\n",
            "At step: 2631 training error: 0.45305763850495095\n",
            "At step: 2632 training error: 0.446920963620645\n",
            "At step: 2633 training error: 0.4336778825765909\n",
            "At step: 2634 training error: 0.4459067062900005\n",
            "At step: 2635 training error: 0.44592990273565114\n",
            "At step: 2636 training error: 0.45180792570951506\n",
            "At step: 2637 training error: 0.45424922041874555\n",
            "At step: 2638 training error: 0.45883491527300524\n",
            "At step: 2639 training error: 0.4711503075325586\n",
            "At step: 2640 training error: 0.4752248094944378\n",
            "At step: 2641 training error: 0.46711067278388124\n",
            "At step: 2642 training error: 0.46147884153346397\n",
            "At step: 2643 training error: 0.4546956438275941\n",
            "At step: 2644 training error: 0.4621091209794232\n",
            "At step: 2645 training error: 0.4630493741965601\n",
            "At step: 2646 training error: 0.4626729519370563\n",
            "At step: 2647 training error: 0.45091182987228484\n",
            "At step: 2648 training error: 0.45123857863255656\n",
            "At step: 2649 training error: 0.45760642476299057\n",
            "At step: 2650 training error: 0.45359903453829536\n",
            "At step: 2651 training error: 0.44897059062429223\n",
            "At step: 2652 training error: 0.4587787281780193\n",
            "At step: 2653 training error: 0.4582928542061546\n",
            "At step: 2654 training error: 0.4559110304108909\n",
            "At step: 2655 training error: 0.4583500845359898\n",
            "At step: 2656 training error: 0.4590603885579119\n",
            "At step: 2657 training error: 0.46838888947805823\n",
            "At step: 2658 training error: 0.46149102882445736\n",
            "At step: 2659 training error: 0.4625623950322222\n",
            "At step: 2660 training error: 0.4588517665662924\n",
            "At step: 2661 training error: 0.4557672936695273\n",
            "At step: 2662 training error: 0.4641285028453991\n",
            "At step: 2663 training error: 0.45422723750365346\n",
            "At step: 2664 training error: 0.45391198529576743\n",
            "At step: 2665 training error: 0.44093302052256195\n",
            "At step: 2666 training error: 0.43462009024964166\n",
            "At step: 2667 training error: 0.4406807297622954\n",
            "At step: 2668 training error: 0.44296472653212127\n",
            "At step: 2669 training error: 0.43926486636693096\n",
            "At step: 2670 training error: 0.43681044002020825\n",
            "At step: 2671 training error: 0.4514839189610626\n",
            "At step: 2672 training error: 0.456900018824957\n",
            "At step: 2673 training error: 0.4520755824124159\n",
            "At step: 2674 training error: 0.458883167871111\n",
            "At step: 2675 training error: 0.4476635328384957\n",
            "At step: 2676 training error: 0.4483961966919345\n",
            "At step: 2677 training error: 0.44613640923814113\n",
            "At step: 2678 training error: 0.44482746181436333\n",
            "At step: 2679 training error: 0.45716277480575623\n",
            "At step: 2680 training error: 0.45028362545899786\n",
            "At step: 2681 training error: 0.4616023197096256\n",
            "At step: 2682 training error: 0.46143105410156116\n",
            "At step: 2683 training error: 0.45170526058129623\n",
            "At step: 2684 training error: 0.4618630143007974\n",
            "At step: 2685 training error: 0.46351672501368524\n",
            "At step: 2686 training error: 0.47316519107458643\n",
            "At step: 2687 training error: 0.4781939509399715\n",
            "At step: 2688 training error: 0.46426255544771544\n",
            "At step: 2689 training error: 0.4558319684764527\n",
            "At step: 2690 training error: 0.4498710902739326\n",
            "At step: 2691 training error: 0.450568796234727\n",
            "At step: 2692 training error: 0.45186450223572894\n",
            "At step: 2693 training error: 0.44645472890936644\n",
            "At step: 2694 training error: 0.44244396944161435\n",
            "At step: 2695 training error: 0.44321763460212465\n",
            "At step: 2696 training error: 0.4397311971264765\n",
            "At step: 2697 training error: 0.4495581962380465\n",
            "At step: 2698 training error: 0.4641703319919642\n",
            "At step: 2699 training error: 0.4604735023135635\n",
            "At step: 2700 training error: 0.4582321363159001\n",
            "At step: 2701 training error: 0.45926411986881155\n",
            "At step: 2702 training error: 0.46591835892378264\n",
            "At step: 2703 training error: 0.4617634826617313\n",
            "At step: 2704 training error: 0.4507815895515781\n",
            "At step: 2705 training error: 0.44186500024516384\n",
            "At step: 2706 training error: 0.44814969289375883\n",
            "At step: 2707 training error: 0.4444830521599051\n",
            "At step: 2708 training error: 0.43175763357747\n",
            "At step: 2709 training error: 0.4409615012194765\n",
            "At step: 2710 training error: 0.4614297624024104\n",
            "At step: 2711 training error: 0.45564667532943814\n",
            "At step: 2712 training error: 0.44936264788553326\n",
            "At step: 2713 training error: 0.45407822008130516\n",
            "At step: 2714 training error: 0.4446832356058523\n",
            "At step: 2715 training error: 0.4480459834916123\n",
            "At step: 2716 training error: 0.4592311109735007\n",
            "At step: 2717 training error: 0.4676450278509291\n",
            "At step: 2718 training error: 0.4642581907588357\n",
            "At step: 2719 training error: 0.4748025074773122\n",
            "At step: 2720 training error: 0.4817758787730719\n",
            "At step: 2721 training error: 0.4746975465218945\n",
            "At step: 2722 training error: 0.4698656175273966\n",
            "At step: 2723 training error: 0.46302580868086485\n",
            "At step: 2724 training error: 0.45922926349959486\n",
            "At step: 2725 training error: 0.4480647968382227\n",
            "At step: 2726 training error: 0.44635390341515335\n",
            "At step: 2727 training error: 0.4553344838841634\n",
            "At step: 2728 training error: 0.4556910453924678\n",
            "At step: 2729 training error: 0.4555089004185168\n",
            "At step: 2730 training error: 0.4545928696370662\n",
            "At step: 2731 training error: 0.45078885793549234\n",
            "At step: 2732 training error: 0.452767261727048\n",
            "At step: 2733 training error: 0.46989019201220006\n",
            "At step: 2734 training error: 0.46979379403834276\n",
            "At step: 2735 training error: 0.46872146005118553\n",
            "At step: 2736 training error: 0.45997517006423566\n",
            "At step: 2737 training error: 0.45315170636444313\n",
            "At step: 2738 training error: 0.4572693545440398\n",
            "At step: 2739 training error: 0.4483160027727485\n",
            "At step: 2740 training error: 0.4479150134581432\n",
            "At step: 2741 training error: 0.4518250341352574\n",
            "At step: 2742 training error: 0.458585675197102\n",
            "At step: 2743 training error: 0.454003802235586\n",
            "At step: 2744 training error: 0.4483931412822141\n",
            "At step: 2745 training error: 0.4530056182182182\n",
            "At step: 2746 training error: 0.441600523242154\n",
            "At step: 2747 training error: 0.4486252563475237\n",
            "At step: 2748 training error: 0.44976092467347006\n",
            "At step: 2749 training error: 0.4512202545128917\n",
            "At step: 2750 training error: 0.4579650045098945\n",
            "At step: 2751 training error: 0.4533580106899258\n",
            "At step: 2752 training error: 0.4503612919349278\n",
            "At step: 2753 training error: 0.45762789651476893\n",
            "At step: 2754 training error: 0.4585165173247816\n",
            "At step: 2755 training error: 0.4666006757977208\n",
            "At step: 2756 training error: 0.46149350489517105\n",
            "At step: 2757 training error: 0.4580739470344978\n",
            "At step: 2758 training error: 0.46162093829013484\n",
            "At step: 2759 training error: 0.46042655336004507\n",
            "At step: 2760 training error: 0.4652624918336127\n",
            "At step: 2761 training error: 0.4540564163024508\n",
            "At step: 2762 training error: 0.4451918020240989\n",
            "At step: 2763 training error: 0.44586314520357095\n",
            "At step: 2764 training error: 0.4516442529842021\n",
            "At step: 2765 training error: 0.4551074852225471\n",
            "At step: 2766 training error: 0.45501478678431206\n",
            "At step: 2767 training error: 0.45610469535389087\n",
            "At step: 2768 training error: 0.4613960624782274\n",
            "At step: 2769 training error: 0.47844553997150907\n",
            "At step: 2770 training error: 0.4675999921826516\n",
            "At step: 2771 training error: 0.46456779033173395\n",
            "At step: 2772 training error: 0.46853387040421185\n",
            "At step: 2773 training error: 0.4646803560395125\n",
            "At step: 2774 training error: 0.45975579766826935\n",
            "At step: 2775 training error: 0.46178579744036663\n",
            "At step: 2776 training error: 0.47046434111786634\n",
            "At step: 2777 training error: 0.47186923028816946\n",
            "At step: 2778 training error: 0.46878114793547976\n",
            "At step: 2779 training error: 0.45850051134641484\n",
            "At step: 2780 training error: 0.4502461049052004\n",
            "At step: 2781 training error: 0.46031503871087553\n",
            "At step: 2782 training error: 0.4620927655583589\n",
            "At step: 2783 training error: 0.47693628195653626\n",
            "At step: 2784 training error: 0.4686371586996094\n",
            "At step: 2785 training error: 0.4731928282274945\n",
            "At step: 2786 training error: 0.4713068211157785\n",
            "At step: 2787 training error: 0.481528940221995\n",
            "At step: 2788 training error: 0.47567654908944856\n",
            "At step: 2789 training error: 0.47816098207811153\n",
            "At step: 2790 training error: 0.474226311930714\n",
            "At step: 2791 training error: 0.48053525234304606\n",
            "At step: 2792 training error: 0.47189916807311283\n",
            "At step: 2793 training error: 0.4608489565432962\n",
            "At step: 2794 training error: 0.469579139434799\n",
            "At step: 2795 training error: 0.46357605181552647\n",
            "At step: 2796 training error: 0.46339702316538967\n",
            "At step: 2797 training error: 0.4632200441098997\n",
            "At step: 2798 training error: 0.45713325459474063\n",
            "At step: 2799 training error: 0.4478591697358606\n",
            "At step: 2800 training error: 0.4442186815925007\n",
            "At step: 2801 training error: 0.4492669969740836\n",
            "At step: 2802 training error: 0.44818424595146505\n",
            "At step: 2803 training error: 0.44258966774362907\n",
            "At step: 2804 training error: 0.4398571351539514\n",
            "At step: 2805 training error: 0.4347455751949577\n",
            "At step: 2806 training error: 0.43663668702393843\n",
            "At step: 2807 training error: 0.43743277967101696\n",
            "At step: 2808 training error: 0.44473329752497104\n",
            "At step: 2809 training error: 0.44029390088444414\n",
            "At step: 2810 training error: 0.44467478947727046\n",
            "At step: 2811 training error: 0.438810638184481\n",
            "At step: 2812 training error: 0.4431764966937202\n",
            "At step: 2813 training error: 0.4417233237004722\n",
            "At step: 2814 training error: 0.4386641268853947\n",
            "At step: 2815 training error: 0.4409868893858489\n",
            "At step: 2816 training error: 0.45576375236741035\n",
            "At step: 2817 training error: 0.45966538000254903\n",
            "At step: 2818 training error: 0.44281913725738664\n",
            "At step: 2819 training error: 0.44946894620544947\n",
            "At step: 2820 training error: 0.45370242513928993\n",
            "At step: 2821 training error: 0.4625757995673816\n",
            "At step: 2822 training error: 0.4643361609480878\n",
            "At step: 2823 training error: 0.4591365274075283\n",
            "At step: 2824 training error: 0.4686489103018511\n",
            "At step: 2825 training error: 0.4700634387455911\n",
            "At step: 2826 training error: 0.4722841995292689\n",
            "At step: 2827 training error: 0.46890487444397916\n",
            "At step: 2828 training error: 0.4626969645783472\n",
            "At step: 2829 training error: 0.4680572982806696\n",
            "At step: 2830 training error: 0.47308707804875744\n",
            "At step: 2831 training error: 0.47433800299030937\n",
            "At step: 2832 training error: 0.4731718692701986\n",
            "At step: 2833 training error: 0.4617402625523785\n",
            "At step: 2834 training error: 0.45496520762876147\n",
            "At step: 2835 training error: 0.4743444255441951\n",
            "At step: 2836 training error: 0.47789256730863405\n",
            "At step: 2837 training error: 0.48518559692111574\n",
            "At step: 2838 training error: 0.48320445550678204\n",
            "At step: 2839 training error: 0.4695999954317854\n",
            "At step: 2840 training error: 0.46081623032540014\n",
            "At step: 2841 training error: 0.4725336812236142\n",
            "At step: 2842 training error: 0.46074725041895837\n",
            "At step: 2843 training error: 0.45357491008284523\n",
            "At step: 2844 training error: 0.44822679442463903\n",
            "At step: 2845 training error: 0.4574729944889363\n",
            "At step: 2846 training error: 0.44541015022933134\n",
            "At step: 2847 training error: 0.4437153811396978\n",
            "At step: 2848 training error: 0.4434758376724232\n",
            "At step: 2849 training error: 0.4450854060199788\n",
            "At step: 2850 training error: 0.4468055817678332\n",
            "At step: 2851 training error: 0.4442620882521581\n",
            "At step: 2852 training error: 0.4563083084626626\n",
            "At step: 2853 training error: 0.4575317332114601\n",
            "At step: 2854 training error: 0.4618849003460056\n",
            "At step: 2855 training error: 0.4585054372254898\n",
            "At step: 2856 training error: 0.4607080678128263\n",
            "At step: 2857 training error: 0.4616283787678447\n",
            "At step: 2858 training error: 0.45757874122702136\n",
            "At step: 2859 training error: 0.45484458224855523\n",
            "At step: 2860 training error: 0.4564806117804775\n",
            "At step: 2861 training error: 0.455898787630594\n",
            "At step: 2862 training error: 0.46507815454068563\n",
            "At step: 2863 training error: 0.4606028762221194\n",
            "At step: 2864 training error: 0.45376708858611997\n",
            "At step: 2865 training error: 0.4487202570953355\n",
            "At step: 2866 training error: 0.4646730193473339\n",
            "At step: 2867 training error: 0.45620723706969585\n",
            "At step: 2868 training error: 0.46339146258725267\n",
            "At step: 2869 training error: 0.4572900114480941\n",
            "At step: 2870 training error: 0.45206315256047735\n",
            "At step: 2871 training error: 0.4510512661816679\n",
            "At step: 2872 training error: 0.4518485916306575\n",
            "At step: 2873 training error: 0.44915543967473603\n",
            "At step: 2874 training error: 0.4466866873898609\n",
            "At step: 2875 training error: 0.4522120713912321\n",
            "At step: 2876 training error: 0.4513478693799589\n",
            "At step: 2877 training error: 0.43956836415555006\n",
            "At step: 2878 training error: 0.44357202622659\n",
            "At step: 2879 training error: 0.44781620163872704\n",
            "At step: 2880 training error: 0.4429130347330931\n",
            "At step: 2881 training error: 0.44142602326573527\n",
            "At step: 2882 training error: 0.4430322411552386\n",
            "At step: 2883 training error: 0.43656300739712467\n",
            "At step: 2884 training error: 0.4446325230057189\n",
            "At step: 2885 training error: 0.43360856929687114\n",
            "At step: 2886 training error: 0.4359700323703545\n",
            "At step: 2887 training error: 0.44849141188172037\n",
            "At step: 2888 training error: 0.4466240065225126\n",
            "At step: 2889 training error: 0.4410509314511362\n",
            "At step: 2890 training error: 0.44642874485851447\n",
            "At step: 2891 training error: 0.449316030724663\n",
            "At step: 2892 training error: 0.44858044760792826\n",
            "At step: 2893 training error: 0.45543114818032043\n",
            "At step: 2894 training error: 0.4569914660128347\n",
            "At step: 2895 training error: 0.4577705292302808\n",
            "At step: 2896 training error: 0.4679900287391896\n",
            "At step: 2897 training error: 0.4706017440576873\n",
            "At step: 2898 training error: 0.47310047194140603\n",
            "At step: 2899 training error: 0.466081099523448\n",
            "At step: 2900 training error: 0.4725841719638151\n",
            "At step: 2901 training error: 0.4601331665594472\n",
            "At step: 2902 training error: 0.46205137973942856\n",
            "At step: 2903 training error: 0.47455211523513463\n",
            "At step: 2904 training error: 0.4686978337692889\n",
            "At step: 2905 training error: 0.46029677536275987\n",
            "At step: 2906 training error: 0.45790678509227045\n",
            "At step: 2907 training error: 0.4492970985696355\n",
            "At step: 2908 training error: 0.4510511668563299\n",
            "At step: 2909 training error: 0.45366402517338555\n",
            "At step: 2910 training error: 0.45503157892066387\n",
            "At step: 2911 training error: 0.45618900799607237\n",
            "At step: 2912 training error: 0.45698840996863976\n",
            "At step: 2913 training error: 0.4569846994539227\n",
            "At step: 2914 training error: 0.4646423471196066\n",
            "At step: 2915 training error: 0.4594060317295012\n",
            "At step: 2916 training error: 0.4560391687896414\n",
            "At step: 2917 training error: 0.4505423649757057\n",
            "At step: 2918 training error: 0.45434507136612606\n",
            "At step: 2919 training error: 0.45366364773211787\n",
            "At step: 2920 training error: 0.44838439962844623\n",
            "At step: 2921 training error: 0.461218728962813\n",
            "At step: 2922 training error: 0.4525324195844031\n",
            "At step: 2923 training error: 0.46063121259681067\n",
            "At step: 2924 training error: 0.46226547837523335\n",
            "At step: 2925 training error: 0.4640130116531378\n",
            "At step: 2926 training error: 0.464464702963029\n",
            "At step: 2927 training error: 0.45813756976739206\n",
            "At step: 2928 training error: 0.4600950188413291\n",
            "At step: 2929 training error: 0.4672862610817475\n",
            "At step: 2930 training error: 0.4644390413665033\n",
            "At step: 2931 training error: 0.4510981669297121\n",
            "At step: 2932 training error: 0.4446256553416054\n",
            "At step: 2933 training error: 0.4531416451809159\n",
            "At step: 2934 training error: 0.45462696946312986\n",
            "At step: 2935 training error: 0.4530636717327514\n",
            "At step: 2936 training error: 0.44357414790379496\n",
            "At step: 2937 training error: 0.4466315069648582\n",
            "At step: 2938 training error: 0.43643796093010945\n",
            "At step: 2939 training error: 0.4311457491073973\n",
            "At step: 2940 training error: 0.4248400054676793\n",
            "At step: 2941 training error: 0.4239823867924459\n",
            "At step: 2942 training error: 0.42874754080157507\n",
            "At step: 2943 training error: 0.4302926837595408\n",
            "At step: 2944 training error: 0.4262717342140249\n",
            "At step: 2945 training error: 0.4269232043640932\n",
            "At step: 2946 training error: 0.43491491895928347\n",
            "At step: 2947 training error: 0.42551905829231823\n",
            "At step: 2948 training error: 0.4271658394745378\n",
            "At step: 2949 training error: 0.43570487307774386\n",
            "At step: 2950 training error: 0.4282118661339241\n",
            "At step: 2951 training error: 0.42148387314313757\n",
            "At step: 2952 training error: 0.42437522505653225\n",
            "At step: 2953 training error: 0.4323068777193458\n",
            "At step: 2954 training error: 0.4465680386043011\n",
            "At step: 2955 training error: 0.4428590112265769\n",
            "At step: 2956 training error: 0.4481518999511591\n",
            "At step: 2957 training error: 0.4569367123674459\n",
            "At step: 2958 training error: 0.4588806004698538\n",
            "At step: 2959 training error: 0.45388638237972023\n",
            "At step: 2960 training error: 0.4619634307469854\n",
            "At step: 2961 training error: 0.45509743461513263\n",
            "At step: 2962 training error: 0.45975970788039283\n",
            "At step: 2963 training error: 0.4565463279475609\n",
            "At step: 2964 training error: 0.45765581953856327\n",
            "At step: 2965 training error: 0.4508148591417155\n",
            "At step: 2966 training error: 0.46138277172554415\n",
            "At step: 2967 training error: 0.46191202021795447\n",
            "At step: 2968 training error: 0.46364286742899974\n",
            "At step: 2969 training error: 0.4666752340989364\n",
            "At step: 2970 training error: 0.4580024639546708\n",
            "At step: 2971 training error: 0.45430979443309616\n",
            "At step: 2972 training error: 0.44129078137856814\n",
            "At step: 2973 training error: 0.44615567034377773\n",
            "At step: 2974 training error: 0.4511941545282211\n",
            "At step: 2975 training error: 0.4498649575965074\n",
            "At step: 2976 training error: 0.4521240131949104\n",
            "At step: 2977 training error: 0.45271209643097543\n",
            "At step: 2978 training error: 0.45898490325859864\n",
            "At step: 2979 training error: 0.46713684337800543\n",
            "At step: 2980 training error: 0.46727483220349236\n",
            "At step: 2981 training error: 0.4621035114068433\n",
            "At step: 2982 training error: 0.4522360236323645\n",
            "At step: 2983 training error: 0.44545175570783135\n",
            "At step: 2984 training error: 0.44266898037348157\n",
            "At step: 2985 training error: 0.44559664849475605\n",
            "At step: 2986 training error: 0.45990641872859633\n",
            "At step: 2987 training error: 0.4599101824395487\n",
            "At step: 2988 training error: 0.45802716416060707\n",
            "At step: 2989 training error: 0.45603919320117425\n",
            "At step: 2990 training error: 0.4484829519811273\n",
            "At step: 2991 training error: 0.4468281830953556\n",
            "At step: 2992 training error: 0.43982396667417833\n",
            "At step: 2993 training error: 0.45186849254716294\n",
            "At step: 2994 training error: 0.4596609474218642\n",
            "At step: 2995 training error: 0.45195789517670426\n",
            "At step: 2996 training error: 0.45671023895413543\n",
            "At step: 2997 training error: 0.4580609646635272\n",
            "At step: 2998 training error: 0.4575427190320508\n",
            "At step: 2999 training error: 0.44403745781197457\n",
            "At step: 3000 training error: 0.43846828157120676\n",
            "At step: 3001 training error: 0.4341843162968573\n",
            "At step: 3002 training error: 0.44850088260650767\n",
            "At step: 3003 training error: 0.457590031654711\n",
            "At step: 3004 training error: 0.45798948520809113\n",
            "At step: 3005 training error: 0.45724580774883383\n",
            "At step: 3006 training error: 0.46201985881196606\n",
            "At step: 3007 training error: 0.4652220643275521\n",
            "At step: 3008 training error: 0.45513038761330393\n",
            "At step: 3009 training error: 0.4626190662031235\n",
            "At step: 3010 training error: 0.4678182850524936\n",
            "At step: 3011 training error: 0.46348230390947764\n",
            "At step: 3012 training error: 0.4571728764251969\n",
            "At step: 3013 training error: 0.45142758874539546\n",
            "At step: 3014 training error: 0.46043888501616675\n",
            "At step: 3015 training error: 0.4665044876069828\n",
            "At step: 3016 training error: 0.47232405958855883\n",
            "At step: 3017 training error: 0.45490899991575734\n",
            "At step: 3018 training error: 0.4440271806344031\n",
            "At step: 3019 training error: 0.4371002427641506\n",
            "At step: 3020 training error: 0.4285367463810707\n",
            "At step: 3021 training error: 0.43752247139787626\n",
            "At step: 3022 training error: 0.4475504760482181\n",
            "At step: 3023 training error: 0.4438987602451405\n",
            "At step: 3024 training error: 0.44405084600605216\n",
            "At step: 3025 training error: 0.4397356926334165\n",
            "At step: 3026 training error: 0.4375667430763116\n",
            "At step: 3027 training error: 0.4481574958956037\n",
            "At step: 3028 training error: 0.4521202115161795\n",
            "At step: 3029 training error: 0.458240698152122\n",
            "At step: 3030 training error: 0.45387616859442137\n",
            "At step: 3031 training error: 0.4478893924962015\n",
            "At step: 3032 training error: 0.44846748402267284\n",
            "At step: 3033 training error: 0.4447249189561918\n",
            "At step: 3034 training error: 0.44365483564253927\n",
            "At step: 3035 training error: 0.45001785826658225\n",
            "At step: 3036 training error: 0.4577457635691262\n",
            "At step: 3037 training error: 0.4649224929701105\n",
            "At step: 3038 training error: 0.46811924859192144\n",
            "At step: 3039 training error: 0.47436471338757635\n",
            "At step: 3040 training error: 0.48077171593911544\n",
            "At step: 3041 training error: 0.4797141716118055\n",
            "At step: 3042 training error: 0.47727795756406816\n",
            "At step: 3043 training error: 0.4633370802426561\n",
            "At step: 3044 training error: 0.46982497103151755\n",
            "At step: 3045 training error: 0.46644334285153743\n",
            "At step: 3046 training error: 0.47759095016080727\n",
            "At step: 3047 training error: 0.47582057427565466\n",
            "At step: 3048 training error: 0.47688101539036537\n",
            "At step: 3049 training error: 0.4752687451265595\n",
            "At step: 3050 training error: 0.4771329414020962\n",
            "At step: 3051 training error: 0.4713946152094751\n",
            "At step: 3052 training error: 0.46772726318175545\n",
            "At step: 3053 training error: 0.4773829710703213\n",
            "At step: 3054 training error: 0.4697437313484471\n",
            "At step: 3055 training error: 0.47430369310962117\n",
            "At step: 3056 training error: 0.47831595702801244\n",
            "At step: 3057 training error: 0.47448564654548125\n",
            "At step: 3058 training error: 0.47018391210746047\n",
            "At step: 3059 training error: 0.46939712226404784\n",
            "At step: 3060 training error: 0.4579707062111185\n",
            "At step: 3061 training error: 0.46361750508447275\n",
            "At step: 3062 training error: 0.4540674841677755\n",
            "At step: 3063 training error: 0.4531517479458993\n",
            "At step: 3064 training error: 0.4504813387900319\n",
            "At step: 3065 training error: 0.44821239828606224\n",
            "At step: 3066 training error: 0.4537566269049782\n",
            "At step: 3067 training error: 0.45219538727622094\n",
            "At step: 3068 training error: 0.4504708394651691\n",
            "At step: 3069 training error: 0.4496444154782653\n",
            "At step: 3070 training error: 0.4553224850883497\n",
            "At step: 3071 training error: 0.44535138294896864\n",
            "At step: 3072 training error: 0.44680121773702985\n",
            "At step: 3073 training error: 0.46090982305051514\n",
            "At step: 3074 training error: 0.45871190333691675\n",
            "At step: 3075 training error: 0.4607347851137394\n",
            "At step: 3076 training error: 0.4586519418470609\n",
            "At step: 3077 training error: 0.4535794826637436\n",
            "At step: 3078 training error: 0.4540164465456073\n",
            "At step: 3079 training error: 0.44936297387035196\n",
            "At step: 3080 training error: 0.4420795556458529\n",
            "At step: 3081 training error: 0.4499845758748561\n",
            "At step: 3082 training error: 0.45711037589679254\n",
            "At step: 3083 training error: 0.45626306748047507\n",
            "At step: 3084 training error: 0.4568868686536263\n",
            "At step: 3085 training error: 0.4494157017909254\n",
            "At step: 3086 training error: 0.43959737314957886\n",
            "At step: 3087 training error: 0.44028612939543266\n",
            "At step: 3088 training error: 0.4436142705975539\n",
            "At step: 3089 training error: 0.45559861343664737\n",
            "At step: 3090 training error: 0.45301229291306716\n",
            "At step: 3091 training error: 0.4600199336646949\n",
            "At step: 3092 training error: 0.4523653689160082\n",
            "At step: 3093 training error: 0.44723497499256926\n",
            "At step: 3094 training error: 0.4490491253976743\n",
            "At step: 3095 training error: 0.4483235211433588\n",
            "At step: 3096 training error: 0.4430351071384937\n",
            "At step: 3097 training error: 0.4520530003450435\n",
            "At step: 3098 training error: 0.4497710667902424\n",
            "At step: 3099 training error: 0.4510021659197071\n",
            "At step: 3100 training error: 0.45229994652685535\n",
            "At step: 3101 training error: 0.45948994221449213\n",
            "At step: 3102 training error: 0.4590758772174263\n",
            "At step: 3103 training error: 0.461956949754093\n",
            "At step: 3104 training error: 0.4646343489428687\n",
            "At step: 3105 training error: 0.4547040279076587\n",
            "At step: 3106 training error: 0.44645405489348255\n",
            "At step: 3107 training error: 0.4417820352048031\n",
            "At step: 3108 training error: 0.4529674749006205\n",
            "At step: 3109 training error: 0.4490578868631082\n",
            "At step: 3110 training error: 0.43800299055513886\n",
            "At step: 3111 training error: 0.4378848564675305\n",
            "At step: 3112 training error: 0.44551361837546083\n",
            "At step: 3113 training error: 0.449865025436525\n",
            "At step: 3114 training error: 0.45285503943204525\n",
            "At step: 3115 training error: 0.4541640298904815\n",
            "At step: 3116 training error: 0.4497560415006009\n",
            "At step: 3117 training error: 0.4471563521206277\n",
            "At step: 3118 training error: 0.454693996442481\n",
            "At step: 3119 training error: 0.4532818020229489\n",
            "At step: 3120 training error: 0.44472262046327554\n",
            "At step: 3121 training error: 0.4476886056727732\n",
            "At step: 3122 training error: 0.44383420358208214\n",
            "At step: 3123 training error: 0.44057708653629546\n",
            "At step: 3124 training error: 0.4461930457662555\n",
            "At step: 3125 training error: 0.43943367999873123\n",
            "At step: 3126 training error: 0.4431339877750624\n",
            "At step: 3127 training error: 0.4445353666539506\n",
            "At step: 3128 training error: 0.45570948561881325\n",
            "At step: 3129 training error: 0.46290722088679487\n",
            "At step: 3130 training error: 0.46601104814598693\n",
            "At step: 3131 training error: 0.4712900250184032\n",
            "At step: 3132 training error: 0.4762343982754229\n",
            "At step: 3133 training error: 0.4688079011105919\n",
            "At step: 3134 training error: 0.4606074037858126\n",
            "At step: 3135 training error: 0.4555573944641865\n",
            "At step: 3136 training error: 0.4570426895634994\n",
            "At step: 3137 training error: 0.45410137588974847\n",
            "At step: 3138 training error: 0.4671602791898983\n",
            "At step: 3139 training error: 0.4634746427878814\n",
            "At step: 3140 training error: 0.46301132496448427\n",
            "At step: 3141 training error: 0.46654989957143567\n",
            "At step: 3142 training error: 0.45399273080221725\n",
            "At step: 3143 training error: 0.446512749623393\n",
            "At step: 3144 training error: 0.45631856962177764\n",
            "At step: 3145 training error: 0.46834718571186984\n",
            "At step: 3146 training error: 0.4671483776106521\n",
            "At step: 3147 training error: 0.4663297151059228\n",
            "At step: 3148 training error: 0.45977347463938606\n",
            "At step: 3149 training error: 0.4610457145470395\n",
            "At step: 3150 training error: 0.45113422386084345\n",
            "At step: 3151 training error: 0.4498880425796278\n",
            "At step: 3152 training error: 0.45784953007443613\n",
            "At step: 3153 training error: 0.46406222950726167\n",
            "At step: 3154 training error: 0.4664701129952762\n",
            "At step: 3155 training error: 0.4634562834997879\n",
            "At step: 3156 training error: 0.4594490622436852\n",
            "At step: 3157 training error: 0.4560962933677869\n",
            "At step: 3158 training error: 0.4467230896541875\n",
            "At step: 3159 training error: 0.45329074328230556\n",
            "At step: 3160 training error: 0.4598112714057297\n",
            "At step: 3161 training error: 0.45702788249304005\n",
            "At step: 3162 training error: 0.4631636002899967\n",
            "At step: 3163 training error: 0.4552569272662519\n",
            "At step: 3164 training error: 0.4618473695765466\n",
            "At step: 3165 training error: 0.45642528527688425\n",
            "At step: 3166 training error: 0.44900685340162266\n",
            "At step: 3167 training error: 0.4572027854121984\n",
            "At step: 3168 training error: 0.4497905700703202\n",
            "At step: 3169 training error: 0.45424806894682085\n",
            "At step: 3170 training error: 0.45516079448576025\n",
            "At step: 3171 training error: 0.45509660441704747\n",
            "At step: 3172 training error: 0.4581598525584489\n",
            "At step: 3173 training error: 0.4546779160046421\n",
            "At step: 3174 training error: 0.4571094280727497\n",
            "At step: 3175 training error: 0.4501965078959185\n",
            "At step: 3176 training error: 0.45400512408741345\n",
            "At step: 3177 training error: 0.44803790978664215\n",
            "At step: 3178 training error: 0.4392471326811881\n",
            "At step: 3179 training error: 0.44338716748767754\n",
            "At step: 3180 training error: 0.44423774160041346\n",
            "At step: 3181 training error: 0.4408251568836381\n",
            "At step: 3182 training error: 0.4326619834282529\n",
            "At step: 3183 training error: 0.4315370239753232\n",
            "At step: 3184 training error: 0.44164975906490994\n",
            "At step: 3185 training error: 0.43479231249804917\n",
            "At step: 3186 training error: 0.45041021149867455\n",
            "At step: 3187 training error: 0.4452752536995205\n",
            "At step: 3188 training error: 0.44167426351768607\n",
            "At step: 3189 training error: 0.4365946430730474\n",
            "At step: 3190 training error: 0.4314722544339591\n",
            "At step: 3191 training error: 0.43334966717770096\n",
            "At step: 3192 training error: 0.43643818632385595\n",
            "At step: 3193 training error: 0.4346994155979979\n",
            "At step: 3194 training error: 0.4369828982054125\n",
            "At step: 3195 training error: 0.43587858376782973\n",
            "At step: 3196 training error: 0.4301690896990452\n",
            "At step: 3197 training error: 0.4464799992130968\n",
            "At step: 3198 training error: 0.4349320272405928\n",
            "At step: 3199 training error: 0.4339822375813858\n",
            "At step: 3200 training error: 0.4358970014161304\n",
            "At step: 3201 training error: 0.43576745430463737\n",
            "At step: 3202 training error: 0.4378787893661651\n",
            "At step: 3203 training error: 0.43236347278169274\n",
            "At step: 3204 training error: 0.4264111954949899\n",
            "At step: 3205 training error: 0.43238695160013785\n",
            "At step: 3206 training error: 0.43004366444313297\n",
            "At step: 3207 training error: 0.42375829834105533\n",
            "At step: 3208 training error: 0.43099798603216505\n",
            "At step: 3209 training error: 0.43183821864888294\n",
            "At step: 3210 training error: 0.4332182292611296\n",
            "At step: 3211 training error: 0.4306845433308857\n",
            "At step: 3212 training error: 0.42632686356614735\n",
            "At step: 3213 training error: 0.4251423702689095\n",
            "At step: 3214 training error: 0.4214346904968857\n",
            "At step: 3215 training error: 0.42576193187602945\n",
            "At step: 3216 training error: 0.42963054177953736\n",
            "At step: 3217 training error: 0.436718002167194\n",
            "At step: 3218 training error: 0.4537264908721261\n",
            "At step: 3219 training error: 0.4541822386764922\n",
            "At step: 3220 training error: 0.4689101801509426\n",
            "At step: 3221 training error: 0.4601891523648644\n",
            "At step: 3222 training error: 0.47036596975128264\n",
            "At step: 3223 training error: 0.4651366357823796\n",
            "At step: 3224 training error: 0.46172825674034945\n",
            "At step: 3225 training error: 0.46153850715811107\n",
            "At step: 3226 training error: 0.4586645977268688\n",
            "At step: 3227 training error: 0.44685670512164244\n",
            "At step: 3228 training error: 0.44755462384944894\n",
            "At step: 3229 training error: 0.442439934568881\n",
            "At step: 3230 training error: 0.4393977269850108\n",
            "At step: 3231 training error: 0.4454037356047445\n",
            "At step: 3232 training error: 0.4407729400050319\n",
            "At step: 3233 training error: 0.4422530547296629\n",
            "At step: 3234 training error: 0.4389126590584145\n",
            "At step: 3235 training error: 0.43662005282886857\n",
            "At step: 3236 training error: 0.44063491975648017\n",
            "At step: 3237 training error: 0.4435341033911481\n",
            "At step: 3238 training error: 0.4473603928774779\n",
            "At step: 3239 training error: 0.44624940697495086\n",
            "At step: 3240 training error: 0.4429769052833878\n",
            "At step: 3241 training error: 0.4436144462977461\n",
            "At step: 3242 training error: 0.4313213998251478\n",
            "At step: 3243 training error: 0.43550141447832325\n",
            "At step: 3244 training error: 0.4280815258909287\n",
            "At step: 3245 training error: 0.44104618274618274\n",
            "At step: 3246 training error: 0.4340950310675862\n",
            "At step: 3247 training error: 0.43284609005153496\n",
            "At step: 3248 training error: 0.4396545220107166\n",
            "At step: 3249 training error: 0.4340271452028607\n",
            "At step: 3250 training error: 0.43942727237264256\n",
            "At step: 3251 training error: 0.44829231332043284\n",
            "At step: 3252 training error: 0.4500803619312434\n",
            "At step: 3253 training error: 0.4467672344765896\n",
            "At step: 3254 training error: 0.44496800352155835\n",
            "At step: 3255 training error: 0.43617619721430395\n",
            "At step: 3256 training error: 0.4354203394479322\n",
            "At step: 3257 training error: 0.42877937897186896\n",
            "At step: 3258 training error: 0.4216745327990171\n",
            "At step: 3259 training error: 0.42617968397036876\n",
            "At step: 3260 training error: 0.4297002447506578\n",
            "At step: 3261 training error: 0.43126997320101307\n",
            "At step: 3262 training error: 0.4398451012863534\n",
            "At step: 3263 training error: 0.44157049998415165\n",
            "At step: 3264 training error: 0.44724090363885816\n",
            "At step: 3265 training error: 0.4345362010171362\n",
            "At step: 3266 training error: 0.4336900822288486\n",
            "At step: 3267 training error: 0.4374617490265751\n",
            "At step: 3268 training error: 0.4419913962784901\n",
            "At step: 3269 training error: 0.43898715235960506\n",
            "At step: 3270 training error: 0.430937204856724\n",
            "At step: 3271 training error: 0.4264869481849416\n",
            "At step: 3272 training error: 0.44173966599844233\n",
            "At step: 3273 training error: 0.4591894267809411\n",
            "At step: 3274 training error: 0.4494384800550853\n",
            "At step: 3275 training error: 0.44178611948925856\n",
            "At step: 3276 training error: 0.44150699082523553\n",
            "At step: 3277 training error: 0.43860028787668287\n",
            "At step: 3278 training error: 0.4273014770144336\n",
            "At step: 3279 training error: 0.4277999482656681\n",
            "At step: 3280 training error: 0.43613558788488266\n",
            "At step: 3281 training error: 0.44423705833978916\n",
            "At step: 3282 training error: 0.44604655083770006\n",
            "At step: 3283 training error: 0.4485167889717881\n",
            "At step: 3284 training error: 0.4552065802724355\n",
            "At step: 3285 training error: 0.46981291879466824\n",
            "At step: 3286 training error: 0.471135918669583\n",
            "At step: 3287 training error: 0.47393680842685176\n",
            "At step: 3288 training error: 0.48243665134608915\n",
            "At step: 3289 training error: 0.46767043421199483\n",
            "At step: 3290 training error: 0.4673274965603231\n",
            "At step: 3291 training error: 0.4617920598444043\n",
            "At step: 3292 training error: 0.464227421917611\n",
            "At step: 3293 training error: 0.4630868781650454\n",
            "At step: 3294 training error: 0.45825936511349424\n",
            "At step: 3295 training error: 0.45437960904661917\n",
            "At step: 3296 training error: 0.4403330093929054\n",
            "At step: 3297 training error: 0.4441528594716855\n",
            "At step: 3298 training error: 0.441576568249873\n",
            "At step: 3299 training error: 0.4484500462390295\n",
            "At step: 3300 training error: 0.44836739551860627\n",
            "At step: 3301 training error: 0.4627672046732843\n",
            "At step: 3302 training error: 0.4686320935893594\n",
            "At step: 3303 training error: 0.46529427191247524\n",
            "At step: 3304 training error: 0.4588763850143925\n",
            "At step: 3305 training error: 0.452097453577897\n",
            "At step: 3306 training error: 0.4529628289667371\n",
            "At step: 3307 training error: 0.454120453917758\n",
            "At step: 3308 training error: 0.4543745623112887\n",
            "At step: 3309 training error: 0.4523028384522075\n",
            "At step: 3310 training error: 0.4528989496629725\n",
            "At step: 3311 training error: 0.45301085881122627\n",
            "At step: 3312 training error: 0.4532074190285842\n",
            "At step: 3313 training error: 0.4526897340594667\n",
            "At step: 3314 training error: 0.44328726880975106\n",
            "At step: 3315 training error: 0.43621764232338267\n",
            "At step: 3316 training error: 0.44802262582965635\n",
            "At step: 3317 training error: 0.45159545722450756\n",
            "At step: 3318 training error: 0.4478354065987662\n",
            "At step: 3319 training error: 0.4529297614240379\n",
            "At step: 3320 training error: 0.45521362525556375\n",
            "At step: 3321 training error: 0.4562019241652188\n",
            "At step: 3322 training error: 0.45525118405421716\n",
            "At step: 3323 training error: 0.44242045176445033\n",
            "At step: 3324 training error: 0.443107894049768\n",
            "At step: 3325 training error: 0.45119851969974273\n",
            "At step: 3326 training error: 0.4449463762324326\n",
            "At step: 3327 training error: 0.4408485725947083\n",
            "At step: 3328 training error: 0.4403500511206776\n",
            "At step: 3329 training error: 0.43682013946649184\n",
            "At step: 3330 training error: 0.4369621301262304\n",
            "At step: 3331 training error: 0.4375959904923076\n",
            "At step: 3332 training error: 0.44153579421371014\n",
            "At step: 3333 training error: 0.44033571036921376\n",
            "At step: 3334 training error: 0.4425744225082571\n",
            "At step: 3335 training error: 0.43517649128745395\n",
            "At step: 3336 training error: 0.4342667551869615\n",
            "At step: 3337 training error: 0.43251036428064993\n",
            "At step: 3338 training error: 0.4341157349616208\n",
            "At step: 3339 training error: 0.42872051445105946\n",
            "At step: 3340 training error: 0.44729571922471845\n",
            "At step: 3341 training error: 0.44201923136860766\n",
            "At step: 3342 training error: 0.448015677821794\n",
            "At step: 3343 training error: 0.446736664605644\n",
            "At step: 3344 training error: 0.43724484597077623\n",
            "At step: 3345 training error: 0.4430187033508877\n",
            "At step: 3346 training error: 0.43931105568052886\n",
            "At step: 3347 training error: 0.442573224541713\n",
            "At step: 3348 training error: 0.43167210301652487\n",
            "At step: 3349 training error: 0.4354241743137414\n",
            "At step: 3350 training error: 0.4245128889791165\n",
            "At step: 3351 training error: 0.421537333243494\n",
            "At step: 3352 training error: 0.42553868477391155\n",
            "At step: 3353 training error: 0.41992431445049067\n",
            "At step: 3354 training error: 0.4275820892889599\n",
            "At step: 3355 training error: 0.42726167448071356\n",
            "At step: 3356 training error: 0.431556675368625\n",
            "At step: 3357 training error: 0.42856557162954345\n",
            "At step: 3358 training error: 0.4323628615611869\n",
            "At step: 3359 training error: 0.42736607614737687\n",
            "At step: 3360 training error: 0.4286802584133221\n",
            "At step: 3361 training error: 0.42754592283247983\n",
            "At step: 3362 training error: 0.42704562045154415\n",
            "At step: 3363 training error: 0.43331244323923723\n",
            "At step: 3364 training error: 0.432009855171417\n",
            "At step: 3365 training error: 0.4408202249205143\n",
            "At step: 3366 training error: 0.43905111001464814\n",
            "At step: 3367 training error: 0.4402483410347342\n",
            "At step: 3368 training error: 0.4405079175337129\n",
            "At step: 3369 training error: 0.4397768441868797\n",
            "At step: 3370 training error: 0.4433871124757422\n",
            "At step: 3371 training error: 0.458057507463197\n",
            "At step: 3372 training error: 0.4559433269150208\n",
            "At step: 3373 training error: 0.4566184930235355\n",
            "At step: 3374 training error: 0.45677476930104316\n",
            "At step: 3375 training error: 0.45323058449463394\n",
            "At step: 3376 training error: 0.4570542444282409\n",
            "At step: 3377 training error: 0.4626977975876819\n",
            "At step: 3378 training error: 0.4589558137681966\n",
            "At step: 3379 training error: 0.45869008291173013\n",
            "At step: 3380 training error: 0.454874160517713\n",
            "At step: 3381 training error: 0.4495117881772754\n",
            "At step: 3382 training error: 0.45320677378800867\n",
            "At step: 3383 training error: 0.449854793625978\n",
            "At step: 3384 training error: 0.46962889294388505\n",
            "At step: 3385 training error: 0.46935352977456307\n",
            "At step: 3386 training error: 0.4511315280724332\n",
            "At step: 3387 training error: 0.45524096475455844\n",
            "At step: 3388 training error: 0.4532842839708608\n",
            "At step: 3389 training error: 0.4501671517771686\n",
            "At step: 3390 training error: 0.4464374731668335\n",
            "At step: 3391 training error: 0.4385270374921453\n",
            "At step: 3392 training error: 0.43434857920717185\n",
            "At step: 3393 training error: 0.4351771532078137\n",
            "At step: 3394 training error: 0.43650687903875934\n",
            "At step: 3395 training error: 0.44315572455139063\n",
            "At step: 3396 training error: 0.4453602749184013\n",
            "At step: 3397 training error: 0.44163123123295034\n",
            "At step: 3398 training error: 0.4448441144588839\n",
            "At step: 3399 training error: 0.44710491387452816\n",
            "At step: 3400 training error: 0.4544482616213262\n",
            "At step: 3401 training error: 0.4615787257317808\n",
            "At step: 3402 training error: 0.45423104995075714\n",
            "At step: 3403 training error: 0.455568059242114\n",
            "At step: 3404 training error: 0.4527516402081848\n",
            "At step: 3405 training error: 0.45406319396792655\n",
            "At step: 3406 training error: 0.4546008266253297\n",
            "At step: 3407 training error: 0.45631817205307346\n",
            "At step: 3408 training error: 0.4554745965062682\n",
            "At step: 3409 training error: 0.46324364713170063\n",
            "At step: 3410 training error: 0.4567036866968336\n",
            "At step: 3411 training error: 0.4489186390429778\n",
            "At step: 3412 training error: 0.45067125263730146\n",
            "At step: 3413 training error: 0.46268587732322136\n",
            "At step: 3414 training error: 0.4598134195190936\n",
            "At step: 3415 training error: 0.4559882552916249\n",
            "At step: 3416 training error: 0.4546007110464371\n",
            "At step: 3417 training error: 0.45546030131524934\n",
            "At step: 3418 training error: 0.45508759290286444\n",
            "At step: 3419 training error: 0.45361756402142184\n",
            "At step: 3420 training error: 0.45719937799149296\n",
            "At step: 3421 training error: 0.45036548678428345\n",
            "At step: 3422 training error: 0.43926306736523335\n",
            "At step: 3423 training error: 0.4363079489263438\n",
            "At step: 3424 training error: 0.44254315870429284\n",
            "At step: 3425 training error: 0.4337134258542177\n",
            "At step: 3426 training error: 0.4376560230868649\n",
            "At step: 3427 training error: 0.4240486427027457\n",
            "At step: 3428 training error: 0.41424322219272786\n",
            "At step: 3429 training error: 0.4183515977200875\n",
            "At step: 3430 training error: 0.4187813332605634\n",
            "At step: 3431 training error: 0.4146514336124786\n",
            "At step: 3432 training error: 0.4088487955168174\n",
            "At step: 3433 training error: 0.41095857306264066\n",
            "At step: 3434 training error: 0.41097639016104437\n",
            "At step: 3435 training error: 0.4048976009477185\n",
            "At step: 3436 training error: 0.4120852732496129\n",
            "At step: 3437 training error: 0.4162153452466143\n",
            "At step: 3438 training error: 0.41819948266979245\n",
            "At step: 3439 training error: 0.4311905827410494\n",
            "At step: 3440 training error: 0.4365599450283761\n",
            "At step: 3441 training error: 0.43765293747578\n",
            "At step: 3442 training error: 0.4267655641415163\n",
            "At step: 3443 training error: 0.4291797083200551\n",
            "At step: 3444 training error: 0.41498842000402447\n",
            "At step: 3445 training error: 0.4212698778145812\n",
            "At step: 3446 training error: 0.43022135248491516\n",
            "At step: 3447 training error: 0.4277542951055697\n",
            "At step: 3448 training error: 0.4252341669885704\n",
            "At step: 3449 training error: 0.4234904517185171\n",
            "At step: 3450 training error: 0.42015876415523645\n",
            "At step: 3451 training error: 0.4246983360187593\n",
            "At step: 3452 training error: 0.4273102998231764\n",
            "At step: 3453 training error: 0.43676343127924894\n",
            "At step: 3454 training error: 0.4473357820944013\n",
            "At step: 3455 training error: 0.4377051637827981\n",
            "At step: 3456 training error: 0.43935473073083714\n",
            "At step: 3457 training error: 0.44258045268362894\n",
            "At step: 3458 training error: 0.4430218323235656\n",
            "At step: 3459 training error: 0.4395996808836494\n",
            "At step: 3460 training error: 0.4314777207485589\n",
            "At step: 3461 training error: 0.4364505923909832\n",
            "At step: 3462 training error: 0.43338075706560586\n",
            "At step: 3463 training error: 0.43319274812237707\n",
            "At step: 3464 training error: 0.4377923944837204\n",
            "At step: 3465 training error: 0.4551990986115555\n",
            "At step: 3466 training error: 0.4543856956873303\n",
            "At step: 3467 training error: 0.4475065213410168\n",
            "At step: 3468 training error: 0.44903456714890316\n",
            "At step: 3469 training error: 0.43749291032735443\n",
            "At step: 3470 training error: 0.4301733213558409\n",
            "At step: 3471 training error: 0.43083845712104807\n",
            "At step: 3472 training error: 0.42925081907607965\n",
            "At step: 3473 training error: 0.41679245680476346\n",
            "At step: 3474 training error: 0.4196682828788119\n",
            "At step: 3475 training error: 0.42558866150497643\n",
            "At step: 3476 training error: 0.42624004879145583\n",
            "At step: 3477 training error: 0.4246079267294792\n",
            "At step: 3478 training error: 0.41992155501470263\n",
            "At step: 3479 training error: 0.42357714835864674\n",
            "At step: 3480 training error: 0.4346631624025562\n",
            "At step: 3481 training error: 0.4289290292305486\n",
            "At step: 3482 training error: 0.4263705145979979\n",
            "At step: 3483 training error: 0.4159716765580146\n",
            "At step: 3484 training error: 0.4095539298742443\n",
            "At step: 3485 training error: 0.41800200110516395\n",
            "At step: 3486 training error: 0.4273351210582236\n",
            "At step: 3487 training error: 0.43141599592695684\n",
            "At step: 3488 training error: 0.44549955072163017\n",
            "At step: 3489 training error: 0.45092546573664916\n",
            "At step: 3490 training error: 0.4512335956094744\n",
            "At step: 3491 training error: 0.44759928932668813\n",
            "At step: 3492 training error: 0.44685206153359525\n",
            "At step: 3493 training error: 0.450382949469778\n",
            "At step: 3494 training error: 0.4515015126175861\n",
            "At step: 3495 training error: 0.4386985266530646\n",
            "At step: 3496 training error: 0.4326754493546661\n",
            "At step: 3497 training error: 0.4390264238618113\n",
            "At step: 3498 training error: 0.43998587533033623\n",
            "At step: 3499 training error: 0.43880867580391425\n",
            "At step: 3500 training error: 0.44511716046813177\n",
            "At step: 3501 training error: 0.4335937408914944\n",
            "At step: 3502 training error: 0.43704330659779844\n",
            "At step: 3503 training error: 0.44178678297463897\n",
            "At step: 3504 training error: 0.43560610641961484\n",
            "At step: 3505 training error: 0.4263360181078855\n",
            "At step: 3506 training error: 0.42415954549990775\n",
            "At step: 3507 training error: 0.42352987479692933\n",
            "At step: 3508 training error: 0.4199914580613879\n",
            "At step: 3509 training error: 0.4146172835325091\n",
            "At step: 3510 training error: 0.4114348484940422\n",
            "At step: 3511 training error: 0.42242265971085624\n",
            "At step: 3512 training error: 0.41727590966263367\n",
            "At step: 3513 training error: 0.40809759350319313\n",
            "At step: 3514 training error: 0.4026344525792564\n",
            "At step: 3515 training error: 0.40297596665703334\n",
            "At step: 3516 training error: 0.4052823550348192\n",
            "At step: 3517 training error: 0.4040973252675154\n",
            "At step: 3518 training error: 0.4153975407325483\n",
            "At step: 3519 training error: 0.4118873066528724\n",
            "At step: 3520 training error: 0.40952318751569683\n",
            "At step: 3521 training error: 0.4106225106524979\n",
            "At step: 3522 training error: 0.41776977146970906\n",
            "At step: 3523 training error: 0.4195900079066164\n",
            "At step: 3524 training error: 0.4156119604442028\n",
            "At step: 3525 training error: 0.43217629802900565\n",
            "At step: 3526 training error: 0.4453817728188108\n",
            "At step: 3527 training error: 0.44714224757261156\n",
            "At step: 3528 training error: 0.4456727496099063\n",
            "At step: 3529 training error: 0.4354959101269157\n",
            "At step: 3530 training error: 0.42636971976628707\n",
            "At step: 3531 training error: 0.43038499467694474\n",
            "At step: 3532 training error: 0.43349441895035823\n",
            "At step: 3533 training error: 0.4347878767510459\n",
            "At step: 3534 training error: 0.43733424646625685\n",
            "At step: 3535 training error: 0.42851894240084965\n",
            "At step: 3536 training error: 0.44028970065614165\n",
            "At step: 3537 training error: 0.42781161143228896\n",
            "At step: 3538 training error: 0.4298185210108753\n",
            "At step: 3539 training error: 0.42508890617252854\n",
            "At step: 3540 training error: 0.42279156772630927\n",
            "At step: 3541 training error: 0.4145026749067027\n",
            "At step: 3542 training error: 0.422645978036464\n",
            "At step: 3543 training error: 0.4180935124630418\n",
            "At step: 3544 training error: 0.4087911447957012\n",
            "At step: 3545 training error: 0.40452092085552305\n",
            "At step: 3546 training error: 0.39981951522513726\n",
            "At step: 3547 training error: 0.39726161974378976\n",
            "At step: 3548 training error: 0.4051449416254035\n",
            "At step: 3549 training error: 0.4083555373600688\n",
            "At step: 3550 training error: 0.41517470940318174\n",
            "At step: 3551 training error: 0.4209132614967085\n",
            "At step: 3552 training error: 0.4199504460817578\n",
            "At step: 3553 training error: 0.4201078138541387\n",
            "At step: 3554 training error: 0.4195569126174049\n",
            "At step: 3555 training error: 0.4201349239558205\n",
            "At step: 3556 training error: 0.43430603013928026\n",
            "At step: 3557 training error: 0.4420174689787049\n",
            "At step: 3558 training error: 0.4365631830416161\n",
            "At step: 3559 training error: 0.4484676533557619\n",
            "At step: 3560 training error: 0.4526924956667996\n",
            "At step: 3561 training error: 0.45957098421659376\n",
            "At step: 3562 training error: 0.45809653607538536\n",
            "At step: 3563 training error: 0.46063627681923947\n",
            "At step: 3564 training error: 0.4624394509150325\n",
            "At step: 3565 training error: 0.46182790269372653\n",
            "At step: 3566 training error: 0.4701600748128601\n",
            "At step: 3567 training error: 0.4615862263490088\n",
            "At step: 3568 training error: 0.45784414626077685\n",
            "At step: 3569 training error: 0.4551654845697912\n",
            "At step: 3570 training error: 0.46119281712490506\n",
            "At step: 3571 training error: 0.46844411681741055\n",
            "At step: 3572 training error: 0.46218387942367434\n",
            "At step: 3573 training error: 0.45782251568242305\n",
            "At step: 3574 training error: 0.4510926534956489\n",
            "At step: 3575 training error: 0.4441628865797885\n",
            "At step: 3576 training error: 0.44530913682326645\n",
            "At step: 3577 training error: 0.44012253206139085\n",
            "At step: 3578 training error: 0.4383223864342257\n",
            "At step: 3579 training error: 0.4431986460266849\n",
            "At step: 3580 training error: 0.4479700584678473\n",
            "At step: 3581 training error: 0.4438174677325225\n",
            "At step: 3582 training error: 0.4518110764263281\n",
            "At step: 3583 training error: 0.4442308358035468\n",
            "At step: 3584 training error: 0.4393700436602349\n",
            "At step: 3585 training error: 0.4323528768314748\n",
            "At step: 3586 training error: 0.41607722453054535\n",
            "At step: 3587 training error: 0.4331326765026645\n",
            "At step: 3588 training error: 0.43685700213868184\n",
            "At step: 3589 training error: 0.4459994620520778\n",
            "At step: 3590 training error: 0.4610176826253783\n",
            "At step: 3591 training error: 0.454779774578084\n",
            "At step: 3592 training error: 0.45122519815161055\n",
            "At step: 3593 training error: 0.45078087799391026\n",
            "At step: 3594 training error: 0.43979657718382925\n",
            "At step: 3595 training error: 0.43335194741559546\n",
            "At step: 3596 training error: 0.4210586447543027\n",
            "At step: 3597 training error: 0.42287213019733905\n",
            "At step: 3598 training error: 0.4217311882585276\n",
            "At step: 3599 training error: 0.41527729924379686\n",
            "At step: 3600 training error: 0.411463410411525\n",
            "At step: 3601 training error: 0.4185602317957319\n",
            "At step: 3602 training error: 0.4201338086013713\n",
            "At step: 3603 training error: 0.43449873564316843\n",
            "At step: 3604 training error: 0.43265870248207594\n",
            "At step: 3605 training error: 0.43664852525525516\n",
            "At step: 3606 training error: 0.43120391074652764\n",
            "At step: 3607 training error: 0.4268528867366509\n",
            "At step: 3608 training error: 0.4250102984917526\n",
            "At step: 3609 training error: 0.4198652427799027\n",
            "At step: 3610 training error: 0.42303516620022535\n",
            "At step: 3611 training error: 0.4150859342847635\n",
            "At step: 3612 training error: 0.4227406748287096\n",
            "At step: 3613 training error: 0.42985549570741427\n",
            "At step: 3614 training error: 0.43158897958275555\n",
            "At step: 3615 training error: 0.43623768701116455\n",
            "At step: 3616 training error: 0.43246493645966333\n",
            "At step: 3617 training error: 0.4253455751134418\n",
            "At step: 3618 training error: 0.43046525854296147\n",
            "At step: 3619 training error: 0.4264744310192866\n",
            "At step: 3620 training error: 0.42944053192395026\n",
            "At step: 3621 training error: 0.4291752772190669\n",
            "At step: 3622 training error: 0.4293734190378495\n",
            "At step: 3623 training error: 0.4283770033911988\n",
            "At step: 3624 training error: 0.42992993758256975\n",
            "At step: 3625 training error: 0.4406186236100812\n",
            "At step: 3626 training error: 0.4396494786739957\n",
            "At step: 3627 training error: 0.4468717609792069\n",
            "At step: 3628 training error: 0.4397159303424642\n",
            "At step: 3629 training error: 0.4553059710804196\n",
            "At step: 3630 training error: 0.45124089871375406\n",
            "At step: 3631 training error: 0.4586950458689671\n",
            "At step: 3632 training error: 0.4575831836020212\n",
            "At step: 3633 training error: 0.4608393265861143\n",
            "At step: 3634 training error: 0.4561295770790136\n",
            "At step: 3635 training error: 0.45526697157167223\n",
            "At step: 3636 training error: 0.464869867746992\n",
            "At step: 3637 training error: 0.46810446789013405\n",
            "At step: 3638 training error: 0.4640996732736838\n",
            "At step: 3639 training error: 0.4630183234528531\n",
            "At step: 3640 training error: 0.4524405752738795\n",
            "At step: 3641 training error: 0.459239944427864\n",
            "At step: 3642 training error: 0.4573570443735052\n",
            "At step: 3643 training error: 0.4563863736623329\n",
            "At step: 3644 training error: 0.4568057321929307\n",
            "At step: 3645 training error: 0.4526298588773564\n",
            "At step: 3646 training error: 0.44683746622356973\n",
            "At step: 3647 training error: 0.44470209297661156\n",
            "At step: 3648 training error: 0.45078354696978756\n",
            "At step: 3649 training error: 0.44122737888913444\n",
            "At step: 3650 training error: 0.4404958451063702\n",
            "At step: 3651 training error: 0.43620394479165014\n",
            "At step: 3652 training error: 0.4403202112408868\n",
            "At step: 3653 training error: 0.4334557886221907\n",
            "At step: 3654 training error: 0.43529861958870525\n",
            "At step: 3655 training error: 0.4289208641405304\n",
            "At step: 3656 training error: 0.4311135638861621\n",
            "At step: 3657 training error: 0.435047545971801\n",
            "At step: 3658 training error: 0.44222335682616104\n",
            "At step: 3659 training error: 0.4387681244219937\n",
            "At step: 3660 training error: 0.43637224177631534\n",
            "At step: 3661 training error: 0.4316581959180596\n",
            "At step: 3662 training error: 0.43758421537510844\n",
            "At step: 3663 training error: 0.43946677068915235\n",
            "At step: 3664 training error: 0.4458035929493112\n",
            "At step: 3665 training error: 0.4505008426775354\n",
            "At step: 3666 training error: 0.4503820345443073\n",
            "At step: 3667 training error: 0.4559973214470725\n",
            "At step: 3668 training error: 0.45029564551773343\n",
            "At step: 3669 training error: 0.44711970243397314\n",
            "At step: 3670 training error: 0.44537705929717414\n",
            "At step: 3671 training error: 0.4389304593757384\n",
            "At step: 3672 training error: 0.43779487726367133\n",
            "At step: 3673 training error: 0.44034958218663994\n",
            "At step: 3674 training error: 0.4276793536247862\n",
            "At step: 3675 training error: 0.420913980696428\n",
            "At step: 3676 training error: 0.4128985331508267\n",
            "At step: 3677 training error: 0.40196542827391846\n",
            "At step: 3678 training error: 0.41412340858314173\n",
            "At step: 3679 training error: 0.41953214877002604\n",
            "At step: 3680 training error: 0.4181638340335425\n",
            "At step: 3681 training error: 0.4234470279967045\n",
            "At step: 3682 training error: 0.4129562408066864\n",
            "At step: 3683 training error: 0.40795337572572943\n",
            "At step: 3684 training error: 0.4231792466491535\n",
            "At step: 3685 training error: 0.42467458608240616\n",
            "At step: 3686 training error: 0.42885917870690277\n",
            "At step: 3687 training error: 0.43245899324751935\n",
            "At step: 3688 training error: 0.4239001394161377\n",
            "At step: 3689 training error: 0.41805522309821386\n",
            "At step: 3690 training error: 0.41618197558391634\n",
            "At step: 3691 training error: 0.41533583394735135\n",
            "At step: 3692 training error: 0.4139135486795612\n",
            "At step: 3693 training error: 0.40895829946762036\n",
            "At step: 3694 training error: 0.41353334511108636\n",
            "At step: 3695 training error: 0.4157246645503463\n",
            "At step: 3696 training error: 0.4073307856510738\n",
            "At step: 3697 training error: 0.40522051507763646\n",
            "At step: 3698 training error: 0.4207965387965513\n",
            "At step: 3699 training error: 0.4192915038906066\n",
            "At step: 3700 training error: 0.421497132848113\n",
            "At step: 3701 training error: 0.41950064440228285\n",
            "At step: 3702 training error: 0.42610338403880677\n",
            "At step: 3703 training error: 0.4210272940734544\n",
            "At step: 3704 training error: 0.43022983669792014\n",
            "At step: 3705 training error: 0.42750661795798583\n",
            "At step: 3706 training error: 0.42509431617170035\n",
            "At step: 3707 training error: 0.4208907863155164\n",
            "At step: 3708 training error: 0.4196503912852692\n",
            "At step: 3709 training error: 0.42490718296238245\n",
            "At step: 3710 training error: 0.4249168056410072\n",
            "At step: 3711 training error: 0.4335092358780682\n",
            "At step: 3712 training error: 0.43820419194531796\n",
            "At step: 3713 training error: 0.45074809816139805\n",
            "At step: 3714 training error: 0.44775951444507545\n",
            "At step: 3715 training error: 0.44808487009048403\n",
            "At step: 3716 training error: 0.4435835533218597\n",
            "At step: 3717 training error: 0.45686113981195203\n",
            "At step: 3718 training error: 0.46280695356368795\n",
            "At step: 3719 training error: 0.4625733550282696\n",
            "At step: 3720 training error: 0.4663713437280934\n",
            "At step: 3721 training error: 0.46091919187932084\n",
            "At step: 3722 training error: 0.4454825287708292\n",
            "At step: 3723 training error: 0.4567775254112601\n",
            "At step: 3724 training error: 0.4548220998387726\n",
            "At step: 3725 training error: 0.45423391579295896\n",
            "At step: 3726 training error: 0.4514802945434619\n",
            "At step: 3727 training error: 0.45116354606497067\n",
            "At step: 3728 training error: 0.4483872518415257\n",
            "At step: 3729 training error: 0.44211670739537356\n",
            "At step: 3730 training error: 0.44333237407779624\n",
            "At step: 3731 training error: 0.44511284036761034\n",
            "At step: 3732 training error: 0.4374101437992424\n",
            "At step: 3733 training error: 0.43164427309861864\n",
            "At step: 3734 training error: 0.42860726529954346\n",
            "At step: 3735 training error: 0.4371254006070653\n",
            "At step: 3736 training error: 0.43241431844619216\n",
            "At step: 3737 training error: 0.43377871183464556\n",
            "At step: 3738 training error: 0.43558660896718215\n",
            "At step: 3739 training error: 0.43166642397636323\n",
            "At step: 3740 training error: 0.42867127479363915\n",
            "At step: 3741 training error: 0.42117572457089614\n",
            "At step: 3742 training error: 0.4291931318325943\n",
            "At step: 3743 training error: 0.4458353423956611\n",
            "At step: 3744 training error: 0.43846659431701485\n",
            "At step: 3745 training error: 0.43746691463506865\n",
            "At step: 3746 training error: 0.43503243569346667\n",
            "At step: 3747 training error: 0.43660432621587447\n",
            "At step: 3748 training error: 0.43675676721984746\n",
            "At step: 3749 training error: 0.4385498488743702\n",
            "At step: 3750 training error: 0.45367570214835734\n",
            "At step: 3751 training error: 0.4513106988999355\n",
            "At step: 3752 training error: 0.45663176469826566\n",
            "At step: 3753 training error: 0.4508084680714551\n",
            "At step: 3754 training error: 0.44309681569563253\n",
            "At step: 3755 training error: 0.4534325559671084\n",
            "At step: 3756 training error: 0.46039355409905475\n",
            "At step: 3757 training error: 0.4557387575630006\n",
            "At step: 3758 training error: 0.4510603868558879\n",
            "At step: 3759 training error: 0.4461123711675395\n",
            "At step: 3760 training error: 0.4398090581143533\n",
            "At step: 3761 training error: 0.44365109120927476\n",
            "At step: 3762 training error: 0.4419755749386794\n",
            "At step: 3763 training error: 0.4413351199149286\n",
            "At step: 3764 training error: 0.4450496388571974\n",
            "At step: 3765 training error: 0.4425358395747078\n",
            "At step: 3766 training error: 0.44231342649809124\n",
            "At step: 3767 training error: 0.4390690713471471\n",
            "At step: 3768 training error: 0.43791854545303743\n",
            "At step: 3769 training error: 0.4370159219845423\n",
            "At step: 3770 training error: 0.44279863096697314\n",
            "At step: 3771 training error: 0.44706323767394274\n",
            "At step: 3772 training error: 0.4530481218632655\n",
            "At step: 3773 training error: 0.4584405633278418\n",
            "At step: 3774 training error: 0.44667894283516013\n",
            "At step: 3775 training error: 0.4416790293937358\n",
            "At step: 3776 training error: 0.44108562720242195\n",
            "At step: 3777 training error: 0.4371403203402247\n",
            "At step: 3778 training error: 0.44033773751007577\n",
            "At step: 3779 training error: 0.4338695766543999\n",
            "At step: 3780 training error: 0.43810824258847664\n",
            "At step: 3781 training error: 0.4459464395294192\n",
            "At step: 3782 training error: 0.443374355915465\n",
            "At step: 3783 training error: 0.4338658771356445\n",
            "At step: 3784 training error: 0.4406197911902849\n",
            "At step: 3785 training error: 0.43841999070519116\n",
            "At step: 3786 training error: 0.44578172582114506\n",
            "At step: 3787 training error: 0.4436517507332046\n",
            "At step: 3788 training error: 0.44724862496009243\n",
            "At step: 3789 training error: 0.44479237590523657\n",
            "At step: 3790 training error: 0.45175681732591716\n",
            "At step: 3791 training error: 0.44952010734622583\n",
            "At step: 3792 training error: 0.4442402594490191\n",
            "At step: 3793 training error: 0.4381011611097755\n",
            "At step: 3794 training error: 0.4320253480901902\n",
            "At step: 3795 training error: 0.4354326164881286\n",
            "At step: 3796 training error: 0.43758911260757927\n",
            "At step: 3797 training error: 0.431227557263436\n",
            "At step: 3798 training error: 0.4428699181160124\n",
            "At step: 3799 training error: 0.4423237057070774\n",
            "At step: 3800 training error: 0.4517155227242791\n",
            "At step: 3801 training error: 0.4410418879834098\n",
            "At step: 3802 training error: 0.4506562088655734\n",
            "At step: 3803 training error: 0.45071186792425366\n",
            "At step: 3804 training error: 0.44944139100243174\n",
            "At step: 3805 training error: 0.4459701544341573\n",
            "At step: 3806 training error: 0.44203962937361907\n",
            "At step: 3807 training error: 0.4450219717954952\n",
            "At step: 3808 training error: 0.44932834061270605\n",
            "At step: 3809 training error: 0.4512531319925842\n",
            "At step: 3810 training error: 0.451231586922584\n",
            "At step: 3811 training error: 0.4451104606536639\n",
            "At step: 3812 training error: 0.44795079862436216\n",
            "At step: 3813 training error: 0.43914295457881414\n",
            "At step: 3814 training error: 0.4356120085573625\n",
            "At step: 3815 training error: 0.4310836973148935\n",
            "At step: 3816 training error: 0.4314398572648476\n",
            "At step: 3817 training error: 0.4318484428836622\n",
            "At step: 3818 training error: 0.435681759454257\n",
            "At step: 3819 training error: 0.42926295497089556\n",
            "At step: 3820 training error: 0.41934349150407096\n",
            "At step: 3821 training error: 0.425051390485404\n",
            "At step: 3822 training error: 0.4332787504490973\n",
            "At step: 3823 training error: 0.4343669733643836\n",
            "At step: 3824 training error: 0.43524260797830944\n",
            "At step: 3825 training error: 0.44442489265569557\n",
            "At step: 3826 training error: 0.43082639388848176\n",
            "At step: 3827 training error: 0.44681727725047904\n",
            "At step: 3828 training error: 0.4396695149106854\n",
            "At step: 3829 training error: 0.4283030844921194\n",
            "At step: 3830 training error: 0.42451753517702007\n",
            "At step: 3831 training error: 0.4244529495422956\n",
            "At step: 3832 training error: 0.4276208644005522\n",
            "At step: 3833 training error: 0.4408546979760239\n",
            "At step: 3834 training error: 0.4391668518591088\n",
            "At step: 3835 training error: 0.4342073341671668\n",
            "At step: 3836 training error: 0.4298211866931322\n",
            "At step: 3837 training error: 0.4191493578707534\n",
            "At step: 3838 training error: 0.41404830911184853\n",
            "At step: 3839 training error: 0.41338390994129776\n",
            "At step: 3840 training error: 0.4107006459271739\n",
            "At step: 3841 training error: 0.40354094058561557\n",
            "At step: 3842 training error: 0.4038163807843541\n",
            "At step: 3843 training error: 0.41277464671962083\n",
            "At step: 3844 training error: 0.4192740589474019\n",
            "At step: 3845 training error: 0.4167957796299693\n",
            "At step: 3846 training error: 0.42840775515573926\n",
            "At step: 3847 training error: 0.4357680871901311\n",
            "At step: 3848 training error: 0.4392348910754296\n",
            "At step: 3849 training error: 0.4429931250887912\n",
            "At step: 3850 training error: 0.4439348334982114\n",
            "At step: 3851 training error: 0.436551015505703\n",
            "At step: 3852 training error: 0.4398061831568632\n",
            "At step: 3853 training error: 0.43000319269473575\n",
            "At step: 3854 training error: 0.42348572171987364\n",
            "At step: 3855 training error: 0.43287542213115776\n",
            "At step: 3856 training error: 0.43087252592788355\n",
            "At step: 3857 training error: 0.4300286748045997\n",
            "At step: 3858 training error: 0.4251300560552229\n",
            "At step: 3859 training error: 0.43028286028225715\n",
            "At step: 3860 training error: 0.4326537829307754\n",
            "At step: 3861 training error: 0.434423959034667\n",
            "At step: 3862 training error: 0.4286273722089414\n",
            "At step: 3863 training error: 0.4316388675090627\n",
            "At step: 3864 training error: 0.42332650478998946\n",
            "At step: 3865 training error: 0.42641841781166834\n",
            "At step: 3866 training error: 0.4263592352758363\n",
            "At step: 3867 training error: 0.42187944447945086\n",
            "At step: 3868 training error: 0.425147092869062\n",
            "At step: 3869 training error: 0.4209322081101794\n",
            "At step: 3870 training error: 0.4311507662265621\n",
            "At step: 3871 training error: 0.42839136387116267\n",
            "At step: 3872 training error: 0.4458464836022886\n",
            "At step: 3873 training error: 0.4410103705635313\n",
            "At step: 3874 training error: 0.4375210476619832\n",
            "At step: 3875 training error: 0.43354396164166464\n",
            "At step: 3876 training error: 0.42781759530978863\n",
            "At step: 3877 training error: 0.426082053752149\n",
            "At step: 3878 training error: 0.4238394027547536\n",
            "At step: 3879 training error: 0.42616489209850367\n",
            "At step: 3880 training error: 0.42317417772971805\n",
            "At step: 3881 training error: 0.4299536552470003\n",
            "At step: 3882 training error: 0.4331961515628655\n",
            "At step: 3883 training error: 0.4375522577339947\n",
            "At step: 3884 training error: 0.42677813635591977\n",
            "At step: 3885 training error: 0.42453640379294855\n",
            "At step: 3886 training error: 0.42694046359833426\n",
            "At step: 3887 training error: 0.435508076224152\n",
            "At step: 3888 training error: 0.4435948042247205\n",
            "At step: 3889 training error: 0.44651241753918425\n",
            "At step: 3890 training error: 0.4522293892637196\n",
            "At step: 3891 training error: 0.44398055767985856\n",
            "At step: 3892 training error: 0.44110312042943534\n",
            "At step: 3893 training error: 0.43165504184087\n",
            "At step: 3894 training error: 0.43377039963605624\n",
            "At step: 3895 training error: 0.4455823925889433\n",
            "At step: 3896 training error: 0.43384647854409675\n",
            "At step: 3897 training error: 0.43122682752354047\n",
            "At step: 3898 training error: 0.4369500508483762\n",
            "At step: 3899 training error: 0.4368010047383828\n",
            "At step: 3900 training error: 0.439876961225145\n",
            "At step: 3901 training error: 0.44318709513829546\n",
            "At step: 3902 training error: 0.45574892962247293\n",
            "At step: 3903 training error: 0.4586105049761707\n",
            "At step: 3904 training error: 0.45880751151373195\n",
            "At step: 3905 training error: 0.45266001192565125\n",
            "At step: 3906 training error: 0.44165656982559065\n",
            "At step: 3907 training error: 0.4388631974257714\n",
            "At step: 3908 training error: 0.4426615364850074\n",
            "At step: 3909 training error: 0.4430158730248712\n",
            "At step: 3910 training error: 0.4355784632273139\n",
            "At step: 3911 training error: 0.4374510247094724\n",
            "At step: 3912 training error: 0.4507309131109861\n",
            "At step: 3913 training error: 0.4497759430013676\n",
            "At step: 3914 training error: 0.4447758048305874\n",
            "At step: 3915 training error: 0.45489201166689297\n",
            "At step: 3916 training error: 0.44705771166803726\n",
            "At step: 3917 training error: 0.43505774354621835\n",
            "At step: 3918 training error: 0.43481993613468783\n",
            "At step: 3919 training error: 0.4348286869390475\n",
            "At step: 3920 training error: 0.43381971968539107\n",
            "At step: 3921 training error: 0.43234338944601003\n",
            "At step: 3922 training error: 0.4356700786986944\n",
            "At step: 3923 training error: 0.43005760367404544\n",
            "At step: 3924 training error: 0.4245079015666372\n",
            "At step: 3925 training error: 0.41697669029945933\n",
            "At step: 3926 training error: 0.4239812010033075\n",
            "At step: 3927 training error: 0.41300876653503915\n",
            "At step: 3928 training error: 0.41242345509985756\n",
            "At step: 3929 training error: 0.4132955091163667\n",
            "At step: 3930 training error: 0.4115092901804836\n",
            "At step: 3931 training error: 0.41063243763082935\n",
            "At step: 3932 training error: 0.40537541235918184\n",
            "At step: 3933 training error: 0.41359187966813327\n",
            "At step: 3934 training error: 0.41474527981698617\n",
            "At step: 3935 training error: 0.4316109933317469\n",
            "At step: 3936 training error: 0.4286820008843586\n",
            "At step: 3937 training error: 0.41844431604300947\n",
            "At step: 3938 training error: 0.42256816639177697\n",
            "At step: 3939 training error: 0.4273841339500386\n",
            "At step: 3940 training error: 0.43563313790911434\n",
            "At step: 3941 training error: 0.43724032621865455\n",
            "At step: 3942 training error: 0.43452450503096995\n",
            "At step: 3943 training error: 0.4309168473597278\n",
            "At step: 3944 training error: 0.42285723372491735\n",
            "At step: 3945 training error: 0.4221829398493344\n",
            "At step: 3946 training error: 0.4336936279940127\n",
            "At step: 3947 training error: 0.43218740857310844\n",
            "At step: 3948 training error: 0.4283203147926345\n",
            "At step: 3949 training error: 0.4253279396370297\n",
            "At step: 3950 training error: 0.42949452522965537\n",
            "At step: 3951 training error: 0.4448776629733479\n",
            "At step: 3952 training error: 0.4413399165655198\n",
            "At step: 3953 training error: 0.451318269357729\n",
            "At step: 3954 training error: 0.4548632778585921\n",
            "At step: 3955 training error: 0.4534059953307105\n",
            "At step: 3956 training error: 0.45512441427281447\n",
            "At step: 3957 training error: 0.4497550487867246\n",
            "At step: 3958 training error: 0.44755751655963605\n",
            "At step: 3959 training error: 0.46000530024857944\n",
            "At step: 3960 training error: 0.45949429819265464\n",
            "At step: 3961 training error: 0.45568717580029106\n",
            "At step: 3962 training error: 0.44512551905669556\n",
            "At step: 3963 training error: 0.4452340661993416\n",
            "At step: 3964 training error: 0.4503753459881341\n",
            "At step: 3965 training error: 0.4497630551194003\n",
            "At step: 3966 training error: 0.4560637357933424\n",
            "At step: 3967 training error: 0.45339298308057807\n",
            "At step: 3968 training error: 0.45603781380985303\n",
            "At step: 3969 training error: 0.46002326067836347\n",
            "At step: 3970 training error: 0.4592199341146769\n",
            "At step: 3971 training error: 0.4523152399991209\n",
            "At step: 3972 training error: 0.4476955075952108\n",
            "At step: 3973 training error: 0.44250116457907984\n",
            "At step: 3974 training error: 0.44283706907280246\n",
            "At step: 3975 training error: 0.4317914000223836\n",
            "At step: 3976 training error: 0.44135304744819304\n",
            "At step: 3977 training error: 0.4346991274116196\n",
            "At step: 3978 training error: 0.44040384160630863\n",
            "At step: 3979 training error: 0.44229267453773924\n",
            "At step: 3980 training error: 0.45053213337391734\n",
            "At step: 3981 training error: 0.4494125056998688\n",
            "At step: 3982 training error: 0.45485231386255776\n",
            "At step: 3983 training error: 0.45144532836039364\n",
            "At step: 3984 training error: 0.44794487123365445\n",
            "At step: 3985 training error: 0.4507539648841713\n",
            "At step: 3986 training error: 0.4530788921065957\n",
            "At step: 3987 training error: 0.4520668612610309\n",
            "At step: 3988 training error: 0.4433818429580483\n",
            "At step: 3989 training error: 0.4409587888705885\n",
            "At step: 3990 training error: 0.4450702065529098\n",
            "At step: 3991 training error: 0.4409755275507519\n",
            "At step: 3992 training error: 0.44251233692760283\n",
            "At step: 3993 training error: 0.44336849917931204\n",
            "At step: 3994 training error: 0.43879145410976866\n",
            "At step: 3995 training error: 0.44025856775679195\n",
            "At step: 3996 training error: 0.43998733419517333\n",
            "At step: 3997 training error: 0.43990394282673334\n",
            "At step: 3998 training error: 0.43370799672174726\n",
            "At step: 3999 training error: 0.4378374464056814\n",
            "At step: 4000 training error: 0.44151857241043974\n",
            "At step: 4001 training error: 0.444826764517502\n",
            "At step: 4002 training error: 0.4537578633060144\n",
            "At step: 4003 training error: 0.44729347722779395\n",
            "At step: 4004 training error: 0.45006232032354176\n",
            "At step: 4005 training error: 0.44899804035239205\n",
            "At step: 4006 training error: 0.4593303096249163\n",
            "At step: 4007 training error: 0.44466971801016064\n",
            "At step: 4008 training error: 0.44352538766559946\n",
            "At step: 4009 training error: 0.43550872100529286\n",
            "At step: 4010 training error: 0.4350874895163312\n",
            "At step: 4011 training error: 0.4264598038774076\n",
            "At step: 4012 training error: 0.4217328435997524\n",
            "At step: 4013 training error: 0.42753307912190225\n",
            "At step: 4014 training error: 0.41808528006777307\n",
            "At step: 4015 training error: 0.42610166891070894\n",
            "At step: 4016 training error: 0.4256230560556194\n",
            "At step: 4017 training error: 0.4249232323718564\n",
            "At step: 4018 training error: 0.41092903880534404\n",
            "At step: 4019 training error: 0.4085687817462002\n",
            "At step: 4020 training error: 0.4268931662223595\n",
            "At step: 4021 training error: 0.4309395837286111\n",
            "At step: 4022 training error: 0.42778389508538694\n",
            "At step: 4023 training error: 0.42682359373944107\n",
            "At step: 4024 training error: 0.42724153371174456\n",
            "At step: 4025 training error: 0.4236644779682044\n",
            "At step: 4026 training error: 0.4261844818727897\n",
            "At step: 4027 training error: 0.43334818844931355\n",
            "At step: 4028 training error: 0.4343264687687755\n",
            "At step: 4029 training error: 0.4374119236621129\n",
            "At step: 4030 training error: 0.4368555819271539\n",
            "At step: 4031 training error: 0.44180287141650887\n",
            "At step: 4032 training error: 0.4564031196560121\n",
            "At step: 4033 training error: 0.45367829320098463\n",
            "At step: 4034 training error: 0.44647550004706715\n",
            "At step: 4035 training error: 0.4305336016656405\n",
            "At step: 4036 training error: 0.4358289213713744\n",
            "At step: 4037 training error: 0.4387226728092985\n",
            "At step: 4038 training error: 0.4332241704355275\n",
            "At step: 4039 training error: 0.4383116421435483\n",
            "At step: 4040 training error: 0.4456333732528832\n",
            "At step: 4041 training error: 0.4463349533807329\n",
            "At step: 4042 training error: 0.4554723615408055\n",
            "At step: 4043 training error: 0.44149250074670404\n",
            "At step: 4044 training error: 0.4400322967413424\n",
            "At step: 4045 training error: 0.4481756699044342\n",
            "At step: 4046 training error: 0.45019184951108976\n",
            "At step: 4047 training error: 0.43910949045354536\n",
            "At step: 4048 training error: 0.4343588938193692\n",
            "At step: 4049 training error: 0.44707997649977504\n",
            "At step: 4050 training error: 0.44138926075049156\n",
            "At step: 4051 training error: 0.44098610283630707\n",
            "At step: 4052 training error: 0.44781161811330933\n",
            "At step: 4053 training error: 0.4555814460011832\n",
            "At step: 4054 training error: 0.4448546494540583\n",
            "At step: 4055 training error: 0.44010056741177034\n",
            "At step: 4056 training error: 0.4406061966707756\n",
            "At step: 4057 training error: 0.4405188927239109\n",
            "At step: 4058 training error: 0.44963993932143964\n",
            "At step: 4059 training error: 0.4557259008213577\n",
            "At step: 4060 training error: 0.45558236201126623\n",
            "At step: 4061 training error: 0.45407240946106764\n",
            "At step: 4062 training error: 0.45638928137645135\n",
            "At step: 4063 training error: 0.4495569573275941\n",
            "At step: 4064 training error: 0.4365741501741844\n",
            "At step: 4065 training error: 0.43600118412597655\n",
            "At step: 4066 training error: 0.4315148509719335\n",
            "At step: 4067 training error: 0.4144865305929932\n",
            "At step: 4068 training error: 0.4267471827895241\n",
            "At step: 4069 training error: 0.4309588263669776\n",
            "At step: 4070 training error: 0.44223756028785643\n",
            "At step: 4071 training error: 0.4460753591932378\n",
            "At step: 4072 training error: 0.44550464178498295\n",
            "At step: 4073 training error: 0.43326097961577537\n",
            "At step: 4074 training error: 0.4326716507556968\n",
            "At step: 4075 training error: 0.4342017922839292\n",
            "At step: 4076 training error: 0.444601939089183\n",
            "At step: 4077 training error: 0.44817824121243166\n",
            "At step: 4078 training error: 0.4523148283215631\n",
            "At step: 4079 training error: 0.45565370766289304\n",
            "At step: 4080 training error: 0.4476643555727741\n",
            "At step: 4081 training error: 0.4505846197830316\n",
            "At step: 4082 training error: 0.447852181746116\n",
            "At step: 4083 training error: 0.4495057710835795\n",
            "At step: 4084 training error: 0.446841540767383\n",
            "At step: 4085 training error: 0.4366405066474367\n",
            "At step: 4086 training error: 0.43528670180890444\n",
            "At step: 4087 training error: 0.441754349220133\n",
            "At step: 4088 training error: 0.44539631973773736\n",
            "At step: 4089 training error: 0.44282001919800507\n",
            "At step: 4090 training error: 0.4422636928134782\n",
            "At step: 4091 training error: 0.4352545844449253\n",
            "At step: 4092 training error: 0.4332702414992309\n",
            "At step: 4093 training error: 0.433888349477652\n",
            "At step: 4094 training error: 0.4442128424869311\n",
            "At step: 4095 training error: 0.4430644456261452\n",
            "At step: 4096 training error: 0.4317200621358008\n",
            "At step: 4097 training error: 0.43677127388493253\n",
            "At step: 4098 training error: 0.4376987491094669\n",
            "At step: 4099 training error: 0.43763243548762076\n",
            "At step: 4100 training error: 0.43098099104895476\n",
            "At step: 4101 training error: 0.43200485454427856\n",
            "At step: 4102 training error: 0.4306520657001096\n",
            "At step: 4103 training error: 0.42170201064113344\n",
            "At step: 4104 training error: 0.42168370644742503\n",
            "At step: 4105 training error: 0.40968081020802544\n",
            "At step: 4106 training error: 0.40366392458927186\n",
            "At step: 4107 training error: 0.4038534251773644\n",
            "At step: 4108 training error: 0.4070787386354652\n",
            "At step: 4109 training error: 0.402737792180097\n",
            "At step: 4110 training error: 0.3908534892236324\n",
            "At step: 4111 training error: 0.3999736192878729\n",
            "At step: 4112 training error: 0.39932463966161147\n",
            "At step: 4113 training error: 0.42124803431842617\n",
            "At step: 4114 training error: 0.41579198670994394\n",
            "At step: 4115 training error: 0.4214848555755679\n",
            "At step: 4116 training error: 0.4162497668375741\n",
            "At step: 4117 training error: 0.41856554540384294\n",
            "At step: 4118 training error: 0.4305854381093866\n",
            "At step: 4119 training error: 0.4328990035931827\n",
            "At step: 4120 training error: 0.4324611689730612\n",
            "At step: 4121 training error: 0.4294504512046898\n",
            "At step: 4122 training error: 0.4286530198912276\n",
            "At step: 4123 training error: 0.43471460621304525\n",
            "At step: 4124 training error: 0.4291186363248257\n",
            "At step: 4125 training error: 0.4337660302150418\n",
            "At step: 4126 training error: 0.4380816557191316\n",
            "At step: 4127 training error: 0.4409370064825083\n",
            "At step: 4128 training error: 0.43464903094894947\n",
            "At step: 4129 training error: 0.4367673661018995\n",
            "At step: 4130 training error: 0.44316799297449394\n",
            "At step: 4131 training error: 0.43947078126908484\n",
            "At step: 4132 training error: 0.4293904502770346\n",
            "At step: 4133 training error: 0.4261175884833602\n",
            "At step: 4134 training error: 0.4251803103657891\n",
            "At step: 4135 training error: 0.42985411689426806\n",
            "At step: 4136 training error: 0.436123328071079\n",
            "At step: 4137 training error: 0.4379160952028296\n",
            "At step: 4138 training error: 0.4331619556096319\n",
            "At step: 4139 training error: 0.4405673229447695\n",
            "At step: 4140 training error: 0.4384960037759541\n",
            "At step: 4141 training error: 0.44371513129147483\n",
            "At step: 4142 training error: 0.43924121516834036\n",
            "At step: 4143 training error: 0.43011460710493366\n",
            "At step: 4144 training error: 0.42649545061575317\n",
            "At step: 4145 training error: 0.4246573898810631\n",
            "At step: 4146 training error: 0.4407941022512634\n",
            "At step: 4147 training error: 0.44168509747613993\n",
            "At step: 4148 training error: 0.43918561752431795\n",
            "At step: 4149 training error: 0.44389707740465956\n",
            "At step: 4150 training error: 0.44046466797534467\n",
            "At step: 4151 training error: 0.43757495276743136\n",
            "At step: 4152 training error: 0.44248276416343546\n",
            "At step: 4153 training error: 0.4420230311776665\n",
            "At step: 4154 training error: 0.4653274493816686\n",
            "At step: 4155 training error: 0.46455231884515996\n",
            "At step: 4156 training error: 0.4657185448837624\n",
            "At step: 4157 training error: 0.47267166536464755\n",
            "At step: 4158 training error: 0.4643731814252213\n",
            "At step: 4159 training error: 0.47368981993346954\n",
            "At step: 4160 training error: 0.47540009508389747\n",
            "At step: 4161 training error: 0.4702928840221815\n",
            "At step: 4162 training error: 0.4615453387775107\n",
            "At step: 4163 training error: 0.46539363210699286\n",
            "At step: 4164 training error: 0.45666893393969293\n",
            "At step: 4165 training error: 0.455253006151918\n",
            "At step: 4166 training error: 0.4488853161124122\n",
            "At step: 4167 training error: 0.4498325938979414\n",
            "At step: 4168 training error: 0.4511851607481685\n",
            "At step: 4169 training error: 0.4594979790376527\n",
            "At step: 4170 training error: 0.4504743614203274\n",
            "At step: 4171 training error: 0.4429154612141913\n",
            "At step: 4172 training error: 0.4400215337208493\n",
            "At step: 4173 training error: 0.43939448656404284\n",
            "At step: 4174 training error: 0.42885786402547915\n",
            "At step: 4175 training error: 0.44277401957707846\n",
            "At step: 4176 training error: 0.44501666193254485\n",
            "At step: 4177 training error: 0.4467845574772142\n",
            "At step: 4178 training error: 0.4490149151096064\n",
            "At step: 4179 training error: 0.44365428232151877\n",
            "At step: 4180 training error: 0.4417938903845879\n",
            "At step: 4181 training error: 0.43817862275084235\n",
            "At step: 4182 training error: 0.4434242159572338\n",
            "At step: 4183 training error: 0.4520082269121373\n",
            "At step: 4184 training error: 0.438221784248806\n",
            "At step: 4185 training error: 0.4381225364079824\n",
            "At step: 4186 training error: 0.4438211325213622\n",
            "At step: 4187 training error: 0.4451872199775454\n",
            "At step: 4188 training error: 0.4508284243295117\n",
            "At step: 4189 training error: 0.448375440100587\n",
            "At step: 4190 training error: 0.44506379831727705\n",
            "At step: 4191 training error: 0.4507813617644372\n",
            "At step: 4192 training error: 0.4475768372196033\n",
            "At step: 4193 training error: 0.45401913570575503\n",
            "At step: 4194 training error: 0.4593850313797757\n",
            "At step: 4195 training error: 0.44984049923833297\n",
            "At step: 4196 training error: 0.44657228868418797\n",
            "At step: 4197 training error: 0.4371890561965617\n",
            "At step: 4198 training error: 0.43206331131579656\n",
            "At step: 4199 training error: 0.426907659359992\n",
            "At step: 4200 training error: 0.43326071267636823\n",
            "At step: 4201 training error: 0.4389568718161353\n",
            "At step: 4202 training error: 0.43773811662614004\n",
            "At step: 4203 training error: 0.42739932164243344\n",
            "At step: 4204 training error: 0.4239394678406276\n",
            "At step: 4205 training error: 0.4233664998788672\n",
            "At step: 4206 training error: 0.4364398896458889\n",
            "At step: 4207 training error: 0.43979978614494125\n",
            "At step: 4208 training error: 0.43421113375097714\n",
            "At step: 4209 training error: 0.4287572142907886\n",
            "At step: 4210 training error: 0.4313292257251326\n",
            "At step: 4211 training error: 0.4356165452818126\n",
            "At step: 4212 training error: 0.4382602037557723\n",
            "At step: 4213 training error: 0.4281460987902141\n",
            "At step: 4214 training error: 0.4414274369463557\n",
            "At step: 4215 training error: 0.4379654952199663\n",
            "At step: 4216 training error: 0.44087820395153465\n",
            "At step: 4217 training error: 0.4481356483798299\n",
            "At step: 4218 training error: 0.44398990278964084\n",
            "At step: 4219 training error: 0.44583219048105144\n",
            "At step: 4220 training error: 0.4390960544201585\n",
            "At step: 4221 training error: 0.4400928335436264\n",
            "At step: 4222 training error: 0.4312294213241916\n",
            "At step: 4223 training error: 0.43722964113494694\n",
            "At step: 4224 training error: 0.43752559885404885\n",
            "At step: 4225 training error: 0.43874002243199245\n",
            "At step: 4226 training error: 0.43406375865452984\n",
            "At step: 4227 training error: 0.4312089819221777\n",
            "At step: 4228 training error: 0.436131697378063\n",
            "At step: 4229 training error: 0.44189873849355626\n",
            "At step: 4230 training error: 0.44532370621064454\n",
            "At step: 4231 training error: 0.4423567916893976\n",
            "At step: 4232 training error: 0.4420855329182724\n",
            "At step: 4233 training error: 0.4440414404263278\n",
            "At step: 4234 training error: 0.45207976122031635\n",
            "At step: 4235 training error: 0.45571101828097715\n",
            "At step: 4236 training error: 0.456251916632298\n",
            "At step: 4237 training error: 0.45336708893283695\n",
            "At step: 4238 training error: 0.4426075179581746\n",
            "At step: 4239 training error: 0.4514490265814\n",
            "At step: 4240 training error: 0.4431365323744559\n",
            "At step: 4241 training error: 0.4549091016009022\n",
            "At step: 4242 training error: 0.45340612818649934\n",
            "At step: 4243 training error: 0.4540849666186436\n",
            "At step: 4244 training error: 0.4606875565504242\n",
            "At step: 4245 training error: 0.4505169401945638\n",
            "At step: 4246 training error: 0.43422024127138265\n",
            "At step: 4247 training error: 0.4340257425915116\n",
            "At step: 4248 training error: 0.4375419728580444\n",
            "At step: 4249 training error: 0.43482773162756694\n",
            "At step: 4250 training error: 0.43320546158500256\n",
            "At step: 4251 training error: 0.4317885642863143\n",
            "At step: 4252 training error: 0.42948617391951316\n",
            "At step: 4253 training error: 0.43990607022771855\n",
            "At step: 4254 training error: 0.4372318289309578\n",
            "At step: 4255 training error: 0.43337652026277207\n",
            "At step: 4256 training error: 0.4278838209830477\n",
            "At step: 4257 training error: 0.42429961127383753\n",
            "At step: 4258 training error: 0.42976114383802627\n",
            "At step: 4259 training error: 0.423166655523292\n",
            "At step: 4260 training error: 0.41938382959169723\n",
            "At step: 4261 training error: 0.4187252337252878\n",
            "At step: 4262 training error: 0.42580732318502384\n",
            "At step: 4263 training error: 0.42279183370541934\n",
            "At step: 4264 training error: 0.42150182122872987\n",
            "At step: 4265 training error: 0.419991905054502\n",
            "At step: 4266 training error: 0.41696378552568647\n",
            "At step: 4267 training error: 0.4287912542461679\n",
            "At step: 4268 training error: 0.43610596317119066\n",
            "At step: 4269 training error: 0.4298502951826068\n",
            "At step: 4270 training error: 0.4286167053010299\n",
            "At step: 4271 training error: 0.42059463185140034\n",
            "At step: 4272 training error: 0.41370728137043017\n",
            "At step: 4273 training error: 0.413063432573153\n",
            "At step: 4274 training error: 0.4183981168593501\n",
            "At step: 4275 training error: 0.4294392105510262\n",
            "At step: 4276 training error: 0.4286286306567359\n",
            "At step: 4277 training error: 0.4211772650704943\n",
            "At step: 4278 training error: 0.42295522738622016\n",
            "At step: 4279 training error: 0.4133605777025637\n",
            "At step: 4280 training error: 0.4124320101642155\n",
            "At step: 4281 training error: 0.41555272120281084\n",
            "At step: 4282 training error: 0.40792233487650553\n",
            "At step: 4283 training error: 0.4181594855552358\n",
            "At step: 4284 training error: 0.41876120411930545\n",
            "At step: 4285 training error: 0.4237309069266102\n",
            "At step: 4286 training error: 0.4252859788158946\n",
            "At step: 4287 training error: 0.42575456287890096\n",
            "At step: 4288 training error: 0.42514169225754994\n",
            "At step: 4289 training error: 0.4337746165422539\n",
            "At step: 4290 training error: 0.4344278323114142\n",
            "At step: 4291 training error: 0.4372923621618905\n",
            "At step: 4292 training error: 0.43621722148172337\n",
            "At step: 4293 training error: 0.42678826792494484\n",
            "At step: 4294 training error: 0.4205466895965491\n",
            "At step: 4295 training error: 0.42341803714621323\n",
            "At step: 4296 training error: 0.4251810425950119\n",
            "At step: 4297 training error: 0.42974117910685616\n",
            "At step: 4298 training error: 0.43039679306392586\n",
            "At step: 4299 training error: 0.43059649634745434\n",
            "At step: 4300 training error: 0.44006594332585824\n",
            "At step: 4301 training error: 0.437062200112805\n",
            "At step: 4302 training error: 0.4297965511109582\n",
            "At step: 4303 training error: 0.4285199684251007\n",
            "At step: 4304 training error: 0.41956228199602186\n",
            "At step: 4305 training error: 0.42122429442573733\n",
            "At step: 4306 training error: 0.4203926384659107\n",
            "At step: 4307 training error: 0.42141280646991996\n",
            "At step: 4308 training error: 0.4241288273002721\n",
            "At step: 4309 training error: 0.4320149290916654\n",
            "At step: 4310 training error: 0.4379261059946865\n",
            "At step: 4311 training error: 0.4535787231629244\n",
            "At step: 4312 training error: 0.4520632121853412\n",
            "At step: 4313 training error: 0.44650738434658016\n",
            "At step: 4314 training error: 0.43838973436066375\n",
            "At step: 4315 training error: 0.4275253375604192\n",
            "At step: 4316 training error: 0.41806879171946065\n",
            "At step: 4317 training error: 0.42689128730487635\n",
            "At step: 4318 training error: 0.42739686542776645\n",
            "At step: 4319 training error: 0.4301403401436537\n",
            "At step: 4320 training error: 0.4267800998249286\n",
            "At step: 4321 training error: 0.43172915153500996\n",
            "At step: 4322 training error: 0.43277596044800903\n",
            "At step: 4323 training error: 0.4344650992561465\n",
            "At step: 4324 training error: 0.4321002185769987\n",
            "At step: 4325 training error: 0.4464265782270288\n",
            "At step: 4326 training error: 0.451167624428054\n",
            "At step: 4327 training error: 0.45598752078712906\n",
            "At step: 4328 training error: 0.45074127815048287\n",
            "At step: 4329 training error: 0.4542199730319155\n",
            "At step: 4330 training error: 0.45975183357897864\n",
            "At step: 4331 training error: 0.45700236689455476\n",
            "At step: 4332 training error: 0.4505068587170824\n",
            "At step: 4333 training error: 0.4467480368826465\n",
            "At step: 4334 training error: 0.449389793775624\n",
            "At step: 4335 training error: 0.4441482838575927\n",
            "At step: 4336 training error: 0.45163820761627804\n",
            "At step: 4337 training error: 0.4515496154386933\n",
            "At step: 4338 training error: 0.45880802989685016\n",
            "At step: 4339 training error: 0.45373171569370946\n",
            "At step: 4340 training error: 0.4463247333117063\n",
            "At step: 4341 training error: 0.44801341475243417\n",
            "At step: 4342 training error: 0.44448171634598665\n",
            "At step: 4343 training error: 0.4480399805652341\n",
            "At step: 4344 training error: 0.4499544899437261\n",
            "At step: 4345 training error: 0.45077014581383634\n",
            "At step: 4346 training error: 0.4481294083660759\n",
            "At step: 4347 training error: 0.45436224176940465\n",
            "At step: 4348 training error: 0.4530441942233821\n",
            "At step: 4349 training error: 0.46437429181598844\n",
            "At step: 4350 training error: 0.4647221382691944\n",
            "At step: 4351 training error: 0.47062219043912906\n",
            "At step: 4352 training error: 0.47452454061008004\n",
            "At step: 4353 training error: 0.47342887862807376\n",
            "At step: 4354 training error: 0.4732057947841232\n",
            "At step: 4355 training error: 0.46641250267956974\n",
            "At step: 4356 training error: 0.4617677885497048\n",
            "At step: 4357 training error: 0.4640850895767103\n",
            "At step: 4358 training error: 0.45927096508216314\n",
            "At step: 4359 training error: 0.45862465006337366\n",
            "At step: 4360 training error: 0.46590756285361684\n",
            "At step: 4361 training error: 0.4550434689356435\n",
            "At step: 4362 training error: 0.45345555392855963\n",
            "At step: 4363 training error: 0.46453875819046175\n",
            "At step: 4364 training error: 0.4576722481551501\n",
            "At step: 4365 training error: 0.4549374281748765\n",
            "At step: 4366 training error: 0.46617587996293475\n",
            "At step: 4367 training error: 0.46388447129475435\n",
            "At step: 4368 training error: 0.45813571212747284\n",
            "At step: 4369 training error: 0.46290182130667357\n",
            "At step: 4370 training error: 0.45643437792785596\n",
            "At step: 4371 training error: 0.4513976032742024\n",
            "At step: 4372 training error: 0.4569298405958114\n",
            "At step: 4373 training error: 0.4584797619608182\n",
            "At step: 4374 training error: 0.46239727820762466\n",
            "At step: 4375 training error: 0.4639054493781532\n",
            "At step: 4376 training error: 0.4639099991202134\n",
            "At step: 4377 training error: 0.46249171605878947\n",
            "At step: 4378 training error: 0.4569977586963053\n",
            "At step: 4379 training error: 0.4496775321873652\n",
            "At step: 4380 training error: 0.44441430665393095\n",
            "At step: 4381 training error: 0.4485235541311991\n",
            "At step: 4382 training error: 0.45821042985372035\n",
            "At step: 4383 training error: 0.45733475547005725\n",
            "At step: 4384 training error: 0.4602440671122835\n",
            "At step: 4385 training error: 0.4596497320246322\n",
            "At step: 4386 training error: 0.45174790511084495\n",
            "At step: 4387 training error: 0.45195312066355364\n",
            "At step: 4388 training error: 0.4535068719479148\n",
            "At step: 4389 training error: 0.4436899305195738\n",
            "At step: 4390 training error: 0.4406688388434187\n",
            "At step: 4391 training error: 0.4361944366739782\n",
            "At step: 4392 training error: 0.43446998070829396\n",
            "At step: 4393 training error: 0.43756933587885144\n",
            "At step: 4394 training error: 0.4407656194893286\n",
            "At step: 4395 training error: 0.43198714202989247\n",
            "At step: 4396 training error: 0.43049327921822045\n",
            "At step: 4397 training error: 0.4353132805601851\n",
            "At step: 4398 training error: 0.4393672368309446\n",
            "At step: 4399 training error: 0.44753509268103797\n",
            "At step: 4400 training error: 0.44746775250094917\n",
            "At step: 4401 training error: 0.45506214455320326\n",
            "At step: 4402 training error: 0.44561977334185854\n",
            "At step: 4403 training error: 0.4424701192043947\n",
            "At step: 4404 training error: 0.44293528154437406\n",
            "At step: 4405 training error: 0.44320135890657536\n",
            "At step: 4406 training error: 0.4334842163377554\n",
            "At step: 4407 training error: 0.4365252236999517\n",
            "At step: 4408 training error: 0.43271253660882264\n",
            "At step: 4409 training error: 0.44868332803196015\n",
            "At step: 4410 training error: 0.4471847424623131\n",
            "At step: 4411 training error: 0.43992671176335413\n",
            "At step: 4412 training error: 0.43805919451476594\n",
            "At step: 4413 training error: 0.42929402106107784\n",
            "At step: 4414 training error: 0.43042190564814226\n",
            "At step: 4415 training error: 0.4326163252942774\n",
            "At step: 4416 training error: 0.4272413015903089\n",
            "At step: 4417 training error: 0.4312368500560193\n",
            "At step: 4418 training error: 0.42087591427386134\n",
            "At step: 4419 training error: 0.43454116475423055\n",
            "At step: 4420 training error: 0.43702964342097284\n",
            "At step: 4421 training error: 0.42378423302613677\n",
            "At step: 4422 training error: 0.41784460579884364\n",
            "At step: 4423 training error: 0.4125905395139648\n",
            "At step: 4424 training error: 0.40674551148009236\n",
            "At step: 4425 training error: 0.4099210373446982\n",
            "At step: 4426 training error: 0.4072049898359532\n",
            "At step: 4427 training error: 0.42277252284984784\n",
            "At step: 4428 training error: 0.4261753203376676\n",
            "At step: 4429 training error: 0.4304916094362962\n",
            "At step: 4430 training error: 0.4285941547928336\n",
            "At step: 4431 training error: 0.42569932766743607\n",
            "At step: 4432 training error: 0.41786718439564297\n",
            "At step: 4433 training error: 0.4195899778394873\n",
            "At step: 4434 training error: 0.4169232542614162\n",
            "At step: 4435 training error: 0.4143172369957056\n",
            "At step: 4436 training error: 0.41420255573095016\n",
            "At step: 4437 training error: 0.412490078766677\n",
            "At step: 4438 training error: 0.4087990282686247\n",
            "At step: 4439 training error: 0.4096219439411384\n",
            "At step: 4440 training error: 0.4152460686310722\n",
            "At step: 4441 training error: 0.4247006779539194\n",
            "At step: 4442 training error: 0.42877697518105323\n",
            "At step: 4443 training error: 0.4272905415867767\n",
            "At step: 4444 training error: 0.43276916272737714\n",
            "At step: 4445 training error: 0.424514551181451\n",
            "At step: 4446 training error: 0.4367114961391453\n",
            "At step: 4447 training error: 0.4383616562157365\n",
            "At step: 4448 training error: 0.44184432632784887\n",
            "At step: 4449 training error: 0.4311623378995386\n",
            "At step: 4450 training error: 0.4327192559192926\n",
            "At step: 4451 training error: 0.437557074843262\n",
            "At step: 4452 training error: 0.43242862562678186\n",
            "At step: 4453 training error: 0.4359410488374952\n",
            "At step: 4454 training error: 0.4276746576149711\n",
            "At step: 4455 training error: 0.41960634144439724\n",
            "At step: 4456 training error: 0.4230338631091744\n",
            "At step: 4457 training error: 0.4165892298510091\n",
            "At step: 4458 training error: 0.41199538507557515\n",
            "At step: 4459 training error: 0.4126605294341178\n",
            "At step: 4460 training error: 0.4125052253439524\n",
            "At step: 4461 training error: 0.4266557459148879\n",
            "At step: 4462 training error: 0.41406878012798815\n",
            "At step: 4463 training error: 0.4108345896513359\n",
            "At step: 4464 training error: 0.40052925274502116\n",
            "At step: 4465 training error: 0.39775670700515636\n",
            "At step: 4466 training error: 0.40184013158230936\n",
            "At step: 4467 training error: 0.39711436903296987\n",
            "At step: 4468 training error: 0.4074781277021618\n",
            "At step: 4469 training error: 0.4160075069726862\n",
            "At step: 4470 training error: 0.41475918733195616\n",
            "At step: 4471 training error: 0.4184513789829104\n",
            "At step: 4472 training error: 0.4167314921399254\n",
            "At step: 4473 training error: 0.43149600505169755\n",
            "At step: 4474 training error: 0.4379744198803219\n",
            "At step: 4475 training error: 0.43573246208188615\n",
            "At step: 4476 training error: 0.43479582398540767\n",
            "At step: 4477 training error: 0.4461685767584934\n",
            "At step: 4478 training error: 0.4488946544326393\n",
            "At step: 4479 training error: 0.4425192569583676\n",
            "At step: 4480 training error: 0.43364396394313126\n",
            "At step: 4481 training error: 0.44695364832793816\n",
            "At step: 4482 training error: 0.4351110491515562\n",
            "At step: 4483 training error: 0.4398838322340065\n",
            "At step: 4484 training error: 0.431793787113878\n",
            "At step: 4485 training error: 0.43162623511197007\n",
            "At step: 4486 training error: 0.43091265072253643\n",
            "At step: 4487 training error: 0.43028696047404796\n",
            "At step: 4488 training error: 0.4159136467939906\n",
            "At step: 4489 training error: 0.4270725504318824\n",
            "At step: 4490 training error: 0.4207390893825984\n",
            "At step: 4491 training error: 0.4156267173391703\n",
            "At step: 4492 training error: 0.41661661121806126\n",
            "At step: 4493 training error: 0.42012559153308104\n",
            "At step: 4494 training error: 0.43255984751929366\n",
            "At step: 4495 training error: 0.4276214790761769\n",
            "At step: 4496 training error: 0.4314962281240468\n",
            "At step: 4497 training error: 0.43371097278406234\n",
            "At step: 4498 training error: 0.4317582884749167\n",
            "At step: 4499 training error: 0.43329843472107576\n",
            "At step: 4500 training error: 0.43059906278553606\n",
            "At step: 4501 training error: 0.4249282356303612\n",
            "At step: 4502 training error: 0.42808541393841265\n",
            "At step: 4503 training error: 0.4294218797069352\n",
            "At step: 4504 training error: 0.4285008248788807\n",
            "At step: 4505 training error: 0.4293484353316679\n",
            "At step: 4506 training error: 0.42477373248036654\n",
            "At step: 4507 training error: 0.4311004871145484\n",
            "At step: 4508 training error: 0.4333011532785326\n",
            "At step: 4509 training error: 0.43200869190925084\n",
            "At step: 4510 training error: 0.43657582609529055\n",
            "At step: 4511 training error: 0.4380345550477454\n",
            "At step: 4512 training error: 0.4405643527387022\n",
            "At step: 4513 training error: 0.43795504150679887\n",
            "At step: 4514 training error: 0.43228816127280584\n",
            "At step: 4515 training error: 0.4356136951516809\n",
            "At step: 4516 training error: 0.4459518973074514\n",
            "At step: 4517 training error: 0.44797340529834906\n",
            "At step: 4518 training error: 0.4519425783321818\n",
            "At step: 4519 training error: 0.44543997278083686\n",
            "At step: 4520 training error: 0.43987874388732\n",
            "At step: 4521 training error: 0.43806304350964026\n",
            "At step: 4522 training error: 0.4323452491716634\n",
            "At step: 4523 training error: 0.42741701981777974\n",
            "At step: 4524 training error: 0.4186234803796889\n",
            "At step: 4525 training error: 0.4260033366394062\n",
            "At step: 4526 training error: 0.434477680627688\n",
            "At step: 4527 training error: 0.42844830160601677\n",
            "At step: 4528 training error: 0.43042970506705047\n",
            "At step: 4529 training error: 0.42880182961242236\n",
            "At step: 4530 training error: 0.4327944205280611\n",
            "At step: 4531 training error: 0.44078008040875144\n",
            "At step: 4532 training error: 0.4431238380638509\n",
            "At step: 4533 training error: 0.445152424017669\n",
            "At step: 4534 training error: 0.4382313835140288\n",
            "At step: 4535 training error: 0.44183694039303417\n",
            "At step: 4536 training error: 0.4444665203728622\n",
            "At step: 4537 training error: 0.4458660945441405\n",
            "At step: 4538 training error: 0.43925383307647464\n",
            "At step: 4539 training error: 0.45670544334499263\n",
            "At step: 4540 training error: 0.46022352270400324\n",
            "At step: 4541 training error: 0.4597559200482256\n",
            "At step: 4542 training error: 0.44812275137313085\n",
            "At step: 4543 training error: 0.4373627299551145\n",
            "At step: 4544 training error: 0.4363953568552528\n",
            "At step: 4545 training error: 0.42225713941307674\n",
            "At step: 4546 training error: 0.4210898259059157\n",
            "At step: 4547 training error: 0.4197760346647605\n",
            "At step: 4548 training error: 0.41192836488604284\n",
            "At step: 4549 training error: 0.41885618466426455\n",
            "At step: 4550 training error: 0.4233202947890478\n",
            "At step: 4551 training error: 0.4195548665695568\n",
            "At step: 4552 training error: 0.4135825837978805\n",
            "At step: 4553 training error: 0.4089330364113003\n",
            "At step: 4554 training error: 0.406299380064556\n",
            "At step: 4555 training error: 0.41517135453850856\n",
            "At step: 4556 training error: 0.4222623416205764\n",
            "At step: 4557 training error: 0.4188452009421621\n",
            "At step: 4558 training error: 0.41952472493090087\n",
            "At step: 4559 training error: 0.41286404193508547\n",
            "At step: 4560 training error: 0.41454732244244497\n",
            "At step: 4561 training error: 0.41265572764440533\n",
            "At step: 4562 training error: 0.41311403493641535\n",
            "At step: 4563 training error: 0.4241541020066113\n",
            "At step: 4564 training error: 0.42205498004386843\n",
            "At step: 4565 training error: 0.40779980389563103\n",
            "At step: 4566 training error: 0.42368901538824477\n",
            "At step: 4567 training error: 0.43011886328166\n",
            "At step: 4568 training error: 0.4404589834684578\n",
            "At step: 4569 training error: 0.43764252041894564\n",
            "At step: 4570 training error: 0.4318547097997745\n",
            "At step: 4571 training error: 0.44059023430408056\n",
            "At step: 4572 training error: 0.4311166731020742\n",
            "At step: 4573 training error: 0.43077743492468984\n",
            "At step: 4574 training error: 0.43384199656189837\n",
            "At step: 4575 training error: 0.43368017653828633\n",
            "At step: 4576 training error: 0.4336562559879378\n",
            "At step: 4577 training error: 0.43489591381534526\n",
            "At step: 4578 training error: 0.4405995585780491\n",
            "At step: 4579 training error: 0.4268157980074224\n",
            "At step: 4580 training error: 0.42431352024766317\n",
            "At step: 4581 training error: 0.4225278141126027\n",
            "At step: 4582 training error: 0.43100263931951543\n",
            "At step: 4583 training error: 0.42726645822517184\n",
            "At step: 4584 training error: 0.4279561873382851\n",
            "At step: 4585 training error: 0.42886501996937954\n",
            "At step: 4586 training error: 0.42596135191096063\n",
            "At step: 4587 training error: 0.42008403422664486\n",
            "At step: 4588 training error: 0.41477479869521433\n",
            "At step: 4589 training error: 0.41544905519410313\n",
            "At step: 4590 training error: 0.41401948064257243\n",
            "At step: 4591 training error: 0.4087759141477898\n",
            "At step: 4592 training error: 0.4104635351182593\n",
            "At step: 4593 training error: 0.4221433637970183\n",
            "At step: 4594 training error: 0.41994052323549036\n",
            "At step: 4595 training error: 0.4241653065445371\n",
            "At step: 4596 training error: 0.4210141088959176\n",
            "At step: 4597 training error: 0.42336642762406906\n",
            "At step: 4598 training error: 0.4189927449841591\n",
            "At step: 4599 training error: 0.41525501748454546\n",
            "At step: 4600 training error: 0.41830448336211884\n",
            "At step: 4601 training error: 0.42001424381447905\n",
            "At step: 4602 training error: 0.4330101324216282\n",
            "At step: 4603 training error: 0.4363071677576615\n",
            "At step: 4604 training error: 0.43947912995906857\n",
            "At step: 4605 training error: 0.4410084530926367\n",
            "At step: 4606 training error: 0.44603733123881406\n",
            "At step: 4607 training error: 0.4507299702716089\n",
            "At step: 4608 training error: 0.45488246781157915\n",
            "At step: 4609 training error: 0.4503670234240825\n",
            "At step: 4610 training error: 0.44785041799784975\n",
            "At step: 4611 training error: 0.43789989667065715\n",
            "At step: 4612 training error: 0.43411885432934216\n",
            "At step: 4613 training error: 0.42676829286554574\n",
            "At step: 4614 training error: 0.4209541376034145\n",
            "At step: 4615 training error: 0.42073137161336843\n",
            "At step: 4616 training error: 0.42388904128361826\n",
            "At step: 4617 training error: 0.41840922486452264\n",
            "At step: 4618 training error: 0.4167549633282272\n",
            "At step: 4619 training error: 0.41724246819720884\n",
            "At step: 4620 training error: 0.41459459377715435\n",
            "At step: 4621 training error: 0.41625786154078875\n",
            "At step: 4622 training error: 0.41785301560810256\n",
            "At step: 4623 training error: 0.40771164881365973\n",
            "At step: 4624 training error: 0.40471678697937924\n",
            "At step: 4625 training error: 0.4030916963270215\n",
            "At step: 4626 training error: 0.41411791413470234\n",
            "At step: 4627 training error: 0.4167194571397342\n",
            "At step: 4628 training error: 0.41690566605641144\n",
            "At step: 4629 training error: 0.4263046816087771\n",
            "At step: 4630 training error: 0.4214574252053095\n",
            "At step: 4631 training error: 0.4144670594985642\n",
            "At step: 4632 training error: 0.4023569246557165\n",
            "At step: 4633 training error: 0.40541523540423574\n",
            "At step: 4634 training error: 0.4038634804768071\n",
            "At step: 4635 training error: 0.40490730103977557\n",
            "At step: 4636 training error: 0.41745705358434637\n",
            "At step: 4637 training error: 0.4181822132306714\n",
            "At step: 4638 training error: 0.42482778509194424\n",
            "At step: 4639 training error: 0.4177772224724409\n",
            "At step: 4640 training error: 0.4259386642642901\n",
            "At step: 4641 training error: 0.4306950742921539\n",
            "At step: 4642 training error: 0.436712336180625\n",
            "At step: 4643 training error: 0.4332587546348668\n",
            "At step: 4644 training error: 0.43242259712827213\n",
            "At step: 4645 training error: 0.4334821116039397\n",
            "At step: 4646 training error: 0.4310494976769099\n",
            "At step: 4647 training error: 0.4263556052099264\n",
            "At step: 4648 training error: 0.43289342700236966\n",
            "At step: 4649 training error: 0.4346987863696836\n",
            "At step: 4650 training error: 0.42635584147487293\n",
            "At step: 4651 training error: 0.42476251258028896\n",
            "At step: 4652 training error: 0.4269996470853946\n",
            "At step: 4653 training error: 0.42783970220821854\n",
            "At step: 4654 training error: 0.42642836939284007\n",
            "At step: 4655 training error: 0.4381130751865575\n",
            "At step: 4656 training error: 0.441246325172561\n",
            "At step: 4657 training error: 0.43931266232297445\n",
            "At step: 4658 training error: 0.4410638097302798\n",
            "At step: 4659 training error: 0.45235058817039575\n",
            "At step: 4660 training error: 0.4548227434866551\n",
            "At step: 4661 training error: 0.45304902900701016\n",
            "At step: 4662 training error: 0.4440922035136759\n",
            "At step: 4663 training error: 0.4444803124099871\n",
            "At step: 4664 training error: 0.4418787521939469\n",
            "At step: 4665 training error: 0.46202150107984696\n",
            "At step: 4666 training error: 0.4570006733434063\n",
            "At step: 4667 training error: 0.4612205318818665\n",
            "At step: 4668 training error: 0.4615557823621881\n",
            "At step: 4669 training error: 0.4500108404543826\n",
            "At step: 4670 training error: 0.4437783862878501\n",
            "At step: 4671 training error: 0.4382014584555102\n",
            "At step: 4672 training error: 0.4429582263894622\n",
            "At step: 4673 training error: 0.4386946497024774\n",
            "At step: 4674 training error: 0.4346754347621801\n",
            "At step: 4675 training error: 0.43816503628757186\n",
            "At step: 4676 training error: 0.4281921014734911\n",
            "At step: 4677 training error: 0.43293492227261754\n",
            "At step: 4678 training error: 0.42969297732065637\n",
            "At step: 4679 training error: 0.434997352566837\n",
            "At step: 4680 training error: 0.44149404761117056\n",
            "At step: 4681 training error: 0.4479118308756086\n",
            "At step: 4682 training error: 0.4438861628844838\n",
            "At step: 4683 training error: 0.4386279777380202\n",
            "At step: 4684 training error: 0.444075099074925\n",
            "At step: 4685 training error: 0.43802452490061033\n",
            "At step: 4686 training error: 0.4332660366870068\n",
            "At step: 4687 training error: 0.42785296547230706\n",
            "At step: 4688 training error: 0.4232349927995249\n",
            "At step: 4689 training error: 0.4248407576289668\n",
            "At step: 4690 training error: 0.4274690951723189\n",
            "At step: 4691 training error: 0.43848558966911444\n",
            "At step: 4692 training error: 0.4358971907101571\n",
            "At step: 4693 training error: 0.4281168483312989\n",
            "At step: 4694 training error: 0.4340772254286926\n",
            "At step: 4695 training error: 0.44134919313275794\n",
            "At step: 4696 training error: 0.4426077244868597\n",
            "At step: 4697 training error: 0.44045474464063206\n",
            "At step: 4698 training error: 0.4323158601214756\n",
            "At step: 4699 training error: 0.4264431219546215\n",
            "At step: 4700 training error: 0.4194071412153365\n",
            "At step: 4701 training error: 0.4100882279121616\n",
            "At step: 4702 training error: 0.4090395554788653\n",
            "At step: 4703 training error: 0.4151115348926383\n",
            "At step: 4704 training error: 0.4218446663732427\n",
            "At step: 4705 training error: 0.41145366772140624\n",
            "At step: 4706 training error: 0.41935584087480937\n",
            "At step: 4707 training error: 0.419378362949805\n",
            "At step: 4708 training error: 0.43176454316509183\n",
            "At step: 4709 training error: 0.42148250652967495\n",
            "At step: 4710 training error: 0.4327051663062191\n",
            "At step: 4711 training error: 0.43696909873289796\n",
            "At step: 4712 training error: 0.4340003684527226\n",
            "At step: 4713 training error: 0.441942532438553\n",
            "At step: 4714 training error: 0.43796847882491446\n",
            "At step: 4715 training error: 0.43511480818806875\n",
            "At step: 4716 training error: 0.43282628143514523\n",
            "At step: 4717 training error: 0.4374495247526393\n",
            "At step: 4718 training error: 0.4344789393764429\n",
            "At step: 4719 training error: 0.4254335355013692\n",
            "At step: 4720 training error: 0.43730612931633983\n",
            "At step: 4721 training error: 0.4283814021016693\n",
            "At step: 4722 training error: 0.43833589718736843\n",
            "At step: 4723 training error: 0.43354543704005244\n",
            "At step: 4724 training error: 0.44359314902787395\n",
            "At step: 4725 training error: 0.4370120057606659\n",
            "At step: 4726 training error: 0.4198032061537638\n",
            "At step: 4727 training error: 0.4204212306860327\n",
            "At step: 4728 training error: 0.4096933323721491\n",
            "At step: 4729 training error: 0.4087368525395013\n",
            "At step: 4730 training error: 0.41521610376966567\n",
            "At step: 4731 training error: 0.41841328459930005\n",
            "At step: 4732 training error: 0.41313903824485343\n",
            "At step: 4733 training error: 0.4216666858541698\n",
            "At step: 4734 training error: 0.421493952183948\n",
            "At step: 4735 training error: 0.4210583282773198\n",
            "At step: 4736 training error: 0.4166972473971771\n",
            "At step: 4737 training error: 0.4178777530764052\n",
            "At step: 4738 training error: 0.42331794460562044\n",
            "At step: 4739 training error: 0.4221138739266151\n",
            "At step: 4740 training error: 0.42676997350342916\n",
            "At step: 4741 training error: 0.43507889204707384\n",
            "At step: 4742 training error: 0.4421873755610791\n",
            "At step: 4743 training error: 0.4417526227790127\n",
            "At step: 4744 training error: 0.4266545367557427\n",
            "At step: 4745 training error: 0.43612911111247576\n",
            "At step: 4746 training error: 0.44327618593312046\n",
            "At step: 4747 training error: 0.454183781379296\n",
            "At step: 4748 training error: 0.45633229646841594\n",
            "At step: 4749 training error: 0.453940164652503\n",
            "At step: 4750 training error: 0.4376113659652009\n",
            "At step: 4751 training error: 0.4454594633994956\n",
            "At step: 4752 training error: 0.4360358654483475\n",
            "At step: 4753 training error: 0.4429163158608681\n",
            "At step: 4754 training error: 0.44573578652637713\n",
            "At step: 4755 training error: 0.45047709034646727\n",
            "At step: 4756 training error: 0.4509008041401866\n",
            "At step: 4757 training error: 0.4385624456501602\n",
            "At step: 4758 training error: 0.44865386115233913\n",
            "At step: 4759 training error: 0.44551248548898364\n",
            "At step: 4760 training error: 0.44371010162124874\n",
            "At step: 4761 training error: 0.4352503782638432\n",
            "At step: 4762 training error: 0.43587327293915007\n",
            "At step: 4763 training error: 0.43894318863664294\n",
            "At step: 4764 training error: 0.45204404934364123\n",
            "At step: 4765 training error: 0.44623041545176034\n",
            "At step: 4766 training error: 0.438883348411356\n",
            "At step: 4767 training error: 0.4324383657435521\n",
            "At step: 4768 training error: 0.4262825590337513\n",
            "At step: 4769 training error: 0.4410587002908277\n",
            "At step: 4770 training error: 0.43904095250504643\n",
            "At step: 4771 training error: 0.4408088076001069\n",
            "At step: 4772 training error: 0.4491579530633481\n",
            "At step: 4773 training error: 0.45612525866693165\n",
            "At step: 4774 training error: 0.4463539219465994\n",
            "At step: 4775 training error: 0.4483591773332368\n",
            "At step: 4776 training error: 0.43648108005419994\n",
            "At step: 4777 training error: 0.4379663361247902\n",
            "At step: 4778 training error: 0.4430030296557461\n",
            "At step: 4779 training error: 0.44146941807262213\n",
            "At step: 4780 training error: 0.4382166829804725\n",
            "At step: 4781 training error: 0.4410483059580313\n",
            "At step: 4782 training error: 0.4396597511641995\n",
            "At step: 4783 training error: 0.43121346162426094\n",
            "At step: 4784 training error: 0.439061603667662\n",
            "At step: 4785 training error: 0.4240270677430987\n",
            "At step: 4786 training error: 0.42719067825713064\n",
            "At step: 4787 training error: 0.4237110895275963\n",
            "At step: 4788 training error: 0.41514080311516477\n",
            "At step: 4789 training error: 0.41474153510715933\n",
            "At step: 4790 training error: 0.4169286816998427\n",
            "At step: 4791 training error: 0.4083450102394066\n",
            "At step: 4792 training error: 0.4101266052705357\n",
            "At step: 4793 training error: 0.4209772683640671\n",
            "At step: 4794 training error: 0.42193060211297406\n",
            "At step: 4795 training error: 0.4239505441389518\n",
            "At step: 4796 training error: 0.4196007077844943\n",
            "At step: 4797 training error: 0.41618720088042505\n",
            "At step: 4798 training error: 0.4144730850958295\n",
            "At step: 4799 training error: 0.4117526902109654\n",
            "At step: 4800 training error: 0.4154198939623046\n",
            "At step: 4801 training error: 0.40893130421815194\n",
            "At step: 4802 training error: 0.4086270753220735\n",
            "At step: 4803 training error: 0.40222951400572265\n",
            "At step: 4804 training error: 0.3984187036675827\n",
            "At step: 4805 training error: 0.41429784975794354\n",
            "At step: 4806 training error: 0.4140510918369809\n",
            "At step: 4807 training error: 0.41034040676838135\n",
            "At step: 4808 training error: 0.4151448352309465\n",
            "At step: 4809 training error: 0.41367189400928095\n",
            "At step: 4810 training error: 0.42087966113294867\n",
            "At step: 4811 training error: 0.42595418669529445\n",
            "At step: 4812 training error: 0.430595599720813\n",
            "At step: 4813 training error: 0.4322722717731063\n",
            "At step: 4814 training error: 0.430223037989241\n",
            "At step: 4815 training error: 0.4409440052763316\n",
            "At step: 4816 training error: 0.43312393991708625\n",
            "At step: 4817 training error: 0.4248964131073254\n",
            "At step: 4818 training error: 0.4283381306775674\n",
            "At step: 4819 training error: 0.42223859788857626\n",
            "At step: 4820 training error: 0.4300277634637492\n",
            "At step: 4821 training error: 0.4377771332723599\n",
            "At step: 4822 training error: 0.4542413520830506\n",
            "At step: 4823 training error: 0.46549126585532247\n",
            "At step: 4824 training error: 0.45587447342215925\n",
            "At step: 4825 training error: 0.4552196334073525\n",
            "At step: 4826 training error: 0.4516480135702386\n",
            "At step: 4827 training error: 0.45474035649103783\n",
            "At step: 4828 training error: 0.45963136450062647\n",
            "At step: 4829 training error: 0.4578994898619084\n",
            "At step: 4830 training error: 0.4588693182878516\n",
            "At step: 4831 training error: 0.46329658050421957\n",
            "At step: 4832 training error: 0.46482231696062937\n",
            "At step: 4833 training error: 0.46107506957306665\n",
            "At step: 4834 training error: 0.44974341491645886\n",
            "At step: 4835 training error: 0.44992538300555024\n",
            "At step: 4836 training error: 0.4465511996833858\n",
            "At step: 4837 training error: 0.45374693189726967\n",
            "At step: 4838 training error: 0.46209064165447983\n",
            "At step: 4839 training error: 0.46046626112754785\n",
            "At step: 4840 training error: 0.4595254309696291\n",
            "At step: 4841 training error: 0.4505988100057429\n",
            "At step: 4842 training error: 0.43762105780375676\n",
            "At step: 4843 training error: 0.4361926628821473\n",
            "At step: 4844 training error: 0.43452695470286085\n",
            "At step: 4845 training error: 0.43066045494437366\n",
            "At step: 4846 training error: 0.4282070271997944\n",
            "At step: 4847 training error: 0.42945987076871\n",
            "At step: 4848 training error: 0.4325570473713638\n",
            "At step: 4849 training error: 0.4204958718670916\n",
            "At step: 4850 training error: 0.42256058403995106\n",
            "At step: 4851 training error: 0.4261596499798242\n",
            "At step: 4852 training error: 0.41815728044613115\n",
            "At step: 4853 training error: 0.4120283146985414\n",
            "At step: 4854 training error: 0.4020294866778552\n",
            "At step: 4855 training error: 0.40395692736955313\n",
            "At step: 4856 training error: 0.40915440813606385\n",
            "At step: 4857 training error: 0.40636369905645175\n",
            "At step: 4858 training error: 0.4084906749009513\n",
            "At step: 4859 training error: 0.40107192038575606\n",
            "At step: 4860 training error: 0.40212617033013376\n",
            "At step: 4861 training error: 0.41659513267855997\n",
            "At step: 4862 training error: 0.419683640480352\n",
            "At step: 4863 training error: 0.42636001377699484\n",
            "At step: 4864 training error: 0.42690449240767775\n",
            "At step: 4865 training error: 0.4281816898089513\n",
            "At step: 4866 training error: 0.43031186521212034\n",
            "At step: 4867 training error: 0.4263277517803729\n",
            "At step: 4868 training error: 0.42021924131478844\n",
            "At step: 4869 training error: 0.42880590463593615\n",
            "At step: 4870 training error: 0.41430187640001565\n",
            "At step: 4871 training error: 0.4137311508595054\n",
            "At step: 4872 training error: 0.41350184303459236\n",
            "At step: 4873 training error: 0.4190179434375686\n",
            "At step: 4874 training error: 0.42863907604398255\n",
            "At step: 4875 training error: 0.43665318022543587\n",
            "At step: 4876 training error: 0.4268164777454059\n",
            "At step: 4877 training error: 0.42502914486492815\n",
            "At step: 4878 training error: 0.4189945801602902\n",
            "At step: 4879 training error: 0.4203084553410255\n",
            "At step: 4880 training error: 0.42501043515595577\n",
            "At step: 4881 training error: 0.4181721613810008\n",
            "At step: 4882 training error: 0.4256415406103755\n",
            "At step: 4883 training error: 0.42064644821065345\n",
            "At step: 4884 training error: 0.4179048096867593\n",
            "At step: 4885 training error: 0.41536887284448265\n",
            "At step: 4886 training error: 0.4093898889060437\n",
            "At step: 4887 training error: 0.4039910310707049\n",
            "At step: 4888 training error: 0.4119387887733696\n",
            "At step: 4889 training error: 0.40950973093627374\n",
            "At step: 4890 training error: 0.40563823838734164\n",
            "At step: 4891 training error: 0.4090676734272003\n",
            "At step: 4892 training error: 0.4145042650786138\n",
            "At step: 4893 training error: 0.4231812122813444\n",
            "At step: 4894 training error: 0.41754869661044197\n",
            "At step: 4895 training error: 0.41902867973233326\n",
            "At step: 4896 training error: 0.41955603236436945\n",
            "At step: 4897 training error: 0.4212832184937386\n",
            "At step: 4898 training error: 0.4218178026681278\n",
            "At step: 4899 training error: 0.4108461008863066\n",
            "At step: 4900 training error: 0.4184072292066703\n",
            "At step: 4901 training error: 0.4232747673259245\n",
            "At step: 4902 training error: 0.42839442910865166\n",
            "At step: 4903 training error: 0.43432051433071583\n",
            "At step: 4904 training error: 0.42714683526712277\n",
            "At step: 4905 training error: 0.429293287856782\n",
            "At step: 4906 training error: 0.42210224589733825\n",
            "At step: 4907 training error: 0.41627354543975104\n",
            "At step: 4908 training error: 0.41516879025054565\n",
            "At step: 4909 training error: 0.41782299354279273\n",
            "At step: 4910 training error: 0.41853273055869616\n",
            "At step: 4911 training error: 0.42467037210889885\n",
            "At step: 4912 training error: 0.4283092709514249\n",
            "At step: 4913 training error: 0.42537951144805597\n",
            "At step: 4914 training error: 0.421648020023339\n",
            "At step: 4915 training error: 0.42514005683644485\n",
            "At step: 4916 training error: 0.4196872852357419\n",
            "At step: 4917 training error: 0.41489884097893676\n",
            "At step: 4918 training error: 0.41710209912172613\n",
            "At step: 4919 training error: 0.417656749950422\n",
            "At step: 4920 training error: 0.4110247390466892\n",
            "At step: 4921 training error: 0.41477108483891567\n",
            "At step: 4922 training error: 0.4213567247656879\n",
            "At step: 4923 training error: 0.4198451869425731\n",
            "At step: 4924 training error: 0.43392594378848126\n",
            "At step: 4925 training error: 0.4251859088283336\n",
            "At step: 4926 training error: 0.4323182263083341\n",
            "At step: 4927 training error: 0.43365072418071254\n",
            "At step: 4928 training error: 0.4367688839038567\n",
            "At step: 4929 training error: 0.43534596422194666\n",
            "At step: 4930 training error: 0.43590997877972465\n",
            "At step: 4931 training error: 0.436925934794651\n",
            "At step: 4932 training error: 0.430216778635641\n",
            "At step: 4933 training error: 0.4344763358673506\n",
            "At step: 4934 training error: 0.4304065861263969\n",
            "At step: 4935 training error: 0.4232022594795558\n",
            "At step: 4936 training error: 0.41921056795816897\n",
            "At step: 4937 training error: 0.4128575133963327\n",
            "At step: 4938 training error: 0.418857515779154\n",
            "At step: 4939 training error: 0.41853927381262795\n",
            "At step: 4940 training error: 0.4202215126434688\n",
            "At step: 4941 training error: 0.4319986831544059\n",
            "At step: 4942 training error: 0.4158647012663294\n",
            "At step: 4943 training error: 0.4279677483901959\n",
            "At step: 4944 training error: 0.4192775699744009\n",
            "At step: 4945 training error: 0.42287302597926024\n",
            "At step: 4946 training error: 0.41855612478534077\n",
            "At step: 4947 training error: 0.421994800480527\n",
            "At step: 4948 training error: 0.43033455921014024\n",
            "At step: 4949 training error: 0.43078559505157643\n",
            "At step: 4950 training error: 0.430831962381521\n",
            "At step: 4951 training error: 0.44135454669546437\n",
            "At step: 4952 training error: 0.43696956090933625\n",
            "At step: 4953 training error: 0.42815290359886504\n",
            "At step: 4954 training error: 0.4212941264065786\n",
            "At step: 4955 training error: 0.41521259415380124\n",
            "At step: 4956 training error: 0.41229906130964733\n",
            "At step: 4957 training error: 0.40542137272072737\n",
            "At step: 4958 training error: 0.4174677685036697\n",
            "At step: 4959 training error: 0.4201289180825525\n",
            "At step: 4960 training error: 0.4164387407220953\n",
            "At step: 4961 training error: 0.4091005646460579\n",
            "At step: 4962 training error: 0.41023922018118636\n",
            "At step: 4963 training error: 0.4259403942111813\n",
            "At step: 4964 training error: 0.43433798067504165\n",
            "At step: 4965 training error: 0.42292694518953955\n",
            "At step: 4966 training error: 0.4182488195398663\n",
            "At step: 4967 training error: 0.4121379357255471\n",
            "At step: 4968 training error: 0.42099082003149396\n",
            "At step: 4969 training error: 0.41270630615734133\n",
            "At step: 4970 training error: 0.4257280260568568\n",
            "At step: 4971 training error: 0.42040044959044776\n",
            "At step: 4972 training error: 0.42143918700922234\n",
            "At step: 4973 training error: 0.41268230499404546\n",
            "At step: 4974 training error: 0.4130491598203941\n",
            "At step: 4975 training error: 0.41213083118738036\n",
            "At step: 4976 training error: 0.417936419672399\n",
            "At step: 4977 training error: 0.41198902345101696\n",
            "At step: 4978 training error: 0.4168044332757908\n",
            "At step: 4979 training error: 0.4263167315476136\n",
            "At step: 4980 training error: 0.4271862779517589\n",
            "At step: 4981 training error: 0.4215312206368574\n",
            "At step: 4982 training error: 0.4192069395937996\n",
            "At step: 4983 training error: 0.4266742011759809\n",
            "At step: 4984 training error: 0.4258600988621904\n",
            "At step: 4985 training error: 0.43092839771077385\n",
            "At step: 4986 training error: 0.42854788012153866\n",
            "At step: 4987 training error: 0.42428147812445327\n",
            "At step: 4988 training error: 0.4174881186417436\n",
            "At step: 4989 training error: 0.41554144296681206\n",
            "At step: 4990 training error: 0.41284821778562303\n",
            "At step: 4991 training error: 0.4089140213211219\n",
            "At step: 4992 training error: 0.4071879882170566\n",
            "At step: 4993 training error: 0.4087945991487805\n",
            "At step: 4994 training error: 0.4093456337248752\n",
            "At step: 4995 training error: 0.4119196915112619\n",
            "At step: 4996 training error: 0.4101105980441709\n",
            "At step: 4997 training error: 0.4174157477995556\n",
            "At step: 4998 training error: 0.42012815777232726\n",
            "At step: 4999 training error: 0.41626810114007745\n",
            "At step: 5000 training error: 0.42613503482658777\n",
            "At step: 5001 training error: 0.4330982000170424\n",
            "At step: 5002 training error: 0.4220801538118563\n",
            "At step: 5003 training error: 0.4191480069828652\n",
            "At step: 5004 training error: 0.4143260129089893\n",
            "At step: 5005 training error: 0.4092274293050152\n",
            "At step: 5006 training error: 0.4161400200531915\n",
            "At step: 5007 training error: 0.41940725289245984\n",
            "At step: 5008 training error: 0.41639759519796327\n",
            "At step: 5009 training error: 0.41776177512768425\n",
            "At step: 5010 training error: 0.4132177677639134\n",
            "At step: 5011 training error: 0.40829649600788154\n",
            "At step: 5012 training error: 0.41041056514268726\n",
            "At step: 5013 training error: 0.4140441930993524\n",
            "At step: 5014 training error: 0.40273894305276214\n",
            "At step: 5015 training error: 0.40886015904432704\n",
            "At step: 5016 training error: 0.4179015165942234\n",
            "At step: 5017 training error: 0.42745130022999056\n",
            "At step: 5018 training error: 0.4319185908682722\n",
            "At step: 5019 training error: 0.4294478562660995\n",
            "At step: 5020 training error: 0.4262868220173239\n",
            "At step: 5021 training error: 0.42593856169308225\n",
            "At step: 5022 training error: 0.42757461201215424\n",
            "At step: 5023 training error: 0.4251066896795592\n",
            "At step: 5024 training error: 0.4264627128827894\n",
            "At step: 5025 training error: 0.42015861635716\n",
            "At step: 5026 training error: 0.41785627109337087\n",
            "At step: 5027 training error: 0.4131636737960267\n",
            "At step: 5028 training error: 0.416858726080295\n",
            "At step: 5029 training error: 0.4157110010141686\n",
            "At step: 5030 training error: 0.4109627338504978\n",
            "At step: 5031 training error: 0.4153174699335258\n",
            "At step: 5032 training error: 0.4170289016447583\n",
            "At step: 5033 training error: 0.4206496008795819\n",
            "At step: 5034 training error: 0.4118095414446691\n",
            "At step: 5035 training error: 0.4122389765169493\n",
            "At step: 5036 training error: 0.41295903598865336\n",
            "At step: 5037 training error: 0.42923864964017017\n",
            "At step: 5038 training error: 0.42290921327051695\n",
            "At step: 5039 training error: 0.42214404486950496\n",
            "At step: 5040 training error: 0.4136514301654963\n",
            "At step: 5041 training error: 0.4232217101075997\n",
            "At step: 5042 training error: 0.41613583047305\n",
            "At step: 5043 training error: 0.4105614846312214\n",
            "At step: 5044 training error: 0.419051039761943\n",
            "At step: 5045 training error: 0.41833613176347223\n",
            "At step: 5046 training error: 0.4113559385529977\n",
            "At step: 5047 training error: 0.4192445248902608\n",
            "At step: 5048 training error: 0.41105777836581336\n",
            "At step: 5049 training error: 0.40173163287765756\n",
            "At step: 5050 training error: 0.39842215619696003\n",
            "At step: 5051 training error: 0.41297378070719715\n",
            "At step: 5052 training error: 0.41601530994331104\n",
            "At step: 5053 training error: 0.4145418260785176\n",
            "At step: 5054 training error: 0.42205842951063255\n",
            "At step: 5055 training error: 0.4233447530112316\n",
            "At step: 5056 training error: 0.42717436694602406\n",
            "At step: 5057 training error: 0.4277875668185588\n",
            "At step: 5058 training error: 0.4434957941623848\n",
            "At step: 5059 training error: 0.43531815915998123\n",
            "At step: 5060 training error: 0.4250452898666186\n",
            "At step: 5061 training error: 0.42321543659070693\n",
            "At step: 5062 training error: 0.420760831777466\n",
            "At step: 5063 training error: 0.4212580640854844\n",
            "At step: 5064 training error: 0.42002672973011146\n",
            "At step: 5065 training error: 0.4236755482383654\n",
            "At step: 5066 training error: 0.42352488966821145\n",
            "At step: 5067 training error: 0.4272022969758946\n",
            "At step: 5068 training error: 0.4223161578018809\n",
            "At step: 5069 training error: 0.4291605031522287\n",
            "At step: 5070 training error: 0.4280964876489245\n",
            "At step: 5071 training error: 0.4454669909942598\n",
            "At step: 5072 training error: 0.43641840268099685\n",
            "At step: 5073 training error: 0.4434085883455984\n",
            "At step: 5074 training error: 0.45025797744935303\n",
            "At step: 5075 training error: 0.44521882435062743\n",
            "At step: 5076 training error: 0.4490248954550781\n",
            "At step: 5077 training error: 0.44254544051185896\n",
            "At step: 5078 training error: 0.44077949058125315\n",
            "At step: 5079 training error: 0.439741370639038\n",
            "At step: 5080 training error: 0.43801589746096103\n",
            "At step: 5081 training error: 0.4448466371022062\n",
            "At step: 5082 training error: 0.4514699705195361\n",
            "At step: 5083 training error: 0.45419273466860455\n",
            "At step: 5084 training error: 0.4511365596657687\n",
            "At step: 5085 training error: 0.4446095047790956\n",
            "At step: 5086 training error: 0.4423552485993833\n",
            "At step: 5087 training error: 0.43656340249768544\n",
            "At step: 5088 training error: 0.4446857823318178\n",
            "At step: 5089 training error: 0.44568751796628103\n",
            "At step: 5090 training error: 0.4462183058946473\n",
            "At step: 5091 training error: 0.45191627391394174\n",
            "At step: 5092 training error: 0.44098075934101666\n",
            "At step: 5093 training error: 0.44133971451971077\n",
            "At step: 5094 training error: 0.4377277495471005\n",
            "At step: 5095 training error: 0.42715704667047866\n",
            "At step: 5096 training error: 0.4260219059545649\n",
            "At step: 5097 training error: 0.437119094263111\n",
            "At step: 5098 training error: 0.4371506882071043\n",
            "At step: 5099 training error: 0.4376183349057686\n",
            "At step: 5100 training error: 0.4352794486969985\n",
            "At step: 5101 training error: 0.421442467245992\n",
            "At step: 5102 training error: 0.4200876184606002\n",
            "At step: 5103 training error: 0.42736180780983823\n",
            "At step: 5104 training error: 0.4145135225909241\n",
            "At step: 5105 training error: 0.4141651212241435\n",
            "At step: 5106 training error: 0.42279286710629804\n",
            "At step: 5107 training error: 0.4152580534728901\n",
            "At step: 5108 training error: 0.4076737333838186\n",
            "At step: 5109 training error: 0.41614509832668356\n",
            "At step: 5110 training error: 0.41472634416458865\n",
            "At step: 5111 training error: 0.41431127409921953\n",
            "At step: 5112 training error: 0.407946943613925\n",
            "At step: 5113 training error: 0.4144149228674728\n",
            "At step: 5114 training error: 0.41432829024770523\n",
            "At step: 5115 training error: 0.4171091207168541\n",
            "At step: 5116 training error: 0.4221492670594198\n",
            "At step: 5117 training error: 0.41448652952198406\n",
            "At step: 5118 training error: 0.41733620630663154\n",
            "At step: 5119 training error: 0.4207090229566426\n",
            "At step: 5120 training error: 0.4139787092051909\n",
            "At step: 5121 training error: 0.4214643220320045\n",
            "At step: 5122 training error: 0.410795733994568\n",
            "At step: 5123 training error: 0.40060189675737057\n",
            "At step: 5124 training error: 0.39566512969951495\n",
            "At step: 5125 training error: 0.3875082205467188\n",
            "At step: 5126 training error: 0.3927145131324812\n",
            "At step: 5127 training error: 0.40050297009394725\n",
            "At step: 5128 training error: 0.4075105488588756\n",
            "At step: 5129 training error: 0.4127853935436233\n",
            "At step: 5130 training error: 0.4086462778264974\n",
            "At step: 5131 training error: 0.41425659276782445\n",
            "At step: 5132 training error: 0.4141223783635082\n",
            "At step: 5133 training error: 0.40673187598056\n",
            "At step: 5134 training error: 0.4020845096185268\n",
            "At step: 5135 training error: 0.40829868307600015\n",
            "At step: 5136 training error: 0.4131471326494751\n",
            "At step: 5137 training error: 0.4153406719536515\n",
            "At step: 5138 training error: 0.420955672813592\n",
            "At step: 5139 training error: 0.43025308315789335\n",
            "At step: 5140 training error: 0.4295318741635304\n",
            "At step: 5141 training error: 0.4292027257951152\n",
            "At step: 5142 training error: 0.42317934374780414\n",
            "At step: 5143 training error: 0.41974397742766945\n",
            "At step: 5144 training error: 0.4176080079392558\n",
            "At step: 5145 training error: 0.41160033067265556\n",
            "At step: 5146 training error: 0.4148087355864423\n",
            "At step: 5147 training error: 0.41674737324705513\n",
            "At step: 5148 training error: 0.41652090115304113\n",
            "At step: 5149 training error: 0.41872325106548575\n",
            "At step: 5150 training error: 0.42180250647634643\n",
            "At step: 5151 training error: 0.4200632111170895\n",
            "At step: 5152 training error: 0.42054533966923907\n",
            "At step: 5153 training error: 0.4292450893241875\n",
            "At step: 5154 training error: 0.425700269568297\n",
            "At step: 5155 training error: 0.4266769666923339\n",
            "At step: 5156 training error: 0.42481795340740924\n",
            "At step: 5157 training error: 0.4262783904071998\n",
            "At step: 5158 training error: 0.4201439485717179\n",
            "At step: 5159 training error: 0.4170110239517732\n",
            "At step: 5160 training error: 0.40676578481770415\n",
            "At step: 5161 training error: 0.39644396430794693\n",
            "At step: 5162 training error: 0.39076158119033066\n",
            "At step: 5163 training error: 0.3880375324879307\n",
            "At step: 5164 training error: 0.3873341876570272\n",
            "At step: 5165 training error: 0.39615804581317954\n",
            "At step: 5166 training error: 0.3991992591816634\n",
            "At step: 5167 training error: 0.3909250008644129\n",
            "At step: 5168 training error: 0.3973256281559048\n",
            "At step: 5169 training error: 0.39847168960964885\n",
            "At step: 5170 training error: 0.4075731440786324\n",
            "At step: 5171 training error: 0.4229548964713967\n",
            "At step: 5172 training error: 0.4216688896524683\n",
            "At step: 5173 training error: 0.41728467019675797\n",
            "At step: 5174 training error: 0.41824875157524377\n",
            "At step: 5175 training error: 0.42150167100038\n",
            "At step: 5176 training error: 0.4184763070259947\n",
            "At step: 5177 training error: 0.4179014198367449\n",
            "At step: 5178 training error: 0.42201493835324916\n",
            "At step: 5179 training error: 0.41677112099217845\n",
            "At step: 5180 training error: 0.41103104566236937\n",
            "At step: 5181 training error: 0.414014043432934\n",
            "At step: 5182 training error: 0.41862077277693666\n",
            "At step: 5183 training error: 0.41574115672528267\n",
            "At step: 5184 training error: 0.41831028389242797\n",
            "At step: 5185 training error: 0.41947472117902657\n",
            "At step: 5186 training error: 0.4160770561312323\n",
            "At step: 5187 training error: 0.42213642665389034\n",
            "At step: 5188 training error: 0.42904981868347264\n",
            "At step: 5189 training error: 0.43713020473376263\n",
            "At step: 5190 training error: 0.4387520737163281\n",
            "At step: 5191 training error: 0.4337183984188855\n",
            "At step: 5192 training error: 0.4287726159080616\n",
            "At step: 5193 training error: 0.43184152173696716\n",
            "At step: 5194 training error: 0.43016529176944707\n",
            "At step: 5195 training error: 0.4391873478242898\n",
            "At step: 5196 training error: 0.44299120732974684\n",
            "At step: 5197 training error: 0.4473951780250408\n",
            "At step: 5198 training error: 0.43906357681533986\n",
            "At step: 5199 training error: 0.44367198603578917\n",
            "At step: 5200 training error: 0.44199390823115986\n",
            "At step: 5201 training error: 0.4449976857272364\n",
            "At step: 5202 training error: 0.4403065267841612\n",
            "At step: 5203 training error: 0.43426903979207143\n",
            "At step: 5204 training error: 0.43832193263690383\n",
            "At step: 5205 training error: 0.4312363388675237\n",
            "At step: 5206 training error: 0.4281083905733735\n",
            "At step: 5207 training error: 0.43227711239133215\n",
            "At step: 5208 training error: 0.4367764808396913\n",
            "At step: 5209 training error: 0.42784690588730556\n",
            "At step: 5210 training error: 0.41778375096816867\n",
            "At step: 5211 training error: 0.4170919184159764\n",
            "At step: 5212 training error: 0.44267092767867144\n",
            "At step: 5213 training error: 0.4472212229299543\n",
            "At step: 5214 training error: 0.45445273556954474\n",
            "At step: 5215 training error: 0.44730397188255494\n",
            "At step: 5216 training error: 0.4502873695700077\n",
            "At step: 5217 training error: 0.449442532806917\n",
            "At step: 5218 training error: 0.4505307596237815\n",
            "At step: 5219 training error: 0.43196478130914173\n",
            "At step: 5220 training error: 0.4354006315912393\n",
            "At step: 5221 training error: 0.43094780934437715\n",
            "At step: 5222 training error: 0.44489765721849467\n",
            "At step: 5223 training error: 0.44112313210915755\n",
            "At step: 5224 training error: 0.4484494308290641\n",
            "At step: 5225 training error: 0.4448934234638743\n",
            "At step: 5226 training error: 0.4424455407590533\n",
            "At step: 5227 training error: 0.44900189137661256\n",
            "At step: 5228 training error: 0.44095739949886065\n",
            "At step: 5229 training error: 0.434908575242003\n",
            "At step: 5230 training error: 0.4449376167001623\n",
            "At step: 5231 training error: 0.4540348742210872\n",
            "At step: 5232 training error: 0.44555334507979866\n",
            "At step: 5233 training error: 0.4352459916555083\n",
            "At step: 5234 training error: 0.43495587948288267\n",
            "At step: 5235 training error: 0.4272352581359677\n",
            "At step: 5236 training error: 0.4299592359930431\n",
            "At step: 5237 training error: 0.42875181544778074\n",
            "At step: 5238 training error: 0.4336055869000036\n",
            "At step: 5239 training error: 0.423606572608737\n",
            "At step: 5240 training error: 0.4227275584399692\n",
            "At step: 5241 training error: 0.4163706176848317\n",
            "At step: 5242 training error: 0.4225933628165198\n",
            "At step: 5243 training error: 0.40855339972906907\n",
            "At step: 5244 training error: 0.40282469865180387\n",
            "At step: 5245 training error: 0.41705631530433357\n",
            "At step: 5246 training error: 0.42517577455111444\n",
            "At step: 5247 training error: 0.42306249502335336\n",
            "At step: 5248 training error: 0.4294087956101407\n",
            "At step: 5249 training error: 0.43500741648752095\n",
            "At step: 5250 training error: 0.42785113939180497\n",
            "At step: 5251 training error: 0.42592614524903705\n",
            "At step: 5252 training error: 0.4357535770932902\n",
            "At step: 5253 training error: 0.4297383892568687\n",
            "At step: 5254 training error: 0.4219283109520173\n",
            "At step: 5255 training error: 0.42884798027385657\n",
            "At step: 5256 training error: 0.42608684894637533\n",
            "At step: 5257 training error: 0.4246995326074636\n",
            "At step: 5258 training error: 0.41914897780788773\n",
            "At step: 5259 training error: 0.41321836975738746\n",
            "At step: 5260 training error: 0.4089694006663787\n",
            "At step: 5261 training error: 0.3931903310621473\n",
            "At step: 5262 training error: 0.40059739673859357\n",
            "At step: 5263 training error: 0.410428683261499\n",
            "At step: 5264 training error: 0.4118579794692091\n",
            "At step: 5265 training error: 0.4156618774806905\n",
            "At step: 5266 training error: 0.4252002854441425\n",
            "At step: 5267 training error: 0.4083056685455057\n",
            "At step: 5268 training error: 0.42020294081829224\n",
            "At step: 5269 training error: 0.41580590226100356\n",
            "At step: 5270 training error: 0.4164411795132495\n",
            "At step: 5271 training error: 0.41696302663857937\n",
            "At step: 5272 training error: 0.42204681573297365\n",
            "At step: 5273 training error: 0.432679428546036\n",
            "At step: 5274 training error: 0.4442733153484023\n",
            "At step: 5275 training error: 0.45674021094615813\n",
            "At step: 5276 training error: 0.4514491613140275\n",
            "At step: 5277 training error: 0.4512974198520119\n",
            "At step: 5278 training error: 0.4497754447210434\n",
            "At step: 5279 training error: 0.4478473036703315\n",
            "At step: 5280 training error: 0.4336856812815289\n",
            "At step: 5281 training error: 0.4407774602931351\n",
            "At step: 5282 training error: 0.43490976858357105\n",
            "At step: 5283 training error: 0.43500951998304643\n",
            "At step: 5284 training error: 0.43187461642111274\n",
            "At step: 5285 training error: 0.43226320960088366\n",
            "At step: 5286 training error: 0.43654747119167825\n",
            "At step: 5287 training error: 0.43898888451618495\n",
            "At step: 5288 training error: 0.43486356348669697\n",
            "At step: 5289 training error: 0.43335302623240446\n",
            "At step: 5290 training error: 0.43119435453163646\n",
            "At step: 5291 training error: 0.4303275870977893\n",
            "At step: 5292 training error: 0.4240727620992684\n",
            "At step: 5293 training error: 0.41621021955028215\n",
            "At step: 5294 training error: 0.4173920491991155\n",
            "At step: 5295 training error: 0.41745149027949263\n",
            "At step: 5296 training error: 0.4215488782303051\n",
            "At step: 5297 training error: 0.42508480059242804\n",
            "At step: 5298 training error: 0.41814452828754467\n",
            "At step: 5299 training error: 0.41506667449006657\n",
            "At step: 5300 training error: 0.40720489891755907\n",
            "At step: 5301 training error: 0.40223854501330564\n",
            "At step: 5302 training error: 0.39882745023987054\n",
            "At step: 5303 training error: 0.4041325121786682\n",
            "At step: 5304 training error: 0.41154609013088905\n",
            "At step: 5305 training error: 0.41446255791039116\n",
            "At step: 5306 training error: 0.41087149894085273\n",
            "At step: 5307 training error: 0.41481705694078375\n",
            "At step: 5308 training error: 0.41873388216978347\n",
            "At step: 5309 training error: 0.4121193847359237\n",
            "At step: 5310 training error: 0.4120462086027309\n",
            "At step: 5311 training error: 0.4066414591127022\n",
            "At step: 5312 training error: 0.4115885141144057\n",
            "At step: 5313 training error: 0.4156195644943512\n",
            "At step: 5314 training error: 0.41360280344474776\n",
            "At step: 5315 training error: 0.40637142003203586\n",
            "At step: 5316 training error: 0.4128022456245819\n",
            "At step: 5317 training error: 0.4136023291566639\n",
            "At step: 5318 training error: 0.4121527472281811\n",
            "At step: 5319 training error: 0.40555814324609535\n",
            "At step: 5320 training error: 0.39841251115106996\n",
            "At step: 5321 training error: 0.4020141604299926\n",
            "At step: 5322 training error: 0.40030462164835257\n",
            "At step: 5323 training error: 0.3977204276245657\n",
            "At step: 5324 training error: 0.404922246027281\n",
            "At step: 5325 training error: 0.41415529734782425\n",
            "At step: 5326 training error: 0.4066237369183263\n",
            "At step: 5327 training error: 0.40980080173100847\n",
            "At step: 5328 training error: 0.40079302325765376\n",
            "At step: 5329 training error: 0.40322457528266864\n",
            "At step: 5330 training error: 0.3999167494178547\n",
            "At step: 5331 training error: 0.3862719487539412\n",
            "At step: 5332 training error: 0.3845672716159514\n",
            "At step: 5333 training error: 0.3929590102295706\n",
            "At step: 5334 training error: 0.3751437677064538\n",
            "At step: 5335 training error: 0.37844647197037856\n",
            "At step: 5336 training error: 0.37385140447561105\n",
            "At step: 5337 training error: 0.3831398684768374\n",
            "At step: 5338 training error: 0.38825945327354644\n",
            "At step: 5339 training error: 0.38709737726612514\n",
            "At step: 5340 training error: 0.39489942123876964\n",
            "At step: 5341 training error: 0.39463293923210657\n",
            "At step: 5342 training error: 0.40121046493291734\n",
            "At step: 5343 training error: 0.40646799763372365\n",
            "At step: 5344 training error: 0.41125169716601195\n",
            "At step: 5345 training error: 0.40861149670218305\n",
            "At step: 5346 training error: 0.40703088454038944\n",
            "At step: 5347 training error: 0.4013179413671543\n",
            "At step: 5348 training error: 0.3992584824210944\n",
            "At step: 5349 training error: 0.3970565580945132\n",
            "At step: 5350 training error: 0.39155374949959904\n",
            "At step: 5351 training error: 0.39111267487352996\n",
            "At step: 5352 training error: 0.38575243743991544\n",
            "At step: 5353 training error: 0.3922090395174471\n",
            "At step: 5354 training error: 0.3994911108492012\n",
            "At step: 5355 training error: 0.3979507269850354\n",
            "At step: 5356 training error: 0.4096591758332961\n",
            "At step: 5357 training error: 0.4148932889803147\n",
            "At step: 5358 training error: 0.41803153175030217\n",
            "At step: 5359 training error: 0.43146348040715593\n",
            "At step: 5360 training error: 0.42350972364800454\n",
            "At step: 5361 training error: 0.41589390932977316\n",
            "At step: 5362 training error: 0.40844588493697837\n",
            "At step: 5363 training error: 0.411919153252884\n",
            "At step: 5364 training error: 0.41272280528777594\n",
            "At step: 5365 training error: 0.410407395859589\n",
            "At step: 5366 training error: 0.407598537041672\n",
            "At step: 5367 training error: 0.406794953102994\n",
            "At step: 5368 training error: 0.391512258562547\n",
            "At step: 5369 training error: 0.38649571087756535\n",
            "At step: 5370 training error: 0.3798587202792818\n",
            "At step: 5371 training error: 0.3765398167514517\n",
            "At step: 5372 training error: 0.3787031192641195\n",
            "At step: 5373 training error: 0.3760794955187769\n",
            "At step: 5374 training error: 0.3749054165915309\n",
            "At step: 5375 training error: 0.3844176392591844\n",
            "At step: 5376 training error: 0.3745724415713839\n",
            "At step: 5377 training error: 0.3758710387773784\n",
            "At step: 5378 training error: 0.39180107582043333\n",
            "At step: 5379 training error: 0.3909029646732578\n",
            "At step: 5380 training error: 0.38949357295996956\n",
            "At step: 5381 training error: 0.3975874040711292\n",
            "At step: 5382 training error: 0.3923368956290982\n",
            "At step: 5383 training error: 0.39540286624004684\n",
            "At step: 5384 training error: 0.38758988562329477\n",
            "At step: 5385 training error: 0.38012370245453025\n",
            "At step: 5386 training error: 0.39239537948344344\n",
            "At step: 5387 training error: 0.40070439926568935\n",
            "At step: 5388 training error: 0.4090112128960658\n",
            "At step: 5389 training error: 0.40442515170664817\n",
            "At step: 5390 training error: 0.41433489624339565\n",
            "At step: 5391 training error: 0.4098292895635527\n",
            "At step: 5392 training error: 0.40275386691110826\n",
            "At step: 5393 training error: 0.38947473199564353\n",
            "At step: 5394 training error: 0.39315579290937985\n",
            "At step: 5395 training error: 0.39386388480170587\n",
            "At step: 5396 training error: 0.38806103126772434\n",
            "At step: 5397 training error: 0.37814661056747345\n",
            "At step: 5398 training error: 0.3751274932726833\n",
            "At step: 5399 training error: 0.3792782644912585\n",
            "At step: 5400 training error: 0.37679885517062267\n",
            "At step: 5401 training error: 0.3721297945302819\n",
            "At step: 5402 training error: 0.3781244398510725\n",
            "At step: 5403 training error: 0.38978789003712505\n",
            "At step: 5404 training error: 0.38504456598373116\n",
            "At step: 5405 training error: 0.385484086970897\n",
            "At step: 5406 training error: 0.3878181829692029\n",
            "At step: 5407 training error: 0.3914446802622493\n",
            "At step: 5408 training error: 0.38768653091017896\n",
            "At step: 5409 training error: 0.37995398235429373\n",
            "At step: 5410 training error: 0.3858656043494849\n",
            "At step: 5411 training error: 0.38853228518163746\n",
            "At step: 5412 training error: 0.39171103494671156\n",
            "At step: 5413 training error: 0.3942613143194311\n",
            "At step: 5414 training error: 0.39376199318445554\n",
            "At step: 5415 training error: 0.3863450446735472\n",
            "At step: 5416 training error: 0.37724159032086463\n",
            "At step: 5417 training error: 0.3893241512699635\n",
            "At step: 5418 training error: 0.3923590159941898\n",
            "At step: 5419 training error: 0.3834042619793774\n",
            "At step: 5420 training error: 0.3811705734591237\n",
            "At step: 5421 training error: 0.3869380042011292\n",
            "At step: 5422 training error: 0.38506453078434827\n",
            "At step: 5423 training error: 0.3878013873253335\n",
            "At step: 5424 training error: 0.38674844682297993\n",
            "At step: 5425 training error: 0.3937212595803562\n",
            "At step: 5426 training error: 0.3984461581320644\n",
            "At step: 5427 training error: 0.4047402401298048\n",
            "At step: 5428 training error: 0.3992408681993816\n",
            "At step: 5429 training error: 0.416767376149055\n",
            "At step: 5430 training error: 0.40751593194086166\n",
            "At step: 5431 training error: 0.4070169281479943\n",
            "At step: 5432 training error: 0.4052562630321764\n",
            "At step: 5433 training error: 0.41042655782700244\n",
            "At step: 5434 training error: 0.4110920228294334\n",
            "At step: 5435 training error: 0.42544336188561205\n",
            "At step: 5436 training error: 0.4298770345407241\n",
            "At step: 5437 training error: 0.4211410207946197\n",
            "At step: 5438 training error: 0.43906713892370053\n",
            "At step: 5439 training error: 0.43070626167931514\n",
            "At step: 5440 training error: 0.42014094120279194\n",
            "At step: 5441 training error: 0.4243802494559657\n",
            "At step: 5442 training error: 0.41833994210210806\n",
            "At step: 5443 training error: 0.41786439914631346\n",
            "At step: 5444 training error: 0.41836887552332275\n",
            "At step: 5445 training error: 0.41069971904059954\n",
            "At step: 5446 training error: 0.4056901247089574\n",
            "At step: 5447 training error: 0.4078715513684458\n",
            "At step: 5448 training error: 0.4007200494711596\n",
            "At step: 5449 training error: 0.4097366710058286\n",
            "At step: 5450 training error: 0.4130997468169481\n",
            "At step: 5451 training error: 0.41589641442438485\n",
            "At step: 5452 training error: 0.41721344456123705\n",
            "At step: 5453 training error: 0.4224929990487699\n",
            "At step: 5454 training error: 0.4139578119501609\n",
            "At step: 5455 training error: 0.41777576845239117\n",
            "At step: 5456 training error: 0.42545900512568147\n",
            "At step: 5457 training error: 0.4223255193482133\n",
            "At step: 5458 training error: 0.421229207981727\n",
            "At step: 5459 training error: 0.41652325466521395\n",
            "At step: 5460 training error: 0.4130684959393648\n",
            "At step: 5461 training error: 0.4073282501534236\n",
            "At step: 5462 training error: 0.41680826880916166\n",
            "At step: 5463 training error: 0.4239903906671673\n",
            "At step: 5464 training error: 0.4258656557994709\n",
            "At step: 5465 training error: 0.41582469028011243\n",
            "At step: 5466 training error: 0.4042006944092667\n",
            "At step: 5467 training error: 0.39822199870817426\n",
            "At step: 5468 training error: 0.39857633614524246\n",
            "At step: 5469 training error: 0.4039436168781395\n",
            "At step: 5470 training error: 0.4074118150735101\n",
            "At step: 5471 training error: 0.39847967579503263\n",
            "At step: 5472 training error: 0.4006567288665337\n",
            "At step: 5473 training error: 0.4008778804786921\n",
            "At step: 5474 training error: 0.39797368001680755\n",
            "At step: 5475 training error: 0.39238737672295393\n",
            "At step: 5476 training error: 0.3824835363598164\n",
            "At step: 5477 training error: 0.3842067338979798\n",
            "At step: 5478 training error: 0.39458170724231567\n",
            "At step: 5479 training error: 0.39600464468627494\n",
            "At step: 5480 training error: 0.3867520452335215\n",
            "At step: 5481 training error: 0.387831575541712\n",
            "At step: 5482 training error: 0.4000671517571226\n",
            "At step: 5483 training error: 0.4024402048940535\n",
            "At step: 5484 training error: 0.3892639620310205\n",
            "At step: 5485 training error: 0.3836252275351263\n",
            "At step: 5486 training error: 0.3941094529914233\n",
            "At step: 5487 training error: 0.3933502867081119\n",
            "At step: 5488 training error: 0.3951587713481454\n",
            "At step: 5489 training error: 0.3965855454240411\n",
            "At step: 5490 training error: 0.41086555552924814\n",
            "At step: 5491 training error: 0.4083459100949328\n",
            "At step: 5492 training error: 0.4073474100139499\n",
            "At step: 5493 training error: 0.39764449103460664\n",
            "At step: 5494 training error: 0.40957363488687193\n",
            "At step: 5495 training error: 0.40882953894309493\n",
            "At step: 5496 training error: 0.4051637606429788\n",
            "At step: 5497 training error: 0.40938288407139295\n",
            "At step: 5498 training error: 0.40355762818947233\n",
            "At step: 5499 training error: 0.40492426018370586\n",
            "At step: 5500 training error: 0.3976923217098911\n",
            "At step: 5501 training error: 0.39097233340174303\n",
            "At step: 5502 training error: 0.40617609854541614\n",
            "At step: 5503 training error: 0.41299666954115066\n",
            "At step: 5504 training error: 0.4061391277944608\n",
            "At step: 5505 training error: 0.40086525681411067\n",
            "At step: 5506 training error: 0.4017457877345112\n",
            "At step: 5507 training error: 0.40136667204168613\n",
            "At step: 5508 training error: 0.40611248577354014\n",
            "At step: 5509 training error: 0.3996551095986067\n",
            "At step: 5510 training error: 0.40016169364736864\n",
            "At step: 5511 training error: 0.4013664891561384\n",
            "At step: 5512 training error: 0.39747073358200286\n",
            "At step: 5513 training error: 0.3936444134528281\n",
            "At step: 5514 training error: 0.396200639843561\n",
            "At step: 5515 training error: 0.40456372067425866\n",
            "At step: 5516 training error: 0.41012666688619526\n",
            "At step: 5517 training error: 0.41919700824383127\n",
            "At step: 5518 training error: 0.42182378716809515\n",
            "At step: 5519 training error: 0.43061732199272357\n",
            "At step: 5520 training error: 0.42592945262469833\n",
            "At step: 5521 training error: 0.4158387205923034\n",
            "At step: 5522 training error: 0.4087075692158928\n",
            "At step: 5523 training error: 0.41360750333458984\n",
            "At step: 5524 training error: 0.41250039658286136\n",
            "At step: 5525 training error: 0.41756173917370343\n",
            "At step: 5526 training error: 0.41394614914625466\n",
            "At step: 5527 training error: 0.4058170333772716\n",
            "At step: 5528 training error: 0.41083114898221473\n",
            "At step: 5529 training error: 0.4062780244869833\n",
            "At step: 5530 training error: 0.42223559896366947\n",
            "At step: 5531 training error: 0.42329366482397135\n",
            "At step: 5532 training error: 0.4247386064296556\n",
            "At step: 5533 training error: 0.4184590660907422\n",
            "At step: 5534 training error: 0.421393650113099\n",
            "At step: 5535 training error: 0.4193687213586375\n",
            "At step: 5536 training error: 0.42108824952036683\n",
            "At step: 5537 training error: 0.42105352018418934\n",
            "At step: 5538 training error: 0.4205120051547462\n",
            "At step: 5539 training error: 0.4100330380492942\n",
            "At step: 5540 training error: 0.4248194838656057\n",
            "At step: 5541 training error: 0.43031608825162265\n",
            "At step: 5542 training error: 0.4181551408941123\n",
            "At step: 5543 training error: 0.4217682838371075\n",
            "At step: 5544 training error: 0.42526401323170115\n",
            "At step: 5545 training error: 0.4172048521808357\n",
            "At step: 5546 training error: 0.4146330609875101\n",
            "At step: 5547 training error: 0.4104072093879527\n",
            "At step: 5548 training error: 0.40916336096178485\n",
            "At step: 5549 training error: 0.41019758444945165\n",
            "At step: 5550 training error: 0.4155012371567298\n",
            "At step: 5551 training error: 0.4159659764358775\n",
            "At step: 5552 training error: 0.4097270465413997\n",
            "At step: 5553 training error: 0.40200815435900134\n",
            "At step: 5554 training error: 0.3992609533422047\n",
            "At step: 5555 training error: 0.40789041826370387\n",
            "At step: 5556 training error: 0.4045551285316264\n",
            "At step: 5557 training error: 0.4129324455572141\n",
            "At step: 5558 training error: 0.4020457566636166\n",
            "At step: 5559 training error: 0.40161286095231663\n",
            "At step: 5560 training error: 0.4051432813937853\n",
            "At step: 5561 training error: 0.3944541545451313\n",
            "At step: 5562 training error: 0.4052748176997906\n",
            "At step: 5563 training error: 0.4073037591681407\n",
            "At step: 5564 training error: 0.41594485765864925\n",
            "At step: 5565 training error: 0.4125271492140291\n",
            "At step: 5566 training error: 0.4100668992040335\n",
            "At step: 5567 training error: 0.4044406916176699\n",
            "At step: 5568 training error: 0.4048110740705627\n",
            "At step: 5569 training error: 0.40476857785313985\n",
            "At step: 5570 training error: 0.4083405917780084\n",
            "At step: 5571 training error: 0.4058607548356178\n",
            "At step: 5572 training error: 0.4164724930148964\n",
            "At step: 5573 training error: 0.41906774122971463\n",
            "At step: 5574 training error: 0.42130793724849397\n",
            "At step: 5575 training error: 0.42206338024774465\n",
            "At step: 5576 training error: 0.4202865190185416\n",
            "At step: 5577 training error: 0.4182523346316447\n",
            "At step: 5578 training error: 0.4168545689420119\n",
            "At step: 5579 training error: 0.41334783329416813\n",
            "At step: 5580 training error: 0.422266556444469\n",
            "At step: 5581 training error: 0.4306533619122715\n",
            "At step: 5582 training error: 0.4179188748804941\n",
            "At step: 5583 training error: 0.4134441759049895\n",
            "At step: 5584 training error: 0.41097447079460586\n",
            "At step: 5585 training error: 0.40235240661053306\n",
            "At step: 5586 training error: 0.4096854454323783\n",
            "At step: 5587 training error: 0.4032915804420416\n",
            "At step: 5588 training error: 0.4014581150758408\n",
            "At step: 5589 training error: 0.3892189803123751\n",
            "At step: 5590 training error: 0.39117901362794383\n",
            "At step: 5591 training error: 0.4021829011587348\n",
            "At step: 5592 training error: 0.392489141447533\n",
            "At step: 5593 training error: 0.3918652745798801\n",
            "At step: 5594 training error: 0.3954918125702483\n",
            "At step: 5595 training error: 0.3991525225680705\n",
            "At step: 5596 training error: 0.39023341472789486\n",
            "At step: 5597 training error: 0.39374378369515467\n",
            "At step: 5598 training error: 0.39042892931704043\n",
            "At step: 5599 training error: 0.39059790664258914\n",
            "At step: 5600 training error: 0.3922699120857779\n",
            "At step: 5601 training error: 0.3994715539998125\n",
            "At step: 5602 training error: 0.4000501123351414\n",
            "At step: 5603 training error: 0.40602713724663664\n",
            "At step: 5604 training error: 0.40971260081965066\n",
            "At step: 5605 training error: 0.40950331499145987\n",
            "At step: 5606 training error: 0.4069771877092642\n",
            "At step: 5607 training error: 0.40138512742062005\n",
            "At step: 5608 training error: 0.398796208585463\n",
            "At step: 5609 training error: 0.39293477762709766\n",
            "At step: 5610 training error: 0.3861945781818132\n",
            "At step: 5611 training error: 0.38125486787665486\n",
            "At step: 5612 training error: 0.3833153824261109\n",
            "At step: 5613 training error: 0.38943120441626505\n",
            "At step: 5614 training error: 0.3813756057305108\n",
            "At step: 5615 training error: 0.3784745741398921\n",
            "At step: 5616 training error: 0.3737933733849153\n",
            "At step: 5617 training error: 0.3738060975552475\n",
            "At step: 5618 training error: 0.3807718936194275\n",
            "At step: 5619 training error: 0.3814682226186514\n",
            "At step: 5620 training error: 0.3844817618171019\n",
            "At step: 5621 training error: 0.3871199625515359\n",
            "At step: 5622 training error: 0.3925614741793378\n",
            "At step: 5623 training error: 0.38523232294339155\n",
            "At step: 5624 training error: 0.39259979918062055\n",
            "At step: 5625 training error: 0.4125924045628047\n",
            "At step: 5626 training error: 0.4162360599204771\n",
            "At step: 5627 training error: 0.4067464406622744\n",
            "At step: 5628 training error: 0.40041954302378324\n",
            "At step: 5629 training error: 0.4003537038405947\n",
            "At step: 5630 training error: 0.39347895344079076\n",
            "At step: 5631 training error: 0.39595743776779535\n",
            "At step: 5632 training error: 0.4070640095102897\n",
            "At step: 5633 training error: 0.41857801241588694\n",
            "At step: 5634 training error: 0.42005835801395686\n",
            "At step: 5635 training error: 0.42491060389601565\n",
            "At step: 5636 training error: 0.4269766403544693\n",
            "At step: 5637 training error: 0.424790087808215\n",
            "At step: 5638 training error: 0.425879089631379\n",
            "At step: 5639 training error: 0.4236805147261277\n",
            "At step: 5640 training error: 0.4128221187834352\n",
            "At step: 5641 training error: 0.4141882867453169\n",
            "At step: 5642 training error: 0.41218819849256844\n",
            "At step: 5643 training error: 0.4083382038795478\n",
            "At step: 5644 training error: 0.4142764002811552\n",
            "At step: 5645 training error: 0.4104588161952139\n",
            "At step: 5646 training error: 0.41360829206783023\n",
            "At step: 5647 training error: 0.4153581195947672\n",
            "At step: 5648 training error: 0.4210165575364311\n",
            "At step: 5649 training error: 0.4226012013892266\n",
            "At step: 5650 training error: 0.4180083723823096\n",
            "At step: 5651 training error: 0.42209013805673706\n",
            "At step: 5652 training error: 0.4148778023040357\n",
            "At step: 5653 training error: 0.4141989005841721\n",
            "At step: 5654 training error: 0.4129972661366873\n",
            "At step: 5655 training error: 0.41281292609058823\n",
            "At step: 5656 training error: 0.4187972096880911\n",
            "At step: 5657 training error: 0.4279863907506567\n",
            "At step: 5658 training error: 0.4387743896844877\n",
            "At step: 5659 training error: 0.4365424001060275\n",
            "At step: 5660 training error: 0.4399429489892212\n",
            "At step: 5661 training error: 0.4283897181182221\n",
            "At step: 5662 training error: 0.4299401243373763\n",
            "At step: 5663 training error: 0.4359320123793927\n",
            "At step: 5664 training error: 0.429532175898194\n",
            "At step: 5665 training error: 0.4289949309908131\n",
            "At step: 5666 training error: 0.42140090058762253\n",
            "At step: 5667 training error: 0.4222736061796578\n",
            "At step: 5668 training error: 0.4241694183516253\n",
            "At step: 5669 training error: 0.43198109057036993\n",
            "At step: 5670 training error: 0.42414360254464534\n",
            "At step: 5671 training error: 0.4238379730127085\n",
            "At step: 5672 training error: 0.42493960615619003\n",
            "At step: 5673 training error: 0.41535664751397844\n",
            "At step: 5674 training error: 0.42566709968979644\n",
            "At step: 5675 training error: 0.4252366907331316\n",
            "At step: 5676 training error: 0.41666020139279475\n",
            "At step: 5677 training error: 0.4184257539487968\n",
            "At step: 5678 training error: 0.423634285337662\n",
            "At step: 5679 training error: 0.4175854394605849\n",
            "At step: 5680 training error: 0.41353502708630663\n",
            "At step: 5681 training error: 0.4220644669702243\n",
            "At step: 5682 training error: 0.41420132459717557\n",
            "At step: 5683 training error: 0.4178473849315017\n",
            "At step: 5684 training error: 0.4100394119101171\n",
            "At step: 5685 training error: 0.39875731059818753\n",
            "At step: 5686 training error: 0.39415500878511\n",
            "At step: 5687 training error: 0.40090350349591863\n",
            "At step: 5688 training error: 0.3996441693448418\n",
            "At step: 5689 training error: 0.4059117613560079\n",
            "At step: 5690 training error: 0.40938002800138384\n",
            "At step: 5691 training error: 0.40455165333372\n",
            "At step: 5692 training error: 0.4092202227728885\n",
            "At step: 5693 training error: 0.4039997137729704\n",
            "At step: 5694 training error: 0.40359336965494\n",
            "At step: 5695 training error: 0.399510095111915\n",
            "At step: 5696 training error: 0.3966285669459169\n",
            "At step: 5697 training error: 0.40496881172286076\n",
            "At step: 5698 training error: 0.3949160463333606\n",
            "At step: 5699 training error: 0.38254470471130253\n",
            "At step: 5700 training error: 0.39241739538718035\n",
            "At step: 5701 training error: 0.401091139478763\n",
            "At step: 5702 training error: 0.394982551772386\n",
            "At step: 5703 training error: 0.39591783172970707\n",
            "At step: 5704 training error: 0.39482146099664517\n",
            "At step: 5705 training error: 0.39108242484342254\n",
            "At step: 5706 training error: 0.384541564219068\n",
            "At step: 5707 training error: 0.37863814412758323\n",
            "At step: 5708 training error: 0.38066134100815024\n",
            "At step: 5709 training error: 0.38015332285315484\n",
            "At step: 5710 training error: 0.3872772266823384\n",
            "At step: 5711 training error: 0.3840994213797065\n",
            "At step: 5712 training error: 0.37601925574964784\n",
            "At step: 5713 training error: 0.37511251483501173\n",
            "At step: 5714 training error: 0.36889783154722355\n",
            "At step: 5715 training error: 0.37783900342769844\n",
            "At step: 5716 training error: 0.38408839593294186\n",
            "At step: 5717 training error: 0.38878667480682894\n",
            "At step: 5718 training error: 0.3955519869265889\n",
            "At step: 5719 training error: 0.4018264775534203\n",
            "At step: 5720 training error: 0.4143460507949043\n",
            "At step: 5721 training error: 0.41027711853807003\n",
            "At step: 5722 training error: 0.4076488987954999\n",
            "At step: 5723 training error: 0.4100351873865491\n",
            "At step: 5724 training error: 0.4131442579268441\n",
            "At step: 5725 training error: 0.4168096813495471\n",
            "At step: 5726 training error: 0.41500203475369013\n",
            "At step: 5727 training error: 0.4130412308260205\n",
            "At step: 5728 training error: 0.41085680362451105\n",
            "At step: 5729 training error: 0.40978978966490937\n",
            "At step: 5730 training error: 0.41757094572553854\n",
            "At step: 5731 training error: 0.4110955914472726\n",
            "At step: 5732 training error: 0.4156613926645628\n",
            "At step: 5733 training error: 0.40701839357000186\n",
            "At step: 5734 training error: 0.414044933197355\n",
            "At step: 5735 training error: 0.40858779224255903\n",
            "At step: 5736 training error: 0.4078998311032917\n",
            "At step: 5737 training error: 0.41204173658710813\n",
            "At step: 5738 training error: 0.40127424954366253\n",
            "At step: 5739 training error: 0.3997027712755519\n",
            "At step: 5740 training error: 0.4140337244996553\n",
            "At step: 5741 training error: 0.4142857939585302\n",
            "At step: 5742 training error: 0.4135648841713794\n",
            "At step: 5743 training error: 0.40974652760106217\n",
            "At step: 5744 training error: 0.4092639746470898\n",
            "At step: 5745 training error: 0.40596529378635393\n",
            "At step: 5746 training error: 0.4093950830433809\n",
            "At step: 5747 training error: 0.423138061563616\n",
            "At step: 5748 training error: 0.41180260225541376\n",
            "At step: 5749 training error: 0.4106942411760346\n",
            "At step: 5750 training error: 0.40678304022452666\n",
            "At step: 5751 training error: 0.40026195831404204\n",
            "At step: 5752 training error: 0.4047156697784553\n",
            "At step: 5753 training error: 0.4062836482200275\n",
            "At step: 5754 training error: 0.40439831804483584\n",
            "At step: 5755 training error: 0.4215327127695883\n",
            "At step: 5756 training error: 0.4113957487716546\n",
            "At step: 5757 training error: 0.4150210428938458\n",
            "At step: 5758 training error: 0.4114617676958301\n",
            "At step: 5759 training error: 0.40656966882314033\n",
            "At step: 5760 training error: 0.4124706620338035\n",
            "At step: 5761 training error: 0.4157810331545732\n",
            "At step: 5762 training error: 0.4031503808787282\n",
            "At step: 5763 training error: 0.41110752041854565\n",
            "At step: 5764 training error: 0.4036341419451498\n",
            "At step: 5765 training error: 0.3966487057032493\n",
            "At step: 5766 training error: 0.40014048711432837\n",
            "At step: 5767 training error: 0.4040181840328246\n",
            "At step: 5768 training error: 0.40979993312580115\n",
            "At step: 5769 training error: 0.4064144376132448\n",
            "At step: 5770 training error: 0.40270699884956074\n",
            "At step: 5771 training error: 0.41167991119021424\n",
            "At step: 5772 training error: 0.40505838646527903\n",
            "At step: 5773 training error: 0.423054040505624\n",
            "At step: 5774 training error: 0.42598588992368636\n",
            "At step: 5775 training error: 0.4293656405469114\n",
            "At step: 5776 training error: 0.4343263388187449\n",
            "At step: 5777 training error: 0.419878759712977\n",
            "At step: 5778 training error: 0.42005570472044207\n",
            "At step: 5779 training error: 0.41385480974393757\n",
            "At step: 5780 training error: 0.3996447729187173\n",
            "At step: 5781 training error: 0.39946362242288347\n",
            "At step: 5782 training error: 0.4048941463681007\n",
            "At step: 5783 training error: 0.4119727060753783\n",
            "At step: 5784 training error: 0.41338122612239725\n",
            "At step: 5785 training error: 0.41338200377107454\n",
            "At step: 5786 training error: 0.4127939697945042\n",
            "At step: 5787 training error: 0.42434785658970664\n",
            "At step: 5788 training error: 0.41460945915756714\n",
            "At step: 5789 training error: 0.4069447277855428\n",
            "At step: 5790 training error: 0.4150215923716696\n",
            "At step: 5791 training error: 0.41994061021064216\n",
            "At step: 5792 training error: 0.41634922063955904\n",
            "At step: 5793 training error: 0.42036403396644334\n",
            "At step: 5794 training error: 0.4162761968239284\n",
            "At step: 5795 training error: 0.42082732330935657\n",
            "At step: 5796 training error: 0.41472964301809656\n",
            "At step: 5797 training error: 0.41256581306039\n",
            "At step: 5798 training error: 0.40618071489610924\n",
            "At step: 5799 training error: 0.40853083754830655\n",
            "At step: 5800 training error: 0.4065395525983059\n",
            "At step: 5801 training error: 0.4062009228248591\n",
            "At step: 5802 training error: 0.41174022836110324\n",
            "At step: 5803 training error: 0.4174978614534532\n",
            "At step: 5804 training error: 0.43264964680333756\n",
            "At step: 5805 training error: 0.4295990574846821\n",
            "At step: 5806 training error: 0.42341532914861096\n",
            "At step: 5807 training error: 0.4186245350298692\n",
            "At step: 5808 training error: 0.41975739234789866\n",
            "At step: 5809 training error: 0.40868476772745665\n",
            "At step: 5810 training error: 0.4114839537088946\n",
            "At step: 5811 training error: 0.4046675575263948\n",
            "At step: 5812 training error: 0.4150450412373754\n",
            "At step: 5813 training error: 0.4162636670556272\n",
            "At step: 5814 training error: 0.41619205970438\n",
            "At step: 5815 training error: 0.42407175318818247\n",
            "At step: 5816 training error: 0.4335363518787838\n",
            "At step: 5817 training error: 0.42960120162877347\n",
            "At step: 5818 training error: 0.42596989564578835\n",
            "At step: 5819 training error: 0.4205213186420147\n",
            "At step: 5820 training error: 0.42088029328187687\n",
            "At step: 5821 training error: 0.42492788621759964\n",
            "At step: 5822 training error: 0.42409424746671315\n",
            "At step: 5823 training error: 0.41488482141717387\n",
            "At step: 5824 training error: 0.41239166970883223\n",
            "At step: 5825 training error: 0.40638436935131445\n",
            "At step: 5826 training error: 0.4114625865275501\n",
            "At step: 5827 training error: 0.41522585740896256\n",
            "At step: 5828 training error: 0.41516139474054026\n",
            "At step: 5829 training error: 0.4156145807315671\n",
            "At step: 5830 training error: 0.41629753891802673\n",
            "At step: 5831 training error: 0.42137988740979365\n",
            "At step: 5832 training error: 0.4173373385524855\n",
            "At step: 5833 training error: 0.41622755853267757\n",
            "At step: 5834 training error: 0.4139393843569462\n",
            "At step: 5835 training error: 0.4118892030739067\n",
            "At step: 5836 training error: 0.4146793131357123\n",
            "At step: 5837 training error: 0.41767557449679205\n",
            "At step: 5838 training error: 0.41922857086030263\n",
            "At step: 5839 training error: 0.4131776232055425\n",
            "At step: 5840 training error: 0.40919456533408827\n",
            "At step: 5841 training error: 0.4183449243213213\n",
            "At step: 5842 training error: 0.41059190577624166\n",
            "At step: 5843 training error: 0.4050865583483858\n",
            "At step: 5844 training error: 0.4053628896437571\n",
            "At step: 5845 training error: 0.41273147800316273\n",
            "At step: 5846 training error: 0.42154137272445374\n",
            "At step: 5847 training error: 0.4298821548155977\n",
            "At step: 5848 training error: 0.43388204207318004\n",
            "At step: 5849 training error: 0.43765005743934976\n",
            "At step: 5850 training error: 0.43158122986423414\n",
            "At step: 5851 training error: 0.4258282240644426\n",
            "At step: 5852 training error: 0.4316073317968406\n",
            "At step: 5853 training error: 0.4314443310402585\n",
            "At step: 5854 training error: 0.44766413078644285\n",
            "At step: 5855 training error: 0.4461617111157534\n",
            "At step: 5856 training error: 0.43424147081342546\n",
            "At step: 5857 training error: 0.4284095892424659\n",
            "At step: 5858 training error: 0.4358744368787554\n",
            "At step: 5859 training error: 0.42971192199382685\n",
            "At step: 5860 training error: 0.42767118960747\n",
            "At step: 5861 training error: 0.43124000058164097\n",
            "At step: 5862 training error: 0.4379297052862568\n",
            "At step: 5863 training error: 0.44133989256713385\n",
            "At step: 5864 training error: 0.439938415417526\n",
            "At step: 5865 training error: 0.4401590485719118\n",
            "At step: 5866 training error: 0.4235722778134674\n",
            "At step: 5867 training error: 0.42387776636881813\n",
            "At step: 5868 training error: 0.41601057547600273\n",
            "At step: 5869 training error: 0.41584358539111593\n",
            "At step: 5870 training error: 0.4251108706883762\n",
            "At step: 5871 training error: 0.41812046814691567\n",
            "At step: 5872 training error: 0.4211632027089944\n",
            "At step: 5873 training error: 0.41751985753670345\n",
            "At step: 5874 training error: 0.4069759456926508\n",
            "At step: 5875 training error: 0.4090795152750424\n",
            "At step: 5876 training error: 0.4015363037808038\n",
            "At step: 5877 training error: 0.40057777863440386\n",
            "At step: 5878 training error: 0.40360412091772\n",
            "At step: 5879 training error: 0.40285932371436545\n",
            "At step: 5880 training error: 0.4042522587798263\n",
            "At step: 5881 training error: 0.4025579989610216\n",
            "At step: 5882 training error: 0.3983434615055561\n",
            "At step: 5883 training error: 0.39411874591874557\n",
            "At step: 5884 training error: 0.39628855396852464\n",
            "At step: 5885 training error: 0.3917718628385364\n",
            "At step: 5886 training error: 0.39618808571662223\n",
            "At step: 5887 training error: 0.4072243369648918\n",
            "At step: 5888 training error: 0.40622659624974405\n",
            "At step: 5889 training error: 0.4101494584758857\n",
            "At step: 5890 training error: 0.40427191635564247\n",
            "At step: 5891 training error: 0.4079204497645058\n",
            "At step: 5892 training error: 0.40366071253641156\n",
            "At step: 5893 training error: 0.39971966447839763\n",
            "At step: 5894 training error: 0.40047376091385223\n",
            "At step: 5895 training error: 0.4037242194354531\n",
            "At step: 5896 training error: 0.4095637705377587\n",
            "At step: 5897 training error: 0.4187533997815087\n",
            "At step: 5898 training error: 0.4245015310595283\n",
            "At step: 5899 training error: 0.4219361148071406\n",
            "At step: 5900 training error: 0.4184554313341817\n",
            "At step: 5901 training error: 0.4151853833725142\n",
            "At step: 5902 training error: 0.41602181921839365\n",
            "At step: 5903 training error: 0.41151736749138806\n",
            "At step: 5904 training error: 0.4075469908919301\n",
            "At step: 5905 training error: 0.408704512279583\n",
            "At step: 5906 training error: 0.41603660730991227\n",
            "At step: 5907 training error: 0.4217989842164825\n",
            "At step: 5908 training error: 0.41800732107895866\n",
            "At step: 5909 training error: 0.4036706600490076\n",
            "At step: 5910 training error: 0.4073184292390069\n",
            "At step: 5911 training error: 0.4033447101772034\n",
            "At step: 5912 training error: 0.3988062799713633\n",
            "At step: 5913 training error: 0.3966875890809334\n",
            "At step: 5914 training error: 0.4067791450179966\n",
            "At step: 5915 training error: 0.4135970772070131\n",
            "At step: 5916 training error: 0.4228072628658936\n",
            "At step: 5917 training error: 0.4166705821786905\n",
            "At step: 5918 training error: 0.42069873959012327\n",
            "At step: 5919 training error: 0.42149450526119026\n",
            "At step: 5920 training error: 0.41714551256589005\n",
            "At step: 5921 training error: 0.4090998513324322\n",
            "At step: 5922 training error: 0.4061906352726077\n",
            "At step: 5923 training error: 0.4043265450277578\n",
            "At step: 5924 training error: 0.40277019544998244\n",
            "At step: 5925 training error: 0.41704082226246075\n",
            "At step: 5926 training error: 0.4200672511394881\n",
            "At step: 5927 training error: 0.4193750439338713\n",
            "At step: 5928 training error: 0.4173294635969132\n",
            "At step: 5929 training error: 0.41143234844109106\n",
            "At step: 5930 training error: 0.40622175680315514\n",
            "At step: 5931 training error: 0.4069642986644547\n",
            "At step: 5932 training error: 0.4049158177380582\n",
            "At step: 5933 training error: 0.41127681258353066\n",
            "At step: 5934 training error: 0.41083158767431033\n",
            "At step: 5935 training error: 0.4122856147576597\n",
            "At step: 5936 training error: 0.4135337008029105\n",
            "At step: 5937 training error: 0.42026409767975736\n",
            "At step: 5938 training error: 0.4076897011325163\n",
            "At step: 5939 training error: 0.40892404998279547\n",
            "At step: 5940 training error: 0.41167439613926843\n",
            "At step: 5941 training error: 0.41991847986945596\n",
            "At step: 5942 training error: 0.42335155482137876\n",
            "At step: 5943 training error: 0.4308183353067849\n",
            "At step: 5944 training error: 0.43195048625148025\n",
            "At step: 5945 training error: 0.43009092480038125\n",
            "At step: 5946 training error: 0.43052322153239425\n",
            "At step: 5947 training error: 0.42216200130395626\n",
            "At step: 5948 training error: 0.4291959169309647\n",
            "At step: 5949 training error: 0.4304219530667601\n",
            "At step: 5950 training error: 0.4269306859698525\n",
            "At step: 5951 training error: 0.4178045031629692\n",
            "At step: 5952 training error: 0.4044689956574198\n",
            "At step: 5953 training error: 0.4162258603721051\n",
            "At step: 5954 training error: 0.40991141759618976\n",
            "At step: 5955 training error: 0.41238427196675975\n",
            "At step: 5956 training error: 0.402372890761803\n",
            "At step: 5957 training error: 0.4040088719321285\n",
            "At step: 5958 training error: 0.430010790319731\n",
            "At step: 5959 training error: 0.4384082675279431\n",
            "At step: 5960 training error: 0.4358068779547628\n",
            "At step: 5961 training error: 0.4310985351078336\n",
            "At step: 5962 training error: 0.42594155801495376\n",
            "At step: 5963 training error: 0.4443206632922654\n",
            "At step: 5964 training error: 0.4478984153896551\n",
            "At step: 5965 training error: 0.44460199745538975\n",
            "At step: 5966 training error: 0.4536121536961867\n",
            "At step: 5967 training error: 0.45389315731860413\n",
            "At step: 5968 training error: 0.43642734953232903\n",
            "At step: 5969 training error: 0.4326114590018094\n",
            "At step: 5970 training error: 0.4261834327451703\n",
            "At step: 5971 training error: 0.42362200430541486\n",
            "At step: 5972 training error: 0.4178710191568208\n",
            "At step: 5973 training error: 0.4100337083342665\n",
            "At step: 5974 training error: 0.4112121341810065\n",
            "At step: 5975 training error: 0.41692278769172497\n",
            "At step: 5976 training error: 0.4175031453435854\n",
            "At step: 5977 training error: 0.4293305676202407\n",
            "At step: 5978 training error: 0.4302138861135658\n",
            "At step: 5979 training error: 0.41983015031178134\n",
            "At step: 5980 training error: 0.4097663238360532\n",
            "At step: 5981 training error: 0.4117407560007887\n",
            "At step: 5982 training error: 0.410897489507928\n",
            "At step: 5983 training error: 0.41113613501494684\n",
            "At step: 5984 training error: 0.40747588347601926\n",
            "At step: 5985 training error: 0.40524698886462057\n",
            "At step: 5986 training error: 0.40742023486235646\n",
            "At step: 5987 training error: 0.41752976855430435\n",
            "At step: 5988 training error: 0.41591651833431353\n",
            "At step: 5989 training error: 0.41553560879640683\n",
            "At step: 5990 training error: 0.4146556850867915\n",
            "At step: 5991 training error: 0.4089650825048785\n",
            "At step: 5992 training error: 0.4013549723531027\n",
            "At step: 5993 training error: 0.3972317796896496\n",
            "At step: 5994 training error: 0.4066569061498497\n",
            "At step: 5995 training error: 0.415384541517906\n",
            "At step: 5996 training error: 0.3973876479358982\n",
            "At step: 5997 training error: 0.39561125421318044\n",
            "At step: 5998 training error: 0.39918443142843996\n",
            "At step: 5999 training error: 0.38910310162410844\n",
            "At step: 6000 training error: 0.39496808107448433\n",
            "At step: 6001 training error: 0.40088850128454934\n",
            "At step: 6002 training error: 0.4029709512852482\n",
            "At step: 6003 training error: 0.40969645042739006\n",
            "At step: 6004 training error: 0.41473815952720805\n",
            "At step: 6005 training error: 0.4024642418641519\n",
            "At step: 6006 training error: 0.40433960197982594\n",
            "At step: 6007 training error: 0.40587021847375504\n",
            "At step: 6008 training error: 0.40830415241074225\n",
            "At step: 6009 training error: 0.4012590082060489\n",
            "At step: 6010 training error: 0.4184750414124772\n",
            "At step: 6011 training error: 0.4152482412807193\n",
            "At step: 6012 training error: 0.4206441998049676\n",
            "At step: 6013 training error: 0.41720955605871024\n",
            "At step: 6014 training error: 0.4050074642791791\n",
            "At step: 6015 training error: 0.41048018259519403\n",
            "At step: 6016 training error: 0.41568648105311234\n",
            "At step: 6017 training error: 0.41328946646262893\n",
            "At step: 6018 training error: 0.4007080066848396\n",
            "At step: 6019 training error: 0.4022434818984475\n",
            "At step: 6020 training error: 0.40100760420262205\n",
            "At step: 6021 training error: 0.3916527615483796\n",
            "At step: 6022 training error: 0.3980227624230089\n",
            "At step: 6023 training error: 0.3991161229636861\n",
            "At step: 6024 training error: 0.39566636232745644\n",
            "At step: 6025 training error: 0.3932834902573759\n",
            "At step: 6026 training error: 0.3952098671942232\n",
            "At step: 6027 training error: 0.40753568709533605\n",
            "At step: 6028 training error: 0.3977334217354757\n",
            "At step: 6029 training error: 0.40882810850843543\n",
            "At step: 6030 training error: 0.4243397109315754\n",
            "At step: 6031 training error: 0.41961484385765624\n",
            "At step: 6032 training error: 0.4103278901958066\n",
            "At step: 6033 training error: 0.41833201942301534\n",
            "At step: 6034 training error: 0.41255480963932223\n",
            "At step: 6035 training error: 0.4092902887281163\n",
            "At step: 6036 training error: 0.4060353557427727\n",
            "At step: 6037 training error: 0.40720490046440766\n",
            "At step: 6038 training error: 0.4060492207523702\n",
            "At step: 6039 training error: 0.3962009458903283\n",
            "At step: 6040 training error: 0.4049727409307087\n",
            "At step: 6041 training error: 0.3989614430309586\n",
            "At step: 6042 training error: 0.40209475984427706\n",
            "At step: 6043 training error: 0.4099982318454989\n",
            "At step: 6044 training error: 0.4175634058362765\n",
            "At step: 6045 training error: 0.4169427185005108\n",
            "At step: 6046 training error: 0.4173637626598301\n",
            "At step: 6047 training error: 0.4084384402552379\n",
            "At step: 6048 training error: 0.4097697283372079\n",
            "At step: 6049 training error: 0.4158557286976551\n",
            "At step: 6050 training error: 0.4055852449593142\n",
            "At step: 6051 training error: 0.4028938591379144\n",
            "At step: 6052 training error: 0.4011850576302122\n",
            "At step: 6053 training error: 0.40720097553628926\n",
            "At step: 6054 training error: 0.3904382745428811\n",
            "At step: 6055 training error: 0.3855502576014132\n",
            "At step: 6056 training error: 0.38233196638716016\n",
            "At step: 6057 training error: 0.3894962009795135\n",
            "At step: 6058 training error: 0.40066240622168525\n",
            "At step: 6059 training error: 0.40806174633654135\n",
            "At step: 6060 training error: 0.40390577372566744\n",
            "At step: 6061 training error: 0.4052402089562596\n",
            "At step: 6062 training error: 0.4038206605529879\n",
            "At step: 6063 training error: 0.4019139121187586\n",
            "At step: 6064 training error: 0.40890520197656227\n",
            "At step: 6065 training error: 0.42173964397489067\n",
            "At step: 6066 training error: 0.41912894927286226\n",
            "At step: 6067 training error: 0.41117553260631884\n",
            "At step: 6068 training error: 0.4113453495760054\n",
            "At step: 6069 training error: 0.4047942894970847\n",
            "At step: 6070 training error: 0.40770436307846414\n",
            "At step: 6071 training error: 0.41958284971097526\n",
            "At step: 6072 training error: 0.4130886996491747\n",
            "At step: 6073 training error: 0.40377531427548297\n",
            "At step: 6074 training error: 0.40441287909779416\n",
            "At step: 6075 training error: 0.40087002020104656\n",
            "At step: 6076 training error: 0.4121368905894558\n",
            "At step: 6077 training error: 0.40647235729577647\n",
            "At step: 6078 training error: 0.4132638365637348\n",
            "At step: 6079 training error: 0.406071871287246\n",
            "At step: 6080 training error: 0.3966401935082263\n",
            "At step: 6081 training error: 0.3929401923237227\n",
            "At step: 6082 training error: 0.3907104967081717\n",
            "At step: 6083 training error: 0.3982246866247497\n",
            "At step: 6084 training error: 0.3936894756673339\n",
            "At step: 6085 training error: 0.404688546828211\n",
            "At step: 6086 training error: 0.41002261637316567\n",
            "At step: 6087 training error: 0.4007381295541806\n",
            "At step: 6088 training error: 0.39884308440032146\n",
            "At step: 6089 training error: 0.39490981916412277\n",
            "At step: 6090 training error: 0.3849425133828084\n",
            "At step: 6091 training error: 0.3774723877438518\n",
            "At step: 6092 training error: 0.38523258822916223\n",
            "At step: 6093 training error: 0.37840374461283105\n",
            "At step: 6094 training error: 0.39059941088442673\n",
            "At step: 6095 training error: 0.39213808500219066\n",
            "At step: 6096 training error: 0.3886223363556168\n",
            "At step: 6097 training error: 0.38593161147730676\n",
            "At step: 6098 training error: 0.3907017663689422\n",
            "At step: 6099 training error: 0.3937800683016802\n",
            "At step: 6100 training error: 0.39999029857109236\n",
            "At step: 6101 training error: 0.4015896206095414\n",
            "At step: 6102 training error: 0.4069812582208979\n",
            "At step: 6103 training error: 0.39864885412838064\n",
            "At step: 6104 training error: 0.3995891601878634\n",
            "At step: 6105 training error: 0.4083654280640556\n",
            "At step: 6106 training error: 0.3970852636883108\n",
            "At step: 6107 training error: 0.40045764683754725\n",
            "At step: 6108 training error: 0.3982581280543219\n",
            "At step: 6109 training error: 0.40200757183244407\n",
            "At step: 6110 training error: 0.40310648355082684\n",
            "At step: 6111 training error: 0.3930072921040066\n",
            "At step: 6112 training error: 0.3855118223452794\n",
            "At step: 6113 training error: 0.39450826932710464\n",
            "At step: 6114 training error: 0.3922894249247015\n",
            "At step: 6115 training error: 0.4014752469816981\n",
            "At step: 6116 training error: 0.4105113957074319\n",
            "At step: 6117 training error: 0.39874102830796476\n",
            "At step: 6118 training error: 0.4099697074126122\n",
            "At step: 6119 training error: 0.40605391873320135\n",
            "At step: 6120 training error: 0.397265808332311\n",
            "At step: 6121 training error: 0.4082553798190126\n",
            "At step: 6122 training error: 0.41307766456538797\n",
            "At step: 6123 training error: 0.41552957686174286\n",
            "At step: 6124 training error: 0.41799418711000086\n",
            "At step: 6125 training error: 0.4175676448105453\n",
            "At step: 6126 training error: 0.4202776509386875\n",
            "At step: 6127 training error: 0.4266847210408776\n",
            "At step: 6128 training error: 0.4286411666136636\n",
            "At step: 6129 training error: 0.41362010693150325\n",
            "At step: 6130 training error: 0.41265704828642574\n",
            "At step: 6131 training error: 0.4045085762545344\n",
            "At step: 6132 training error: 0.3950057222585157\n",
            "At step: 6133 training error: 0.4011464960488591\n",
            "At step: 6134 training error: 0.40950922389413735\n",
            "At step: 6135 training error: 0.3987921609140002\n",
            "At step: 6136 training error: 0.4002237936319176\n",
            "At step: 6137 training error: 0.40076432973126974\n",
            "At step: 6138 training error: 0.4054460039728948\n",
            "At step: 6139 training error: 0.41227841463384707\n",
            "At step: 6140 training error: 0.4112180152337802\n",
            "At step: 6141 training error: 0.41049530029178816\n",
            "At step: 6142 training error: 0.40817540652459006\n",
            "At step: 6143 training error: 0.41065552700418856\n",
            "At step: 6144 training error: 0.4207687990433558\n",
            "At step: 6145 training error: 0.40764558676214885\n",
            "At step: 6146 training error: 0.3991645751483597\n",
            "At step: 6147 training error: 0.39369683102774494\n",
            "At step: 6148 training error: 0.3891991175464017\n",
            "At step: 6149 training error: 0.3914023006563498\n",
            "At step: 6150 training error: 0.3913367540105786\n",
            "At step: 6151 training error: 0.39544914710892587\n",
            "At step: 6152 training error: 0.4007065771734091\n",
            "At step: 6153 training error: 0.38937976639190053\n",
            "At step: 6154 training error: 0.3849703879064947\n",
            "At step: 6155 training error: 0.3836714449849282\n",
            "At step: 6156 training error: 0.38397548557607764\n",
            "At step: 6157 training error: 0.38500882824241905\n",
            "At step: 6158 training error: 0.3902171073992439\n",
            "At step: 6159 training error: 0.38609111049555683\n",
            "At step: 6160 training error: 0.38133483033215\n",
            "At step: 6161 training error: 0.38149918798813204\n",
            "At step: 6162 training error: 0.36864516653148577\n",
            "At step: 6163 training error: 0.36959080167000224\n",
            "At step: 6164 training error: 0.3754176895341327\n",
            "At step: 6165 training error: 0.37000219483817226\n",
            "At step: 6166 training error: 0.3728176227395867\n",
            "At step: 6167 training error: 0.37337198517099146\n",
            "At step: 6168 training error: 0.37219304475091003\n",
            "At step: 6169 training error: 0.37299787327697215\n",
            "At step: 6170 training error: 0.37885322567191193\n",
            "At step: 6171 training error: 0.37901196092771744\n",
            "At step: 6172 training error: 0.37831188499603374\n",
            "At step: 6173 training error: 0.3792193200387736\n",
            "At step: 6174 training error: 0.3773606739482151\n",
            "At step: 6175 training error: 0.38251923905146407\n",
            "At step: 6176 training error: 0.37418068208200783\n",
            "At step: 6177 training error: 0.37721150528985775\n",
            "At step: 6178 training error: 0.3846303195204167\n",
            "At step: 6179 training error: 0.3836962491908301\n",
            "At step: 6180 training error: 0.3847764447091802\n",
            "At step: 6181 training error: 0.3887789483042696\n",
            "At step: 6182 training error: 0.38870348510902564\n",
            "At step: 6183 training error: 0.3933462938953546\n",
            "At step: 6184 training error: 0.3991932968718762\n",
            "At step: 6185 training error: 0.39306727257580687\n",
            "At step: 6186 training error: 0.405865423813656\n",
            "At step: 6187 training error: 0.40661080035907327\n",
            "At step: 6188 training error: 0.4220746413258418\n",
            "At step: 6189 training error: 0.41444247720280003\n",
            "At step: 6190 training error: 0.40904423367543\n",
            "At step: 6191 training error: 0.4097794722514122\n",
            "At step: 6192 training error: 0.41434852864819643\n",
            "At step: 6193 training error: 0.4164469266228191\n",
            "At step: 6194 training error: 0.4129106011298623\n",
            "At step: 6195 training error: 0.41002869768480066\n",
            "At step: 6196 training error: 0.4185217290565588\n",
            "At step: 6197 training error: 0.4125031532196629\n",
            "At step: 6198 training error: 0.40969168468454636\n",
            "At step: 6199 training error: 0.4137547744799216\n",
            "At step: 6200 training error: 0.4248687114837802\n",
            "At step: 6201 training error: 0.4228430765782794\n",
            "At step: 6202 training error: 0.41737009266429165\n",
            "At step: 6203 training error: 0.4157041971374155\n",
            "At step: 6204 training error: 0.40619302082227776\n",
            "At step: 6205 training error: 0.41543661755638184\n",
            "At step: 6206 training error: 0.4052800435276898\n",
            "At step: 6207 training error: 0.41155178059614445\n",
            "At step: 6208 training error: 0.4136299290193197\n",
            "At step: 6209 training error: 0.4158923346401333\n",
            "At step: 6210 training error: 0.4186783101917244\n",
            "At step: 6211 training error: 0.42013361689245654\n",
            "At step: 6212 training error: 0.41477074975354195\n",
            "At step: 6213 training error: 0.41357283662803057\n",
            "At step: 6214 training error: 0.40603680031426326\n",
            "At step: 6215 training error: 0.40610000309003963\n",
            "At step: 6216 training error: 0.4039203987214627\n",
            "At step: 6217 training error: 0.40578867737636454\n",
            "At step: 6218 training error: 0.40502469821830583\n",
            "At step: 6219 training error: 0.3976525034384813\n",
            "At step: 6220 training error: 0.3911255394959485\n",
            "At step: 6221 training error: 0.39688264252552063\n",
            "At step: 6222 training error: 0.40086784678833437\n",
            "At step: 6223 training error: 0.40406668088696523\n",
            "At step: 6224 training error: 0.4188528017210612\n",
            "At step: 6225 training error: 0.4286351709598224\n",
            "At step: 6226 training error: 0.42075839018418426\n",
            "At step: 6227 training error: 0.42040718921006925\n",
            "At step: 6228 training error: 0.4223804612569721\n",
            "At step: 6229 training error: 0.42372656824778543\n",
            "At step: 6230 training error: 0.41482651521013697\n",
            "At step: 6231 training error: 0.4158469058850466\n",
            "At step: 6232 training error: 0.41891215958976885\n",
            "At step: 6233 training error: 0.41118856665069725\n",
            "At step: 6234 training error: 0.40823111257824296\n",
            "At step: 6235 training error: 0.4001734975190653\n",
            "At step: 6236 training error: 0.3927143087332799\n",
            "At step: 6237 training error: 0.39323693043007013\n",
            "At step: 6238 training error: 0.3989127696844275\n",
            "At step: 6239 training error: 0.3893780537851136\n",
            "At step: 6240 training error: 0.3847943555719652\n",
            "At step: 6241 training error: 0.3885468968381657\n",
            "At step: 6242 training error: 0.38305367122222783\n",
            "At step: 6243 training error: 0.38854967806088253\n",
            "At step: 6244 training error: 0.40087195493225897\n",
            "At step: 6245 training error: 0.40772985649993543\n",
            "At step: 6246 training error: 0.4174357051192346\n",
            "At step: 6247 training error: 0.41265943667330257\n",
            "At step: 6248 training error: 0.4129348802334529\n",
            "At step: 6249 training error: 0.4086481950377786\n",
            "At step: 6250 training error: 0.39948079226671335\n",
            "At step: 6251 training error: 0.40813952005497545\n",
            "At step: 6252 training error: 0.40512465295046546\n",
            "At step: 6253 training error: 0.4033096262837449\n",
            "At step: 6254 training error: 0.39017913191637066\n",
            "At step: 6255 training error: 0.40005030108405326\n",
            "At step: 6256 training error: 0.40821239205280124\n",
            "At step: 6257 training error: 0.42388862548118617\n",
            "At step: 6258 training error: 0.4151090038879045\n",
            "At step: 6259 training error: 0.39959321977464285\n",
            "At step: 6260 training error: 0.408301578030675\n",
            "At step: 6261 training error: 0.409672357689904\n",
            "At step: 6262 training error: 0.4021535230506084\n",
            "At step: 6263 training error: 0.4077828805563867\n",
            "At step: 6264 training error: 0.39711171262065303\n",
            "At step: 6265 training error: 0.40162618926952903\n",
            "At step: 6266 training error: 0.41237788922863633\n",
            "At step: 6267 training error: 0.41972615978479344\n",
            "At step: 6268 training error: 0.41581524061509556\n",
            "At step: 6269 training error: 0.4151004931266138\n",
            "At step: 6270 training error: 0.4222328542209784\n",
            "At step: 6271 training error: 0.42363255981734976\n",
            "At step: 6272 training error: 0.4139586434944465\n",
            "At step: 6273 training error: 0.4059947045896041\n",
            "At step: 6274 training error: 0.41015483526043955\n",
            "At step: 6275 training error: 0.40534902946022555\n",
            "At step: 6276 training error: 0.4014725140098887\n",
            "At step: 6277 training error: 0.3980017184521033\n",
            "At step: 6278 training error: 0.3935546815638076\n",
            "At step: 6279 training error: 0.39251416752395696\n",
            "At step: 6280 training error: 0.3932572177907523\n",
            "At step: 6281 training error: 0.39170266952550925\n",
            "At step: 6282 training error: 0.39308424889483906\n",
            "At step: 6283 training error: 0.39440098320236466\n",
            "At step: 6284 training error: 0.3808481883675824\n",
            "At step: 6285 training error: 0.3823016940325224\n",
            "At step: 6286 training error: 0.3986390691225666\n",
            "At step: 6287 training error: 0.4031865839661711\n",
            "At step: 6288 training error: 0.4134516568784853\n",
            "At step: 6289 training error: 0.4142494760438516\n",
            "At step: 6290 training error: 0.41271119075238555\n",
            "At step: 6291 training error: 0.41450732550848507\n",
            "At step: 6292 training error: 0.41319218703507565\n",
            "At step: 6293 training error: 0.4209333237977517\n",
            "At step: 6294 training error: 0.41997370306133963\n",
            "At step: 6295 training error: 0.4125705051667574\n",
            "At step: 6296 training error: 0.41462075784709224\n",
            "At step: 6297 training error: 0.4083956673739585\n",
            "At step: 6298 training error: 0.39528069579992947\n",
            "At step: 6299 training error: 0.4105657714141323\n",
            "At step: 6300 training error: 0.420651834090034\n",
            "At step: 6301 training error: 0.42474623356800173\n",
            "At step: 6302 training error: 0.4145076498064918\n",
            "At step: 6303 training error: 0.41963082990213024\n",
            "At step: 6304 training error: 0.4189149297128856\n",
            "At step: 6305 training error: 0.4228984160479531\n",
            "At step: 6306 training error: 0.42935007693118005\n",
            "At step: 6307 training error: 0.4197205707756923\n",
            "At step: 6308 training error: 0.4167212944093171\n",
            "At step: 6309 training error: 0.41428880998480383\n",
            "At step: 6310 training error: 0.4109820727663092\n",
            "At step: 6311 training error: 0.4231583063844223\n",
            "At step: 6312 training error: 0.4309981745975965\n",
            "At step: 6313 training error: 0.43189098403093296\n",
            "At step: 6314 training error: 0.43892409048820313\n",
            "At step: 6315 training error: 0.4484921956112191\n",
            "At step: 6316 training error: 0.45663672199497424\n",
            "At step: 6317 training error: 0.4516045651830827\n",
            "At step: 6318 training error: 0.44192084549362\n",
            "At step: 6319 training error: 0.4376222407068964\n",
            "At step: 6320 training error: 0.43742748231374645\n",
            "At step: 6321 training error: 0.4399609259421836\n",
            "At step: 6322 training error: 0.43188936592969973\n",
            "At step: 6323 training error: 0.4168293559788876\n",
            "At step: 6324 training error: 0.40896065961572464\n",
            "At step: 6325 training error: 0.40841758446247\n",
            "At step: 6326 training error: 0.40892240977799277\n",
            "At step: 6327 training error: 0.4116266559113404\n",
            "At step: 6328 training error: 0.41508204872969734\n",
            "At step: 6329 training error: 0.413964357750105\n",
            "At step: 6330 training error: 0.41296574886665416\n",
            "At step: 6331 training error: 0.40954431754417864\n",
            "At step: 6332 training error: 0.4047368986719624\n",
            "At step: 6333 training error: 0.39467359587544865\n",
            "At step: 6334 training error: 0.41096513581119787\n",
            "At step: 6335 training error: 0.4139230937047527\n",
            "At step: 6336 training error: 0.41898512372899177\n",
            "At step: 6337 training error: 0.4104238398207727\n",
            "At step: 6338 training error: 0.41186860877980735\n",
            "At step: 6339 training error: 0.4108088277549767\n",
            "At step: 6340 training error: 0.40667713797910454\n",
            "At step: 6341 training error: 0.40379891354114505\n",
            "At step: 6342 training error: 0.3996598011884481\n",
            "At step: 6343 training error: 0.3988600927756428\n",
            "At step: 6344 training error: 0.3920766763582818\n",
            "At step: 6345 training error: 0.4057930690667194\n",
            "At step: 6346 training error: 0.4017829541620944\n",
            "At step: 6347 training error: 0.3942294083112605\n",
            "At step: 6348 training error: 0.39355904578275946\n",
            "At step: 6349 training error: 0.4092606057244534\n",
            "At step: 6350 training error: 0.4021023715572512\n",
            "At step: 6351 training error: 0.4105735240375245\n",
            "At step: 6352 training error: 0.4143343183152868\n",
            "At step: 6353 training error: 0.41690608594592393\n",
            "At step: 6354 training error: 0.4096862396428375\n",
            "At step: 6355 training error: 0.41225029329333185\n",
            "At step: 6356 training error: 0.4147947073079269\n",
            "At step: 6357 training error: 0.40834902695732894\n",
            "At step: 6358 training error: 0.40582752468039884\n",
            "At step: 6359 training error: 0.4034738982221547\n",
            "At step: 6360 training error: 0.40119647004428904\n",
            "At step: 6361 training error: 0.4035835495435426\n",
            "At step: 6362 training error: 0.39668002079125825\n",
            "At step: 6363 training error: 0.4005509577401606\n",
            "At step: 6364 training error: 0.3979771018071254\n",
            "At step: 6365 training error: 0.39059681569797666\n",
            "At step: 6366 training error: 0.3772175181095234\n",
            "At step: 6367 training error: 0.38693038320956896\n",
            "At step: 6368 training error: 0.3929229234209498\n",
            "At step: 6369 training error: 0.39916251253679547\n",
            "At step: 6370 training error: 0.39623539724741197\n",
            "At step: 6371 training error: 0.3997506596531446\n",
            "At step: 6372 training error: 0.39845651301755836\n",
            "At step: 6373 training error: 0.3990228244813351\n",
            "At step: 6374 training error: 0.4047155011252236\n",
            "At step: 6375 training error: 0.41412432788598774\n",
            "At step: 6376 training error: 0.4061299445322766\n",
            "At step: 6377 training error: 0.3995845216807352\n",
            "At step: 6378 training error: 0.4024886870871652\n",
            "At step: 6379 training error: 0.4062422846959591\n",
            "At step: 6380 training error: 0.39406999856457825\n",
            "At step: 6381 training error: 0.3842405818006152\n",
            "At step: 6382 training error: 0.3827786766610325\n",
            "At step: 6383 training error: 0.37626257265293994\n",
            "At step: 6384 training error: 0.3786265412060253\n",
            "At step: 6385 training error: 0.37207881319407254\n",
            "At step: 6386 training error: 0.3688472807302583\n",
            "At step: 6387 training error: 0.3650170684828279\n",
            "At step: 6388 training error: 0.36150221714007047\n",
            "At step: 6389 training error: 0.36312211218796464\n",
            "At step: 6390 training error: 0.3598746019681739\n",
            "At step: 6391 training error: 0.35835496632422625\n",
            "At step: 6392 training error: 0.3565721109217457\n",
            "At step: 6393 training error: 0.36182358570342976\n",
            "At step: 6394 training error: 0.36712330297922907\n",
            "At step: 6395 training error: 0.37316141120115204\n",
            "At step: 6396 training error: 0.3736326182606714\n",
            "At step: 6397 training error: 0.37015035203914154\n",
            "At step: 6398 training error: 0.3734979659859749\n",
            "At step: 6399 training error: 0.3770196158568318\n",
            "At step: 6400 training error: 0.376285718311649\n",
            "At step: 6401 training error: 0.36802137445515926\n",
            "At step: 6402 training error: 0.3682371074066035\n",
            "At step: 6403 training error: 0.36526479710146137\n",
            "At step: 6404 training error: 0.3761115254089318\n",
            "At step: 6405 training error: 0.38286448712489385\n",
            "At step: 6406 training error: 0.3900022575251522\n",
            "At step: 6407 training error: 0.39594845809324997\n",
            "At step: 6408 training error: 0.3990357160383502\n",
            "At step: 6409 training error: 0.4029046723301564\n",
            "At step: 6410 training error: 0.40538781951495056\n",
            "At step: 6411 training error: 0.4052335003404054\n",
            "At step: 6412 training error: 0.40781450480781295\n",
            "At step: 6413 training error: 0.4105420428482116\n",
            "At step: 6414 training error: 0.392886041887909\n",
            "At step: 6415 training error: 0.3887533321670534\n",
            "At step: 6416 training error: 0.4000791586425314\n",
            "At step: 6417 training error: 0.4038224870470818\n",
            "At step: 6418 training error: 0.391543742025194\n",
            "At step: 6419 training error: 0.3999737095971366\n",
            "At step: 6420 training error: 0.39707200648966756\n",
            "At step: 6421 training error: 0.3883971629372153\n",
            "At step: 6422 training error: 0.3948346770429322\n",
            "At step: 6423 training error: 0.3932472923886587\n",
            "At step: 6424 training error: 0.393560063088781\n",
            "At step: 6425 training error: 0.41025513861569296\n",
            "At step: 6426 training error: 0.40738964163587865\n",
            "At step: 6427 training error: 0.40243545922111085\n",
            "At step: 6428 training error: 0.4070472098184907\n",
            "At step: 6429 training error: 0.40301489668432244\n",
            "At step: 6430 training error: 0.40680559852949405\n",
            "At step: 6431 training error: 0.41181072774890637\n",
            "At step: 6432 training error: 0.40689572763000126\n",
            "At step: 6433 training error: 0.4123500985003166\n",
            "At step: 6434 training error: 0.402093612660087\n",
            "At step: 6435 training error: 0.39793133917209433\n",
            "At step: 6436 training error: 0.4052396094718114\n",
            "At step: 6437 training error: 0.4065740012850419\n",
            "At step: 6438 training error: 0.39838808165165335\n",
            "At step: 6439 training error: 0.40654723124086883\n",
            "At step: 6440 training error: 0.4032985672429183\n",
            "At step: 6441 training error: 0.3930564489893898\n",
            "At step: 6442 training error: 0.38910418548686665\n",
            "At step: 6443 training error: 0.3904905939975371\n",
            "At step: 6444 training error: 0.3889513457340649\n",
            "At step: 6445 training error: 0.3943895130016925\n",
            "At step: 6446 training error: 0.3935039515884014\n",
            "At step: 6447 training error: 0.39940215299617643\n",
            "At step: 6448 training error: 0.38992723260250156\n",
            "At step: 6449 training error: 0.393268482094945\n",
            "At step: 6450 training error: 0.3828817184149598\n",
            "At step: 6451 training error: 0.3878051215972683\n",
            "At step: 6452 training error: 0.39251529342486824\n",
            "At step: 6453 training error: 0.39206975499307456\n",
            "At step: 6454 training error: 0.3992663073008357\n",
            "At step: 6455 training error: 0.40009855621374024\n",
            "At step: 6456 training error: 0.3917139523694834\n",
            "At step: 6457 training error: 0.39340627455193483\n",
            "At step: 6458 training error: 0.4004259027502118\n",
            "At step: 6459 training error: 0.38708839380152926\n",
            "At step: 6460 training error: 0.3932885757170474\n",
            "At step: 6461 training error: 0.3877266980699152\n",
            "At step: 6462 training error: 0.3823141424713476\n",
            "At step: 6463 training error: 0.38009551145171155\n",
            "At step: 6464 training error: 0.3821954034840409\n",
            "At step: 6465 training error: 0.3862148568887548\n",
            "At step: 6466 training error: 0.396336885402086\n",
            "At step: 6467 training error: 0.4066248481254263\n",
            "At step: 6468 training error: 0.41466742768417064\n",
            "At step: 6469 training error: 0.41396719326093856\n",
            "At step: 6470 training error: 0.40823582078714127\n",
            "At step: 6471 training error: 0.40201841992185433\n",
            "At step: 6472 training error: 0.3889093538129518\n",
            "At step: 6473 training error: 0.388191888283861\n",
            "At step: 6474 training error: 0.38908737763469814\n",
            "At step: 6475 training error: 0.4018243388996038\n",
            "At step: 6476 training error: 0.39488184842426055\n",
            "At step: 6477 training error: 0.39604390339400236\n",
            "At step: 6478 training error: 0.4033062915348925\n",
            "At step: 6479 training error: 0.3985827912293489\n",
            "At step: 6480 training error: 0.40613681031129467\n",
            "At step: 6481 training error: 0.3959390047056684\n",
            "At step: 6482 training error: 0.40275211968567415\n",
            "At step: 6483 training error: 0.406707714498868\n",
            "At step: 6484 training error: 0.3981459470692649\n",
            "At step: 6485 training error: 0.39174193516310396\n",
            "At step: 6486 training error: 0.3978122759066597\n",
            "At step: 6487 training error: 0.39917804931698125\n",
            "At step: 6488 training error: 0.40527769660535384\n",
            "At step: 6489 training error: 0.41280963031139745\n",
            "At step: 6490 training error: 0.4182896003821451\n",
            "At step: 6491 training error: 0.4197593360237815\n",
            "At step: 6492 training error: 0.418755609052418\n",
            "At step: 6493 training error: 0.41341948630629555\n",
            "At step: 6494 training error: 0.4233675650345345\n",
            "At step: 6495 training error: 0.42151819114886724\n",
            "At step: 6496 training error: 0.40826381305668463\n",
            "At step: 6497 training error: 0.39572272288621957\n",
            "At step: 6498 training error: 0.3926308867587097\n",
            "At step: 6499 training error: 0.3968019944285164\n",
            "At step: 6500 training error: 0.39871887930683486\n",
            "At step: 6501 training error: 0.4080351939706959\n",
            "At step: 6502 training error: 0.4026917481567869\n",
            "At step: 6503 training error: 0.41174519746508914\n",
            "At step: 6504 training error: 0.40121866055263106\n",
            "At step: 6505 training error: 0.3938297877102114\n",
            "At step: 6506 training error: 0.38636917679668387\n",
            "At step: 6507 training error: 0.37715889684380294\n",
            "At step: 6508 training error: 0.3816405905164822\n",
            "At step: 6509 training error: 0.380848008209584\n",
            "At step: 6510 training error: 0.3793437005690253\n",
            "At step: 6511 training error: 0.3833502214211845\n",
            "At step: 6512 training error: 0.38689069201656456\n",
            "At step: 6513 training error: 0.40631424890015105\n",
            "At step: 6514 training error: 0.39963277863379804\n",
            "At step: 6515 training error: 0.4066960940049915\n",
            "At step: 6516 training error: 0.402282802608036\n",
            "At step: 6517 training error: 0.41038609004663473\n",
            "At step: 6518 training error: 0.3999424145966765\n",
            "At step: 6519 training error: 0.40446239083274976\n",
            "At step: 6520 training error: 0.39572119351531015\n",
            "At step: 6521 training error: 0.40098867403586724\n",
            "At step: 6522 training error: 0.3939747464739524\n",
            "At step: 6523 training error: 0.38667669955669776\n",
            "At step: 6524 training error: 0.3880419020768964\n",
            "At step: 6525 training error: 0.3950275671847994\n",
            "At step: 6526 training error: 0.3951325960899346\n",
            "At step: 6527 training error: 0.3905717653184986\n",
            "At step: 6528 training error: 0.38421562822523025\n",
            "At step: 6529 training error: 0.394085862815455\n",
            "At step: 6530 training error: 0.3932472822851002\n",
            "At step: 6531 training error: 0.39041011068626386\n",
            "At step: 6532 training error: 0.38476628589097545\n",
            "At step: 6533 training error: 0.38512661707330487\n",
            "At step: 6534 training error: 0.379185389992196\n",
            "At step: 6535 training error: 0.3779273887049486\n",
            "At step: 6536 training error: 0.3766170114360797\n",
            "At step: 6537 training error: 0.38265915914631554\n",
            "At step: 6538 training error: 0.37916773066925574\n",
            "At step: 6539 training error: 0.39108231484663414\n",
            "At step: 6540 training error: 0.3903577360337363\n",
            "At step: 6541 training error: 0.38504009350618573\n",
            "At step: 6542 training error: 0.37307242297971105\n",
            "At step: 6543 training error: 0.37307462977542594\n",
            "At step: 6544 training error: 0.3750587412628556\n",
            "At step: 6545 training error: 0.37845875910195087\n",
            "At step: 6546 training error: 0.3760397981367878\n",
            "At step: 6547 training error: 0.37973187099787076\n",
            "At step: 6548 training error: 0.3734874113297944\n",
            "At step: 6549 training error: 0.37144534068981105\n",
            "At step: 6550 training error: 0.37495891111242075\n",
            "At step: 6551 training error: 0.36240659545944515\n",
            "At step: 6552 training error: 0.35283761306597955\n",
            "At step: 6553 training error: 0.3514908992156216\n",
            "At step: 6554 training error: 0.35667384283856196\n",
            "At step: 6555 training error: 0.36995881725687646\n",
            "At step: 6556 training error: 0.3794240538317792\n",
            "At step: 6557 training error: 0.3878684557713695\n",
            "At step: 6558 training error: 0.38124946905012763\n",
            "At step: 6559 training error: 0.3903883429621301\n",
            "At step: 6560 training error: 0.3878457111278793\n",
            "At step: 6561 training error: 0.3874167225168394\n",
            "At step: 6562 training error: 0.3854523596213766\n",
            "At step: 6563 training error: 0.3944987849350534\n",
            "At step: 6564 training error: 0.38741968736357085\n",
            "At step: 6565 training error: 0.3830213610323513\n",
            "At step: 6566 training error: 0.37286782556541914\n",
            "At step: 6567 training error: 0.37784118472453515\n",
            "At step: 6568 training error: 0.3737894263280241\n",
            "At step: 6569 training error: 0.37870911551740283\n",
            "At step: 6570 training error: 0.38039345511122236\n",
            "At step: 6571 training error: 0.3936453578276048\n",
            "At step: 6572 training error: 0.39545506726792046\n",
            "At step: 6573 training error: 0.39281616577754186\n",
            "At step: 6574 training error: 0.39758934298096194\n",
            "At step: 6575 training error: 0.3898410896813256\n",
            "At step: 6576 training error: 0.38192354164863274\n",
            "At step: 6577 training error: 0.3830557696708192\n",
            "At step: 6578 training error: 0.3880355882830763\n",
            "At step: 6579 training error: 0.37810448708450617\n",
            "At step: 6580 training error: 0.3769873143556488\n",
            "At step: 6581 training error: 0.37206252043813315\n",
            "At step: 6582 training error: 0.3814766083777427\n",
            "At step: 6583 training error: 0.3758287935042721\n",
            "At step: 6584 training error: 0.37805565484491926\n",
            "At step: 6585 training error: 0.3802797298963605\n",
            "At step: 6586 training error: 0.3874571779666469\n",
            "At step: 6587 training error: 0.3960654513271795\n",
            "At step: 6588 training error: 0.39944606966832885\n",
            "At step: 6589 training error: 0.3935120865915752\n",
            "At step: 6590 training error: 0.3888371713525557\n",
            "At step: 6591 training error: 0.38529743190403587\n",
            "At step: 6592 training error: 0.4005836126870695\n",
            "At step: 6593 training error: 0.3943458750995563\n",
            "At step: 6594 training error: 0.3859329702966714\n",
            "At step: 6595 training error: 0.38617677506684134\n",
            "At step: 6596 training error: 0.3851297862646038\n",
            "At step: 6597 training error: 0.376839937817464\n",
            "At step: 6598 training error: 0.3829842516324282\n",
            "At step: 6599 training error: 0.3830555708490295\n",
            "At step: 6600 training error: 0.3748189549824045\n",
            "At step: 6601 training error: 0.3799839059711071\n",
            "At step: 6602 training error: 0.3813002590123469\n",
            "At step: 6603 training error: 0.3857312565889325\n",
            "At step: 6604 training error: 0.37976701966056925\n",
            "At step: 6605 training error: 0.3767002054057724\n",
            "At step: 6606 training error: 0.38359540357437216\n",
            "At step: 6607 training error: 0.38522844994322936\n",
            "At step: 6608 training error: 0.393711217102284\n",
            "At step: 6609 training error: 0.3928284426653857\n",
            "At step: 6610 training error: 0.390127593350938\n",
            "At step: 6611 training error: 0.38721282084637765\n",
            "At step: 6612 training error: 0.38928696465593937\n",
            "At step: 6613 training error: 0.3740192262181006\n",
            "At step: 6614 training error: 0.3746621052306778\n",
            "At step: 6615 training error: 0.3807044632568794\n",
            "At step: 6616 training error: 0.38426648288879495\n",
            "At step: 6617 training error: 0.38200911933139514\n",
            "At step: 6618 training error: 0.38386416402263923\n",
            "At step: 6619 training error: 0.3949414599629355\n",
            "At step: 6620 training error: 0.39802791140402055\n",
            "At step: 6621 training error: 0.39543250722740836\n",
            "At step: 6622 training error: 0.3905496655557867\n",
            "At step: 6623 training error: 0.38766102570427385\n",
            "At step: 6624 training error: 0.3816220315215146\n",
            "At step: 6625 training error: 0.38668359116395445\n",
            "At step: 6626 training error: 0.3906084131394467\n",
            "At step: 6627 training error: 0.39743573101434154\n",
            "At step: 6628 training error: 0.40515671652896496\n",
            "At step: 6629 training error: 0.4043237599530467\n",
            "At step: 6630 training error: 0.40481331500931705\n",
            "At step: 6631 training error: 0.4077479695513258\n",
            "At step: 6632 training error: 0.4074094315394626\n",
            "At step: 6633 training error: 0.41752695068557705\n",
            "At step: 6634 training error: 0.4110550406314656\n",
            "At step: 6635 training error: 0.4067796918087148\n",
            "At step: 6636 training error: 0.39578597604253896\n",
            "At step: 6637 training error: 0.3868345634159359\n",
            "At step: 6638 training error: 0.3854685494319686\n",
            "At step: 6639 training error: 0.382712613868415\n",
            "At step: 6640 training error: 0.39034284677308506\n",
            "At step: 6641 training error: 0.39449842813939195\n",
            "At step: 6642 training error: 0.38637206411103364\n",
            "At step: 6643 training error: 0.37971885453062426\n",
            "At step: 6644 training error: 0.38365121615903286\n",
            "At step: 6645 training error: 0.3808664808426168\n",
            "At step: 6646 training error: 0.38234689635118285\n",
            "At step: 6647 training error: 0.3857072139107005\n",
            "At step: 6648 training error: 0.38649852212535185\n",
            "At step: 6649 training error: 0.39484292654977604\n",
            "At step: 6650 training error: 0.39723029303241786\n",
            "At step: 6651 training error: 0.3843460813730221\n",
            "At step: 6652 training error: 0.37899337540346817\n",
            "At step: 6653 training error: 0.3968898718802623\n",
            "At step: 6654 training error: 0.39150583163750224\n",
            "At step: 6655 training error: 0.39242749192152465\n",
            "At step: 6656 training error: 0.4094990426212034\n",
            "At step: 6657 training error: 0.412993936074841\n",
            "At step: 6658 training error: 0.4056350796968362\n",
            "At step: 6659 training error: 0.4011991527316349\n",
            "At step: 6660 training error: 0.40525274187141375\n",
            "At step: 6661 training error: 0.3995135700921079\n",
            "At step: 6662 training error: 0.40462083527982096\n",
            "At step: 6663 training error: 0.3981328616008663\n",
            "At step: 6664 training error: 0.4001777375146528\n",
            "At step: 6665 training error: 0.3956423894405988\n",
            "At step: 6666 training error: 0.4021000420037455\n",
            "At step: 6667 training error: 0.40187455955226103\n",
            "At step: 6668 training error: 0.4144352580463736\n",
            "At step: 6669 training error: 0.42014479397520105\n",
            "At step: 6670 training error: 0.41849341322291045\n",
            "At step: 6671 training error: 0.4223107051805166\n",
            "At step: 6672 training error: 0.42534475374715347\n",
            "At step: 6673 training error: 0.4140411498624541\n",
            "At step: 6674 training error: 0.42498812317594264\n",
            "At step: 6675 training error: 0.4151232404638832\n",
            "At step: 6676 training error: 0.4118199539790067\n",
            "At step: 6677 training error: 0.4033852450876866\n",
            "At step: 6678 training error: 0.3988449002455683\n",
            "At step: 6679 training error: 0.4072549150097916\n",
            "At step: 6680 training error: 0.40727012654473815\n",
            "At step: 6681 training error: 0.4013433280563844\n",
            "At step: 6682 training error: 0.40519796535655184\n",
            "At step: 6683 training error: 0.4027765082757908\n",
            "At step: 6684 training error: 0.39874223657914837\n",
            "At step: 6685 training error: 0.3950721676058455\n",
            "At step: 6686 training error: 0.39473157273912646\n",
            "At step: 6687 training error: 0.3888783045235536\n",
            "At step: 6688 training error: 0.3947095911317181\n",
            "At step: 6689 training error: 0.3853045658967436\n",
            "At step: 6690 training error: 0.3941827271023785\n",
            "At step: 6691 training error: 0.3910135839747861\n",
            "At step: 6692 training error: 0.3928318322491129\n",
            "At step: 6693 training error: 0.4126829493057127\n",
            "At step: 6694 training error: 0.41282680438242314\n",
            "At step: 6695 training error: 0.40715500157017853\n",
            "At step: 6696 training error: 0.4048187842315813\n",
            "At step: 6697 training error: 0.4021110904228081\n",
            "At step: 6698 training error: 0.4062160139329701\n",
            "At step: 6699 training error: 0.39390351364435877\n",
            "At step: 6700 training error: 0.3994821100325336\n",
            "At step: 6701 training error: 0.3993978180675992\n",
            "At step: 6702 training error: 0.40086796406165975\n",
            "At step: 6703 training error: 0.3951012637388733\n",
            "At step: 6704 training error: 0.3914719769123475\n",
            "At step: 6705 training error: 0.4007269592621109\n",
            "At step: 6706 training error: 0.4067752864611758\n",
            "At step: 6707 training error: 0.40532357577494577\n",
            "At step: 6708 training error: 0.3981553149273031\n",
            "At step: 6709 training error: 0.40057692889872665\n",
            "At step: 6710 training error: 0.404112407572035\n",
            "At step: 6711 training error: 0.4036650656262979\n",
            "At step: 6712 training error: 0.40301212931662983\n",
            "At step: 6713 training error: 0.39797231477349376\n",
            "At step: 6714 training error: 0.40101714177905473\n",
            "At step: 6715 training error: 0.4014439307448271\n",
            "At step: 6716 training error: 0.39603849980413336\n",
            "At step: 6717 training error: 0.39468192293586424\n",
            "At step: 6718 training error: 0.40499750353036434\n",
            "At step: 6719 training error: 0.4051448804857015\n",
            "At step: 6720 training error: 0.40873933274978663\n",
            "At step: 6721 training error: 0.4177179092469536\n",
            "At step: 6722 training error: 0.4175509701830188\n",
            "At step: 6723 training error: 0.41675587930546465\n",
            "At step: 6724 training error: 0.4225313975056197\n",
            "At step: 6725 training error: 0.429549684548121\n",
            "At step: 6726 training error: 0.4133622906694467\n",
            "At step: 6727 training error: 0.41182853796569546\n",
            "At step: 6728 training error: 0.4091121460237024\n",
            "At step: 6729 training error: 0.41074568188120325\n",
            "At step: 6730 training error: 0.40053587392377465\n",
            "At step: 6731 training error: 0.4041478096420624\n",
            "At step: 6732 training error: 0.4109973609872368\n",
            "At step: 6733 training error: 0.40191077463154257\n",
            "At step: 6734 training error: 0.4008784960450802\n",
            "At step: 6735 training error: 0.3983475489079561\n",
            "At step: 6736 training error: 0.3950846546524396\n",
            "At step: 6737 training error: 0.3943575088292713\n",
            "At step: 6738 training error: 0.39845461777776553\n",
            "At step: 6739 training error: 0.40483195180201126\n",
            "At step: 6740 training error: 0.4103881132198299\n",
            "At step: 6741 training error: 0.4139708707007341\n",
            "At step: 6742 training error: 0.41129362744980913\n",
            "At step: 6743 training error: 0.40373927245461533\n",
            "At step: 6744 training error: 0.3986901300461038\n",
            "At step: 6745 training error: 0.39696946460579247\n",
            "At step: 6746 training error: 0.39798830848078853\n",
            "At step: 6747 training error: 0.3930273504522244\n",
            "At step: 6748 training error: 0.39167543611155603\n",
            "At step: 6749 training error: 0.396341827240202\n",
            "At step: 6750 training error: 0.39259740930340103\n",
            "At step: 6751 training error: 0.3977184270951479\n",
            "At step: 6752 training error: 0.3968165124007416\n",
            "At step: 6753 training error: 0.4058042212165038\n",
            "At step: 6754 training error: 0.39059732592311275\n",
            "At step: 6755 training error: 0.3948913083753665\n",
            "At step: 6756 training error: 0.3867869365625185\n",
            "At step: 6757 training error: 0.39269551899886407\n",
            "At step: 6758 training error: 0.38540689920396354\n",
            "At step: 6759 training error: 0.3858549824327902\n",
            "At step: 6760 training error: 0.38737901173512185\n",
            "At step: 6761 training error: 0.4014887740374201\n",
            "At step: 6762 training error: 0.39119372491408966\n",
            "At step: 6763 training error: 0.3833061676920765\n",
            "At step: 6764 training error: 0.37228070577954786\n",
            "At step: 6765 training error: 0.37587209599502514\n",
            "At step: 6766 training error: 0.3796013710664968\n",
            "At step: 6767 training error: 0.38674338959611604\n",
            "At step: 6768 training error: 0.3863787109993725\n",
            "At step: 6769 training error: 0.3788426369276026\n",
            "At step: 6770 training error: 0.3844779086036013\n",
            "At step: 6771 training error: 0.3802377005932919\n",
            "At step: 6772 training error: 0.37760800124906796\n",
            "At step: 6773 training error: 0.37846565475435967\n",
            "At step: 6774 training error: 0.3803304631395221\n",
            "At step: 6775 training error: 0.37572721627939476\n",
            "At step: 6776 training error: 0.37346290925756875\n",
            "At step: 6777 training error: 0.3851934475874995\n",
            "At step: 6778 training error: 0.38612544538451066\n",
            "At step: 6779 training error: 0.3858598315210437\n",
            "At step: 6780 training error: 0.3944804980543504\n",
            "At step: 6781 training error: 0.3862731933585651\n",
            "At step: 6782 training error: 0.3976795697822665\n",
            "At step: 6783 training error: 0.40520110150337196\n",
            "At step: 6784 training error: 0.4049367425773652\n",
            "At step: 6785 training error: 0.4064526923314443\n",
            "At step: 6786 training error: 0.4072859566750266\n",
            "At step: 6787 training error: 0.40230036326088014\n",
            "At step: 6788 training error: 0.3978662862190304\n",
            "At step: 6789 training error: 0.3939002837225294\n",
            "At step: 6790 training error: 0.3911641307190591\n",
            "At step: 6791 training error: 0.39051051856805025\n",
            "At step: 6792 training error: 0.39415622467107364\n",
            "At step: 6793 training error: 0.3945888350493068\n",
            "At step: 6794 training error: 0.37979504933314684\n",
            "At step: 6795 training error: 0.3805986013259374\n",
            "At step: 6796 training error: 0.37015569742431353\n",
            "At step: 6797 training error: 0.3594173184415184\n",
            "At step: 6798 training error: 0.3544797101023909\n",
            "At step: 6799 training error: 0.3621715972656779\n",
            "At step: 6800 training error: 0.36930114639234124\n",
            "At step: 6801 training error: 0.36534408165890786\n",
            "At step: 6802 training error: 0.36241545308272327\n",
            "At step: 6803 training error: 0.35794964327996676\n",
            "At step: 6804 training error: 0.3664641167626443\n",
            "At step: 6805 training error: 0.3742144534784737\n",
            "At step: 6806 training error: 0.37872578447435024\n",
            "At step: 6807 training error: 0.3768957280873735\n",
            "At step: 6808 training error: 0.38280867782884703\n",
            "At step: 6809 training error: 0.3847302238313957\n",
            "At step: 6810 training error: 0.39246842192723946\n",
            "At step: 6811 training error: 0.3847736140048472\n",
            "At step: 6812 training error: 0.38251114446279755\n",
            "At step: 6813 training error: 0.3778012388761864\n",
            "At step: 6814 training error: 0.388147504629463\n",
            "At step: 6815 training error: 0.38826865557412604\n",
            "At step: 6816 training error: 0.3875176391241416\n",
            "At step: 6817 training error: 0.38933013233331254\n",
            "At step: 6818 training error: 0.38884950926185774\n",
            "At step: 6819 training error: 0.3902448198706118\n",
            "At step: 6820 training error: 0.39324051647006\n",
            "At step: 6821 training error: 0.3848185321007404\n",
            "At step: 6822 training error: 0.3834822288478372\n",
            "At step: 6823 training error: 0.3799150701713969\n",
            "At step: 6824 training error: 0.37040922756859834\n",
            "At step: 6825 training error: 0.36700011300841423\n",
            "At step: 6826 training error: 0.38115264344948874\n",
            "At step: 6827 training error: 0.3873086583015662\n",
            "At step: 6828 training error: 0.3962273597151331\n",
            "At step: 6829 training error: 0.3988627816949057\n",
            "At step: 6830 training error: 0.39183426084284884\n",
            "At step: 6831 training error: 0.3928508044650015\n",
            "At step: 6832 training error: 0.39485351112496936\n",
            "At step: 6833 training error: 0.3863693429403355\n",
            "At step: 6834 training error: 0.38802535898668894\n",
            "At step: 6835 training error: 0.3914204063467149\n",
            "At step: 6836 training error: 0.3999414000535434\n",
            "At step: 6837 training error: 0.4004161305273473\n",
            "At step: 6838 training error: 0.3997361299997379\n",
            "At step: 6839 training error: 0.39668539852072804\n",
            "At step: 6840 training error: 0.39645022559939525\n",
            "At step: 6841 training error: 0.39952867052774754\n",
            "At step: 6842 training error: 0.3979333239608725\n",
            "At step: 6843 training error: 0.3869307938040962\n",
            "At step: 6844 training error: 0.3870422593299869\n",
            "At step: 6845 training error: 0.38073381937048345\n",
            "At step: 6846 training error: 0.38623646770483766\n",
            "At step: 6847 training error: 0.3846855405000555\n",
            "At step: 6848 training error: 0.38977460818243254\n",
            "At step: 6849 training error: 0.39424815607092906\n",
            "At step: 6850 training error: 0.3847597030742149\n",
            "At step: 6851 training error: 0.38124614087539244\n",
            "At step: 6852 training error: 0.37886283916920815\n",
            "At step: 6853 training error: 0.3760203204318424\n",
            "At step: 6854 training error: 0.3725259585824006\n",
            "At step: 6855 training error: 0.3724488230347646\n",
            "At step: 6856 training error: 0.3722539547631895\n",
            "At step: 6857 training error: 0.38376530613801196\n",
            "At step: 6858 training error: 0.3970588934059375\n",
            "At step: 6859 training error: 0.4008943640535528\n",
            "At step: 6860 training error: 0.4029178506518006\n",
            "At step: 6861 training error: 0.3957243781005576\n",
            "At step: 6862 training error: 0.39671877858643984\n",
            "At step: 6863 training error: 0.3964838826159389\n",
            "At step: 6864 training error: 0.4036339172872664\n",
            "At step: 6865 training error: 0.39907027010319673\n",
            "At step: 6866 training error: 0.3990908089853204\n",
            "At step: 6867 training error: 0.3829023239091173\n",
            "At step: 6868 training error: 0.3826062949954259\n",
            "At step: 6869 training error: 0.3956225029546472\n",
            "At step: 6870 training error: 0.39650981392455203\n",
            "At step: 6871 training error: 0.39262728623179755\n",
            "At step: 6872 training error: 0.4006781371510369\n",
            "At step: 6873 training error: 0.39990856163817246\n",
            "At step: 6874 training error: 0.40038577718941915\n",
            "At step: 6875 training error: 0.3851950752789195\n",
            "At step: 6876 training error: 0.3778533723974945\n",
            "At step: 6877 training error: 0.371889004336046\n",
            "At step: 6878 training error: 0.38813189584131397\n",
            "At step: 6879 training error: 0.3806210478770873\n",
            "At step: 6880 training error: 0.37804530946444714\n",
            "At step: 6881 training error: 0.38708470024517067\n",
            "At step: 6882 training error: 0.3829128892200589\n",
            "At step: 6883 training error: 0.38887544499995175\n",
            "At step: 6884 training error: 0.3948608375091517\n",
            "At step: 6885 training error: 0.39362216482740264\n",
            "At step: 6886 training error: 0.38867113901816164\n",
            "At step: 6887 training error: 0.39833862663176667\n",
            "At step: 6888 training error: 0.3996008352244359\n",
            "At step: 6889 training error: 0.38897971288695954\n",
            "At step: 6890 training error: 0.3853490914491156\n",
            "At step: 6891 training error: 0.38024358881047876\n",
            "At step: 6892 training error: 0.38348939003240584\n",
            "At step: 6893 training error: 0.3758563034820729\n",
            "At step: 6894 training error: 0.38178678508986796\n",
            "At step: 6895 training error: 0.3716347277427533\n",
            "At step: 6896 training error: 0.37364251482526056\n",
            "At step: 6897 training error: 0.3726931616869839\n",
            "At step: 6898 training error: 0.38838999438747096\n",
            "At step: 6899 training error: 0.405271243200234\n",
            "At step: 6900 training error: 0.4082724018608717\n",
            "At step: 6901 training error: 0.4078374909339377\n",
            "At step: 6902 training error: 0.4147669966617748\n",
            "At step: 6903 training error: 0.4154094742177629\n",
            "At step: 6904 training error: 0.40778042380732693\n",
            "At step: 6905 training error: 0.3966499895499195\n",
            "At step: 6906 training error: 0.39461634602461565\n",
            "At step: 6907 training error: 0.39621728701112685\n",
            "At step: 6908 training error: 0.4027556851503805\n",
            "At step: 6909 training error: 0.40022131918425574\n",
            "At step: 6910 training error: 0.3976459374088707\n",
            "At step: 6911 training error: 0.38812961619398023\n",
            "At step: 6912 training error: 0.3825287806429864\n",
            "At step: 6913 training error: 0.38856233756866854\n",
            "At step: 6914 training error: 0.39401735720754655\n",
            "At step: 6915 training error: 0.39475197979492777\n",
            "At step: 6916 training error: 0.3976545113436874\n",
            "At step: 6917 training error: 0.4000972150597164\n",
            "At step: 6918 training error: 0.3928946666164647\n",
            "At step: 6919 training error: 0.3969675143650867\n",
            "At step: 6920 training error: 0.40855550283499725\n",
            "At step: 6921 training error: 0.4130832745626385\n",
            "At step: 6922 training error: 0.4275887816281238\n",
            "At step: 6923 training error: 0.4220953459639441\n",
            "At step: 6924 training error: 0.4263256199821016\n",
            "At step: 6925 training error: 0.4180109728074039\n",
            "At step: 6926 training error: 0.41520736111501955\n",
            "At step: 6927 training error: 0.4133433848243294\n",
            "At step: 6928 training error: 0.409923789953025\n",
            "At step: 6929 training error: 0.39967082009956995\n",
            "At step: 6930 training error: 0.3955156614656114\n",
            "At step: 6931 training error: 0.39738167417952086\n",
            "At step: 6932 training error: 0.3970494061118749\n",
            "At step: 6933 training error: 0.4034249574916377\n",
            "At step: 6934 training error: 0.40471519255006905\n",
            "At step: 6935 training error: 0.41152208666968165\n",
            "At step: 6936 training error: 0.4219007214884621\n",
            "At step: 6937 training error: 0.41757695046595233\n",
            "At step: 6938 training error: 0.4197302292269114\n",
            "At step: 6939 training error: 0.42097438863606695\n",
            "At step: 6940 training error: 0.42865974563638387\n",
            "At step: 6941 training error: 0.4271932716320516\n",
            "At step: 6942 training error: 0.4245299485822719\n",
            "At step: 6943 training error: 0.42122582707848827\n",
            "At step: 6944 training error: 0.4190057586976942\n",
            "At step: 6945 training error: 0.41280987149250387\n",
            "At step: 6946 training error: 0.4077653170705046\n",
            "At step: 6947 training error: 0.4133326829378111\n",
            "At step: 6948 training error: 0.41451514772114917\n",
            "At step: 6949 training error: 0.41141542287807426\n",
            "At step: 6950 training error: 0.40987002889793434\n",
            "At step: 6951 training error: 0.4144548658005189\n",
            "At step: 6952 training error: 0.4051245949463742\n",
            "At step: 6953 training error: 0.40335647706885974\n",
            "At step: 6954 training error: 0.40156271692813683\n",
            "At step: 6955 training error: 0.40112166877030236\n",
            "At step: 6956 training error: 0.40953245266060356\n",
            "At step: 6957 training error: 0.41447130226882634\n",
            "At step: 6958 training error: 0.414605371318929\n",
            "At step: 6959 training error: 0.4185588636602072\n",
            "At step: 6960 training error: 0.4196180523571999\n",
            "At step: 6961 training error: 0.4208211613656331\n",
            "At step: 6962 training error: 0.42602166806808867\n",
            "At step: 6963 training error: 0.4139194766396349\n",
            "At step: 6964 training error: 0.4121822078015786\n",
            "At step: 6965 training error: 0.40947408525287077\n",
            "At step: 6966 training error: 0.39831604531258125\n",
            "At step: 6967 training error: 0.4008835902598361\n",
            "At step: 6968 training error: 0.39572901645085323\n",
            "At step: 6969 training error: 0.3887483350729676\n",
            "At step: 6970 training error: 0.3967858648963234\n",
            "At step: 6971 training error: 0.39485429421052953\n",
            "At step: 6972 training error: 0.38595811243651196\n",
            "At step: 6973 training error: 0.3933751073633589\n",
            "At step: 6974 training error: 0.3860470690837759\n",
            "At step: 6975 training error: 0.37033641198601275\n",
            "At step: 6976 training error: 0.36686097334231466\n",
            "At step: 6977 training error: 0.36871355072402334\n",
            "At step: 6978 training error: 0.3677521781671254\n",
            "At step: 6979 training error: 0.3630991436767638\n",
            "At step: 6980 training error: 0.37581415877508884\n",
            "At step: 6981 training error: 0.37856160452107424\n",
            "At step: 6982 training error: 0.38734292088131905\n",
            "At step: 6983 training error: 0.38616937595616213\n",
            "At step: 6984 training error: 0.3952229538856144\n",
            "At step: 6985 training error: 0.39013696188030356\n",
            "At step: 6986 training error: 0.3836954253031047\n",
            "At step: 6987 training error: 0.3873316169437562\n",
            "At step: 6988 training error: 0.3899949051564173\n",
            "At step: 6989 training error: 0.3947123389085577\n",
            "At step: 6990 training error: 0.39854177596639745\n",
            "At step: 6991 training error: 0.4032313643249991\n",
            "At step: 6992 training error: 0.405476594891509\n",
            "At step: 6993 training error: 0.4063548962419189\n",
            "At step: 6994 training error: 0.40982081522233493\n",
            "At step: 6995 training error: 0.4003280213975822\n",
            "At step: 6996 training error: 0.39601719594777857\n",
            "At step: 6997 training error: 0.39677555376584134\n",
            "At step: 6998 training error: 0.39862456366765847\n",
            "At step: 6999 training error: 0.3942253958246248\n",
            "At step: 7000 training error: 0.3931296876777034\n",
            "At step: 7001 training error: 0.39490473786406377\n",
            "At step: 7002 training error: 0.39509855567637386\n",
            "At step: 7003 training error: 0.3976523173241475\n",
            "At step: 7004 training error: 0.4045528615461989\n",
            "At step: 7005 training error: 0.40743998358839095\n",
            "At step: 7006 training error: 0.4072525537378833\n",
            "At step: 7007 training error: 0.4052935662261024\n",
            "At step: 7008 training error: 0.4052504090334153\n",
            "At step: 7009 training error: 0.40622362068958096\n",
            "At step: 7010 training error: 0.402915900379924\n",
            "At step: 7011 training error: 0.39135872324437926\n",
            "At step: 7012 training error: 0.39531776135821833\n",
            "At step: 7013 training error: 0.39408357150034923\n",
            "At step: 7014 training error: 0.3900556189486453\n",
            "At step: 7015 training error: 0.3938014252399915\n",
            "At step: 7016 training error: 0.39242601793195303\n",
            "At step: 7017 training error: 0.3787937766620554\n",
            "At step: 7018 training error: 0.37844386859895834\n",
            "At step: 7019 training error: 0.38874935070423866\n",
            "At step: 7020 training error: 0.3812162226803657\n",
            "At step: 7021 training error: 0.3816630560061631\n",
            "At step: 7022 training error: 0.39281244051786296\n",
            "At step: 7023 training error: 0.4030411060882866\n",
            "At step: 7024 training error: 0.3978985002529349\n",
            "At step: 7025 training error: 0.4039850918299223\n",
            "At step: 7026 training error: 0.4036701587179193\n",
            "At step: 7027 training error: 0.3928600928791408\n",
            "At step: 7028 training error: 0.38744589343089125\n",
            "At step: 7029 training error: 0.3883850670529764\n",
            "At step: 7030 training error: 0.39274628494275926\n",
            "At step: 7031 training error: 0.3970763753681381\n",
            "At step: 7032 training error: 0.3939799359961381\n",
            "At step: 7033 training error: 0.39130531572532556\n",
            "At step: 7034 training error: 0.3968673905307806\n",
            "At step: 7035 training error: 0.407353734355896\n",
            "At step: 7036 training error: 0.4100734976388683\n",
            "At step: 7037 training error: 0.4120358455319356\n",
            "At step: 7038 training error: 0.39653419295167397\n",
            "At step: 7039 training error: 0.3961784241693477\n",
            "At step: 7040 training error: 0.3979161769474939\n",
            "At step: 7041 training error: 0.3960772887810723\n",
            "At step: 7042 training error: 0.3975379658675652\n",
            "At step: 7043 training error: 0.38779227977128655\n",
            "At step: 7044 training error: 0.3856234507132864\n",
            "At step: 7045 training error: 0.38627059555370125\n",
            "At step: 7046 training error: 0.3829144877620226\n",
            "At step: 7047 training error: 0.3855684310695679\n",
            "At step: 7048 training error: 0.3875512119871679\n",
            "At step: 7049 training error: 0.39085035248788913\n",
            "At step: 7050 training error: 0.387880281902731\n",
            "At step: 7051 training error: 0.38729890549427\n",
            "At step: 7052 training error: 0.3891838676238413\n",
            "At step: 7053 training error: 0.389424738742401\n",
            "At step: 7054 training error: 0.39694277314916726\n",
            "At step: 7055 training error: 0.39784920393772094\n",
            "At step: 7056 training error: 0.40224510264173846\n",
            "At step: 7057 training error: 0.3979056781423684\n",
            "At step: 7058 training error: 0.4011144666171522\n",
            "At step: 7059 training error: 0.41646779899637043\n",
            "At step: 7060 training error: 0.41023985838154886\n",
            "At step: 7061 training error: 0.4214945517602248\n",
            "At step: 7062 training error: 0.4118757974089896\n",
            "At step: 7063 training error: 0.4082880038149512\n",
            "At step: 7064 training error: 0.4158943780625377\n",
            "At step: 7065 training error: 0.40702452933610994\n",
            "At step: 7066 training error: 0.40653297444125785\n",
            "At step: 7067 training error: 0.4020627781147911\n",
            "At step: 7068 training error: 0.39925504249343596\n",
            "At step: 7069 training error: 0.40859828104976853\n",
            "At step: 7070 training error: 0.4146474004626622\n",
            "At step: 7071 training error: 0.4172695494853275\n",
            "At step: 7072 training error: 0.42154008010862015\n",
            "At step: 7073 training error: 0.41633983266300834\n",
            "At step: 7074 training error: 0.40746758290523505\n",
            "At step: 7075 training error: 0.41338535262598264\n",
            "At step: 7076 training error: 0.40054238993580454\n",
            "At step: 7077 training error: 0.3982872649487349\n",
            "At step: 7078 training error: 0.3898087405322466\n",
            "At step: 7079 training error: 0.3830953494991501\n",
            "At step: 7080 training error: 0.3770419551497839\n",
            "At step: 7081 training error: 0.3782403141233159\n",
            "At step: 7082 training error: 0.3851381217545762\n",
            "At step: 7083 training error: 0.37521386129512774\n",
            "At step: 7084 training error: 0.38217819170139816\n",
            "At step: 7085 training error: 0.3749875496261962\n",
            "At step: 7086 training error: 0.3791920403710755\n",
            "At step: 7087 training error: 0.3752745509134921\n",
            "At step: 7088 training error: 0.3687730571395542\n",
            "At step: 7089 training error: 0.3759880489045607\n",
            "At step: 7090 training error: 0.37813846454445443\n",
            "At step: 7091 training error: 0.3732556219770651\n",
            "At step: 7092 training error: 0.37055285350089295\n",
            "At step: 7093 training error: 0.37650811343770796\n",
            "At step: 7094 training error: 0.3880105096635547\n",
            "At step: 7095 training error: 0.3919442638659089\n",
            "At step: 7096 training error: 0.40795543531204215\n",
            "At step: 7097 training error: 0.4097827602342899\n",
            "At step: 7098 training error: 0.40697203335612236\n",
            "At step: 7099 training error: 0.3951420764187458\n",
            "At step: 7100 training error: 0.3868151330642931\n",
            "At step: 7101 training error: 0.38535979783402957\n",
            "At step: 7102 training error: 0.3813578493109937\n",
            "At step: 7103 training error: 0.37268561877040607\n",
            "At step: 7104 training error: 0.3644852354842328\n",
            "At step: 7105 training error: 0.36715863146151095\n",
            "At step: 7106 training error: 0.3761750471655232\n",
            "At step: 7107 training error: 0.37265149512575085\n",
            "At step: 7108 training error: 0.3654384309073233\n",
            "At step: 7109 training error: 0.3672321452362117\n",
            "At step: 7110 training error: 0.366185903230061\n",
            "At step: 7111 training error: 0.3601352002051893\n",
            "At step: 7112 training error: 0.36119199883445885\n",
            "At step: 7113 training error: 0.36623885583626276\n",
            "At step: 7114 training error: 0.37078948824011665\n",
            "At step: 7115 training error: 0.37612404113038017\n",
            "At step: 7116 training error: 0.3800748003727337\n",
            "At step: 7117 training error: 0.38588809396316137\n",
            "At step: 7118 training error: 0.380671457858965\n",
            "At step: 7119 training error: 0.3803610353925719\n",
            "At step: 7120 training error: 0.37519256780122434\n",
            "At step: 7121 training error: 0.37286659395474486\n",
            "At step: 7122 training error: 0.3778551366775383\n",
            "At step: 7123 training error: 0.38077635803793947\n",
            "At step: 7124 training error: 0.3914902019478788\n",
            "At step: 7125 training error: 0.39524768857407655\n",
            "At step: 7126 training error: 0.3969438178290479\n",
            "At step: 7127 training error: 0.4103563770620159\n",
            "At step: 7128 training error: 0.412283112552832\n",
            "At step: 7129 training error: 0.41189415124102213\n",
            "At step: 7130 training error: 0.40135994194535396\n",
            "At step: 7131 training error: 0.4035495049978908\n",
            "At step: 7132 training error: 0.4011608660306671\n",
            "At step: 7133 training error: 0.39082169618525975\n",
            "At step: 7134 training error: 0.3919729639980105\n",
            "At step: 7135 training error: 0.3941889234190304\n",
            "At step: 7136 training error: 0.39076889861939584\n",
            "At step: 7137 training error: 0.39576861026107474\n",
            "At step: 7138 training error: 0.39847185127371515\n",
            "At step: 7139 training error: 0.42177289856672284\n",
            "At step: 7140 training error: 0.4154777933124009\n",
            "At step: 7141 training error: 0.4104249896150288\n",
            "At step: 7142 training error: 0.4059495599335909\n",
            "At step: 7143 training error: 0.40201483299260665\n",
            "At step: 7144 training error: 0.4100079831946761\n",
            "At step: 7145 training error: 0.4073140637271876\n",
            "At step: 7146 training error: 0.4019910862292685\n",
            "At step: 7147 training error: 0.39761248657417825\n",
            "At step: 7148 training error: 0.3959077206733072\n",
            "At step: 7149 training error: 0.39654080935254604\n",
            "At step: 7150 training error: 0.4018992635823345\n",
            "At step: 7151 training error: 0.40335822093558704\n",
            "At step: 7152 training error: 0.39551327450302864\n",
            "At step: 7153 training error: 0.3963286647051652\n",
            "At step: 7154 training error: 0.3874309301529961\n",
            "At step: 7155 training error: 0.3895415529174876\n",
            "At step: 7156 training error: 0.3918600070684239\n",
            "At step: 7157 training error: 0.38965555295980253\n",
            "At step: 7158 training error: 0.3881422085266231\n",
            "At step: 7159 training error: 0.39397074602730736\n",
            "At step: 7160 training error: 0.3937533241249475\n",
            "At step: 7161 training error: 0.39279380015538645\n",
            "At step: 7162 training error: 0.3906702336224138\n",
            "At step: 7163 training error: 0.3900034708902803\n",
            "At step: 7164 training error: 0.3855016630619406\n",
            "At step: 7165 training error: 0.3922462528911672\n",
            "At step: 7166 training error: 0.4006574686300716\n",
            "At step: 7167 training error: 0.4071918876715589\n",
            "At step: 7168 training error: 0.41141448134656017\n",
            "At step: 7169 training error: 0.4079547781318491\n",
            "At step: 7170 training error: 0.4099818200328351\n",
            "At step: 7171 training error: 0.39925983342831317\n",
            "At step: 7172 training error: 0.39454398953770176\n",
            "At step: 7173 training error: 0.40580723319774414\n",
            "At step: 7174 training error: 0.4067071118520299\n",
            "At step: 7175 training error: 0.40334815289940606\n",
            "At step: 7176 training error: 0.39285094126678693\n",
            "At step: 7177 training error: 0.4041339825188584\n",
            "At step: 7178 training error: 0.40637014731685356\n",
            "At step: 7179 training error: 0.40747007064585283\n",
            "At step: 7180 training error: 0.41156625812376646\n",
            "At step: 7181 training error: 0.4053626143062113\n",
            "At step: 7182 training error: 0.401366382985225\n",
            "At step: 7183 training error: 0.4097749753487809\n",
            "At step: 7184 training error: 0.4130676095489928\n",
            "At step: 7185 training error: 0.41460483754858407\n",
            "At step: 7186 training error: 0.41317344979406023\n",
            "At step: 7187 training error: 0.416202362135899\n",
            "At step: 7188 training error: 0.41725143614922044\n",
            "At step: 7189 training error: 0.4029730264313253\n",
            "At step: 7190 training error: 0.4068608719044903\n",
            "At step: 7191 training error: 0.4025549160021647\n",
            "At step: 7192 training error: 0.40319210635031494\n",
            "At step: 7193 training error: 0.4121501154325279\n",
            "At step: 7194 training error: 0.421659925846689\n",
            "At step: 7195 training error: 0.4181289937818774\n",
            "At step: 7196 training error: 0.41227793206185914\n",
            "At step: 7197 training error: 0.4198944152791334\n",
            "At step: 7198 training error: 0.41781028218406313\n",
            "At step: 7199 training error: 0.42201940039688823\n",
            "At step: 7200 training error: 0.41265892999507264\n",
            "At step: 7201 training error: 0.4068226696427006\n",
            "At step: 7202 training error: 0.38910154038341505\n",
            "At step: 7203 training error: 0.3843398719223756\n",
            "At step: 7204 training error: 0.38092625632335286\n",
            "At step: 7205 training error: 0.38844425634983837\n",
            "At step: 7206 training error: 0.3847365452684949\n",
            "At step: 7207 training error: 0.3813426579898167\n",
            "At step: 7208 training error: 0.37935895654785995\n",
            "At step: 7209 training error: 0.38018703908801954\n",
            "At step: 7210 training error: 0.3814336924449987\n",
            "At step: 7211 training error: 0.38623907969034854\n",
            "At step: 7212 training error: 0.4072069703386804\n",
            "At step: 7213 training error: 0.40433088323333016\n",
            "At step: 7214 training error: 0.39846464455745934\n",
            "At step: 7215 training error: 0.4047762889986629\n",
            "At step: 7216 training error: 0.397184796680984\n",
            "At step: 7217 training error: 0.403976293636533\n",
            "At step: 7218 training error: 0.39629930021032317\n",
            "At step: 7219 training error: 0.38921210922256966\n",
            "At step: 7220 training error: 0.39072105494085974\n",
            "At step: 7221 training error: 0.3901757756312626\n",
            "At step: 7222 training error: 0.38731899564888017\n",
            "At step: 7223 training error: 0.39110746455321077\n",
            "At step: 7224 training error: 0.39515782849853515\n",
            "At step: 7225 training error: 0.403838476860233\n",
            "At step: 7226 training error: 0.40933167074903865\n",
            "At step: 7227 training error: 0.41581283396151764\n",
            "At step: 7228 training error: 0.41874622419383334\n",
            "At step: 7229 training error: 0.4218673342162435\n",
            "At step: 7230 training error: 0.43130576218431765\n",
            "At step: 7231 training error: 0.4292242145081347\n",
            "At step: 7232 training error: 0.40837076767387237\n",
            "At step: 7233 training error: 0.4123920504702903\n",
            "At step: 7234 training error: 0.3985651799554304\n",
            "At step: 7235 training error: 0.41107934457652107\n",
            "At step: 7236 training error: 0.416370077333791\n",
            "At step: 7237 training error: 0.4218819839292598\n",
            "At step: 7238 training error: 0.4049895103997789\n",
            "At step: 7239 training error: 0.41187321848876723\n",
            "At step: 7240 training error: 0.4052079766044959\n",
            "At step: 7241 training error: 0.3978881638814006\n",
            "At step: 7242 training error: 0.3948814785643807\n",
            "At step: 7243 training error: 0.3950598594501188\n",
            "At step: 7244 training error: 0.3776269496373958\n",
            "At step: 7245 training error: 0.3798143205090314\n",
            "At step: 7246 training error: 0.3853730208031141\n",
            "At step: 7247 training error: 0.38862644677288505\n",
            "At step: 7248 training error: 0.3921360023482072\n",
            "At step: 7249 training error: 0.38427273396363576\n",
            "At step: 7250 training error: 0.3797304353676716\n",
            "At step: 7251 training error: 0.3840626105577173\n",
            "At step: 7252 training error: 0.3853781612172815\n",
            "At step: 7253 training error: 0.3987974372782892\n",
            "At step: 7254 training error: 0.3953913912091672\n",
            "At step: 7255 training error: 0.4024476285208146\n",
            "At step: 7256 training error: 0.4187054662433383\n",
            "At step: 7257 training error: 0.4170040253746623\n",
            "At step: 7258 training error: 0.40216148769239607\n",
            "At step: 7259 training error: 0.39017365009665683\n",
            "At step: 7260 training error: 0.3916928490561898\n",
            "At step: 7261 training error: 0.39993237013963795\n",
            "At step: 7262 training error: 0.4027303886758147\n",
            "At step: 7263 training error: 0.40323943224067554\n",
            "At step: 7264 training error: 0.3973229555408464\n",
            "At step: 7265 training error: 0.3996341449328058\n",
            "At step: 7266 training error: 0.40372221777465933\n",
            "At step: 7267 training error: 0.3918764827048411\n",
            "At step: 7268 training error: 0.3849055454857762\n",
            "At step: 7269 training error: 0.39329080769338687\n",
            "At step: 7270 training error: 0.38165198272003154\n",
            "At step: 7271 training error: 0.38917392103378395\n",
            "At step: 7272 training error: 0.40681515411247476\n",
            "At step: 7273 training error: 0.4111226832410617\n",
            "At step: 7274 training error: 0.4166566380293841\n",
            "At step: 7275 training error: 0.42563459793926994\n",
            "At step: 7276 training error: 0.4191249600787483\n",
            "At step: 7277 training error: 0.4194702615917553\n",
            "At step: 7278 training error: 0.41188809447496494\n",
            "At step: 7279 training error: 0.4059783797115628\n",
            "At step: 7280 training error: 0.41081607176645185\n",
            "At step: 7281 training error: 0.41634222629534073\n",
            "At step: 7282 training error: 0.40836601579044496\n",
            "At step: 7283 training error: 0.410424269932033\n",
            "At step: 7284 training error: 0.4108175543896046\n",
            "At step: 7285 training error: 0.4110040821084506\n",
            "At step: 7286 training error: 0.40915720884794116\n",
            "At step: 7287 training error: 0.4073441145457209\n",
            "At step: 7288 training error: 0.4039828504954363\n",
            "At step: 7289 training error: 0.3980415849135267\n",
            "At step: 7290 training error: 0.39554384812020055\n",
            "At step: 7291 training error: 0.3922717452642561\n",
            "At step: 7292 training error: 0.39374681518818966\n",
            "At step: 7293 training error: 0.40004243363173825\n",
            "At step: 7294 training error: 0.3937250505665064\n",
            "At step: 7295 training error: 0.3871428862599714\n",
            "At step: 7296 training error: 0.3942763366163455\n",
            "At step: 7297 training error: 0.39311662050944696\n",
            "At step: 7298 training error: 0.39545989483762944\n",
            "At step: 7299 training error: 0.3962392025462926\n",
            "At step: 7300 training error: 0.38978386790071184\n",
            "At step: 7301 training error: 0.4055491660965821\n",
            "At step: 7302 training error: 0.40284339120089696\n",
            "At step: 7303 training error: 0.3947298385532002\n",
            "At step: 7304 training error: 0.391094415272327\n",
            "At step: 7305 training error: 0.39792768132858325\n",
            "At step: 7306 training error: 0.40060878243430653\n",
            "At step: 7307 training error: 0.39414823064069343\n",
            "At step: 7308 training error: 0.3912015479442886\n",
            "At step: 7309 training error: 0.3840252752167656\n",
            "At step: 7310 training error: 0.38019168776275375\n",
            "At step: 7311 training error: 0.3747493450972306\n",
            "At step: 7312 training error: 0.3777802144379081\n",
            "At step: 7313 training error: 0.3793801173165159\n",
            "At step: 7314 training error: 0.3776318182279808\n",
            "At step: 7315 training error: 0.3708143181940699\n",
            "At step: 7316 training error: 0.37588973410203486\n",
            "At step: 7317 training error: 0.3767928016782854\n",
            "At step: 7318 training error: 0.3761390136337056\n",
            "At step: 7319 training error: 0.3724145542313162\n",
            "At step: 7320 training error: 0.372416634454121\n",
            "At step: 7321 training error: 0.3700980322430582\n",
            "At step: 7322 training error: 0.36851675261943534\n",
            "At step: 7323 training error: 0.3639664657338981\n",
            "At step: 7324 training error: 0.36157028328578367\n",
            "At step: 7325 training error: 0.356058522008757\n",
            "At step: 7326 training error: 0.3768035553371438\n",
            "At step: 7327 training error: 0.37943386067283125\n",
            "At step: 7328 training error: 0.3819273172863356\n",
            "At step: 7329 training error: 0.37957636242401255\n",
            "At step: 7330 training error: 0.39120180757715445\n",
            "At step: 7331 training error: 0.4000511680861119\n",
            "At step: 7332 training error: 0.39451096469351044\n",
            "At step: 7333 training error: 0.3899354325947186\n",
            "At step: 7334 training error: 0.3894164067467157\n",
            "At step: 7335 training error: 0.38476243326562504\n",
            "At step: 7336 training error: 0.39559058628468313\n",
            "At step: 7337 training error: 0.40177650957320055\n",
            "At step: 7338 training error: 0.3983044801285596\n",
            "At step: 7339 training error: 0.4072594893975987\n",
            "At step: 7340 training error: 0.4078056259450968\n",
            "At step: 7341 training error: 0.4017627135582114\n",
            "At step: 7342 training error: 0.39050689057841537\n",
            "At step: 7343 training error: 0.38970078892664944\n",
            "At step: 7344 training error: 0.382632104602915\n",
            "At step: 7345 training error: 0.390852084524702\n",
            "At step: 7346 training error: 0.38011502102271316\n",
            "At step: 7347 training error: 0.3885093328400086\n",
            "At step: 7348 training error: 0.3895022569978112\n",
            "At step: 7349 training error: 0.3815572825167937\n",
            "At step: 7350 training error: 0.3809971617075667\n",
            "At step: 7351 training error: 0.37908891003586564\n",
            "At step: 7352 training error: 0.38544044706692965\n",
            "At step: 7353 training error: 0.38112260132497555\n",
            "At step: 7354 training error: 0.3888990600394895\n",
            "At step: 7355 training error: 0.39017469288983764\n",
            "At step: 7356 training error: 0.39818460085387564\n",
            "At step: 7357 training error: 0.40108841295906633\n",
            "At step: 7358 training error: 0.4031126556926443\n",
            "At step: 7359 training error: 0.3989650234157024\n",
            "At step: 7360 training error: 0.39880269660628437\n",
            "At step: 7361 training error: 0.39083977515760254\n",
            "At step: 7362 training error: 0.3942171187501673\n",
            "At step: 7363 training error: 0.3984293880918395\n",
            "At step: 7364 training error: 0.39919926352581403\n",
            "At step: 7365 training error: 0.3942398576322515\n",
            "At step: 7366 training error: 0.389944013993405\n",
            "At step: 7367 training error: 0.39713415849677725\n",
            "At step: 7368 training error: 0.38696917252741736\n",
            "At step: 7369 training error: 0.39460955131158887\n",
            "At step: 7370 training error: 0.3925774275082362\n",
            "At step: 7371 training error: 0.38291643004504405\n",
            "At step: 7372 training error: 0.38858515464648885\n",
            "At step: 7373 training error: 0.3843663576872393\n",
            "At step: 7374 training error: 0.3873945749222615\n",
            "At step: 7375 training error: 0.3916813834111645\n",
            "At step: 7376 training error: 0.3832077871796132\n",
            "At step: 7377 training error: 0.3856706990659648\n",
            "At step: 7378 training error: 0.37538023300686535\n",
            "At step: 7379 training error: 0.36388789659530946\n",
            "At step: 7380 training error: 0.3548077697411932\n",
            "At step: 7381 training error: 0.3492851192641131\n",
            "At step: 7382 training error: 0.35735678838924523\n",
            "At step: 7383 training error: 0.35621803291887455\n",
            "At step: 7384 training error: 0.3613724238718003\n",
            "At step: 7385 training error: 0.36257803933346294\n",
            "At step: 7386 training error: 0.3661077601084599\n",
            "At step: 7387 training error: 0.37060130479433095\n",
            "At step: 7388 training error: 0.3762781369781858\n",
            "At step: 7389 training error: 0.37622562722464925\n",
            "At step: 7390 training error: 0.3883712998422081\n",
            "At step: 7391 training error: 0.38522454553973146\n",
            "At step: 7392 training error: 0.378667883924182\n",
            "At step: 7393 training error: 0.37703658360195696\n",
            "At step: 7394 training error: 0.37167967912311617\n",
            "At step: 7395 training error: 0.3675529629537673\n",
            "At step: 7396 training error: 0.37715331367846583\n",
            "At step: 7397 training error: 0.3809116076539045\n",
            "At step: 7398 training error: 0.3790352285983615\n",
            "At step: 7399 training error: 0.3727118977764808\n",
            "At step: 7400 training error: 0.3646152584488966\n",
            "At step: 7401 training error: 0.36038869292380094\n",
            "At step: 7402 training error: 0.376741962988877\n",
            "At step: 7403 training error: 0.3775605941832533\n",
            "At step: 7404 training error: 0.3766885162312334\n",
            "At step: 7405 training error: 0.3790979181580271\n",
            "At step: 7406 training error: 0.37183315059278055\n",
            "At step: 7407 training error: 0.3768518344981302\n",
            "At step: 7408 training error: 0.3867581760249951\n",
            "At step: 7409 training error: 0.37918002052146677\n",
            "At step: 7410 training error: 0.384191476872006\n",
            "At step: 7411 training error: 0.38272016578842083\n",
            "At step: 7412 training error: 0.3798222073967875\n",
            "At step: 7413 training error: 0.36705254576863483\n",
            "At step: 7414 training error: 0.3652201863125161\n",
            "At step: 7415 training error: 0.3763731435321045\n",
            "At step: 7416 training error: 0.36709416341443\n",
            "At step: 7417 training error: 0.3674337162202267\n",
            "At step: 7418 training error: 0.38047907393626723\n",
            "At step: 7419 training error: 0.3863466309537244\n",
            "At step: 7420 training error: 0.3896249914006609\n",
            "At step: 7421 training error: 0.38122147047260874\n",
            "At step: 7422 training error: 0.38751210965458094\n",
            "At step: 7423 training error: 0.39269003064156116\n",
            "At step: 7424 training error: 0.38561605291030626\n",
            "At step: 7425 training error: 0.396410334924504\n",
            "At step: 7426 training error: 0.4007014763560568\n",
            "At step: 7427 training error: 0.4027525800636794\n",
            "At step: 7428 training error: 0.39788658107118496\n",
            "At step: 7429 training error: 0.3951247005937617\n",
            "At step: 7430 training error: 0.3967854275878876\n",
            "At step: 7431 training error: 0.3875961249466075\n",
            "At step: 7432 training error: 0.3891443804569834\n",
            "At step: 7433 training error: 0.3856200053132621\n",
            "At step: 7434 training error: 0.3900349668912081\n",
            "At step: 7435 training error: 0.3987061601384355\n",
            "At step: 7436 training error: 0.4024173822078592\n",
            "At step: 7437 training error: 0.39145736254830804\n",
            "At step: 7438 training error: 0.39169111497979303\n",
            "At step: 7439 training error: 0.39634554884013057\n",
            "At step: 7440 training error: 0.400924049121952\n",
            "At step: 7441 training error: 0.3995847161294832\n",
            "At step: 7442 training error: 0.3996756966571407\n",
            "At step: 7443 training error: 0.3947556250425919\n",
            "At step: 7444 training error: 0.3945850508869743\n",
            "At step: 7445 training error: 0.3925380644107236\n",
            "At step: 7446 training error: 0.3907351140563067\n",
            "At step: 7447 training error: 0.39025476710759177\n",
            "At step: 7448 training error: 0.382465915473644\n",
            "At step: 7449 training error: 0.3768584921924822\n",
            "At step: 7450 training error: 0.39612848624613295\n",
            "At step: 7451 training error: 0.4110581561411732\n",
            "At step: 7452 training error: 0.40443570895850245\n",
            "At step: 7453 training error: 0.4007466591294682\n",
            "At step: 7454 training error: 0.4023498119770573\n",
            "At step: 7455 training error: 0.4012777624753927\n",
            "At step: 7456 training error: 0.4048750677317016\n",
            "At step: 7457 training error: 0.39520493978993637\n",
            "At step: 7458 training error: 0.39520344778488076\n",
            "At step: 7459 training error: 0.3953074190020269\n",
            "At step: 7460 training error: 0.3910395828152109\n",
            "At step: 7461 training error: 0.3955703533256349\n",
            "At step: 7462 training error: 0.39852048666509143\n",
            "At step: 7463 training error: 0.40312093389266335\n",
            "At step: 7464 training error: 0.41533838615061736\n",
            "At step: 7465 training error: 0.4000371826055476\n",
            "At step: 7466 training error: 0.3979783159169963\n",
            "At step: 7467 training error: 0.39544965995709175\n",
            "At step: 7468 training error: 0.3898960094559308\n",
            "At step: 7469 training error: 0.38284291943872156\n",
            "At step: 7470 training error: 0.39205792185686\n",
            "At step: 7471 training error: 0.3907099134030843\n",
            "At step: 7472 training error: 0.39581570564079077\n",
            "At step: 7473 training error: 0.3945171220214184\n",
            "At step: 7474 training error: 0.4016515467613039\n",
            "At step: 7475 training error: 0.3975733589898326\n",
            "At step: 7476 training error: 0.3879150939728684\n",
            "At step: 7477 training error: 0.3998911304178591\n",
            "At step: 7478 training error: 0.3993928036896723\n",
            "At step: 7479 training error: 0.3898537059495153\n",
            "At step: 7480 training error: 0.386693931705962\n",
            "At step: 7481 training error: 0.38654207622227876\n",
            "At step: 7482 training error: 0.3975337556537928\n",
            "At step: 7483 training error: 0.403624687265707\n",
            "At step: 7484 training error: 0.39934103760480255\n",
            "At step: 7485 training error: 0.3941670581121309\n",
            "At step: 7486 training error: 0.39898425854094055\n",
            "At step: 7487 training error: 0.3909688054758396\n",
            "At step: 7488 training error: 0.3821726482731351\n",
            "At step: 7489 training error: 0.3880653403851987\n",
            "At step: 7490 training error: 0.3881233731199339\n",
            "At step: 7491 training error: 0.3924486551110319\n",
            "At step: 7492 training error: 0.39728410670830094\n",
            "At step: 7493 training error: 0.39527228922369667\n",
            "At step: 7494 training error: 0.3954257217901518\n",
            "At step: 7495 training error: 0.390631861730058\n",
            "At step: 7496 training error: 0.3855591490109236\n",
            "At step: 7497 training error: 0.3773371018905831\n",
            "At step: 7498 training error: 0.38161207116671914\n",
            "At step: 7499 training error: 0.37973468376781355\n",
            "At step: 7500 training error: 0.3794588986429518\n",
            "At step: 7501 training error: 0.3802165506769063\n",
            "At step: 7502 training error: 0.38399085073603334\n",
            "At step: 7503 training error: 0.37450081462619206\n",
            "At step: 7504 training error: 0.37531109156333703\n",
            "At step: 7505 training error: 0.37220819442296477\n",
            "At step: 7506 training error: 0.37440477723156024\n",
            "At step: 7507 training error: 0.38082726799016503\n",
            "At step: 7508 training error: 0.38802450913608855\n",
            "At step: 7509 training error: 0.383069624161214\n",
            "At step: 7510 training error: 0.38615963159571626\n",
            "At step: 7511 training error: 0.3915223597137616\n",
            "At step: 7512 training error: 0.403052843372108\n",
            "At step: 7513 training error: 0.3931651516842974\n",
            "At step: 7514 training error: 0.39306248205639527\n",
            "At step: 7515 training error: 0.39732945685169174\n",
            "At step: 7516 training error: 0.40046533028110287\n",
            "At step: 7517 training error: 0.39355793457501026\n",
            "At step: 7518 training error: 0.39341968227980134\n",
            "At step: 7519 training error: 0.3887222903120772\n",
            "At step: 7520 training error: 0.38243745284601716\n",
            "At step: 7521 training error: 0.3892557142237882\n",
            "At step: 7522 training error: 0.390463123759533\n",
            "At step: 7523 training error: 0.39276616095164596\n",
            "At step: 7524 training error: 0.3844471326614338\n",
            "At step: 7525 training error: 0.37107300346927596\n",
            "At step: 7526 training error: 0.38019552878857643\n",
            "At step: 7527 training error: 0.37588823606549293\n",
            "At step: 7528 training error: 0.36002886708271664\n",
            "At step: 7529 training error: 0.3449062663795695\n",
            "At step: 7530 training error: 0.3450582669508716\n",
            "At step: 7531 training error: 0.3668019714142772\n",
            "At step: 7532 training error: 0.3747341356338301\n",
            "At step: 7533 training error: 0.3739818520682744\n",
            "At step: 7534 training error: 0.37100294074652934\n",
            "At step: 7535 training error: 0.3719110938545371\n",
            "At step: 7536 training error: 0.37584935982853707\n",
            "At step: 7537 training error: 0.3739570700530159\n",
            "At step: 7538 training error: 0.36606374542821274\n",
            "At step: 7539 training error: 0.362813087887888\n",
            "At step: 7540 training error: 0.37244346126957933\n",
            "At step: 7541 training error: 0.3724308277699899\n",
            "At step: 7542 training error: 0.370162316338478\n",
            "At step: 7543 training error: 0.37071963819381337\n",
            "At step: 7544 training error: 0.3740300778852478\n",
            "At step: 7545 training error: 0.38052995118091926\n",
            "At step: 7546 training error: 0.38176646765243716\n",
            "At step: 7547 training error: 0.3810187555469986\n",
            "At step: 7548 training error: 0.3908224271489793\n",
            "At step: 7549 training error: 0.4037189317235151\n",
            "At step: 7550 training error: 0.3946058081130734\n",
            "At step: 7551 training error: 0.3923521050706359\n",
            "At step: 7552 training error: 0.3857869378062331\n",
            "At step: 7553 training error: 0.3825652281292195\n",
            "At step: 7554 training error: 0.37957340703599235\n",
            "At step: 7555 training error: 0.3786854237971911\n",
            "At step: 7556 training error: 0.37631397802348765\n",
            "At step: 7557 training error: 0.36290572800374266\n",
            "At step: 7558 training error: 0.37453631072204324\n",
            "At step: 7559 training error: 0.37170695975009127\n",
            "At step: 7560 training error: 0.36387105160351724\n",
            "At step: 7561 training error: 0.3700024724457998\n",
            "At step: 7562 training error: 0.37181012931949275\n",
            "At step: 7563 training error: 0.3798433679458869\n",
            "At step: 7564 training error: 0.37592507188951146\n",
            "At step: 7565 training error: 0.3703250139795642\n",
            "At step: 7566 training error: 0.36471564384302424\n",
            "At step: 7567 training error: 0.36465324800502064\n",
            "At step: 7568 training error: 0.3633528002915508\n",
            "At step: 7569 training error: 0.35521258238521275\n",
            "At step: 7570 training error: 0.3645405974409756\n",
            "At step: 7571 training error: 0.3640785417740023\n",
            "At step: 7572 training error: 0.36291694219950876\n",
            "At step: 7573 training error: 0.359348140282959\n",
            "At step: 7574 training error: 0.3650546427560616\n",
            "At step: 7575 training error: 0.36776676932020175\n",
            "At step: 7576 training error: 0.37790045054462096\n",
            "At step: 7577 training error: 0.37420137802059794\n",
            "At step: 7578 training error: 0.396563295010107\n",
            "At step: 7579 training error: 0.3976886984321392\n",
            "At step: 7580 training error: 0.39426435795147735\n",
            "At step: 7581 training error: 0.3836834572914841\n",
            "At step: 7582 training error: 0.38346717078469716\n",
            "At step: 7583 training error: 0.3777000591341995\n",
            "At step: 7584 training error: 0.3772229593755062\n",
            "At step: 7585 training error: 0.3761151252286052\n",
            "At step: 7586 training error: 0.36330241138432007\n",
            "At step: 7587 training error: 0.36455230257979226\n",
            "At step: 7588 training error: 0.3678442651670715\n",
            "At step: 7589 training error: 0.36725158292204957\n",
            "At step: 7590 training error: 0.37719978750440036\n",
            "At step: 7591 training error: 0.3825269291580369\n",
            "At step: 7592 training error: 0.3735408142707746\n",
            "At step: 7593 training error: 0.374226165425528\n",
            "At step: 7594 training error: 0.38274633684720305\n",
            "At step: 7595 training error: 0.390426615134043\n",
            "At step: 7596 training error: 0.3848413656435675\n",
            "At step: 7597 training error: 0.38723186313115576\n",
            "At step: 7598 training error: 0.3884143836852438\n",
            "At step: 7599 training error: 0.3932057212600473\n",
            "At step: 7600 training error: 0.39256299702077746\n",
            "At step: 7601 training error: 0.3982568961899578\n",
            "At step: 7602 training error: 0.3987948551484215\n",
            "At step: 7603 training error: 0.39164101004575497\n",
            "At step: 7604 training error: 0.38846809063642795\n",
            "At step: 7605 training error: 0.37394924769954735\n",
            "At step: 7606 training error: 0.3790009868906426\n",
            "At step: 7607 training error: 0.3893707813387527\n",
            "At step: 7608 training error: 0.3899429367677701\n",
            "At step: 7609 training error: 0.3958698334302345\n",
            "At step: 7610 training error: 0.39960528494580094\n",
            "At step: 7611 training error: 0.4013900981752123\n",
            "At step: 7612 training error: 0.4042327959658665\n",
            "At step: 7613 training error: 0.4090037085957704\n",
            "At step: 7614 training error: 0.39978612669700575\n",
            "At step: 7615 training error: 0.3929302152001572\n",
            "At step: 7616 training error: 0.40156275912641126\n",
            "At step: 7617 training error: 0.4018519860999791\n",
            "At step: 7618 training error: 0.4022786433642609\n",
            "At step: 7619 training error: 0.4143817517074436\n",
            "At step: 7620 training error: 0.4003311349452572\n",
            "At step: 7621 training error: 0.3941758185806474\n",
            "At step: 7622 training error: 0.3945751344453261\n",
            "At step: 7623 training error: 0.38465592659811826\n",
            "At step: 7624 training error: 0.3746644069306719\n",
            "At step: 7625 training error: 0.3786181724483455\n",
            "At step: 7626 training error: 0.36939089711406425\n",
            "At step: 7627 training error: 0.35969391025872915\n",
            "At step: 7628 training error: 0.374929579462135\n",
            "At step: 7629 training error: 0.3736539968014352\n",
            "At step: 7630 training error: 0.37651324022293897\n",
            "At step: 7631 training error: 0.38310629262638046\n",
            "At step: 7632 training error: 0.37081202979900657\n",
            "At step: 7633 training error: 0.37748587721136395\n",
            "At step: 7634 training error: 0.37617369199166306\n",
            "At step: 7635 training error: 0.3728932025834981\n",
            "At step: 7636 training error: 0.37523231421208125\n",
            "At step: 7637 training error: 0.3696930428867258\n",
            "At step: 7638 training error: 0.3692560508477854\n",
            "At step: 7639 training error: 0.3747643494014784\n",
            "At step: 7640 training error: 0.37179345333529085\n",
            "At step: 7641 training error: 0.3763322391669016\n",
            "At step: 7642 training error: 0.37188147211708805\n",
            "At step: 7643 training error: 0.3782955215967115\n",
            "At step: 7644 training error: 0.3748773703558224\n",
            "At step: 7645 training error: 0.3740083118122573\n",
            "At step: 7646 training error: 0.3738974475584646\n",
            "At step: 7647 training error: 0.3638741506746223\n",
            "At step: 7648 training error: 0.3720127665342271\n",
            "At step: 7649 training error: 0.3777581760888051\n",
            "At step: 7650 training error: 0.3769636598422066\n",
            "At step: 7651 training error: 0.37250835959001244\n",
            "At step: 7652 training error: 0.37115364776097926\n",
            "At step: 7653 training error: 0.37006644596840665\n",
            "At step: 7654 training error: 0.3786247272793917\n",
            "At step: 7655 training error: 0.3858363630481777\n",
            "At step: 7656 training error: 0.384180739056315\n",
            "At step: 7657 training error: 0.38542791761904127\n",
            "At step: 7658 training error: 0.3712501799758627\n",
            "At step: 7659 training error: 0.38576415353459664\n",
            "At step: 7660 training error: 0.38008255056903695\n",
            "At step: 7661 training error: 0.3796935327402988\n",
            "At step: 7662 training error: 0.3926300072745183\n",
            "At step: 7663 training error: 0.3942237979674704\n",
            "At step: 7664 training error: 0.3890988104070858\n",
            "At step: 7665 training error: 0.3874760244028134\n",
            "At step: 7666 training error: 0.3822071721192048\n",
            "At step: 7667 training error: 0.37947522429725317\n",
            "At step: 7668 training error: 0.38694367224522064\n",
            "At step: 7669 training error: 0.38813529976601663\n",
            "At step: 7670 training error: 0.3803777388483082\n",
            "At step: 7671 training error: 0.3884395052799064\n",
            "At step: 7672 training error: 0.38332451303528436\n",
            "At step: 7673 training error: 0.37877545267378665\n",
            "At step: 7674 training error: 0.3747735061550732\n",
            "At step: 7675 training error: 0.38300152776677054\n",
            "At step: 7676 training error: 0.38864558877162\n",
            "At step: 7677 training error: 0.38720146493490204\n",
            "At step: 7678 training error: 0.3877881646120729\n",
            "At step: 7679 training error: 0.3846453339632863\n",
            "At step: 7680 training error: 0.3782740554344371\n",
            "At step: 7681 training error: 0.3628988868474404\n",
            "At step: 7682 training error: 0.3659107621843328\n",
            "At step: 7683 training error: 0.36347973296309705\n",
            "At step: 7684 training error: 0.3782719386186685\n",
            "At step: 7685 training error: 0.38359665685628236\n",
            "At step: 7686 training error: 0.389043319931043\n",
            "At step: 7687 training error: 0.3974888589609285\n",
            "At step: 7688 training error: 0.4028504869359957\n",
            "At step: 7689 training error: 0.4075728740901079\n",
            "At step: 7690 training error: 0.4036182035022904\n",
            "At step: 7691 training error: 0.40381876090843244\n",
            "At step: 7692 training error: 0.4019924407985088\n",
            "At step: 7693 training error: 0.40017695548058263\n",
            "At step: 7694 training error: 0.40094652492415017\n",
            "At step: 7695 training error: 0.403481166076801\n",
            "At step: 7696 training error: 0.40324200822750605\n",
            "At step: 7697 training error: 0.401095188362091\n",
            "At step: 7698 training error: 0.40284383855916356\n",
            "At step: 7699 training error: 0.4077700190595844\n",
            "At step: 7700 training error: 0.4129781320917327\n",
            "At step: 7701 training error: 0.4106016206849145\n",
            "At step: 7702 training error: 0.42240953007902726\n",
            "At step: 7703 training error: 0.425776116163358\n",
            "At step: 7704 training error: 0.43018298036142005\n",
            "At step: 7705 training error: 0.4206351054327618\n",
            "At step: 7706 training error: 0.430534950445049\n",
            "At step: 7707 training error: 0.4326244078115015\n",
            "At step: 7708 training error: 0.4293673975980672\n",
            "At step: 7709 training error: 0.4131816387993447\n",
            "At step: 7710 training error: 0.40773804757957965\n",
            "At step: 7711 training error: 0.39780199322163473\n",
            "At step: 7712 training error: 0.40679499360246413\n",
            "At step: 7713 training error: 0.40907054708132307\n",
            "At step: 7714 training error: 0.40345405868984396\n",
            "At step: 7715 training error: 0.39149177071674357\n",
            "At step: 7716 training error: 0.3905902572266837\n",
            "At step: 7717 training error: 0.38407726336405806\n",
            "At step: 7718 training error: 0.3886905119122738\n",
            "At step: 7719 training error: 0.3857023132066319\n",
            "At step: 7720 training error: 0.3756018457483645\n",
            "At step: 7721 training error: 0.3893743198759506\n",
            "At step: 7722 training error: 0.3950443264402024\n",
            "At step: 7723 training error: 0.39140019915385005\n",
            "At step: 7724 training error: 0.3923230128266562\n",
            "At step: 7725 training error: 0.3997547156389853\n",
            "At step: 7726 training error: 0.39488817615165916\n",
            "At step: 7727 training error: 0.39749144013016796\n",
            "At step: 7728 training error: 0.3939054563537147\n",
            "At step: 7729 training error: 0.38839214713796877\n",
            "At step: 7730 training error: 0.3919906821647171\n",
            "At step: 7731 training error: 0.3839138539793798\n",
            "At step: 7732 training error: 0.39485006919405174\n",
            "At step: 7733 training error: 0.38795256854239935\n",
            "At step: 7734 training error: 0.3834731754975168\n",
            "At step: 7735 training error: 0.3882589859032997\n",
            "At step: 7736 training error: 0.38485237757480917\n",
            "At step: 7737 training error: 0.38674529611107594\n",
            "At step: 7738 training error: 0.39201963856572025\n",
            "At step: 7739 training error: 0.39926046856857494\n",
            "At step: 7740 training error: 0.39481401800415533\n",
            "At step: 7741 training error: 0.38631826490960597\n",
            "At step: 7742 training error: 0.38910004756959854\n",
            "At step: 7743 training error: 0.3912181088804066\n",
            "At step: 7744 training error: 0.3896649167383395\n",
            "At step: 7745 training error: 0.39744366084959576\n",
            "At step: 7746 training error: 0.3993032808534563\n",
            "At step: 7747 training error: 0.3990266012902681\n",
            "At step: 7748 training error: 0.4010624845524324\n",
            "At step: 7749 training error: 0.41444010469791887\n",
            "At step: 7750 training error: 0.41217252780265373\n",
            "At step: 7751 training error: 0.4235058388111049\n",
            "At step: 7752 training error: 0.42472256067565894\n",
            "At step: 7753 training error: 0.4232978273017842\n",
            "At step: 7754 training error: 0.423292486537351\n",
            "At step: 7755 training error: 0.41198328908039694\n",
            "At step: 7756 training error: 0.4100044440194719\n",
            "At step: 7757 training error: 0.39896637403693735\n",
            "At step: 7758 training error: 0.4041518245923378\n",
            "At step: 7759 training error: 0.4035008740840053\n",
            "At step: 7760 training error: 0.3973902722038835\n",
            "At step: 7761 training error: 0.4069579613513602\n",
            "At step: 7762 training error: 0.404388951499818\n",
            "At step: 7763 training error: 0.4008105074471431\n",
            "At step: 7764 training error: 0.38993869387437285\n",
            "At step: 7765 training error: 0.3936532879682532\n",
            "At step: 7766 training error: 0.39124028932607163\n",
            "At step: 7767 training error: 0.3774507709511552\n",
            "At step: 7768 training error: 0.38140153161830576\n",
            "At step: 7769 training error: 0.37188045069650194\n",
            "At step: 7770 training error: 0.36429584672490695\n",
            "At step: 7771 training error: 0.3633261495271229\n",
            "At step: 7772 training error: 0.36739851317332156\n",
            "At step: 7773 training error: 0.3682654659023942\n",
            "At step: 7774 training error: 0.37466181997195747\n",
            "At step: 7775 training error: 0.3741505879875421\n",
            "At step: 7776 training error: 0.3712292174379912\n",
            "At step: 7777 training error: 0.3600653707347388\n",
            "At step: 7778 training error: 0.3659268555400472\n",
            "At step: 7779 training error: 0.36596266005724654\n",
            "At step: 7780 training error: 0.3691401252773155\n",
            "At step: 7781 training error: 0.37246396293190936\n",
            "At step: 7782 training error: 0.3791211766413586\n",
            "At step: 7783 training error: 0.3734855105396485\n",
            "At step: 7784 training error: 0.3732060590344973\n",
            "At step: 7785 training error: 0.3705623279159787\n",
            "At step: 7786 training error: 0.3674362755117456\n",
            "At step: 7787 training error: 0.36334532178003776\n",
            "At step: 7788 training error: 0.3615729502290528\n",
            "At step: 7789 training error: 0.3684634980912573\n",
            "At step: 7790 training error: 0.370969387060903\n",
            "At step: 7791 training error: 0.37816872298760185\n",
            "At step: 7792 training error: 0.3735477600861455\n",
            "At step: 7793 training error: 0.36905307582501734\n",
            "At step: 7794 training error: 0.3750634361524181\n",
            "At step: 7795 training error: 0.3820568829593006\n",
            "At step: 7796 training error: 0.37445917786923655\n",
            "At step: 7797 training error: 0.36775296277062236\n",
            "At step: 7798 training error: 0.3669543678183104\n",
            "At step: 7799 training error: 0.37061176274485774\n",
            "At step: 7800 training error: 0.3739053357326941\n",
            "At step: 7801 training error: 0.37518653436768323\n",
            "At step: 7802 training error: 0.37183623789810655\n",
            "At step: 7803 training error: 0.36718053548082685\n",
            "At step: 7804 training error: 0.3649548487717518\n",
            "At step: 7805 training error: 0.3687697386892167\n",
            "At step: 7806 training error: 0.367205756874973\n",
            "At step: 7807 training error: 0.3780415896206242\n",
            "At step: 7808 training error: 0.38230704360708556\n",
            "At step: 7809 training error: 0.3852898368971756\n",
            "At step: 7810 training error: 0.3894941080555494\n",
            "At step: 7811 training error: 0.3878000821706201\n",
            "At step: 7812 training error: 0.372677892973495\n",
            "At step: 7813 training error: 0.3779201284468533\n",
            "At step: 7814 training error: 0.3784231371352068\n",
            "At step: 7815 training error: 0.387727206735611\n",
            "At step: 7816 training error: 0.3857109634649739\n",
            "At step: 7817 training error: 0.3814044862405068\n",
            "At step: 7818 training error: 0.390035183243678\n",
            "At step: 7819 training error: 0.3966953372631523\n",
            "At step: 7820 training error: 0.3918498992933587\n",
            "At step: 7821 training error: 0.3920025631269147\n",
            "At step: 7822 training error: 0.4108612198064689\n",
            "At step: 7823 training error: 0.4157847936218031\n",
            "At step: 7824 training error: 0.4053562504959761\n",
            "At step: 7825 training error: 0.40119934442117944\n",
            "At step: 7826 training error: 0.3981558670219915\n",
            "At step: 7827 training error: 0.39555812145084285\n",
            "At step: 7828 training error: 0.3982524468439896\n",
            "At step: 7829 training error: 0.3933742751828833\n",
            "At step: 7830 training error: 0.3932706471497193\n",
            "At step: 7831 training error: 0.39050913631270073\n",
            "At step: 7832 training error: 0.3999530863517001\n",
            "At step: 7833 training error: 0.3974476556784755\n",
            "At step: 7834 training error: 0.3946501180522032\n",
            "At step: 7835 training error: 0.4002570087607237\n",
            "At step: 7836 training error: 0.40183876645171535\n",
            "At step: 7837 training error: 0.39751371015583226\n",
            "At step: 7838 training error: 0.401817302154082\n",
            "At step: 7839 training error: 0.4089458053544498\n",
            "At step: 7840 training error: 0.39985189219690304\n",
            "At step: 7841 training error: 0.4115114094347768\n",
            "At step: 7842 training error: 0.40915461538352504\n",
            "At step: 7843 training error: 0.40464675192291344\n",
            "At step: 7844 training error: 0.40612625466559477\n",
            "At step: 7845 training error: 0.3966461180003048\n",
            "At step: 7846 training error: 0.39319650385322974\n",
            "At step: 7847 training error: 0.38930988629667096\n",
            "At step: 7848 training error: 0.38546325485831134\n",
            "At step: 7849 training error: 0.39159866490592377\n",
            "At step: 7850 training error: 0.382679368069643\n",
            "At step: 7851 training error: 0.37216830861809735\n",
            "At step: 7852 training error: 0.3699131557802672\n",
            "At step: 7853 training error: 0.3678677309066393\n",
            "At step: 7854 training error: 0.37058571940287044\n",
            "At step: 7855 training error: 0.385589936339336\n",
            "At step: 7856 training error: 0.38941544395908867\n",
            "At step: 7857 training error: 0.39300064233256776\n",
            "At step: 7858 training error: 0.3863545965603559\n",
            "At step: 7859 training error: 0.4020203300982687\n",
            "At step: 7860 training error: 0.38832993755613976\n",
            "At step: 7861 training error: 0.3870323476624563\n",
            "At step: 7862 training error: 0.3788760227597757\n",
            "At step: 7863 training error: 0.38456322718153024\n",
            "At step: 7864 training error: 0.3870817190515454\n",
            "At step: 7865 training error: 0.3890613562821519\n",
            "At step: 7866 training error: 0.3854020954847904\n",
            "At step: 7867 training error: 0.3887058331197963\n",
            "At step: 7868 training error: 0.37994816729414715\n",
            "At step: 7869 training error: 0.3762348202943753\n",
            "At step: 7870 training error: 0.3613159009488284\n",
            "At step: 7871 training error: 0.36587630622375\n",
            "At step: 7872 training error: 0.38889260722744695\n",
            "At step: 7873 training error: 0.39331731673809256\n",
            "At step: 7874 training error: 0.3850325516468554\n",
            "At step: 7875 training error: 0.3765837417423547\n",
            "At step: 7876 training error: 0.37864323424454727\n",
            "At step: 7877 training error: 0.3718427982176616\n",
            "At step: 7878 training error: 0.3746723733909003\n",
            "At step: 7879 training error: 0.37931204198367463\n",
            "At step: 7880 training error: 0.37724840551486305\n",
            "At step: 7881 training error: 0.3745963797999126\n",
            "At step: 7882 training error: 0.37783173644638274\n",
            "At step: 7883 training error: 0.369588471479284\n",
            "At step: 7884 training error: 0.3743635842137842\n",
            "At step: 7885 training error: 0.3806416391865456\n",
            "At step: 7886 training error: 0.38887499335062686\n",
            "At step: 7887 training error: 0.3793364798625866\n",
            "At step: 7888 training error: 0.3781384883638151\n",
            "At step: 7889 training error: 0.3789352636578023\n",
            "At step: 7890 training error: 0.3839515331931217\n",
            "At step: 7891 training error: 0.37686826912601157\n",
            "At step: 7892 training error: 0.38760987136781233\n",
            "At step: 7893 training error: 0.3777811350623521\n",
            "At step: 7894 training error: 0.3746887379840695\n",
            "At step: 7895 training error: 0.3702330253690347\n",
            "At step: 7896 training error: 0.3903007381576565\n",
            "At step: 7897 training error: 0.38959599405210993\n",
            "At step: 7898 training error: 0.3791827000203385\n",
            "At step: 7899 training error: 0.37770763105182603\n",
            "At step: 7900 training error: 0.3877617569977036\n",
            "At step: 7901 training error: 0.38946966552566786\n",
            "At step: 7902 training error: 0.3922710542605933\n",
            "At step: 7903 training error: 0.39174385593703637\n",
            "At step: 7904 training error: 0.3915676392793934\n",
            "At step: 7905 training error: 0.4052297878455884\n",
            "At step: 7906 training error: 0.40505576074458904\n",
            "At step: 7907 training error: 0.40541375653817224\n",
            "At step: 7908 training error: 0.3976649240060461\n",
            "At step: 7909 training error: 0.39473170721715606\n",
            "At step: 7910 training error: 0.38033896059755934\n",
            "At step: 7911 training error: 0.37934938836316817\n",
            "At step: 7912 training error: 0.3813745358169783\n",
            "At step: 7913 training error: 0.37475780815749693\n",
            "At step: 7914 training error: 0.37717301192146246\n",
            "At step: 7915 training error: 0.3713817473949417\n",
            "At step: 7916 training error: 0.377091744771503\n",
            "At step: 7917 training error: 0.3719085245881714\n",
            "At step: 7918 training error: 0.37404678683777903\n",
            "At step: 7919 training error: 0.3707442143214685\n",
            "At step: 7920 training error: 0.3672205227768981\n",
            "At step: 7921 training error: 0.3676278738867955\n",
            "At step: 7922 training error: 0.3825376942995228\n",
            "At step: 7923 training error: 0.3758171535108083\n",
            "At step: 7924 training error: 0.36085960255038246\n",
            "At step: 7925 training error: 0.3631771018694072\n",
            "At step: 7926 training error: 0.36711825889262806\n",
            "At step: 7927 training error: 0.37719288973665616\n",
            "At step: 7928 training error: 0.3867645977491828\n",
            "At step: 7929 training error: 0.38755727051830585\n",
            "At step: 7930 training error: 0.3910034038509726\n",
            "At step: 7931 training error: 0.39153716594809596\n",
            "At step: 7932 training error: 0.3981340525172999\n",
            "At step: 7933 training error: 0.40302893096202314\n",
            "At step: 7934 training error: 0.4009050559950591\n",
            "At step: 7935 training error: 0.4033482479640603\n",
            "At step: 7936 training error: 0.42453547043748546\n",
            "At step: 7937 training error: 0.42100115560092116\n",
            "At step: 7938 training error: 0.4242506211576921\n",
            "At step: 7939 training error: 0.42197193677329237\n",
            "At step: 7940 training error: 0.4210178204045906\n",
            "At step: 7941 training error: 0.41628846446771134\n",
            "At step: 7942 training error: 0.4250919488315404\n",
            "At step: 7943 training error: 0.42638120861876616\n",
            "At step: 7944 training error: 0.4164297290937664\n",
            "At step: 7945 training error: 0.417232198710041\n",
            "At step: 7946 training error: 0.4227593612909191\n",
            "At step: 7947 training error: 0.4166032037103288\n",
            "At step: 7948 training error: 0.4135693920272133\n",
            "At step: 7949 training error: 0.40949708326260686\n",
            "At step: 7950 training error: 0.40135308442837614\n",
            "At step: 7951 training error: 0.40116558222713644\n",
            "At step: 7952 training error: 0.3951120085036744\n",
            "At step: 7953 training error: 0.39797548869941446\n",
            "At step: 7954 training error: 0.39937207156112003\n",
            "At step: 7955 training error: 0.38963540525291424\n",
            "At step: 7956 training error: 0.3861755272880606\n",
            "At step: 7957 training error: 0.38221976400632\n",
            "At step: 7958 training error: 0.3818271989668373\n",
            "At step: 7959 training error: 0.37472479597088526\n",
            "At step: 7960 training error: 0.3644692660510674\n",
            "At step: 7961 training error: 0.3754222169591383\n",
            "At step: 7962 training error: 0.3681926088299126\n",
            "At step: 7963 training error: 0.3759173676915469\n",
            "At step: 7964 training error: 0.37051703692003013\n",
            "At step: 7965 training error: 0.3900196594620621\n",
            "At step: 7966 training error: 0.3831248958727469\n",
            "At step: 7967 training error: 0.3873764934620489\n",
            "At step: 7968 training error: 0.388017064319718\n",
            "At step: 7969 training error: 0.3869326929738792\n",
            "At step: 7970 training error: 0.3854926277438666\n",
            "At step: 7971 training error: 0.38787457204277603\n",
            "At step: 7972 training error: 0.38773048790757303\n",
            "At step: 7973 training error: 0.3884864080506404\n",
            "At step: 7974 training error: 0.38957602650553896\n",
            "At step: 7975 training error: 0.3882729901059822\n",
            "At step: 7976 training error: 0.3920156425727055\n",
            "At step: 7977 training error: 0.3971783551704041\n",
            "At step: 7978 training error: 0.40812742918891104\n",
            "At step: 7979 training error: 0.3954205094916564\n",
            "At step: 7980 training error: 0.38309354144497443\n",
            "At step: 7981 training error: 0.38418788829331085\n",
            "At step: 7982 training error: 0.3808204759413643\n",
            "At step: 7983 training error: 0.3900342793181625\n",
            "At step: 7984 training error: 0.3948488543756211\n",
            "At step: 7985 training error: 0.39333726311484696\n",
            "At step: 7986 training error: 0.3905257163980208\n",
            "At step: 7987 training error: 0.40023017605087\n",
            "At step: 7988 training error: 0.4013329484975136\n",
            "At step: 7989 training error: 0.3846571639936468\n",
            "At step: 7990 training error: 0.37835787238707913\n",
            "At step: 7991 training error: 0.3914858065897689\n",
            "At step: 7992 training error: 0.39859588048453093\n",
            "At step: 7993 training error: 0.3945105397316796\n",
            "At step: 7994 training error: 0.39354408037969524\n",
            "At step: 7995 training error: 0.38532678304398527\n",
            "At step: 7996 training error: 0.38157078370575936\n",
            "At step: 7997 training error: 0.3875171817674259\n",
            "At step: 7998 training error: 0.3844205425805118\n",
            "At step: 7999 training error: 0.38744097501481856\n",
            "At step: 8000 training error: 0.39179376035003266\n",
            "At step: 8001 training error: 0.40471166300381206\n",
            "At step: 8002 training error: 0.4063765943310361\n",
            "At step: 8003 training error: 0.4157163254547799\n",
            "At step: 8004 training error: 0.40991746279910257\n",
            "At step: 8005 training error: 0.4059041560459065\n",
            "At step: 8006 training error: 0.40383899396672607\n",
            "At step: 8007 training error: 0.4048237182124594\n",
            "At step: 8008 training error: 0.4088012756856142\n",
            "At step: 8009 training error: 0.4107497475217686\n",
            "At step: 8010 training error: 0.406466515175682\n",
            "At step: 8011 training error: 0.39967569240871054\n",
            "At step: 8012 training error: 0.39542877651383757\n",
            "At step: 8013 training error: 0.398017982266331\n",
            "At step: 8014 training error: 0.39699051862811807\n",
            "At step: 8015 training error: 0.3976971490252199\n",
            "At step: 8016 training error: 0.3941488094055936\n",
            "At step: 8017 training error: 0.3893064433868305\n",
            "At step: 8018 training error: 0.39934522350101165\n",
            "At step: 8019 training error: 0.40357396373573395\n",
            "At step: 8020 training error: 0.3982032107281335\n",
            "At step: 8021 training error: 0.3962709226864683\n",
            "At step: 8022 training error: 0.3977635931606895\n",
            "At step: 8023 training error: 0.39558683005870054\n",
            "At step: 8024 training error: 0.3958121283228164\n",
            "At step: 8025 training error: 0.3923421349227342\n",
            "At step: 8026 training error: 0.4013569841900921\n",
            "At step: 8027 training error: 0.4055650132381667\n",
            "At step: 8028 training error: 0.40390326268357324\n",
            "At step: 8029 training error: 0.40141428497545545\n",
            "At step: 8030 training error: 0.4003376098542899\n",
            "At step: 8031 training error: 0.4089335077653891\n",
            "At step: 8032 training error: 0.40992911797757126\n",
            "At step: 8033 training error: 0.40801981356534295\n",
            "At step: 8034 training error: 0.40185623946185434\n",
            "At step: 8035 training error: 0.4063078703432946\n",
            "At step: 8036 training error: 0.4046367527476857\n",
            "At step: 8037 training error: 0.40389275054453894\n",
            "At step: 8038 training error: 0.41086834651132237\n",
            "At step: 8039 training error: 0.40277560235752957\n",
            "At step: 8040 training error: 0.39903275761892937\n",
            "At step: 8041 training error: 0.39525722583777767\n",
            "At step: 8042 training error: 0.3962914245264567\n",
            "At step: 8043 training error: 0.3906830580972039\n",
            "At step: 8044 training error: 0.3973598642308795\n",
            "At step: 8045 training error: 0.4070424864117155\n",
            "At step: 8046 training error: 0.4005739428465094\n",
            "At step: 8047 training error: 0.39964459786032447\n",
            "At step: 8048 training error: 0.39292138682511324\n",
            "At step: 8049 training error: 0.3802813969073082\n",
            "At step: 8050 training error: 0.38077927850581567\n",
            "At step: 8051 training error: 0.3807467234262901\n",
            "At step: 8052 training error: 0.38716948434290893\n",
            "At step: 8053 training error: 0.38570246364167066\n",
            "At step: 8054 training error: 0.3919407438924512\n",
            "At step: 8055 training error: 0.3958257490811607\n",
            "At step: 8056 training error: 0.38931342923775936\n",
            "At step: 8057 training error: 0.3883380174151975\n",
            "At step: 8058 training error: 0.3867484784877827\n",
            "At step: 8059 training error: 0.37891513607426053\n",
            "At step: 8060 training error: 0.3769508093348815\n",
            "At step: 8061 training error: 0.37099348835823615\n",
            "At step: 8062 training error: 0.36700420820364926\n",
            "At step: 8063 training error: 0.37961311060207875\n",
            "At step: 8064 training error: 0.37440892864887315\n",
            "At step: 8065 training error: 0.3820921532953487\n",
            "At step: 8066 training error: 0.3854376867984893\n",
            "At step: 8067 training error: 0.393881870313469\n",
            "At step: 8068 training error: 0.393790119803257\n",
            "At step: 8069 training error: 0.3822561158924875\n",
            "At step: 8070 training error: 0.3826449331329466\n",
            "At step: 8071 training error: 0.39918228763537417\n",
            "At step: 8072 training error: 0.3929292068601086\n",
            "At step: 8073 training error: 0.40601582763816\n",
            "At step: 8074 training error: 0.40147751307723617\n",
            "At step: 8075 training error: 0.4020918021793939\n",
            "At step: 8076 training error: 0.39074659736297074\n",
            "At step: 8077 training error: 0.3950200672109174\n",
            "At step: 8078 training error: 0.3944761816010375\n",
            "At step: 8079 training error: 0.3968726112296272\n",
            "At step: 8080 training error: 0.4008292535080316\n",
            "At step: 8081 training error: 0.39487210916414417\n",
            "At step: 8082 training error: 0.40199321136763566\n",
            "At step: 8083 training error: 0.3933732450685309\n",
            "At step: 8084 training error: 0.39210060949134895\n",
            "At step: 8085 training error: 0.38744554997006964\n",
            "At step: 8086 training error: 0.3887640934459095\n",
            "At step: 8087 training error: 0.3890234682233623\n",
            "At step: 8088 training error: 0.38716489057854053\n",
            "At step: 8089 training error: 0.38604114518923954\n",
            "At step: 8090 training error: 0.3985338401521671\n",
            "At step: 8091 training error: 0.3912260386142035\n",
            "At step: 8092 training error: 0.38595354851939845\n",
            "At step: 8093 training error: 0.38369385643065224\n",
            "At step: 8094 training error: 0.38421694964649145\n",
            "At step: 8095 training error: 0.3793849754106082\n",
            "At step: 8096 training error: 0.38169081687234074\n",
            "At step: 8097 training error: 0.3808888876516258\n",
            "At step: 8098 training error: 0.37409787008629747\n",
            "At step: 8099 training error: 0.3875692086762685\n",
            "At step: 8100 training error: 0.37929444130953593\n",
            "At step: 8101 training error: 0.37222906035827025\n",
            "At step: 8102 training error: 0.3774975465619502\n",
            "At step: 8103 training error: 0.37697127340067155\n",
            "At step: 8104 training error: 0.3713502209416196\n",
            "At step: 8105 training error: 0.37105896707976066\n",
            "At step: 8106 training error: 0.37296938075630526\n",
            "At step: 8107 training error: 0.36871255882894416\n",
            "At step: 8108 training error: 0.37709005973168264\n",
            "At step: 8109 training error: 0.3790990516694732\n",
            "At step: 8110 training error: 0.39334514491516803\n",
            "At step: 8111 training error: 0.39275937786423704\n",
            "At step: 8112 training error: 0.393810916083066\n",
            "At step: 8113 training error: 0.40230296554559347\n",
            "At step: 8114 training error: 0.4191802068702727\n",
            "At step: 8115 training error: 0.412517555964818\n",
            "At step: 8116 training error: 0.3936346341916106\n",
            "At step: 8117 training error: 0.3822730016413382\n",
            "At step: 8118 training error: 0.37774228040570595\n",
            "At step: 8119 training error: 0.3733122340639906\n",
            "At step: 8120 training error: 0.3736346850145903\n",
            "At step: 8121 training error: 0.3727688911827482\n",
            "At step: 8122 training error: 0.3759464046866211\n",
            "At step: 8123 training error: 0.37727697756015804\n",
            "At step: 8124 training error: 0.3724704641990181\n",
            "At step: 8125 training error: 0.357997467772995\n",
            "At step: 8126 training error: 0.3528542286390308\n",
            "At step: 8127 training error: 0.3576159741749796\n",
            "At step: 8128 training error: 0.36463178255913214\n",
            "At step: 8129 training error: 0.3727945556755768\n",
            "At step: 8130 training error: 0.3745401498547018\n",
            "At step: 8131 training error: 0.3792875830804155\n",
            "At step: 8132 training error: 0.3988171034587108\n",
            "At step: 8133 training error: 0.4038937021946428\n",
            "At step: 8134 training error: 0.3997967365504154\n",
            "At step: 8135 training error: 0.3957049167980987\n",
            "At step: 8136 training error: 0.401810038812106\n",
            "At step: 8137 training error: 0.4008510550028394\n",
            "At step: 8138 training error: 0.40641690568140626\n",
            "At step: 8139 training error: 0.3995979493007492\n",
            "At step: 8140 training error: 0.3953120066272335\n",
            "At step: 8141 training error: 0.3953028594765551\n",
            "At step: 8142 training error: 0.39527824365370534\n",
            "At step: 8143 training error: 0.38153508882479137\n",
            "At step: 8144 training error: 0.3806841198089359\n",
            "At step: 8145 training error: 0.3939707915960277\n",
            "At step: 8146 training error: 0.38963348088315836\n",
            "At step: 8147 training error: 0.38919255500998706\n",
            "At step: 8148 training error: 0.39030599871129695\n",
            "At step: 8149 training error: 0.38136042952075255\n",
            "At step: 8150 training error: 0.38652408653634496\n",
            "At step: 8151 training error: 0.38299914433708593\n",
            "At step: 8152 training error: 0.37512443415350993\n",
            "At step: 8153 training error: 0.3722723967954933\n",
            "At step: 8154 training error: 0.3676433334643038\n",
            "At step: 8155 training error: 0.3668870928704517\n",
            "At step: 8156 training error: 0.3681863963396349\n",
            "At step: 8157 training error: 0.3563543898352305\n",
            "At step: 8158 training error: 0.36313099258682613\n",
            "At step: 8159 training error: 0.36223964553662386\n",
            "At step: 8160 training error: 0.3553104335347521\n",
            "At step: 8161 training error: 0.358870955078186\n",
            "At step: 8162 training error: 0.366504681062605\n",
            "At step: 8163 training error: 0.3722014850044142\n",
            "At step: 8164 training error: 0.37669100542824907\n",
            "At step: 8165 training error: 0.3778284988813436\n",
            "At step: 8166 training error: 0.3822218058300245\n",
            "At step: 8167 training error: 0.3736037574366812\n",
            "At step: 8168 training error: 0.37643026712110494\n",
            "At step: 8169 training error: 0.3864843890864048\n",
            "At step: 8170 training error: 0.38313368628494465\n",
            "At step: 8171 training error: 0.3830047521583746\n",
            "At step: 8172 training error: 0.3798861544011444\n",
            "At step: 8173 training error: 0.3784980609086513\n",
            "At step: 8174 training error: 0.3696788420908015\n",
            "At step: 8175 training error: 0.37874539432016924\n",
            "At step: 8176 training error: 0.38210588602544615\n",
            "At step: 8177 training error: 0.38892976905957444\n",
            "At step: 8178 training error: 0.3937744166158016\n",
            "At step: 8179 training error: 0.39332442473269197\n",
            "At step: 8180 training error: 0.3966574778859456\n",
            "At step: 8181 training error: 0.39781291172732913\n",
            "At step: 8182 training error: 0.39169050889794793\n",
            "At step: 8183 training error: 0.39649547833255006\n",
            "At step: 8184 training error: 0.3805899782200812\n",
            "At step: 8185 training error: 0.3865422556359308\n",
            "At step: 8186 training error: 0.3879425541512985\n",
            "At step: 8187 training error: 0.3956014921376535\n",
            "At step: 8188 training error: 0.3939819061712077\n",
            "At step: 8189 training error: 0.3936483196640925\n",
            "At step: 8190 training error: 0.39004168789175264\n",
            "At step: 8191 training error: 0.38252898291361553\n",
            "At step: 8192 training error: 0.38503692934291467\n",
            "At step: 8193 training error: 0.3907680138991595\n",
            "At step: 8194 training error: 0.3818192626798754\n",
            "At step: 8195 training error: 0.38160892209645136\n",
            "At step: 8196 training error: 0.3782089479916621\n",
            "At step: 8197 training error: 0.3749535857633546\n",
            "At step: 8198 training error: 0.3789606034015478\n",
            "At step: 8199 training error: 0.39046233442792644\n",
            "At step: 8200 training error: 0.3863685877771403\n",
            "At step: 8201 training error: 0.38974968967570145\n",
            "At step: 8202 training error: 0.40073924439694586\n",
            "At step: 8203 training error: 0.4141406932783173\n",
            "At step: 8204 training error: 0.4145598904683829\n",
            "At step: 8205 training error: 0.4192035157886642\n",
            "At step: 8206 training error: 0.4296788285145643\n",
            "At step: 8207 training error: 0.43071561548369175\n",
            "At step: 8208 training error: 0.42200366084256724\n",
            "At step: 8209 training error: 0.42360116061448516\n",
            "At step: 8210 training error: 0.41489310911669935\n",
            "At step: 8211 training error: 0.3996982518294599\n",
            "At step: 8212 training error: 0.3952662445530212\n",
            "At step: 8213 training error: 0.39451234501429266\n",
            "At step: 8214 training error: 0.3964168232527525\n",
            "At step: 8215 training error: 0.39267828672988486\n",
            "At step: 8216 training error: 0.3908339362517425\n",
            "At step: 8217 training error: 0.39030999025385815\n",
            "At step: 8218 training error: 0.3924772423929802\n",
            "At step: 8219 training error: 0.4041496497937801\n",
            "At step: 8220 training error: 0.40104473422542236\n",
            "At step: 8221 training error: 0.3982326279223817\n",
            "At step: 8222 training error: 0.4064196188473016\n",
            "At step: 8223 training error: 0.40416451798537767\n",
            "At step: 8224 training error: 0.41304912606754435\n",
            "At step: 8225 training error: 0.4162324182993245\n",
            "At step: 8226 training error: 0.41766482900736024\n",
            "At step: 8227 training error: 0.4096147021926196\n",
            "At step: 8228 training error: 0.4104382389368386\n",
            "At step: 8229 training error: 0.41884188118657145\n",
            "At step: 8230 training error: 0.41676732572979913\n",
            "At step: 8231 training error: 0.40594582023005515\n",
            "At step: 8232 training error: 0.4058359596360803\n",
            "At step: 8233 training error: 0.40122064694175136\n",
            "At step: 8234 training error: 0.39781559702058866\n",
            "At step: 8235 training error: 0.39368475524218993\n",
            "At step: 8236 training error: 0.39373380639296174\n",
            "At step: 8237 training error: 0.39414329871304765\n",
            "At step: 8238 training error: 0.39408250749093804\n",
            "At step: 8239 training error: 0.40026009716761163\n",
            "At step: 8240 training error: 0.4109988825150772\n",
            "At step: 8241 training error: 0.41948237751510514\n",
            "At step: 8242 training error: 0.41107937627533986\n",
            "At step: 8243 training error: 0.4195473115468767\n",
            "At step: 8244 training error: 0.4207740613467926\n",
            "At step: 8245 training error: 0.40578618771594555\n",
            "At step: 8246 training error: 0.40561278585345995\n",
            "At step: 8247 training error: 0.40573153135397527\n",
            "At step: 8248 training error: 0.396878266358076\n",
            "At step: 8249 training error: 0.3877070441038766\n",
            "At step: 8250 training error: 0.3950157790517215\n",
            "At step: 8251 training error: 0.3911688774008551\n",
            "At step: 8252 training error: 0.3985250564442772\n",
            "At step: 8253 training error: 0.393687515646475\n",
            "At step: 8254 training error: 0.3984677115768053\n",
            "At step: 8255 training error: 0.3917583090013318\n",
            "At step: 8256 training error: 0.388529189048605\n",
            "At step: 8257 training error: 0.38756376190279185\n",
            "At step: 8258 training error: 0.3883119092421035\n",
            "At step: 8259 training error: 0.38682127169000957\n",
            "At step: 8260 training error: 0.38719621645350505\n",
            "At step: 8261 training error: 0.3919199311796413\n",
            "At step: 8262 training error: 0.3967084315700624\n",
            "At step: 8263 training error: 0.3912736294038904\n",
            "At step: 8264 training error: 0.3813045868134732\n",
            "At step: 8265 training error: 0.3839254212691909\n",
            "At step: 8266 training error: 0.38735028056422804\n",
            "At step: 8267 training error: 0.3725704132151605\n",
            "At step: 8268 training error: 0.3719641380262663\n",
            "At step: 8269 training error: 0.3647949834245936\n",
            "At step: 8270 training error: 0.3671613214634955\n",
            "At step: 8271 training error: 0.3615310005953612\n",
            "At step: 8272 training error: 0.3564597066888764\n",
            "At step: 8273 training error: 0.3586633026498777\n",
            "At step: 8274 training error: 0.36773653710626736\n",
            "At step: 8275 training error: 0.38095386702926354\n",
            "At step: 8276 training error: 0.37588080714190775\n",
            "At step: 8277 training error: 0.3887029078924704\n",
            "At step: 8278 training error: 0.38117643786344346\n",
            "At step: 8279 training error: 0.3871746201222343\n",
            "At step: 8280 training error: 0.383486275671496\n",
            "At step: 8281 training error: 0.3790835782179418\n",
            "At step: 8282 training error: 0.3734122991782083\n",
            "At step: 8283 training error: 0.3851003954884503\n",
            "At step: 8284 training error: 0.37786665146682547\n",
            "At step: 8285 training error: 0.3820344149579502\n",
            "At step: 8286 training error: 0.37720884203910265\n",
            "At step: 8287 training error: 0.375046542111325\n",
            "At step: 8288 training error: 0.3745103096105254\n",
            "At step: 8289 training error: 0.38562143390377474\n",
            "At step: 8290 training error: 0.3914199273054314\n",
            "At step: 8291 training error: 0.38999827824541566\n",
            "At step: 8292 training error: 0.3856114569914552\n",
            "At step: 8293 training error: 0.3881560289811934\n",
            "At step: 8294 training error: 0.3915961917163123\n",
            "At step: 8295 training error: 0.39165742995842395\n",
            "At step: 8296 training error: 0.3812737834213539\n",
            "At step: 8297 training error: 0.3754107601050049\n",
            "At step: 8298 training error: 0.3700228748973002\n",
            "At step: 8299 training error: 0.3710108778620547\n",
            "At step: 8300 training error: 0.38138363574234657\n",
            "At step: 8301 training error: 0.39140445110390765\n",
            "At step: 8302 training error: 0.391119444831897\n",
            "At step: 8303 training error: 0.4023886117730839\n",
            "At step: 8304 training error: 0.40384721980305616\n",
            "At step: 8305 training error: 0.40141181163892714\n",
            "At step: 8306 training error: 0.4000330865598912\n",
            "At step: 8307 training error: 0.39001832784770696\n",
            "At step: 8308 training error: 0.3937511297796498\n",
            "At step: 8309 training error: 0.39452671439108733\n",
            "At step: 8310 training error: 0.38787293007669016\n",
            "At step: 8311 training error: 0.39989140690495545\n",
            "At step: 8312 training error: 0.4023226559789399\n",
            "At step: 8313 training error: 0.4007907349957584\n",
            "At step: 8314 training error: 0.4044795164827999\n",
            "At step: 8315 training error: 0.4001932228560261\n",
            "At step: 8316 training error: 0.3988619031519128\n",
            "At step: 8317 training error: 0.40752709534964177\n",
            "At step: 8318 training error: 0.40674277465140596\n",
            "At step: 8319 training error: 0.4076126406697682\n",
            "At step: 8320 training error: 0.4143001940820626\n",
            "At step: 8321 training error: 0.4029502459673464\n",
            "At step: 8322 training error: 0.41888674620298993\n",
            "At step: 8323 training error: 0.4187881414190304\n",
            "At step: 8324 training error: 0.40949629326250847\n",
            "At step: 8325 training error: 0.3937949743214834\n",
            "At step: 8326 training error: 0.4004458801227284\n",
            "At step: 8327 training error: 0.4039402106247454\n",
            "At step: 8328 training error: 0.3934105497333714\n",
            "At step: 8329 training error: 0.38776262750129625\n",
            "At step: 8330 training error: 0.40438009956698134\n",
            "At step: 8331 training error: 0.4028426455810792\n",
            "At step: 8332 training error: 0.4062702127429706\n",
            "At step: 8333 training error: 0.4016989627290621\n",
            "At step: 8334 training error: 0.39755748978280664\n",
            "At step: 8335 training error: 0.4074021394606402\n",
            "At step: 8336 training error: 0.3910541072494212\n",
            "At step: 8337 training error: 0.3983977788541814\n",
            "At step: 8338 training error: 0.3998648258670948\n",
            "At step: 8339 training error: 0.40753863058286816\n",
            "At step: 8340 training error: 0.4085337161972361\n",
            "At step: 8341 training error: 0.4043442105148387\n",
            "At step: 8342 training error: 0.4038995799674019\n",
            "At step: 8343 training error: 0.4140179060553669\n",
            "At step: 8344 training error: 0.406985943292132\n",
            "At step: 8345 training error: 0.399160518658402\n",
            "At step: 8346 training error: 0.3834327067844578\n",
            "At step: 8347 training error: 0.38056852733453594\n",
            "At step: 8348 training error: 0.3799577574451609\n",
            "At step: 8349 training error: 0.37631990848938923\n",
            "At step: 8350 training error: 0.38415212384227215\n",
            "At step: 8351 training error: 0.38327211644224\n",
            "At step: 8352 training error: 0.39170073011473155\n",
            "At step: 8353 training error: 0.40058550358757405\n",
            "At step: 8354 training error: 0.38736542950992864\n",
            "At step: 8355 training error: 0.37266055342258636\n",
            "At step: 8356 training error: 0.3772952863852851\n",
            "At step: 8357 training error: 0.38577188792393163\n",
            "At step: 8358 training error: 0.3906450017575447\n",
            "At step: 8359 training error: 0.3970811620984942\n",
            "At step: 8360 training error: 0.3921811780946328\n",
            "At step: 8361 training error: 0.3858577945456324\n",
            "At step: 8362 training error: 0.3806455656550636\n",
            "At step: 8363 training error: 0.37087576530825145\n",
            "At step: 8364 training error: 0.3725133438163125\n",
            "At step: 8365 training error: 0.36272482547613727\n",
            "At step: 8366 training error: 0.3632436670808911\n",
            "At step: 8367 training error: 0.3823942647120608\n",
            "At step: 8368 training error: 0.37948719471620085\n",
            "At step: 8369 training error: 0.3862614410777804\n",
            "At step: 8370 training error: 0.3941777764690038\n",
            "At step: 8371 training error: 0.3925579186898914\n",
            "At step: 8372 training error: 0.39135608342732836\n",
            "At step: 8373 training error: 0.3821364598055507\n",
            "At step: 8374 training error: 0.3826296847420988\n",
            "At step: 8375 training error: 0.38951651285622485\n",
            "At step: 8376 training error: 0.391955196174288\n",
            "At step: 8377 training error: 0.3952346514212036\n",
            "At step: 8378 training error: 0.3891435882073731\n",
            "At step: 8379 training error: 0.3888886175125866\n",
            "At step: 8380 training error: 0.3766249918009174\n",
            "At step: 8381 training error: 0.37090651270689157\n",
            "At step: 8382 training error: 0.37792703109984743\n",
            "At step: 8383 training error: 0.3726565400860333\n",
            "At step: 8384 training error: 0.3777120259747028\n",
            "At step: 8385 training error: 0.3782516345283433\n",
            "At step: 8386 training error: 0.37988810949702695\n",
            "At step: 8387 training error: 0.38053268951205194\n",
            "At step: 8388 training error: 0.39175628984958527\n",
            "At step: 8389 training error: 0.3963104054791759\n",
            "At step: 8390 training error: 0.39626671813019965\n",
            "At step: 8391 training error: 0.3881710273313334\n",
            "At step: 8392 training error: 0.383083447231645\n",
            "At step: 8393 training error: 0.38513772918262956\n",
            "At step: 8394 training error: 0.39335752076450803\n",
            "At step: 8395 training error: 0.38703964079857966\n",
            "At step: 8396 training error: 0.3917960715177208\n",
            "At step: 8397 training error: 0.3864372448766346\n",
            "At step: 8398 training error: 0.3813432706695575\n",
            "At step: 8399 training error: 0.38709335990603727\n",
            "At step: 8400 training error: 0.39810253965953746\n",
            "At step: 8401 training error: 0.3974452435489941\n",
            "At step: 8402 training error: 0.38717594958158535\n",
            "At step: 8403 training error: 0.38256087386227766\n",
            "At step: 8404 training error: 0.37688555637848214\n",
            "At step: 8405 training error: 0.3682451674560901\n",
            "At step: 8406 training error: 0.3679174065499777\n",
            "At step: 8407 training error: 0.36272318188407077\n",
            "At step: 8408 training error: 0.3648571857576487\n",
            "At step: 8409 training error: 0.3640777613544332\n",
            "At step: 8410 training error: 0.3725608326322396\n",
            "At step: 8411 training error: 0.36105344855037497\n",
            "At step: 8412 training error: 0.36012009877465945\n",
            "At step: 8413 training error: 0.36928985112973256\n",
            "At step: 8414 training error: 0.3717524008707551\n",
            "At step: 8415 training error: 0.3715668080385375\n",
            "At step: 8416 training error: 0.3833668968482558\n",
            "At step: 8417 training error: 0.389076425468026\n",
            "At step: 8418 training error: 0.38755796520018004\n",
            "At step: 8419 training error: 0.38668597944634553\n",
            "At step: 8420 training error: 0.36974945712305207\n",
            "At step: 8421 training error: 0.37389350219733936\n",
            "At step: 8422 training error: 0.36047791648784344\n",
            "At step: 8423 training error: 0.3673299310344045\n",
            "At step: 8424 training error: 0.35631188303516764\n",
            "At step: 8425 training error: 0.3571870741461928\n",
            "At step: 8426 training error: 0.3612550416305109\n",
            "At step: 8427 training error: 0.36842321884337037\n",
            "At step: 8428 training error: 0.36595083141291257\n",
            "At step: 8429 training error: 0.3695493646544691\n",
            "At step: 8430 training error: 0.37070070103552377\n",
            "At step: 8431 training error: 0.37235815613399087\n",
            "At step: 8432 training error: 0.3752626541308379\n",
            "At step: 8433 training error: 0.3763994045634152\n",
            "At step: 8434 training error: 0.3702332133938367\n",
            "At step: 8435 training error: 0.3810993301059474\n",
            "At step: 8436 training error: 0.3800696845160525\n",
            "At step: 8437 training error: 0.375564204383828\n",
            "At step: 8438 training error: 0.3876123859077223\n",
            "At step: 8439 training error: 0.3890228717750911\n",
            "At step: 8440 training error: 0.386974745080064\n",
            "At step: 8441 training error: 0.38534377036074174\n",
            "At step: 8442 training error: 0.37618445135413203\n",
            "At step: 8443 training error: 0.3759955206941532\n",
            "At step: 8444 training error: 0.376398552810745\n",
            "At step: 8445 training error: 0.3797336082517823\n",
            "At step: 8446 training error: 0.3752851418713899\n",
            "At step: 8447 training error: 0.3718194530318621\n",
            "At step: 8448 training error: 0.3660399948994086\n",
            "At step: 8449 training error: 0.3747682789414363\n",
            "At step: 8450 training error: 0.37863910749864615\n",
            "At step: 8451 training error: 0.38475112038739\n",
            "At step: 8452 training error: 0.37603339577178774\n",
            "At step: 8453 training error: 0.3738725457907212\n",
            "At step: 8454 training error: 0.36737350613134123\n",
            "At step: 8455 training error: 0.36702650501769685\n",
            "At step: 8456 training error: 0.3648498244853113\n",
            "At step: 8457 training error: 0.366544303809733\n",
            "At step: 8458 training error: 0.37549355667599393\n",
            "At step: 8459 training error: 0.3681645701079766\n",
            "At step: 8460 training error: 0.3769416437027613\n",
            "At step: 8461 training error: 0.37288199982313147\n",
            "At step: 8462 training error: 0.3714953284755287\n",
            "At step: 8463 training error: 0.37281664421821814\n",
            "At step: 8464 training error: 0.3781217461501824\n",
            "At step: 8465 training error: 0.37830913151567025\n",
            "At step: 8466 training error: 0.37704408513096344\n",
            "At step: 8467 training error: 0.390500982469776\n",
            "At step: 8468 training error: 0.38340508529265727\n",
            "At step: 8469 training error: 0.3968441972601263\n",
            "At step: 8470 training error: 0.3913906396239797\n",
            "At step: 8471 training error: 0.3929703965863179\n",
            "At step: 8472 training error: 0.39481639586821593\n",
            "At step: 8473 training error: 0.38009430385609577\n",
            "At step: 8474 training error: 0.377007945888693\n",
            "At step: 8475 training error: 0.37771365394199424\n",
            "At step: 8476 training error: 0.3846394930245177\n",
            "At step: 8477 training error: 0.3795259126557448\n",
            "At step: 8478 training error: 0.3864558242832312\n",
            "At step: 8479 training error: 0.38500542828691925\n",
            "At step: 8480 training error: 0.38139261386408396\n",
            "At step: 8481 training error: 0.38015786109651556\n",
            "At step: 8482 training error: 0.3843716131598891\n",
            "At step: 8483 training error: 0.3833461297372592\n",
            "At step: 8484 training error: 0.3919263872914107\n",
            "At step: 8485 training error: 0.38163611578891166\n",
            "At step: 8486 training error: 0.38203773169036326\n",
            "At step: 8487 training error: 0.38652261624250944\n",
            "At step: 8488 training error: 0.38129053157542575\n",
            "At step: 8489 training error: 0.38497665997222896\n",
            "At step: 8490 training error: 0.39743683573208494\n",
            "At step: 8491 training error: 0.4022809944181372\n",
            "At step: 8492 training error: 0.40364269329316604\n",
            "At step: 8493 training error: 0.39744049281930227\n",
            "At step: 8494 training error: 0.3889469705789848\n",
            "At step: 8495 training error: 0.3781065336163671\n",
            "At step: 8496 training error: 0.38265902326938694\n",
            "At step: 8497 training error: 0.3841529791521009\n",
            "At step: 8498 training error: 0.3789015956969477\n",
            "At step: 8499 training error: 0.3815166858902954\n",
            "At step: 8500 training error: 0.3768466701982947\n",
            "At step: 8501 training error: 0.37886307063773217\n",
            "At step: 8502 training error: 0.37379910955569984\n",
            "At step: 8503 training error: 0.37734340314627657\n",
            "At step: 8504 training error: 0.377288969514472\n",
            "At step: 8505 training error: 0.3631343785765698\n",
            "At step: 8506 training error: 0.3666480667801455\n",
            "At step: 8507 training error: 0.3730505165685292\n",
            "At step: 8508 training error: 0.3755666511190449\n",
            "At step: 8509 training error: 0.37009235949472136\n",
            "At step: 8510 training error: 0.3821652560206601\n",
            "At step: 8511 training error: 0.37506898941891287\n",
            "At step: 8512 training error: 0.38282184037907263\n",
            "At step: 8513 training error: 0.3902915069523222\n",
            "At step: 8514 training error: 0.3882026177853972\n",
            "At step: 8515 training error: 0.39414805421874166\n",
            "At step: 8516 training error: 0.3978326321339351\n",
            "At step: 8517 training error: 0.3934404584698285\n",
            "At step: 8518 training error: 0.38802411084653887\n",
            "At step: 8519 training error: 0.39113263828121303\n",
            "At step: 8520 training error: 0.3950720322333722\n",
            "At step: 8521 training error: 0.3794814567060413\n",
            "At step: 8522 training error: 0.3785222555223904\n",
            "At step: 8523 training error: 0.38186937009117816\n",
            "At step: 8524 training error: 0.3825188720371003\n",
            "At step: 8525 training error: 0.3760029670304302\n",
            "At step: 8526 training error: 0.3805120082356765\n",
            "At step: 8527 training error: 0.3838111047111862\n",
            "At step: 8528 training error: 0.39254859510853735\n",
            "At step: 8529 training error: 0.3869466827060186\n",
            "At step: 8530 training error: 0.38614046811592323\n",
            "At step: 8531 training error: 0.3866173774430728\n",
            "At step: 8532 training error: 0.3937373760317719\n",
            "At step: 8533 training error: 0.3804114247554055\n",
            "At step: 8534 training error: 0.3802741970443408\n",
            "At step: 8535 training error: 0.3828951498330639\n",
            "At step: 8536 training error: 0.377431111246052\n",
            "At step: 8537 training error: 0.37145055490548795\n",
            "At step: 8538 training error: 0.3720162980184974\n",
            "At step: 8539 training error: 0.37399536520549376\n",
            "At step: 8540 training error: 0.3712639444684639\n",
            "At step: 8541 training error: 0.3790671276238051\n",
            "At step: 8542 training error: 0.374526776540379\n",
            "At step: 8543 training error: 0.3756455171816304\n",
            "At step: 8544 training error: 0.3799574469720015\n",
            "At step: 8545 training error: 0.3880209279040438\n",
            "At step: 8546 training error: 0.3880716689693058\n",
            "At step: 8547 training error: 0.38583095050215255\n",
            "At step: 8548 training error: 0.3946203784747679\n",
            "At step: 8549 training error: 0.3900317538791187\n",
            "At step: 8550 training error: 0.39658617747401786\n",
            "At step: 8551 training error: 0.3921368661661122\n",
            "At step: 8552 training error: 0.3909937007406731\n",
            "At step: 8553 training error: 0.4005527165171884\n",
            "At step: 8554 training error: 0.39264555447961924\n",
            "At step: 8555 training error: 0.39414388789917454\n",
            "At step: 8556 training error: 0.397437066677189\n",
            "At step: 8557 training error: 0.3942082155342153\n",
            "At step: 8558 training error: 0.38852690087546277\n",
            "At step: 8559 training error: 0.385548133387365\n",
            "At step: 8560 training error: 0.3980641795622197\n",
            "At step: 8561 training error: 0.39305140850649123\n",
            "At step: 8562 training error: 0.3754546168770395\n",
            "At step: 8563 training error: 0.3763573312925793\n",
            "At step: 8564 training error: 0.38390695000066355\n",
            "At step: 8565 training error: 0.3832132609918792\n",
            "At step: 8566 training error: 0.380362241640786\n",
            "At step: 8567 training error: 0.3880405241098707\n",
            "At step: 8568 training error: 0.39375552151648846\n",
            "At step: 8569 training error: 0.37899693379593613\n",
            "At step: 8570 training error: 0.3861702109102866\n",
            "At step: 8571 training error: 0.3761295848216225\n",
            "At step: 8572 training error: 0.37790877577793736\n",
            "At step: 8573 training error: 0.38562493272427417\n",
            "At step: 8574 training error: 0.37228196991788876\n",
            "At step: 8575 training error: 0.36827791427044715\n",
            "At step: 8576 training error: 0.3634790210805839\n",
            "At step: 8577 training error: 0.36439130374154366\n",
            "At step: 8578 training error: 0.36944473344853346\n",
            "At step: 8579 training error: 0.36806214924203984\n",
            "At step: 8580 training error: 0.3631011880026643\n",
            "At step: 8581 training error: 0.34563145507210086\n",
            "At step: 8582 training error: 0.3455818074959474\n",
            "At step: 8583 training error: 0.3466206016766294\n",
            "At step: 8584 training error: 0.35139404769156546\n",
            "At step: 8585 training error: 0.3454385176775667\n",
            "At step: 8586 training error: 0.35000948690008477\n",
            "At step: 8587 training error: 0.3471475426117002\n",
            "At step: 8588 training error: 0.3551898981924979\n",
            "At step: 8589 training error: 0.341010646326771\n",
            "At step: 8590 training error: 0.3441613817895173\n",
            "At step: 8591 training error: 0.34692954950226385\n",
            "At step: 8592 training error: 0.3492853223926118\n",
            "At step: 8593 training error: 0.34380925977683896\n",
            "At step: 8594 training error: 0.3484760727269997\n",
            "At step: 8595 training error: 0.35560548722026797\n",
            "At step: 8596 training error: 0.34609219647846484\n",
            "At step: 8597 training error: 0.35558141399704346\n",
            "At step: 8598 training error: 0.3580346481324739\n",
            "At step: 8599 training error: 0.3591856358502406\n",
            "At step: 8600 training error: 0.36738115422167483\n",
            "At step: 8601 training error: 0.36953632919385937\n",
            "At step: 8602 training error: 0.38876142529982366\n",
            "At step: 8603 training error: 0.38929506404796443\n",
            "At step: 8604 training error: 0.38850281722573754\n",
            "At step: 8605 training error: 0.3834980405469339\n",
            "At step: 8606 training error: 0.3827652967280817\n",
            "At step: 8607 training error: 0.39626466635588276\n",
            "At step: 8608 training error: 0.3800399162200358\n",
            "At step: 8609 training error: 0.387106049417853\n",
            "At step: 8610 training error: 0.38269686819114773\n",
            "At step: 8611 training error: 0.40891270505537264\n",
            "At step: 8612 training error: 0.41799036120634414\n",
            "At step: 8613 training error: 0.41250898312354173\n",
            "At step: 8614 training error: 0.4101082023659461\n",
            "At step: 8615 training error: 0.40756549290216465\n",
            "At step: 8616 training error: 0.41871008116151787\n",
            "At step: 8617 training error: 0.4207915447897399\n",
            "At step: 8618 training error: 0.41509115246689665\n",
            "At step: 8619 training error: 0.40714030654546896\n",
            "At step: 8620 training error: 0.4039778132640703\n",
            "At step: 8621 training error: 0.3958251133709324\n",
            "At step: 8622 training error: 0.3810631812381165\n",
            "At step: 8623 training error: 0.38341410607681825\n",
            "At step: 8624 training error: 0.37174862256182156\n",
            "At step: 8625 training error: 0.3695373986861475\n",
            "At step: 8626 training error: 0.381929594697858\n",
            "At step: 8627 training error: 0.3714943508937847\n",
            "At step: 8628 training error: 0.3644871319034455\n",
            "At step: 8629 training error: 0.36796831909949423\n",
            "At step: 8630 training error: 0.3648773449604678\n",
            "At step: 8631 training error: 0.359969741529456\n",
            "At step: 8632 training error: 0.3735424688158936\n",
            "At step: 8633 training error: 0.3693273560423088\n",
            "At step: 8634 training error: 0.36549514755320567\n",
            "At step: 8635 training error: 0.37433111359152166\n",
            "At step: 8636 training error: 0.36933409029960707\n",
            "At step: 8637 training error: 0.37232577081239454\n",
            "At step: 8638 training error: 0.37821502766202464\n",
            "At step: 8639 training error: 0.37481152376148374\n",
            "At step: 8640 training error: 0.37033853922028787\n",
            "At step: 8641 training error: 0.3794647365166587\n",
            "At step: 8642 training error: 0.37745677650095544\n",
            "At step: 8643 training error: 0.38938912593824504\n",
            "At step: 8644 training error: 0.3838233302606361\n",
            "At step: 8645 training error: 0.3921533955171337\n",
            "At step: 8646 training error: 0.3891368124656874\n",
            "At step: 8647 training error: 0.382647246817119\n",
            "At step: 8648 training error: 0.37844485088028473\n",
            "At step: 8649 training error: 0.36950481942878627\n",
            "At step: 8650 training error: 0.364595509746539\n",
            "At step: 8651 training error: 0.3616689599614277\n",
            "At step: 8652 training error: 0.380834761929988\n",
            "At step: 8653 training error: 0.37213303549898297\n",
            "At step: 8654 training error: 0.38011191212846657\n",
            "At step: 8655 training error: 0.3825689127543841\n",
            "At step: 8656 training error: 0.3691600494503744\n",
            "At step: 8657 training error: 0.3624273012324348\n",
            "At step: 8658 training error: 0.3557111829514855\n",
            "At step: 8659 training error: 0.35850001003566145\n",
            "At step: 8660 training error: 0.36482704124502247\n",
            "At step: 8661 training error: 0.3666501160118933\n",
            "At step: 8662 training error: 0.37019829821429756\n",
            "At step: 8663 training error: 0.3746602278302864\n",
            "At step: 8664 training error: 0.38368891598544846\n",
            "At step: 8665 training error: 0.3836241622005874\n",
            "At step: 8666 training error: 0.39105208755119303\n",
            "At step: 8667 training error: 0.3843575335997716\n",
            "At step: 8668 training error: 0.3780899200905377\n",
            "At step: 8669 training error: 0.3891755780901542\n",
            "At step: 8670 training error: 0.3975202252743934\n",
            "At step: 8671 training error: 0.3961310694006669\n",
            "At step: 8672 training error: 0.39451617480906825\n",
            "At step: 8673 training error: 0.39193094113717714\n",
            "At step: 8674 training error: 0.38702669899214387\n",
            "At step: 8675 training error: 0.38513164126078053\n",
            "At step: 8676 training error: 0.37981865943968\n",
            "At step: 8677 training error: 0.37344511991538476\n",
            "At step: 8678 training error: 0.3650550285929676\n",
            "At step: 8679 training error: 0.3705497490540152\n",
            "At step: 8680 training error: 0.3575197658469899\n",
            "At step: 8681 training error: 0.3601935547553998\n",
            "At step: 8682 training error: 0.3515460293870077\n",
            "At step: 8683 training error: 0.35618119937116033\n",
            "At step: 8684 training error: 0.36327567166983205\n",
            "At step: 8685 training error: 0.36439003383862917\n",
            "At step: 8686 training error: 0.35924875006230256\n",
            "At step: 8687 training error: 0.35668719267924165\n",
            "At step: 8688 training error: 0.35884874857566584\n",
            "At step: 8689 training error: 0.35434608432573333\n",
            "At step: 8690 training error: 0.34660073958584786\n",
            "At step: 8691 training error: 0.34808123000721\n",
            "At step: 8692 training error: 0.34477366160544903\n",
            "At step: 8693 training error: 0.3408278089721398\n",
            "At step: 8694 training error: 0.34548855962926894\n",
            "At step: 8695 training error: 0.35049627955818424\n",
            "At step: 8696 training error: 0.3455091935032486\n",
            "At step: 8697 training error: 0.3394497731734994\n",
            "At step: 8698 training error: 0.34243200447158306\n",
            "At step: 8699 training error: 0.35716970926006825\n",
            "At step: 8700 training error: 0.35805002005222325\n",
            "At step: 8701 training error: 0.36330595407584865\n",
            "At step: 8702 training error: 0.3609542930396547\n",
            "At step: 8703 training error: 0.36020393307318066\n",
            "At step: 8704 training error: 0.3595041917815337\n",
            "At step: 8705 training error: 0.3625118383230754\n",
            "At step: 8706 training error: 0.36283618529637446\n",
            "At step: 8707 training error: 0.3674261937885086\n",
            "At step: 8708 training error: 0.3611859562385163\n",
            "At step: 8709 training error: 0.3556148474346021\n",
            "At step: 8710 training error: 0.3574364491779861\n",
            "At step: 8711 training error: 0.3545661725516227\n",
            "At step: 8712 training error: 0.355853081293187\n",
            "At step: 8713 training error: 0.35052106764016805\n",
            "At step: 8714 training error: 0.3479683030881469\n",
            "At step: 8715 training error: 0.35352787447104017\n",
            "At step: 8716 training error: 0.35837630784733576\n",
            "At step: 8717 training error: 0.37343183753134435\n",
            "At step: 8718 training error: 0.3752142951963314\n",
            "At step: 8719 training error: 0.36787432953614574\n",
            "At step: 8720 training error: 0.36455064701342577\n",
            "At step: 8721 training error: 0.3603459254388962\n",
            "At step: 8722 training error: 0.3581843854759782\n",
            "At step: 8723 training error: 0.3732036338620232\n",
            "At step: 8724 training error: 0.37758137917489387\n",
            "At step: 8725 training error: 0.38195033956266644\n",
            "At step: 8726 training error: 0.36913867123675653\n",
            "At step: 8727 training error: 0.3737529922162472\n",
            "At step: 8728 training error: 0.368167564218033\n",
            "At step: 8729 training error: 0.3670040855310166\n",
            "At step: 8730 training error: 0.36986587834619084\n",
            "At step: 8731 training error: 0.37130859786125875\n",
            "At step: 8732 training error: 0.37077661524666683\n",
            "At step: 8733 training error: 0.36757073061207335\n",
            "At step: 8734 training error: 0.3748613610456637\n",
            "At step: 8735 training error: 0.3777462783537861\n",
            "At step: 8736 training error: 0.3818274770558188\n",
            "At step: 8737 training error: 0.3828913199453078\n",
            "At step: 8738 training error: 0.387610154802922\n",
            "At step: 8739 training error: 0.3792741227655929\n",
            "At step: 8740 training error: 0.3806872653100114\n",
            "At step: 8741 training error: 0.38501047361973517\n",
            "At step: 8742 training error: 0.3831290839707218\n",
            "At step: 8743 training error: 0.3788032033854125\n",
            "At step: 8744 training error: 0.372072080288818\n",
            "At step: 8745 training error: 0.3672053919388723\n",
            "At step: 8746 training error: 0.36758697384758726\n",
            "At step: 8747 training error: 0.3713273233872158\n",
            "At step: 8748 training error: 0.3770294980252037\n",
            "At step: 8749 training error: 0.35999301249014276\n",
            "At step: 8750 training error: 0.35466707389280344\n",
            "At step: 8751 training error: 0.36399303832115604\n",
            "At step: 8752 training error: 0.35555249629757\n",
            "At step: 8753 training error: 0.3551091708776519\n",
            "At step: 8754 training error: 0.3601877547175761\n",
            "At step: 8755 training error: 0.3763517757858291\n",
            "At step: 8756 training error: 0.3728786433933041\n",
            "At step: 8757 training error: 0.36979556983531636\n",
            "At step: 8758 training error: 0.36713746777365447\n",
            "At step: 8759 training error: 0.3656685791602716\n",
            "At step: 8760 training error: 0.3530211771169489\n",
            "At step: 8761 training error: 0.35901146413630447\n",
            "At step: 8762 training error: 0.36292201969089033\n",
            "At step: 8763 training error: 0.3570870102035948\n",
            "At step: 8764 training error: 0.3608697944828754\n",
            "At step: 8765 training error: 0.35201395584541084\n",
            "At step: 8766 training error: 0.35570097352267877\n",
            "At step: 8767 training error: 0.35852471877153824\n",
            "At step: 8768 training error: 0.3572675685947378\n",
            "At step: 8769 training error: 0.36272331214357234\n",
            "At step: 8770 training error: 0.36287528811017794\n",
            "At step: 8771 training error: 0.3591008536797408\n",
            "At step: 8772 training error: 0.35352785334232567\n",
            "At step: 8773 training error: 0.3477098911185617\n",
            "At step: 8774 training error: 0.37343774087715\n",
            "At step: 8775 training error: 0.37491041237076694\n",
            "At step: 8776 training error: 0.3675714808656745\n",
            "At step: 8777 training error: 0.37138171986173063\n",
            "At step: 8778 training error: 0.3611821593643439\n",
            "At step: 8779 training error: 0.3675087073802942\n",
            "At step: 8780 training error: 0.3715985235532766\n",
            "At step: 8781 training error: 0.3688107222497929\n",
            "At step: 8782 training error: 0.3778148292263421\n",
            "At step: 8783 training error: 0.37101918625976676\n",
            "At step: 8784 training error: 0.3751118644067649\n",
            "At step: 8785 training error: 0.3733894094102246\n",
            "At step: 8786 training error: 0.3740597307968515\n",
            "At step: 8787 training error: 0.3803368244041567\n",
            "At step: 8788 training error: 0.37381892660594945\n",
            "At step: 8789 training error: 0.3776096989376122\n",
            "At step: 8790 training error: 0.3834685879372955\n",
            "At step: 8791 training error: 0.38198772302807427\n",
            "At step: 8792 training error: 0.3861577477509474\n",
            "At step: 8793 training error: 0.3857679192324504\n",
            "At step: 8794 training error: 0.38174695356607663\n",
            "At step: 8795 training error: 0.3793981102795174\n",
            "At step: 8796 training error: 0.36673946763500936\n",
            "At step: 8797 training error: 0.3663926861273116\n",
            "At step: 8798 training error: 0.38238067889458105\n",
            "At step: 8799 training error: 0.36992054599576124\n",
            "At step: 8800 training error: 0.3659560295426731\n",
            "At step: 8801 training error: 0.3627197634237971\n",
            "At step: 8802 training error: 0.35285206194753244\n",
            "At step: 8803 training error: 0.3534994324604926\n",
            "At step: 8804 training error: 0.3640443453833683\n",
            "At step: 8805 training error: 0.3567274676858712\n",
            "At step: 8806 training error: 0.3599433598334587\n",
            "At step: 8807 training error: 0.36526415296185905\n",
            "At step: 8808 training error: 0.36426324215323896\n",
            "At step: 8809 training error: 0.36111992157025286\n",
            "At step: 8810 training error: 0.36585426780679337\n",
            "At step: 8811 training error: 0.35558621138497587\n",
            "At step: 8812 training error: 0.3634864090572628\n",
            "At step: 8813 training error: 0.3511339387194263\n",
            "At step: 8814 training error: 0.3529958869394241\n",
            "At step: 8815 training error: 0.36389865184726056\n",
            "At step: 8816 training error: 0.3666080558537094\n",
            "At step: 8817 training error: 0.3589840413755957\n",
            "At step: 8818 training error: 0.36103914873730003\n",
            "At step: 8819 training error: 0.3693536851751929\n",
            "At step: 8820 training error: 0.3644898514352391\n",
            "At step: 8821 training error: 0.3552141399276585\n",
            "At step: 8822 training error: 0.3610208304145959\n",
            "At step: 8823 training error: 0.36701370456805793\n",
            "At step: 8824 training error: 0.37872966915066747\n",
            "At step: 8825 training error: 0.3724876121781285\n",
            "At step: 8826 training error: 0.3655676420144927\n",
            "At step: 8827 training error: 0.36141363013560324\n",
            "At step: 8828 training error: 0.36420362948210444\n",
            "At step: 8829 training error: 0.3595278555460779\n",
            "At step: 8830 training error: 0.37004998357074054\n",
            "At step: 8831 training error: 0.3592678222216452\n",
            "At step: 8832 training error: 0.351849640902768\n",
            "At step: 8833 training error: 0.35006760904098966\n",
            "At step: 8834 training error: 0.3439680520532237\n",
            "At step: 8835 training error: 0.35302625391334863\n",
            "At step: 8836 training error: 0.3609930654586149\n",
            "At step: 8837 training error: 0.36248656840075144\n",
            "At step: 8838 training error: 0.3572284112147072\n",
            "At step: 8839 training error: 0.3671069270662627\n",
            "At step: 8840 training error: 0.3576439357207621\n",
            "At step: 8841 training error: 0.35632505483728755\n",
            "At step: 8842 training error: 0.359051820833976\n",
            "At step: 8843 training error: 0.36816273882612294\n",
            "At step: 8844 training error: 0.39638621369997246\n",
            "At step: 8845 training error: 0.40818037560431353\n",
            "At step: 8846 training error: 0.4135252101155944\n",
            "At step: 8847 training error: 0.40656693252756004\n",
            "At step: 8848 training error: 0.398960905598325\n",
            "At step: 8849 training error: 0.3946268475863967\n",
            "At step: 8850 training error: 0.39020283330851435\n",
            "At step: 8851 training error: 0.38990719599159207\n",
            "At step: 8852 training error: 0.38674197597658583\n",
            "At step: 8853 training error: 0.37778054683886486\n",
            "At step: 8854 training error: 0.37710645604014637\n",
            "At step: 8855 training error: 0.372899460171628\n",
            "At step: 8856 training error: 0.3743681288806467\n",
            "At step: 8857 training error: 0.37192953616187724\n",
            "At step: 8858 training error: 0.36470911506346626\n",
            "At step: 8859 training error: 0.3579253901276526\n",
            "At step: 8860 training error: 0.35863223797375965\n",
            "At step: 8861 training error: 0.35992857745090767\n",
            "At step: 8862 training error: 0.3574977418860545\n",
            "At step: 8863 training error: 0.35653275433147225\n",
            "At step: 8864 training error: 0.3564908466719698\n",
            "At step: 8865 training error: 0.35812381103576973\n",
            "At step: 8866 training error: 0.36437101305604436\n",
            "At step: 8867 training error: 0.36553873374976836\n",
            "At step: 8868 training error: 0.3703775577924804\n",
            "At step: 8869 training error: 0.36658445755191416\n",
            "At step: 8870 training error: 0.36744716634450597\n",
            "At step: 8871 training error: 0.3704592037708526\n",
            "At step: 8872 training error: 0.36589372786639474\n",
            "At step: 8873 training error: 0.37462663598811585\n",
            "At step: 8874 training error: 0.3670258264553389\n",
            "At step: 8875 training error: 0.36667439784874595\n",
            "At step: 8876 training error: 0.3807665532991279\n",
            "At step: 8877 training error: 0.3779371533989992\n",
            "At step: 8878 training error: 0.3716664665657612\n",
            "At step: 8879 training error: 0.37080554723126674\n",
            "At step: 8880 training error: 0.367776499359977\n",
            "At step: 8881 training error: 0.363300788366248\n",
            "At step: 8882 training error: 0.36324528553745067\n",
            "At step: 8883 training error: 0.3583319075302358\n",
            "At step: 8884 training error: 0.37614187444723796\n",
            "At step: 8885 training error: 0.370929145300725\n",
            "At step: 8886 training error: 0.37957983549091234\n",
            "At step: 8887 training error: 0.37500652434411935\n",
            "At step: 8888 training error: 0.37308410712089646\n",
            "At step: 8889 training error: 0.3835558848599122\n",
            "At step: 8890 training error: 0.381243253421595\n",
            "At step: 8891 training error: 0.3797566081462827\n",
            "At step: 8892 training error: 0.3842956920953502\n",
            "At step: 8893 training error: 0.38432923490372706\n",
            "At step: 8894 training error: 0.3934021325350613\n",
            "At step: 8895 training error: 0.3935700402172387\n",
            "At step: 8896 training error: 0.3937363573407532\n",
            "At step: 8897 training error: 0.3882152956495031\n",
            "At step: 8898 training error: 0.38827719485953827\n",
            "At step: 8899 training error: 0.3895743626896165\n",
            "At step: 8900 training error: 0.37533374951140874\n",
            "At step: 8901 training error: 0.38425509161903637\n",
            "At step: 8902 training error: 0.3806432114510829\n",
            "At step: 8903 training error: 0.370401461662031\n",
            "At step: 8904 training error: 0.37138280975357274\n",
            "At step: 8905 training error: 0.36864751985328936\n",
            "At step: 8906 training error: 0.36371145232153523\n",
            "At step: 8907 training error: 0.3615396998476536\n",
            "At step: 8908 training error: 0.3587006444549996\n",
            "At step: 8909 training error: 0.35430671713413286\n",
            "At step: 8910 training error: 0.3484295655565658\n",
            "At step: 8911 training error: 0.36187912030699587\n",
            "At step: 8912 training error: 0.3764640535701939\n",
            "At step: 8913 training error: 0.3749711999137009\n",
            "At step: 8914 training error: 0.3602516628096073\n",
            "At step: 8915 training error: 0.35766743120785327\n",
            "At step: 8916 training error: 0.3619771638705285\n",
            "At step: 8917 training error: 0.35634497148566624\n",
            "At step: 8918 training error: 0.36069725604852126\n",
            "At step: 8919 training error: 0.36781023010358305\n",
            "At step: 8920 training error: 0.36183532465856005\n",
            "At step: 8921 training error: 0.3698323065756847\n",
            "At step: 8922 training error: 0.36703692986977987\n",
            "At step: 8923 training error: 0.3793225329123161\n",
            "At step: 8924 training error: 0.36977991578616254\n",
            "At step: 8925 training error: 0.37908656430333204\n",
            "At step: 8926 training error: 0.3839953804568987\n",
            "At step: 8927 training error: 0.39509019182473093\n",
            "At step: 8928 training error: 0.3899984377435162\n",
            "At step: 8929 training error: 0.380774969000803\n",
            "At step: 8930 training error: 0.3790402951164532\n",
            "At step: 8931 training error: 0.38691642896947787\n",
            "At step: 8932 training error: 0.3874671129270531\n",
            "At step: 8933 training error: 0.3901363682588737\n",
            "At step: 8934 training error: 0.38372419427767246\n",
            "At step: 8935 training error: 0.3806649423786949\n",
            "At step: 8936 training error: 0.38303359613340326\n",
            "At step: 8937 training error: 0.3821636972109151\n",
            "At step: 8938 training error: 0.3829142029232406\n",
            "At step: 8939 training error: 0.37744157576751924\n",
            "At step: 8940 training error: 0.37222963555455013\n",
            "At step: 8941 training error: 0.3663837669981454\n",
            "At step: 8942 training error: 0.37341134128877274\n",
            "At step: 8943 training error: 0.38119440636962\n",
            "At step: 8944 training error: 0.38316240601729057\n",
            "At step: 8945 training error: 0.3855305086465684\n",
            "At step: 8946 training error: 0.39406203042143007\n",
            "At step: 8947 training error: 0.39216734159180805\n",
            "At step: 8948 training error: 0.3942534198449651\n",
            "At step: 8949 training error: 0.39743469183895014\n",
            "At step: 8950 training error: 0.3929609329094326\n",
            "At step: 8951 training error: 0.3755960133239369\n",
            "At step: 8952 training error: 0.38035643303314015\n",
            "At step: 8953 training error: 0.3814770189174135\n",
            "At step: 8954 training error: 0.3806515808233231\n",
            "At step: 8955 training error: 0.3881822976989349\n",
            "At step: 8956 training error: 0.3749881371840314\n",
            "At step: 8957 training error: 0.382054797105813\n",
            "At step: 8958 training error: 0.38706706760220494\n",
            "At step: 8959 training error: 0.3833774767371255\n",
            "At step: 8960 training error: 0.3727909851979765\n",
            "At step: 8961 training error: 0.3613300406309313\n",
            "At step: 8962 training error: 0.37237948568923246\n",
            "At step: 8963 training error: 0.371300901182761\n",
            "At step: 8964 training error: 0.3800988148259364\n",
            "At step: 8965 training error: 0.3742350236440443\n",
            "At step: 8966 training error: 0.37254504464975036\n",
            "At step: 8967 training error: 0.37404361369237216\n",
            "At step: 8968 training error: 0.3790166803674234\n",
            "At step: 8969 training error: 0.385871512533666\n",
            "At step: 8970 training error: 0.3786660971445398\n",
            "At step: 8971 training error: 0.37308641608323245\n",
            "At step: 8972 training error: 0.3757543870836234\n",
            "At step: 8973 training error: 0.3686745865164765\n",
            "At step: 8974 training error: 0.36313985431526064\n",
            "At step: 8975 training error: 0.36926951240108996\n",
            "At step: 8976 training error: 0.3760159215389238\n",
            "At step: 8977 training error: 0.3813609967415933\n",
            "At step: 8978 training error: 0.37796599511188406\n",
            "At step: 8979 training error: 0.36671566467457084\n",
            "At step: 8980 training error: 0.37197655687920644\n",
            "At step: 8981 training error: 0.37718006695867656\n",
            "At step: 8982 training error: 0.38259637448009265\n",
            "At step: 8983 training error: 0.37397265671258756\n",
            "At step: 8984 training error: 0.36935948211309017\n",
            "At step: 8985 training error: 0.3615912340430143\n",
            "At step: 8986 training error: 0.3594763938281027\n",
            "At step: 8987 training error: 0.36248632179197926\n",
            "At step: 8988 training error: 0.3511898753090185\n",
            "At step: 8989 training error: 0.3582864193965557\n",
            "At step: 8990 training error: 0.3614660891362182\n",
            "At step: 8991 training error: 0.35920980672059744\n",
            "At step: 8992 training error: 0.3609415276064215\n",
            "At step: 8993 training error: 0.35446308086225536\n",
            "At step: 8994 training error: 0.36265699500387877\n",
            "At step: 8995 training error: 0.35946093112055044\n",
            "At step: 8996 training error: 0.3558572892614838\n",
            "At step: 8997 training error: 0.3498185264588936\n",
            "At step: 8998 training error: 0.35708305845248395\n",
            "At step: 8999 training error: 0.35656293996493527\n",
            "At step: 9000 training error: 0.3575094622088528\n",
            "At step: 9001 training error: 0.3604570971696997\n",
            "At step: 9002 training error: 0.35095135255261745\n",
            "At step: 9003 training error: 0.36711681235905685\n",
            "At step: 9004 training error: 0.3627973926149763\n",
            "At step: 9005 training error: 0.3678497565815839\n",
            "At step: 9006 training error: 0.3700171101005181\n",
            "At step: 9007 training error: 0.36538376187478894\n",
            "At step: 9008 training error: 0.3725994210296264\n",
            "At step: 9009 training error: 0.37475432099923567\n",
            "At step: 9010 training error: 0.3728133845538815\n",
            "At step: 9011 training error: 0.3801733221674259\n",
            "At step: 9012 training error: 0.3747185139777468\n",
            "At step: 9013 training error: 0.3716799873696565\n",
            "At step: 9014 training error: 0.3737920055081793\n",
            "At step: 9015 training error: 0.3784946951231142\n",
            "At step: 9016 training error: 0.37507209183162143\n",
            "At step: 9017 training error: 0.38074691422510193\n",
            "At step: 9018 training error: 0.3783401759459933\n",
            "At step: 9019 training error: 0.38041607711534636\n",
            "At step: 9020 training error: 0.37823604176814646\n",
            "At step: 9021 training error: 0.3767598799818525\n",
            "At step: 9022 training error: 0.37780011197361113\n",
            "At step: 9023 training error: 0.37407277502517866\n",
            "At step: 9024 training error: 0.37575068055868155\n",
            "At step: 9025 training error: 0.3772089664560135\n",
            "At step: 9026 training error: 0.37490077800745586\n",
            "At step: 9027 training error: 0.36715300620045893\n",
            "At step: 9028 training error: 0.36337939694500987\n",
            "At step: 9029 training error: 0.3676141681127326\n",
            "At step: 9030 training error: 0.3654065095679578\n",
            "At step: 9031 training error: 0.36096919672080274\n",
            "At step: 9032 training error: 0.36343879983466154\n",
            "At step: 9033 training error: 0.3492835113740011\n",
            "At step: 9034 training error: 0.3419265909770812\n",
            "At step: 9035 training error: 0.33386872572573745\n",
            "At step: 9036 training error: 0.3300461475385019\n",
            "At step: 9037 training error: 0.3269092658253169\n",
            "At step: 9038 training error: 0.3285213490413149\n",
            "At step: 9039 training error: 0.3312561650232068\n",
            "At step: 9040 training error: 0.3378179235834698\n",
            "At step: 9041 training error: 0.3372675547121559\n",
            "At step: 9042 training error: 0.33442857982169527\n",
            "At step: 9043 training error: 0.3386690718110608\n",
            "At step: 9044 training error: 0.3416144011917746\n",
            "At step: 9045 training error: 0.34354653477468783\n",
            "At step: 9046 training error: 0.3418789310761982\n",
            "At step: 9047 training error: 0.3441952639807233\n",
            "At step: 9048 training error: 0.3384116728574281\n",
            "At step: 9049 training error: 0.34446658001721264\n",
            "At step: 9050 training error: 0.3464836275156157\n",
            "At step: 9051 training error: 0.35174793533418314\n",
            "At step: 9052 training error: 0.35322925164001223\n",
            "At step: 9053 training error: 0.3601331687892825\n",
            "At step: 9054 training error: 0.3770176870206069\n",
            "At step: 9055 training error: 0.37891912998295546\n",
            "At step: 9056 training error: 0.3755944663304666\n",
            "At step: 9057 training error: 0.37447050520104375\n",
            "At step: 9058 training error: 0.36584380013648105\n",
            "At step: 9059 training error: 0.3709077298180561\n",
            "At step: 9060 training error: 0.37540515561343946\n",
            "At step: 9061 training error: 0.3693907381755373\n",
            "At step: 9062 training error: 0.3724787189423498\n",
            "At step: 9063 training error: 0.3650933844801499\n",
            "At step: 9064 training error: 0.373547001010494\n",
            "At step: 9065 training error: 0.37202843389714946\n",
            "At step: 9066 training error: 0.386204017053216\n",
            "At step: 9067 training error: 0.38353382063197855\n",
            "At step: 9068 training error: 0.37861513705587513\n",
            "At step: 9069 training error: 0.377675381056372\n",
            "At step: 9070 training error: 0.384097610767787\n",
            "At step: 9071 training error: 0.37855539796754845\n",
            "At step: 9072 training error: 0.37803014997999224\n",
            "At step: 9073 training error: 0.3628131348597472\n",
            "At step: 9074 training error: 0.3589560245292803\n",
            "At step: 9075 training error: 0.3693069293161047\n",
            "At step: 9076 training error: 0.36491185138482063\n",
            "At step: 9077 training error: 0.3745867961768856\n",
            "At step: 9078 training error: 0.3742031412500243\n",
            "At step: 9079 training error: 0.38117461668274755\n",
            "At step: 9080 training error: 0.37817843671211215\n",
            "At step: 9081 training error: 0.36917744895362725\n",
            "At step: 9082 training error: 0.3670731522719914\n",
            "At step: 9083 training error: 0.35907862018362324\n",
            "At step: 9084 training error: 0.3565470701864337\n",
            "At step: 9085 training error: 0.35013929042627023\n",
            "At step: 9086 training error: 0.35436458119723235\n",
            "At step: 9087 training error: 0.355597002261811\n",
            "At step: 9088 training error: 0.3555210816527001\n",
            "At step: 9089 training error: 0.3635496086759342\n",
            "At step: 9090 training error: 0.3587678707179318\n",
            "At step: 9091 training error: 0.36344957226356783\n",
            "At step: 9092 training error: 0.36533779002949596\n",
            "At step: 9093 training error: 0.36619073559557125\n",
            "At step: 9094 training error: 0.37382276263685993\n",
            "At step: 9095 training error: 0.37715862271777134\n",
            "At step: 9096 training error: 0.36781636593895595\n",
            "At step: 9097 training error: 0.3617107945745131\n",
            "At step: 9098 training error: 0.3600964776905354\n",
            "At step: 9099 training error: 0.37217015696232436\n",
            "At step: 9100 training error: 0.37011752741188403\n",
            "At step: 9101 training error: 0.3809467261065811\n",
            "At step: 9102 training error: 0.3759140012411973\n",
            "At step: 9103 training error: 0.3851262973230899\n",
            "At step: 9104 training error: 0.3800321761580843\n",
            "At step: 9105 training error: 0.37968625918776255\n",
            "At step: 9106 training error: 0.3778070109151885\n",
            "At step: 9107 training error: 0.3730022361372015\n",
            "At step: 9108 training error: 0.3621719028084456\n",
            "At step: 9109 training error: 0.3595873265201545\n",
            "At step: 9110 training error: 0.35777034413249964\n",
            "At step: 9111 training error: 0.361422271363515\n",
            "At step: 9112 training error: 0.3574390546601836\n",
            "At step: 9113 training error: 0.35555847827418335\n",
            "At step: 9114 training error: 0.35095524953885177\n",
            "At step: 9115 training error: 0.35648462022620125\n",
            "At step: 9116 training error: 0.3518205821403836\n",
            "At step: 9117 training error: 0.3513724244364859\n",
            "At step: 9118 training error: 0.3545306991031662\n",
            "At step: 9119 training error: 0.35328963540124797\n",
            "At step: 9120 training error: 0.34997671200310376\n",
            "At step: 9121 training error: 0.34444465579268924\n",
            "At step: 9122 training error: 0.3399926093173954\n",
            "At step: 9123 training error: 0.3401528577511419\n",
            "At step: 9124 training error: 0.34617041314567437\n",
            "At step: 9125 training error: 0.3431977502467438\n",
            "At step: 9126 training error: 0.3455508911659192\n",
            "At step: 9127 training error: 0.35555962610889225\n",
            "At step: 9128 training error: 0.35233728827611704\n",
            "At step: 9129 training error: 0.3451986270261458\n",
            "At step: 9130 training error: 0.34585232671826877\n",
            "At step: 9131 training error: 0.35688266221143883\n",
            "At step: 9132 training error: 0.356402737557639\n",
            "At step: 9133 training error: 0.363421072002953\n",
            "At step: 9134 training error: 0.3590173748465324\n",
            "At step: 9135 training error: 0.3506566738962973\n",
            "At step: 9136 training error: 0.3443051242742591\n",
            "At step: 9137 training error: 0.35509266509590437\n",
            "At step: 9138 training error: 0.3609914335722535\n",
            "At step: 9139 training error: 0.36529835140229744\n",
            "At step: 9140 training error: 0.3634615261468062\n",
            "At step: 9141 training error: 0.36555547799814514\n",
            "At step: 9142 training error: 0.368228885119236\n",
            "At step: 9143 training error: 0.3686961026072661\n",
            "At step: 9144 training error: 0.3657147956637401\n",
            "At step: 9145 training error: 0.3531908077067479\n",
            "At step: 9146 training error: 0.34864987979895484\n",
            "At step: 9147 training error: 0.3490558814098533\n",
            "At step: 9148 training error: 0.3505068837281982\n",
            "At step: 9149 training error: 0.34767537539780974\n",
            "At step: 9150 training error: 0.359154576520499\n",
            "At step: 9151 training error: 0.37072600850409104\n",
            "At step: 9152 training error: 0.373520949559047\n",
            "At step: 9153 training error: 0.3724217491478284\n",
            "At step: 9154 training error: 0.3687046582542707\n",
            "At step: 9155 training error: 0.3670855190919799\n",
            "At step: 9156 training error: 0.3923733694626533\n",
            "At step: 9157 training error: 0.3973028368965173\n",
            "At step: 9158 training error: 0.3936656016709097\n",
            "At step: 9159 training error: 0.3895179912703939\n",
            "At step: 9160 training error: 0.38845968189929186\n",
            "At step: 9161 training error: 0.3807936537910027\n",
            "At step: 9162 training error: 0.3827757610504624\n",
            "At step: 9163 training error: 0.3938620466541025\n",
            "At step: 9164 training error: 0.3884973725534981\n",
            "At step: 9165 training error: 0.3904320820598497\n",
            "At step: 9166 training error: 0.38847755534593925\n",
            "At step: 9167 training error: 0.3862320055283033\n",
            "At step: 9168 training error: 0.384519738219192\n",
            "At step: 9169 training error: 0.38394128968678676\n",
            "At step: 9170 training error: 0.37449923848712025\n",
            "At step: 9171 training error: 0.3856077763633748\n",
            "At step: 9172 training error: 0.3653916104204628\n",
            "At step: 9173 training error: 0.3630300977508151\n",
            "At step: 9174 training error: 0.3601294178728814\n",
            "At step: 9175 training error: 0.36207817906277023\n",
            "At step: 9176 training error: 0.35749261725073683\n",
            "At step: 9177 training error: 0.3487064806613506\n",
            "At step: 9178 training error: 0.3428076859144687\n",
            "At step: 9179 training error: 0.36016474798066866\n",
            "At step: 9180 training error: 0.35201936592652217\n",
            "At step: 9181 training error: 0.35404356939163306\n",
            "At step: 9182 training error: 0.3718593487795713\n",
            "At step: 9183 training error: 0.3764942697697953\n",
            "At step: 9184 training error: 0.3620044617810202\n",
            "At step: 9185 training error: 0.348173719489458\n",
            "At step: 9186 training error: 0.3523403022844697\n",
            "At step: 9187 training error: 0.35646304508417304\n",
            "At step: 9188 training error: 0.3585953609118038\n",
            "At step: 9189 training error: 0.35686982683474117\n",
            "At step: 9190 training error: 0.3616773111430532\n",
            "At step: 9191 training error: 0.3618914008243718\n",
            "At step: 9192 training error: 0.3678437727423514\n",
            "At step: 9193 training error: 0.3587500175403393\n",
            "At step: 9194 training error: 0.3626035533625085\n",
            "At step: 9195 training error: 0.361985668305691\n",
            "At step: 9196 training error: 0.3539031591934616\n",
            "At step: 9197 training error: 0.3616278029375667\n",
            "At step: 9198 training error: 0.36134124131145495\n",
            "At step: 9199 training error: 0.36220262920877416\n",
            "At step: 9200 training error: 0.36283977466057715\n",
            "At step: 9201 training error: 0.36501704725407197\n",
            "At step: 9202 training error: 0.3629241183872203\n",
            "At step: 9203 training error: 0.36877600752865203\n",
            "At step: 9204 training error: 0.3562302236577666\n",
            "At step: 9205 training error: 0.3538908267025943\n",
            "At step: 9206 training error: 0.3610160213026908\n",
            "At step: 9207 training error: 0.3533449156475452\n",
            "At step: 9208 training error: 0.3465546717348139\n",
            "At step: 9209 training error: 0.34192348509495596\n",
            "At step: 9210 training error: 0.34895478795188767\n",
            "At step: 9211 training error: 0.34351000949173033\n",
            "At step: 9212 training error: 0.3545932515766199\n",
            "At step: 9213 training error: 0.3627684641713318\n",
            "At step: 9214 training error: 0.36878018639469173\n",
            "At step: 9215 training error: 0.36683403288708105\n",
            "At step: 9216 training error: 0.3614950646185766\n",
            "At step: 9217 training error: 0.36866819933469325\n",
            "At step: 9218 training error: 0.35614664830034815\n",
            "At step: 9219 training error: 0.35852037917118573\n",
            "At step: 9220 training error: 0.3591823218905875\n",
            "At step: 9221 training error: 0.36820378547773974\n",
            "At step: 9222 training error: 0.3698325967556893\n",
            "At step: 9223 training error: 0.3661450417007017\n",
            "At step: 9224 training error: 0.3775590471771841\n",
            "At step: 9225 training error: 0.37295408100335675\n",
            "At step: 9226 training error: 0.3788803182260501\n",
            "At step: 9227 training error: 0.37790312266193904\n",
            "At step: 9228 training error: 0.3737660124591805\n",
            "At step: 9229 training error: 0.3751313830723264\n",
            "At step: 9230 training error: 0.37510361238142265\n",
            "At step: 9231 training error: 0.3715810432363201\n",
            "At step: 9232 training error: 0.36868240016557163\n",
            "At step: 9233 training error: 0.3675665440042268\n",
            "At step: 9234 training error: 0.36435565280795457\n",
            "At step: 9235 training error: 0.3697198191441524\n",
            "At step: 9236 training error: 0.3662473002335457\n",
            "At step: 9237 training error: 0.3698708922304056\n",
            "At step: 9238 training error: 0.37205884191869965\n",
            "At step: 9239 training error: 0.3695356170559131\n",
            "At step: 9240 training error: 0.37118798959352783\n",
            "At step: 9241 training error: 0.3729749733548233\n",
            "At step: 9242 training error: 0.3732886619121383\n",
            "At step: 9243 training error: 0.3692090321902618\n",
            "At step: 9244 training error: 0.36984988895683246\n",
            "At step: 9245 training error: 0.37063597861554115\n",
            "At step: 9246 training error: 0.37236729736196594\n",
            "At step: 9247 training error: 0.3654236165688831\n",
            "At step: 9248 training error: 0.3789659896858389\n",
            "At step: 9249 training error: 0.3730708983363362\n",
            "At step: 9250 training error: 0.3767626509683711\n",
            "At step: 9251 training error: 0.3756927128453745\n",
            "At step: 9252 training error: 0.3808268068733885\n",
            "At step: 9253 training error: 0.3878486326294103\n",
            "At step: 9254 training error: 0.3861606632852927\n",
            "At step: 9255 training error: 0.3887977787854135\n",
            "At step: 9256 training error: 0.38689872926149604\n",
            "At step: 9257 training error: 0.38228872001717895\n",
            "At step: 9258 training error: 0.3829395150763361\n",
            "At step: 9259 training error: 0.37994709542119925\n",
            "At step: 9260 training error: 0.3768248248762983\n",
            "At step: 9261 training error: 0.37421254430913486\n",
            "At step: 9262 training error: 0.37554284546087663\n",
            "At step: 9263 training error: 0.3690323196073628\n",
            "At step: 9264 training error: 0.3685592716627011\n",
            "At step: 9265 training error: 0.3628466396833241\n",
            "At step: 9266 training error: 0.3568993613628312\n",
            "At step: 9267 training error: 0.3512093950870376\n",
            "At step: 9268 training error: 0.3474805002212327\n",
            "At step: 9269 training error: 0.36039800044713277\n",
            "At step: 9270 training error: 0.3569923867958165\n",
            "At step: 9271 training error: 0.3647683820597196\n",
            "At step: 9272 training error: 0.3618259235917789\n",
            "At step: 9273 training error: 0.3643454559675191\n",
            "At step: 9274 training error: 0.368107574321955\n",
            "At step: 9275 training error: 0.3615115020595055\n",
            "At step: 9276 training error: 0.3585792128764693\n",
            "At step: 9277 training error: 0.35907157555189306\n",
            "At step: 9278 training error: 0.3557043280077251\n",
            "At step: 9279 training error: 0.35001814087110805\n",
            "At step: 9280 training error: 0.3529130399161189\n",
            "At step: 9281 training error: 0.3512253945523713\n",
            "At step: 9282 training error: 0.37038177349112106\n",
            "At step: 9283 training error: 0.37666264647640135\n",
            "At step: 9284 training error: 0.37501824009948964\n",
            "At step: 9285 training error: 0.36684016303412603\n",
            "At step: 9286 training error: 0.36397757030569877\n",
            "At step: 9287 training error: 0.3634297825109872\n",
            "At step: 9288 training error: 0.362189366940692\n",
            "At step: 9289 training error: 0.3632405172520993\n",
            "At step: 9290 training error: 0.35403081167783984\n",
            "At step: 9291 training error: 0.3569527696469986\n",
            "At step: 9292 training error: 0.34214228133066793\n",
            "At step: 9293 training error: 0.345258738533805\n",
            "At step: 9294 training error: 0.3469462698514045\n",
            "At step: 9295 training error: 0.35846467518225594\n",
            "At step: 9296 training error: 0.35958446236282\n",
            "At step: 9297 training error: 0.3648050940702503\n",
            "At step: 9298 training error: 0.3694407937255173\n",
            "At step: 9299 training error: 0.36937039141058586\n",
            "At step: 9300 training error: 0.3692881093529412\n",
            "At step: 9301 training error: 0.36297582418302715\n",
            "At step: 9302 training error: 0.3671909972386091\n",
            "At step: 9303 training error: 0.3703530173547148\n",
            "At step: 9304 training error: 0.3718712795075965\n",
            "At step: 9305 training error: 0.3752235052193621\n",
            "At step: 9306 training error: 0.36301815674205984\n",
            "At step: 9307 training error: 0.36723221358369273\n",
            "At step: 9308 training error: 0.3546748731369411\n",
            "At step: 9309 training error: 0.3534377394548017\n",
            "At step: 9310 training error: 0.3499601697747009\n",
            "At step: 9311 training error: 0.34497063536093014\n",
            "At step: 9312 training error: 0.3467756646780267\n",
            "At step: 9313 training error: 0.3544869935085436\n",
            "At step: 9314 training error: 0.3622253338347517\n",
            "At step: 9315 training error: 0.3743250521951143\n",
            "At step: 9316 training error: 0.37706796985012686\n",
            "At step: 9317 training error: 0.3674489548253018\n",
            "At step: 9318 training error: 0.38288697467738064\n",
            "At step: 9319 training error: 0.3867135929564688\n",
            "At step: 9320 training error: 0.38870417179450195\n",
            "At step: 9321 training error: 0.3903114763993308\n",
            "At step: 9322 training error: 0.3974422818758282\n",
            "At step: 9323 training error: 0.39090514375425045\n",
            "At step: 9324 training error: 0.3925629823433355\n",
            "At step: 9325 training error: 0.39579487586555206\n",
            "At step: 9326 training error: 0.39338731157697115\n",
            "At step: 9327 training error: 0.38744458904157947\n",
            "At step: 9328 training error: 0.38873994108769894\n",
            "At step: 9329 training error: 0.38183711093740486\n",
            "At step: 9330 training error: 0.3667957710341113\n",
            "At step: 9331 training error: 0.37626887680424986\n",
            "At step: 9332 training error: 0.37613541970762565\n",
            "At step: 9333 training error: 0.3707125410753985\n",
            "At step: 9334 training error: 0.3638961970793233\n",
            "At step: 9335 training error: 0.3768654520237734\n",
            "At step: 9336 training error: 0.38177819000120217\n",
            "At step: 9337 training error: 0.3721403204877211\n",
            "At step: 9338 training error: 0.37777130436936307\n",
            "At step: 9339 training error: 0.38743910409937476\n",
            "At step: 9340 training error: 0.3726159514872537\n",
            "At step: 9341 training error: 0.3733960815644461\n",
            "At step: 9342 training error: 0.3637453839597707\n",
            "At step: 9343 training error: 0.3686961025416244\n",
            "At step: 9344 training error: 0.37292306198781855\n",
            "At step: 9345 training error: 0.36798482367967184\n",
            "At step: 9346 training error: 0.37126228360859775\n",
            "At step: 9347 training error: 0.36798332375690046\n",
            "At step: 9348 training error: 0.36809104775330714\n",
            "At step: 9349 training error: 0.36423189934561\n",
            "At step: 9350 training error: 0.376416073561052\n",
            "At step: 9351 training error: 0.3746433707658897\n",
            "At step: 9352 training error: 0.3685476729292916\n",
            "At step: 9353 training error: 0.36807094387758776\n",
            "At step: 9354 training error: 0.37043864293814527\n",
            "At step: 9355 training error: 0.373731849569989\n",
            "At step: 9356 training error: 0.3699598684035793\n",
            "At step: 9357 training error: 0.3682934778507796\n",
            "At step: 9358 training error: 0.3659966652336254\n",
            "At step: 9359 training error: 0.3575010136787417\n",
            "At step: 9360 training error: 0.35448647099923425\n",
            "At step: 9361 training error: 0.3454151450666483\n",
            "At step: 9362 training error: 0.35525683438018074\n",
            "At step: 9363 training error: 0.3495567791349697\n",
            "At step: 9364 training error: 0.3472792173610317\n",
            "At step: 9365 training error: 0.3513723027884136\n",
            "At step: 9366 training error: 0.36679154995702057\n",
            "At step: 9367 training error: 0.3648290770253328\n",
            "At step: 9368 training error: 0.3750132057953326\n",
            "At step: 9369 training error: 0.3756877710661271\n",
            "At step: 9370 training error: 0.3759957365280445\n",
            "At step: 9371 training error: 0.36798426183559524\n",
            "At step: 9372 training error: 0.379024312502057\n",
            "At step: 9373 training error: 0.37124058417164035\n",
            "At step: 9374 training error: 0.3998342750711482\n",
            "At step: 9375 training error: 0.3882335469832348\n",
            "At step: 9376 training error: 0.38401900437950126\n",
            "At step: 9377 training error: 0.3789667094732786\n",
            "At step: 9378 training error: 0.3818465897289879\n",
            "At step: 9379 training error: 0.3881652754241868\n",
            "At step: 9380 training error: 0.39159933046663353\n",
            "At step: 9381 training error: 0.38373487672734763\n",
            "At step: 9382 training error: 0.3848148216848735\n",
            "At step: 9383 training error: 0.3822828986151215\n",
            "At step: 9384 training error: 0.3846415119385427\n",
            "At step: 9385 training error: 0.380209043437155\n",
            "At step: 9386 training error: 0.3781264184699148\n",
            "At step: 9387 training error: 0.3800510269496479\n",
            "At step: 9388 training error: 0.37193910335019575\n",
            "At step: 9389 training error: 0.36467493344045865\n",
            "At step: 9390 training error: 0.36048669097512287\n",
            "At step: 9391 training error: 0.36405632045670255\n",
            "At step: 9392 training error: 0.36838856985734564\n",
            "At step: 9393 training error: 0.37419925035342627\n",
            "At step: 9394 training error: 0.3674672926053378\n",
            "At step: 9395 training error: 0.3689108865949456\n",
            "At step: 9396 training error: 0.3683195691160704\n",
            "At step: 9397 training error: 0.36612054254300275\n",
            "At step: 9398 training error: 0.37529802272758916\n",
            "At step: 9399 training error: 0.3857272648611741\n",
            "At step: 9400 training error: 0.38540730932843326\n",
            "At step: 9401 training error: 0.38704153732426405\n",
            "At step: 9402 training error: 0.4021100172849359\n",
            "At step: 9403 training error: 0.3936966494540124\n",
            "At step: 9404 training error: 0.39558414819778237\n",
            "At step: 9405 training error: 0.3992354312277021\n",
            "At step: 9406 training error: 0.40436751619685934\n",
            "At step: 9407 training error: 0.40460918673899493\n",
            "At step: 9408 training error: 0.39472595317943265\n",
            "At step: 9409 training error: 0.3940083229614595\n",
            "At step: 9410 training error: 0.3881863233584191\n",
            "At step: 9411 training error: 0.38378915948676484\n",
            "At step: 9412 training error: 0.3802471827365539\n",
            "At step: 9413 training error: 0.37093050173852105\n",
            "At step: 9414 training error: 0.36893848604640744\n",
            "At step: 9415 training error: 0.3584673147682087\n",
            "At step: 9416 training error: 0.3616149714854572\n",
            "At step: 9417 training error: 0.3551085884576509\n",
            "At step: 9418 training error: 0.3496390692727757\n",
            "At step: 9419 training error: 0.3469488375992091\n",
            "At step: 9420 training error: 0.3468479896516541\n",
            "At step: 9421 training error: 0.344143495351923\n",
            "At step: 9422 training error: 0.34267178370323625\n",
            "At step: 9423 training error: 0.3396858025341063\n",
            "At step: 9424 training error: 0.34017646608625723\n",
            "At step: 9425 training error: 0.34895114716097164\n",
            "At step: 9426 training error: 0.35360595228988995\n",
            "At step: 9427 training error: 0.35164052073795926\n",
            "At step: 9428 training error: 0.3510903560663598\n",
            "At step: 9429 training error: 0.35135547938648276\n",
            "At step: 9430 training error: 0.3505596162086171\n",
            "At step: 9431 training error: 0.3507633179191568\n",
            "At step: 9432 training error: 0.34932026864564186\n",
            "At step: 9433 training error: 0.3495735963694756\n",
            "At step: 9434 training error: 0.3574819747489979\n",
            "At step: 9435 training error: 0.3618619032682481\n",
            "At step: 9436 training error: 0.3601971297748826\n",
            "At step: 9437 training error: 0.3489484430961242\n",
            "At step: 9438 training error: 0.3652194993486649\n",
            "At step: 9439 training error: 0.3627389296037443\n",
            "At step: 9440 training error: 0.36759388890474853\n",
            "At step: 9441 training error: 0.3484982880337608\n",
            "At step: 9442 training error: 0.34708242447786225\n",
            "At step: 9443 training error: 0.3421646431469863\n",
            "At step: 9444 training error: 0.3442419748284451\n",
            "At step: 9445 training error: 0.35272512896122243\n",
            "At step: 9446 training error: 0.3539819322659425\n",
            "At step: 9447 training error: 0.34188500293825524\n",
            "At step: 9448 training error: 0.35069870811161413\n",
            "At step: 9449 training error: 0.3590771380669391\n",
            "At step: 9450 training error: 0.3589133143997485\n",
            "At step: 9451 training error: 0.3562600649596376\n",
            "At step: 9452 training error: 0.3523848764338869\n",
            "At step: 9453 training error: 0.35433234850458706\n",
            "At step: 9454 training error: 0.348757638978849\n",
            "At step: 9455 training error: 0.34764286341488454\n",
            "At step: 9456 training error: 0.3549993008388522\n",
            "At step: 9457 training error: 0.3455601963931582\n",
            "At step: 9458 training error: 0.3580282444065347\n",
            "At step: 9459 training error: 0.3576231588276333\n",
            "At step: 9460 training error: 0.3581372578817702\n",
            "At step: 9461 training error: 0.3643607131796088\n",
            "At step: 9462 training error: 0.3662098059476789\n",
            "At step: 9463 training error: 0.36974073185073897\n",
            "At step: 9464 training error: 0.3777139980077564\n",
            "At step: 9465 training error: 0.3730407716641347\n",
            "At step: 9466 training error: 0.3802873960290029\n",
            "At step: 9467 training error: 0.3803180892197673\n",
            "At step: 9468 training error: 0.3693416435015404\n",
            "At step: 9469 training error: 0.3767743222444902\n",
            "At step: 9470 training error: 0.3721842843379586\n",
            "At step: 9471 training error: 0.37377562738825154\n",
            "At step: 9472 training error: 0.37616543889701665\n",
            "At step: 9473 training error: 0.3784984760714079\n",
            "At step: 9474 training error: 0.37880695633543804\n",
            "At step: 9475 training error: 0.3866233644213022\n",
            "At step: 9476 training error: 0.3856479557443359\n",
            "At step: 9477 training error: 0.38119900682162783\n",
            "At step: 9478 training error: 0.371281248185496\n",
            "At step: 9479 training error: 0.3775000793599237\n",
            "At step: 9480 training error: 0.3742586279876058\n",
            "At step: 9481 training error: 0.3763318264415513\n",
            "At step: 9482 training error: 0.3792699822158768\n",
            "At step: 9483 training error: 0.37801567289601873\n",
            "At step: 9484 training error: 0.3663337008734529\n",
            "At step: 9485 training error: 0.35779824641232716\n",
            "At step: 9486 training error: 0.3552858682777725\n",
            "At step: 9487 training error: 0.3561183741546489\n",
            "At step: 9488 training error: 0.35952187634236216\n",
            "At step: 9489 training error: 0.3540204401806254\n",
            "At step: 9490 training error: 0.3567309708458511\n",
            "At step: 9491 training error: 0.36277290840737203\n",
            "At step: 9492 training error: 0.35333571989298795\n",
            "At step: 9493 training error: 0.3597032879188056\n",
            "At step: 9494 training error: 0.36014154892865524\n",
            "At step: 9495 training error: 0.35746166761098563\n",
            "At step: 9496 training error: 0.35473044017392374\n",
            "At step: 9497 training error: 0.36746684112393047\n",
            "At step: 9498 training error: 0.3725237600356312\n",
            "At step: 9499 training error: 0.37970923027146547\n",
            "At step: 9500 training error: 0.38694430050563866\n",
            "At step: 9501 training error: 0.3811734956821229\n",
            "At step: 9502 training error: 0.3772516469093233\n",
            "At step: 9503 training error: 0.3806837714875368\n",
            "At step: 9504 training error: 0.38156328942090983\n",
            "At step: 9505 training error: 0.372353182734779\n",
            "At step: 9506 training error: 0.36316388531475086\n",
            "At step: 9507 training error: 0.3637076119742259\n",
            "At step: 9508 training error: 0.36739450568862364\n",
            "At step: 9509 training error: 0.36641605498696617\n",
            "At step: 9510 training error: 0.38122465242306824\n",
            "At step: 9511 training error: 0.3761384462556668\n",
            "At step: 9512 training error: 0.37248011135838716\n",
            "At step: 9513 training error: 0.3780945677059794\n",
            "At step: 9514 training error: 0.3775727876974815\n",
            "At step: 9515 training error: 0.39316786215914984\n",
            "At step: 9516 training error: 0.4047409248901874\n",
            "At step: 9517 training error: 0.3917244405971944\n",
            "At step: 9518 training error: 0.3855391468962668\n",
            "At step: 9519 training error: 0.38135605989888244\n",
            "At step: 9520 training error: 0.38685181885980197\n",
            "At step: 9521 training error: 0.3763458569426742\n",
            "At step: 9522 training error: 0.3658550249820658\n",
            "At step: 9523 training error: 0.36364332575389424\n",
            "At step: 9524 training error: 0.3647439072632866\n",
            "At step: 9525 training error: 0.35773831438106823\n",
            "At step: 9526 training error: 0.35979945549064263\n",
            "At step: 9527 training error: 0.3482757992582854\n",
            "At step: 9528 training error: 0.35192659168984614\n",
            "At step: 9529 training error: 0.3556117831748772\n",
            "At step: 9530 training error: 0.3501145733628394\n",
            "At step: 9531 training error: 0.34308435816253446\n",
            "At step: 9532 training error: 0.351940888176907\n",
            "At step: 9533 training error: 0.3566069580863597\n",
            "At step: 9534 training error: 0.34698703475184767\n",
            "At step: 9535 training error: 0.34987461320870966\n",
            "At step: 9536 training error: 0.3564768701526055\n",
            "At step: 9537 training error: 0.3477532369709255\n",
            "At step: 9538 training error: 0.35233209011949385\n",
            "At step: 9539 training error: 0.34797240861218576\n",
            "At step: 9540 training error: 0.34534089023288156\n",
            "At step: 9541 training error: 0.33709015512568563\n",
            "At step: 9542 training error: 0.33616998446989477\n",
            "At step: 9543 training error: 0.35272180391989194\n",
            "At step: 9544 training error: 0.3614465394368376\n",
            "At step: 9545 training error: 0.3595655747247363\n",
            "At step: 9546 training error: 0.35349914021247264\n",
            "At step: 9547 training error: 0.3461832261300826\n",
            "At step: 9548 training error: 0.3625503747248015\n",
            "At step: 9549 training error: 0.3615743277144246\n",
            "At step: 9550 training error: 0.35103715419350834\n",
            "At step: 9551 training error: 0.3471139396724366\n",
            "At step: 9552 training error: 0.3417640961914122\n",
            "At step: 9553 training error: 0.3483954863602406\n",
            "At step: 9554 training error: 0.3433823096382096\n",
            "At step: 9555 training error: 0.342436639515554\n",
            "At step: 9556 training error: 0.3494003805100837\n",
            "At step: 9557 training error: 0.3416193676566521\n",
            "At step: 9558 training error: 0.34778651901416485\n",
            "At step: 9559 training error: 0.35336356155958715\n",
            "At step: 9560 training error: 0.35450414256503504\n",
            "At step: 9561 training error: 0.35761112724788074\n",
            "At step: 9562 training error: 0.35992171821535707\n",
            "At step: 9563 training error: 0.3553864564707424\n",
            "At step: 9564 training error: 0.3608413961750203\n",
            "At step: 9565 training error: 0.36655159159041223\n",
            "At step: 9566 training error: 0.37179834793731126\n",
            "At step: 9567 training error: 0.37391014151618185\n",
            "At step: 9568 training error: 0.3717822825592422\n",
            "At step: 9569 training error: 0.3644995239274307\n",
            "At step: 9570 training error: 0.3617818678725736\n",
            "At step: 9571 training error: 0.36600371332831017\n",
            "At step: 9572 training error: 0.36157238212968507\n",
            "At step: 9573 training error: 0.36301883908629196\n",
            "At step: 9574 training error: 0.36159192244120286\n",
            "At step: 9575 training error: 0.3482422009344879\n",
            "At step: 9576 training error: 0.3506198951844407\n",
            "At step: 9577 training error: 0.3521111263160134\n",
            "At step: 9578 training error: 0.3442616913570957\n",
            "At step: 9579 training error: 0.34255802813054453\n",
            "At step: 9580 training error: 0.34359656918775894\n",
            "At step: 9581 training error: 0.35373407558544967\n",
            "At step: 9582 training error: 0.3495300480219126\n",
            "At step: 9583 training error: 0.3525123279296997\n",
            "At step: 9584 training error: 0.3513201857016233\n",
            "At step: 9585 training error: 0.3639494196554205\n",
            "At step: 9586 training error: 0.3735416203153183\n",
            "At step: 9587 training error: 0.38391668560622283\n",
            "At step: 9588 training error: 0.3720905091406602\n",
            "At step: 9589 training error: 0.3755856373680009\n",
            "At step: 9590 training error: 0.38065990038205677\n",
            "At step: 9591 training error: 0.37948914024390296\n",
            "At step: 9592 training error: 0.3792915348795315\n",
            "At step: 9593 training error: 0.3859840060787177\n",
            "At step: 9594 training error: 0.3871412277252846\n",
            "At step: 9595 training error: 0.37529034133221334\n",
            "At step: 9596 training error: 0.37334987634394406\n",
            "At step: 9597 training error: 0.3667288458485053\n",
            "At step: 9598 training error: 0.3711847675779424\n",
            "At step: 9599 training error: 0.36618060330881474\n",
            "At step: 9600 training error: 0.35838547862681314\n",
            "At step: 9601 training error: 0.3670389472088297\n",
            "At step: 9602 training error: 0.359257373320484\n",
            "At step: 9603 training error: 0.35139228774889597\n",
            "At step: 9604 training error: 0.35217901668849166\n",
            "At step: 9605 training error: 0.34789245641623273\n",
            "At step: 9606 training error: 0.3465927805339076\n",
            "At step: 9607 training error: 0.34717267131519663\n",
            "At step: 9608 training error: 0.3492734163838451\n",
            "At step: 9609 training error: 0.35205544091552654\n",
            "At step: 9610 training error: 0.36530325033694666\n",
            "At step: 9611 training error: 0.3636815213910504\n",
            "At step: 9612 training error: 0.3731169476969821\n",
            "At step: 9613 training error: 0.37461088100526385\n",
            "At step: 9614 training error: 0.38223567627674343\n",
            "At step: 9615 training error: 0.37436904906472485\n",
            "At step: 9616 training error: 0.3764827656591479\n",
            "At step: 9617 training error: 0.3754954492080831\n",
            "At step: 9618 training error: 0.37429618895686134\n",
            "At step: 9619 training error: 0.3737095866981333\n",
            "At step: 9620 training error: 0.38417572416408685\n",
            "At step: 9621 training error: 0.38031754332199913\n",
            "At step: 9622 training error: 0.37910377818466917\n",
            "At step: 9623 training error: 0.3810474147867544\n",
            "At step: 9624 training error: 0.3777350122181901\n",
            "At step: 9625 training error: 0.3727110467276654\n",
            "At step: 9626 training error: 0.3626123910616821\n",
            "At step: 9627 training error: 0.3551990695893479\n",
            "At step: 9628 training error: 0.35557444867867516\n",
            "At step: 9629 training error: 0.36215989486812716\n",
            "At step: 9630 training error: 0.35512680207366154\n",
            "At step: 9631 training error: 0.3553839219844618\n",
            "At step: 9632 training error: 0.36858475389653805\n",
            "At step: 9633 training error: 0.372004883987076\n",
            "At step: 9634 training error: 0.36890252222783615\n",
            "At step: 9635 training error: 0.35988124786649517\n",
            "At step: 9636 training error: 0.36565199522334335\n",
            "At step: 9637 training error: 0.3778351790508406\n",
            "At step: 9638 training error: 0.37357842548302284\n",
            "At step: 9639 training error: 0.36954632318173875\n",
            "At step: 9640 training error: 0.365304003030746\n",
            "At step: 9641 training error: 0.358582477336413\n",
            "At step: 9642 training error: 0.3615074431504354\n",
            "At step: 9643 training error: 0.3516525243065506\n",
            "At step: 9644 training error: 0.35372636817729425\n",
            "At step: 9645 training error: 0.3683438389640119\n",
            "At step: 9646 training error: 0.3632034658689467\n",
            "At step: 9647 training error: 0.36344413639135087\n",
            "At step: 9648 training error: 0.36961424509852614\n",
            "At step: 9649 training error: 0.3740381969891869\n",
            "At step: 9650 training error: 0.3730865655084863\n",
            "At step: 9651 training error: 0.3753569845909335\n",
            "At step: 9652 training error: 0.3722113716644678\n",
            "At step: 9653 training error: 0.37893086222349764\n",
            "At step: 9654 training error: 0.36780896842774313\n",
            "At step: 9655 training error: 0.3666734259202462\n",
            "At step: 9656 training error: 0.369034002618865\n",
            "At step: 9657 training error: 0.3778218677222356\n",
            "At step: 9658 training error: 0.36830118308674703\n",
            "At step: 9659 training error: 0.3579087230600575\n",
            "At step: 9660 training error: 0.35324093547543556\n",
            "At step: 9661 training error: 0.34616409527563746\n",
            "At step: 9662 training error: 0.3477657633492184\n",
            "At step: 9663 training error: 0.3475716523793986\n",
            "At step: 9664 training error: 0.36330748682643976\n",
            "At step: 9665 training error: 0.3658702367440408\n",
            "At step: 9666 training error: 0.3611084328562928\n",
            "At step: 9667 training error: 0.36343486514943707\n",
            "At step: 9668 training error: 0.3642675318659433\n",
            "At step: 9669 training error: 0.3603527748965354\n",
            "At step: 9670 training error: 0.3617875060639465\n",
            "At step: 9671 training error: 0.3572594068725977\n",
            "At step: 9672 training error: 0.35665822581957984\n",
            "At step: 9673 training error: 0.35944952168435573\n",
            "At step: 9674 training error: 0.353891186266796\n",
            "At step: 9675 training error: 0.3584463088989406\n",
            "At step: 9676 training error: 0.36062331355235827\n",
            "At step: 9677 training error: 0.3701052921060049\n",
            "At step: 9678 training error: 0.3667948428987395\n",
            "At step: 9679 training error: 0.3621500761506449\n",
            "At step: 9680 training error: 0.36182434683659953\n",
            "At step: 9681 training error: 0.35500095284980865\n",
            "At step: 9682 training error: 0.3510120027089076\n",
            "At step: 9683 training error: 0.35537191440698157\n",
            "At step: 9684 training error: 0.34797445483060413\n",
            "At step: 9685 training error: 0.3539413762859889\n",
            "At step: 9686 training error: 0.35464340352626605\n",
            "At step: 9687 training error: 0.359530739873725\n",
            "At step: 9688 training error: 0.36368925101730004\n",
            "At step: 9689 training error: 0.36971602865810743\n",
            "At step: 9690 training error: 0.3680322232852345\n",
            "At step: 9691 training error: 0.3662199341818509\n",
            "At step: 9692 training error: 0.3637898968585666\n",
            "At step: 9693 training error: 0.3741647378378973\n",
            "At step: 9694 training error: 0.3714060905224961\n",
            "At step: 9695 training error: 0.3604049677907553\n",
            "At step: 9696 training error: 0.37049388273567757\n",
            "At step: 9697 training error: 0.37369160217621805\n",
            "At step: 9698 training error: 0.3720407463749358\n",
            "At step: 9699 training error: 0.37368650276304954\n",
            "At step: 9700 training error: 0.3864914804038445\n",
            "At step: 9701 training error: 0.3792283949232435\n",
            "At step: 9702 training error: 0.37948421506341584\n",
            "At step: 9703 training error: 0.372285925163631\n",
            "At step: 9704 training error: 0.36691731223142254\n",
            "At step: 9705 training error: 0.37019319108952653\n",
            "At step: 9706 training error: 0.3738718829867925\n",
            "At step: 9707 training error: 0.3712251266597231\n",
            "At step: 9708 training error: 0.3786102595158936\n",
            "At step: 9709 training error: 0.37293178917075004\n",
            "At step: 9710 training error: 0.3697226972381595\n",
            "At step: 9711 training error: 0.37205639884899355\n",
            "At step: 9712 training error: 0.36597136989869294\n",
            "At step: 9713 training error: 0.37390873180785494\n",
            "At step: 9714 training error: 0.36181199271673686\n",
            "At step: 9715 training error: 0.35690426362411676\n",
            "At step: 9716 training error: 0.35529066495907713\n",
            "At step: 9717 training error: 0.3540137545785418\n",
            "At step: 9718 training error: 0.33981587646422573\n",
            "At step: 9719 training error: 0.3428644175300873\n",
            "At step: 9720 training error: 0.3445027698439365\n",
            "At step: 9721 training error: 0.3390803566431693\n",
            "At step: 9722 training error: 0.34077580263774665\n",
            "At step: 9723 training error: 0.34847767114935013\n",
            "At step: 9724 training error: 0.35545781747405397\n",
            "At step: 9725 training error: 0.3650732875862057\n",
            "At step: 9726 training error: 0.3620855281511505\n",
            "At step: 9727 training error: 0.3668116697251287\n",
            "At step: 9728 training error: 0.3748722048334991\n",
            "At step: 9729 training error: 0.3732687889185352\n",
            "At step: 9730 training error: 0.36603684619011284\n",
            "At step: 9731 training error: 0.35622283934256366\n",
            "At step: 9732 training error: 0.35498388061579433\n",
            "At step: 9733 training error: 0.3569335393598595\n",
            "At step: 9734 training error: 0.3466948635372531\n",
            "At step: 9735 training error: 0.3571124326074245\n",
            "At step: 9736 training error: 0.3610126593698345\n",
            "At step: 9737 training error: 0.3670471118855856\n",
            "At step: 9738 training error: 0.3657052737402845\n",
            "At step: 9739 training error: 0.37005384831300714\n",
            "At step: 9740 training error: 0.37360464822107675\n",
            "At step: 9741 training error: 0.36318165137233377\n",
            "At step: 9742 training error: 0.375050809329136\n",
            "At step: 9743 training error: 0.3875033158795428\n",
            "At step: 9744 training error: 0.38769152775017385\n",
            "At step: 9745 training error: 0.37889908354433505\n",
            "At step: 9746 training error: 0.3792416127591425\n",
            "At step: 9747 training error: 0.37485227735856247\n",
            "At step: 9748 training error: 0.3809909583780205\n",
            "At step: 9749 training error: 0.37899652680950496\n",
            "At step: 9750 training error: 0.3810104815694304\n",
            "At step: 9751 training error: 0.381926941950266\n",
            "At step: 9752 training error: 0.386649665799048\n",
            "At step: 9753 training error: 0.37446779024611127\n",
            "At step: 9754 training error: 0.38844954128150255\n",
            "At step: 9755 training error: 0.3824780548698246\n",
            "At step: 9756 training error: 0.3818444993435236\n",
            "At step: 9757 training error: 0.3770474419721461\n",
            "At step: 9758 training error: 0.38295392532851474\n",
            "At step: 9759 training error: 0.3793181132064923\n",
            "At step: 9760 training error: 0.38415914861412886\n",
            "At step: 9761 training error: 0.3935741531541046\n",
            "At step: 9762 training error: 0.3893053680584649\n",
            "At step: 9763 training error: 0.38821126627805064\n",
            "At step: 9764 training error: 0.3785029487973613\n",
            "At step: 9765 training error: 0.38457268701993574\n",
            "At step: 9766 training error: 0.38659172203018954\n",
            "At step: 9767 training error: 0.39164268311411066\n",
            "At step: 9768 training error: 0.3963909706023353\n",
            "At step: 9769 training error: 0.39683235924312193\n",
            "At step: 9770 training error: 0.3950040717859118\n",
            "At step: 9771 training error: 0.3938474994669835\n",
            "At step: 9772 training error: 0.3862577585058071\n",
            "At step: 9773 training error: 0.37686842482099125\n",
            "At step: 9774 training error: 0.37357331085048917\n",
            "At step: 9775 training error: 0.3851188899378798\n",
            "At step: 9776 training error: 0.382602153601263\n",
            "At step: 9777 training error: 0.3904970741150069\n",
            "At step: 9778 training error: 0.38792747001254474\n",
            "At step: 9779 training error: 0.3869534928454985\n",
            "At step: 9780 training error: 0.3772510166669329\n",
            "At step: 9781 training error: 0.3746026516802213\n",
            "At step: 9782 training error: 0.3679577929766354\n",
            "At step: 9783 training error: 0.36418787388609053\n",
            "At step: 9784 training error: 0.3687238039698745\n",
            "At step: 9785 training error: 0.36551737243149995\n",
            "At step: 9786 training error: 0.377402144764887\n",
            "At step: 9787 training error: 0.36877341607228176\n",
            "At step: 9788 training error: 0.3737101011161865\n",
            "At step: 9789 training error: 0.3683240314943861\n",
            "At step: 9790 training error: 0.3758895775494491\n",
            "At step: 9791 training error: 0.3760927072714004\n",
            "At step: 9792 training error: 0.3819710472542466\n",
            "At step: 9793 training error: 0.369224880070642\n",
            "At step: 9794 training error: 0.364090012789921\n",
            "At step: 9795 training error: 0.3714424226954298\n",
            "At step: 9796 training error: 0.3674919064994927\n",
            "At step: 9797 training error: 0.3770636213515066\n",
            "At step: 9798 training error: 0.39089027049831787\n",
            "At step: 9799 training error: 0.3828570133568628\n",
            "At step: 9800 training error: 0.3840497894195546\n",
            "At step: 9801 training error: 0.3929909481577098\n",
            "At step: 9802 training error: 0.3965514128478141\n",
            "At step: 9803 training error: 0.3878256343406481\n",
            "At step: 9804 training error: 0.37650086871598315\n",
            "At step: 9805 training error: 0.37700402856949145\n",
            "At step: 9806 training error: 0.38042368078700006\n",
            "At step: 9807 training error: 0.3751484124614561\n",
            "At step: 9808 training error: 0.3712315699372288\n",
            "At step: 9809 training error: 0.37554316969005297\n",
            "At step: 9810 training error: 0.3860150858349476\n",
            "At step: 9811 training error: 0.39013548636519596\n",
            "At step: 9812 training error: 0.38412727138239017\n",
            "At step: 9813 training error: 0.3830791531661692\n",
            "At step: 9814 training error: 0.38449036805812736\n",
            "At step: 9815 training error: 0.3718750981742698\n",
            "At step: 9816 training error: 0.37008373881244666\n",
            "At step: 9817 training error: 0.3675918867155097\n",
            "At step: 9818 training error: 0.3627063794201699\n",
            "At step: 9819 training error: 0.36074364705112516\n",
            "At step: 9820 training error: 0.36233658223800574\n",
            "At step: 9821 training error: 0.3588211380080364\n",
            "At step: 9822 training error: 0.3675137626861239\n",
            "At step: 9823 training error: 0.366339876547749\n",
            "At step: 9824 training error: 0.37049484360783314\n",
            "At step: 9825 training error: 0.3801063141193681\n",
            "At step: 9826 training error: 0.376265247522427\n",
            "At step: 9827 training error: 0.3782934937426663\n",
            "At step: 9828 training error: 0.37065837796714296\n",
            "At step: 9829 training error: 0.3692436752740211\n",
            "At step: 9830 training error: 0.3628745202060209\n",
            "At step: 9831 training error: 0.3657572883403395\n",
            "At step: 9832 training error: 0.3677863396832824\n",
            "At step: 9833 training error: 0.3752043086456742\n",
            "At step: 9834 training error: 0.36696479083343386\n",
            "At step: 9835 training error: 0.36263456799611504\n",
            "At step: 9836 training error: 0.3632908288536083\n",
            "At step: 9837 training error: 0.3715847092501598\n",
            "At step: 9838 training error: 0.36909355720412423\n",
            "At step: 9839 training error: 0.36344489459395385\n",
            "At step: 9840 training error: 0.3595737182343851\n",
            "At step: 9841 training error: 0.3774213300642315\n",
            "At step: 9842 training error: 0.37610186200235407\n",
            "At step: 9843 training error: 0.37560610561715463\n",
            "At step: 9844 training error: 0.37661724315157263\n",
            "At step: 9845 training error: 0.3659773534448477\n",
            "At step: 9846 training error: 0.35807232009428824\n",
            "At step: 9847 training error: 0.3557507982354109\n",
            "At step: 9848 training error: 0.3443409277550773\n",
            "At step: 9849 training error: 0.34607050203858875\n",
            "At step: 9850 training error: 0.3350624343286582\n",
            "At step: 9851 training error: 0.3268486444234252\n",
            "At step: 9852 training error: 0.3466792912436574\n",
            "At step: 9853 training error: 0.3340872902747834\n",
            "At step: 9854 training error: 0.3559242595200371\n",
            "At step: 9855 training error: 0.3479904850182921\n",
            "At step: 9856 training error: 0.3588501705683755\n",
            "At step: 9857 training error: 0.36933463001236755\n",
            "At step: 9858 training error: 0.36538664952135413\n",
            "At step: 9859 training error: 0.3623546442293136\n",
            "At step: 9860 training error: 0.36652045142835055\n",
            "At step: 9861 training error: 0.361428574876535\n",
            "At step: 9862 training error: 0.3503836641244146\n",
            "At step: 9863 training error: 0.3476349705849816\n",
            "At step: 9864 training error: 0.3544735906423391\n",
            "At step: 9865 training error: 0.3643924343521863\n",
            "At step: 9866 training error: 0.3662538774497988\n",
            "At step: 9867 training error: 0.35778973985188817\n",
            "At step: 9868 training error: 0.3617376453972536\n",
            "At step: 9869 training error: 0.36326300869630807\n",
            "At step: 9870 training error: 0.35022429190437904\n",
            "At step: 9871 training error: 0.3544409576718203\n",
            "At step: 9872 training error: 0.3485134544156438\n",
            "At step: 9873 training error: 0.3436259886033407\n",
            "At step: 9874 training error: 0.34949109747704366\n",
            "At step: 9875 training error: 0.35056397962781966\n",
            "At step: 9876 training error: 0.35191997162051086\n",
            "At step: 9877 training error: 0.34690113204541695\n",
            "At step: 9878 training error: 0.35291921747332616\n",
            "At step: 9879 training error: 0.3690887277060022\n",
            "At step: 9880 training error: 0.3624217309415233\n",
            "At step: 9881 training error: 0.3526975190639281\n",
            "At step: 9882 training error: 0.34729583996976426\n",
            "At step: 9883 training error: 0.3434198152901289\n",
            "At step: 9884 training error: 0.34135239974834686\n",
            "At step: 9885 training error: 0.3502215774800841\n",
            "At step: 9886 training error: 0.3499632041382869\n",
            "At step: 9887 training error: 0.33989023897195353\n",
            "At step: 9888 training error: 0.3502790427961793\n",
            "At step: 9889 training error: 0.34109335569034693\n",
            "At step: 9890 training error: 0.33523973059249895\n",
            "At step: 9891 training error: 0.32999439255397855\n",
            "At step: 9892 training error: 0.32306826277410555\n",
            "At step: 9893 training error: 0.32419974040132243\n",
            "At step: 9894 training error: 0.3297361913236493\n",
            "At step: 9895 training error: 0.32581897733424453\n",
            "At step: 9896 training error: 0.3260825058750702\n",
            "At step: 9897 training error: 0.33258881714641\n",
            "At step: 9898 training error: 0.34309578293172605\n",
            "At step: 9899 training error: 0.34202628512412453\n",
            "At step: 9900 training error: 0.34969519070761135\n",
            "At step: 9901 training error: 0.34657714827089564\n",
            "At step: 9902 training error: 0.3533400217255871\n",
            "At step: 9903 training error: 0.3463919070617435\n",
            "At step: 9904 training error: 0.3463685318211511\n",
            "At step: 9905 training error: 0.35442647692976215\n",
            "At step: 9906 training error: 0.3591943676736406\n",
            "At step: 9907 training error: 0.360320710196931\n",
            "At step: 9908 training error: 0.36012274990005844\n",
            "At step: 9909 training error: 0.35354495247941964\n",
            "At step: 9910 training error: 0.3479951671330038\n",
            "At step: 9911 training error: 0.3451205892483649\n",
            "At step: 9912 training error: 0.35047127173904014\n",
            "At step: 9913 training error: 0.3600838959903716\n",
            "At step: 9914 training error: 0.36085352844455526\n",
            "At step: 9915 training error: 0.36629753617663274\n",
            "At step: 9916 training error: 0.36430193366426716\n",
            "At step: 9917 training error: 0.3642981270305904\n",
            "At step: 9918 training error: 0.3611252066321787\n",
            "At step: 9919 training error: 0.3556399522306863\n",
            "At step: 9920 training error: 0.35700973900252553\n",
            "At step: 9921 training error: 0.3566695141906274\n",
            "At step: 9922 training error: 0.346071284834861\n",
            "At step: 9923 training error: 0.3423151217713975\n",
            "At step: 9924 training error: 0.3472413818215151\n",
            "At step: 9925 training error: 0.35411584228404774\n",
            "At step: 9926 training error: 0.3406187600929302\n",
            "At step: 9927 training error: 0.3349532160935645\n",
            "At step: 9928 training error: 0.3322670217775814\n",
            "At step: 9929 training error: 0.3341061608672329\n",
            "At step: 9930 training error: 0.33626493811794417\n",
            "At step: 9931 training error: 0.3400178593542281\n",
            "At step: 9932 training error: 0.3410742892196203\n",
            "At step: 9933 training error: 0.34358527764728375\n",
            "At step: 9934 training error: 0.3413748195417714\n",
            "At step: 9935 training error: 0.34004681493101124\n",
            "At step: 9936 training error: 0.3517056085249445\n",
            "At step: 9937 training error: 0.3478927095151662\n",
            "At step: 9938 training error: 0.35386865316085536\n",
            "At step: 9939 training error: 0.3501218315467623\n",
            "At step: 9940 training error: 0.3621523989216611\n",
            "At step: 9941 training error: 0.36517653223821467\n",
            "At step: 9942 training error: 0.35868435483616834\n",
            "At step: 9943 training error: 0.36193515487268846\n",
            "At step: 9944 training error: 0.37230805639358233\n",
            "At step: 9945 training error: 0.36674152680717476\n",
            "At step: 9946 training error: 0.3652138434205789\n",
            "At step: 9947 training error: 0.37046416800249343\n",
            "At step: 9948 training error: 0.3724976337098751\n",
            "At step: 9949 training error: 0.37084035344174887\n",
            "At step: 9950 training error: 0.3621948307669912\n",
            "At step: 9951 training error: 0.35550670629898007\n",
            "At step: 9952 training error: 0.3564073961709826\n",
            "At step: 9953 training error: 0.3588260439539718\n",
            "At step: 9954 training error: 0.36287694879230703\n",
            "At step: 9955 training error: 0.36268167976382615\n",
            "At step: 9956 training error: 0.35712621212383067\n",
            "At step: 9957 training error: 0.35845148559092294\n",
            "At step: 9958 training error: 0.36102328475238793\n",
            "At step: 9959 training error: 0.35386252078160135\n",
            "At step: 9960 training error: 0.34986976128350206\n",
            "At step: 9961 training error: 0.3464386544876001\n",
            "At step: 9962 training error: 0.34032068799801696\n",
            "At step: 9963 training error: 0.3490842023768379\n",
            "At step: 9964 training error: 0.3474843816152581\n",
            "At step: 9965 training error: 0.35403752722248194\n",
            "At step: 9966 training error: 0.3626679263562354\n",
            "At step: 9967 training error: 0.36574435309462844\n",
            "At step: 9968 training error: 0.3652760577607751\n",
            "At step: 9969 training error: 0.3586425053728939\n",
            "At step: 9970 training error: 0.3504600547520054\n",
            "At step: 9971 training error: 0.3484048772461986\n",
            "At step: 9972 training error: 0.3656641237628159\n",
            "At step: 9973 training error: 0.36673863711741156\n",
            "At step: 9974 training error: 0.35612377000260603\n",
            "At step: 9975 training error: 0.3592530605224571\n",
            "At step: 9976 training error: 0.3683048014485111\n",
            "At step: 9977 training error: 0.3788392215608842\n",
            "At step: 9978 training error: 0.38525912496970355\n",
            "At step: 9979 training error: 0.3836883280755075\n",
            "At step: 9980 training error: 0.38173718125959905\n",
            "At step: 9981 training error: 0.39085718495111343\n",
            "At step: 9982 training error: 0.38534324444487655\n",
            "At step: 9983 training error: 0.3815824462693158\n",
            "At step: 9984 training error: 0.3730530948230396\n",
            "At step: 9985 training error: 0.37395718986545445\n",
            "At step: 9986 training error: 0.3729537203505876\n",
            "At step: 9987 training error: 0.3814383426299535\n",
            "At step: 9988 training error: 0.3864188101006563\n",
            "At step: 9989 training error: 0.38762650377229857\n",
            "At step: 9990 training error: 0.3888748774555952\n",
            "At step: 9991 training error: 0.3793991889327736\n",
            "At step: 9992 training error: 0.38139108359425955\n",
            "At step: 9993 training error: 0.38733258307025387\n",
            "At step: 9994 training error: 0.3854776497732252\n",
            "At step: 9995 training error: 0.3941475801329\n",
            "At step: 9996 training error: 0.38766742751950295\n",
            "At step: 9997 training error: 0.3856675395099276\n",
            "At step: 9998 training error: 0.3708737548737342\n",
            "At step: 9999 training error: 0.3796250355406432\n",
            "At Epoch 1, validation error: 0.043011419130185476, validation accuracy 0.7611\n",
            "At step: 0 training error: 0.3943923116298279\n",
            "At step: 1 training error: 0.3903542865598726\n",
            "At step: 2 training error: 0.3826794076541671\n",
            "At step: 3 training error: 0.3843847351538844\n",
            "At step: 4 training error: 0.3842199782609582\n",
            "At step: 5 training error: 0.38959243327794796\n",
            "At step: 6 training error: 0.388398871533964\n",
            "At step: 7 training error: 0.38427163148885934\n",
            "At step: 8 training error: 0.3790071213374472\n",
            "At step: 9 training error: 0.37633344966649956\n",
            "At step: 10 training error: 0.38459425722886553\n",
            "At step: 11 training error: 0.3818932487797659\n",
            "At step: 12 training error: 0.37297645936736384\n",
            "At step: 13 training error: 0.3697163626143875\n",
            "At step: 14 training error: 0.36430022549340446\n",
            "At step: 15 training error: 0.3608802745970423\n",
            "At step: 16 training error: 0.3596881101344896\n",
            "At step: 17 training error: 0.3595758784548623\n",
            "At step: 18 training error: 0.3571096985508231\n",
            "At step: 19 training error: 0.3604039518722676\n",
            "At step: 20 training error: 0.35785900246890184\n",
            "At step: 21 training error: 0.3610737392215203\n",
            "At step: 22 training error: 0.3603887130820466\n",
            "At step: 23 training error: 0.36314267843385906\n",
            "At step: 24 training error: 0.36467027746595443\n",
            "At step: 25 training error: 0.3620554517332977\n",
            "At step: 26 training error: 0.3547394945731746\n",
            "At step: 27 training error: 0.3547050841513522\n",
            "At step: 28 training error: 0.35178303077918616\n",
            "At step: 29 training error: 0.3494443256857994\n",
            "At step: 30 training error: 0.3523715893211867\n",
            "At step: 31 training error: 0.3602878091714841\n",
            "At step: 32 training error: 0.3554010890793905\n",
            "At step: 33 training error: 0.36017334468302914\n",
            "At step: 34 training error: 0.3617371059760025\n",
            "At step: 35 training error: 0.355283876940237\n",
            "At step: 36 training error: 0.3519682233217762\n",
            "At step: 37 training error: 0.35023914136523127\n",
            "At step: 38 training error: 0.3482842657109419\n",
            "At step: 39 training error: 0.3530919738258666\n",
            "At step: 40 training error: 0.35435733313237205\n",
            "At step: 41 training error: 0.3532435077883607\n",
            "At step: 42 training error: 0.3631197769843226\n",
            "At step: 43 training error: 0.3671008948212668\n",
            "At step: 44 training error: 0.37494456970573176\n",
            "At step: 45 training error: 0.3755574199266667\n",
            "At step: 46 training error: 0.3791677484288204\n",
            "At step: 47 training error: 0.3638593305492937\n",
            "At step: 48 training error: 0.3611883336374149\n",
            "At step: 49 training error: 0.36442060884501265\n",
            "At step: 50 training error: 0.3580794527357075\n",
            "At step: 51 training error: 0.3592397795285426\n",
            "At step: 52 training error: 0.3504339751046316\n",
            "At step: 53 training error: 0.3581964157598817\n",
            "At step: 54 training error: 0.3573815414199525\n",
            "At step: 55 training error: 0.3584291268176397\n",
            "At step: 56 training error: 0.3650624751411588\n",
            "At step: 57 training error: 0.37208630335628323\n",
            "At step: 58 training error: 0.38843336064548756\n",
            "At step: 59 training error: 0.3926042200074884\n",
            "At step: 60 training error: 0.3944774149369243\n",
            "At step: 61 training error: 0.3927351362678193\n",
            "At step: 62 training error: 0.3891896825921787\n",
            "At step: 63 training error: 0.38237998435604453\n",
            "At step: 64 training error: 0.3791938008292213\n",
            "At step: 65 training error: 0.36907438205327087\n",
            "At step: 66 training error: 0.3595778761230299\n",
            "At step: 67 training error: 0.3622393205910093\n",
            "At step: 68 training error: 0.36607143524442703\n",
            "At step: 69 training error: 0.3560327001273766\n",
            "At step: 70 training error: 0.35776150888917285\n",
            "At step: 71 training error: 0.355614554950625\n",
            "At step: 72 training error: 0.3499090642086452\n",
            "At step: 73 training error: 0.34870568044167316\n",
            "At step: 74 training error: 0.3495722621058441\n",
            "At step: 75 training error: 0.34132841087739074\n",
            "At step: 76 training error: 0.34067064003876696\n",
            "At step: 77 training error: 0.3521745375521377\n",
            "At step: 78 training error: 0.3579845298641826\n",
            "At step: 79 training error: 0.36880854489569703\n",
            "At step: 80 training error: 0.37345603243312103\n",
            "At step: 81 training error: 0.37826651756752816\n",
            "At step: 82 training error: 0.36417608081314035\n",
            "At step: 83 training error: 0.3682565388400825\n",
            "At step: 84 training error: 0.3569237296845004\n",
            "At step: 85 training error: 0.3407499320886682\n",
            "At step: 86 training error: 0.33095550246676536\n",
            "At step: 87 training error: 0.33023368704385114\n",
            "At step: 88 training error: 0.3320067216244824\n",
            "At step: 89 training error: 0.33987948240929455\n",
            "At step: 90 training error: 0.34010177867127156\n",
            "At step: 91 training error: 0.33991230879850165\n",
            "At step: 92 training error: 0.3388202843894038\n",
            "At step: 93 training error: 0.3389659241910187\n",
            "At step: 94 training error: 0.33649944998479875\n",
            "At step: 95 training error: 0.3382631551593226\n",
            "At step: 96 training error: 0.3376757075515731\n",
            "At step: 97 training error: 0.34390897672304555\n",
            "At step: 98 training error: 0.3472444444928107\n",
            "At step: 99 training error: 0.3588718522128419\n",
            "At step: 100 training error: 0.35717426875810654\n",
            "At step: 101 training error: 0.3650597641709078\n",
            "At step: 102 training error: 0.365144685308282\n",
            "At step: 103 training error: 0.3595753354924659\n",
            "At step: 104 training error: 0.3654350828839412\n",
            "At step: 105 training error: 0.3616250405924263\n",
            "At step: 106 training error: 0.35713758245152005\n",
            "At step: 107 training error: 0.3483130343549204\n",
            "At step: 108 training error: 0.3421862999439434\n",
            "At step: 109 training error: 0.3446872209799838\n",
            "At step: 110 training error: 0.35937747767484624\n",
            "At step: 111 training error: 0.3523095677567497\n",
            "At step: 112 training error: 0.3544874923097332\n",
            "At step: 113 training error: 0.35254446976078585\n",
            "At step: 114 training error: 0.3552584390640916\n",
            "At step: 115 training error: 0.34720459170767193\n",
            "At step: 116 training error: 0.35772578833855356\n",
            "At step: 117 training error: 0.3653326679226719\n",
            "At step: 118 training error: 0.3693572193209612\n",
            "At step: 119 training error: 0.3742902489715068\n",
            "At step: 120 training error: 0.3800857965179561\n",
            "At step: 121 training error: 0.3784837304862417\n",
            "At step: 122 training error: 0.3903570590993849\n",
            "At step: 123 training error: 0.3900855466569201\n",
            "At step: 124 training error: 0.3874024275043767\n",
            "At step: 125 training error: 0.37908134777127633\n",
            "At step: 126 training error: 0.38291795775420845\n",
            "At step: 127 training error: 0.3786215779018765\n",
            "At step: 128 training error: 0.3743948091963935\n",
            "At step: 129 training error: 0.3757111082708479\n",
            "At step: 130 training error: 0.36450471746875895\n",
            "At step: 131 training error: 0.3684821252518907\n",
            "At step: 132 training error: 0.3736227827500451\n",
            "At step: 133 training error: 0.3856437198485674\n",
            "At step: 134 training error: 0.38557498971425974\n",
            "At step: 135 training error: 0.3861151231063421\n",
            "At step: 136 training error: 0.3799054406016172\n",
            "At step: 137 training error: 0.3767411473559987\n",
            "At step: 138 training error: 0.3725909524611861\n",
            "At step: 139 training error: 0.36466733343027863\n",
            "At step: 140 training error: 0.36742138388831624\n",
            "At step: 141 training error: 0.3639886599783063\n",
            "At step: 142 training error: 0.35701480198102237\n",
            "At step: 143 training error: 0.36117569027578056\n",
            "At step: 144 training error: 0.3585885004252108\n",
            "At step: 145 training error: 0.34278099547924656\n",
            "At step: 146 training error: 0.3487966528027269\n",
            "At step: 147 training error: 0.3439701541125637\n",
            "At step: 148 training error: 0.3409831357551167\n",
            "At step: 149 training error: 0.34490946723544147\n",
            "At step: 150 training error: 0.3417759265755598\n",
            "At step: 151 training error: 0.34869853560863584\n",
            "At step: 152 training error: 0.3583036266161198\n",
            "At step: 153 training error: 0.3586846959361819\n",
            "At step: 154 training error: 0.35961886489304296\n",
            "At step: 155 training error: 0.3472230602127954\n",
            "At step: 156 training error: 0.35161052156593653\n",
            "At step: 157 training error: 0.3584265376563797\n",
            "At step: 158 training error: 0.3548919628806767\n",
            "At step: 159 training error: 0.35226312997732157\n",
            "At step: 160 training error: 0.3552620891446519\n",
            "At step: 161 training error: 0.36076354245726694\n",
            "At step: 162 training error: 0.3725922190744759\n",
            "At step: 163 training error: 0.36555410177104236\n",
            "At step: 164 training error: 0.36662186029853616\n",
            "At step: 165 training error: 0.38215915048757776\n",
            "At step: 166 training error: 0.36651893563229493\n",
            "At step: 167 training error: 0.3508792834558428\n",
            "At step: 168 training error: 0.3350593587880673\n",
            "At step: 169 training error: 0.33718111270279133\n",
            "At step: 170 training error: 0.34099779981290157\n",
            "At step: 171 training error: 0.34149827004721356\n",
            "At step: 172 training error: 0.34137896287299946\n",
            "At step: 173 training error: 0.3527986565839437\n",
            "At step: 174 training error: 0.3601232552404649\n",
            "At step: 175 training error: 0.363376531740058\n",
            "At step: 176 training error: 0.36473179469726935\n",
            "At step: 177 training error: 0.3659832928281763\n",
            "At step: 178 training error: 0.35893361509741656\n",
            "At step: 179 training error: 0.3621809276223594\n",
            "At step: 180 training error: 0.3581148614363645\n",
            "At step: 181 training error: 0.36070182153615765\n",
            "At step: 182 training error: 0.35752445909287356\n",
            "At step: 183 training error: 0.3505124480102352\n",
            "At step: 184 training error: 0.34660764445173925\n",
            "At step: 185 training error: 0.3521973242635748\n",
            "At step: 186 training error: 0.3563612673342582\n",
            "At step: 187 training error: 0.35386156060243257\n",
            "At step: 188 training error: 0.3658247785758787\n",
            "At step: 189 training error: 0.3576378691183172\n",
            "At step: 190 training error: 0.3563903296440436\n",
            "At step: 191 training error: 0.3472050314631931\n",
            "At step: 192 training error: 0.35430971182609117\n",
            "At step: 193 training error: 0.36219183932596405\n",
            "At step: 194 training error: 0.36328051335533046\n",
            "At step: 195 training error: 0.3502078770466157\n",
            "At step: 196 training error: 0.35086580112130367\n",
            "At step: 197 training error: 0.35754639787054676\n",
            "At step: 198 training error: 0.3536864817989155\n",
            "At step: 199 training error: 0.36523229424044307\n",
            "At step: 200 training error: 0.36885669677453986\n",
            "At step: 201 training error: 0.3584475042738115\n",
            "At step: 202 training error: 0.34522468822195823\n",
            "At step: 203 training error: 0.3443969550143287\n",
            "At step: 204 training error: 0.33950819180111563\n",
            "At step: 205 training error: 0.3378615156711519\n",
            "At step: 206 training error: 0.328265492777876\n",
            "At step: 207 training error: 0.3244421367527037\n",
            "At step: 208 training error: 0.32895681382499825\n",
            "At step: 209 training error: 0.34507135330401484\n",
            "At step: 210 training error: 0.3468387189856459\n",
            "At step: 211 training error: 0.36095039848118926\n",
            "At step: 212 training error: 0.36811694221868724\n",
            "At step: 213 training error: 0.36924477320156907\n",
            "At step: 214 training error: 0.3549782819429547\n",
            "At step: 215 training error: 0.35818648814019394\n",
            "At step: 216 training error: 0.3464639548761958\n",
            "At step: 217 training error: 0.3571218923693338\n",
            "At step: 218 training error: 0.3578219008406548\n",
            "At step: 219 training error: 0.3470255986096549\n",
            "At step: 220 training error: 0.3513629885925599\n",
            "At step: 221 training error: 0.3481005242148093\n",
            "At step: 222 training error: 0.35356476445391577\n",
            "At step: 223 training error: 0.36192360454952466\n",
            "At step: 224 training error: 0.35615655936395224\n",
            "At step: 225 training error: 0.35595728177882807\n",
            "At step: 226 training error: 0.36327601545769966\n",
            "At step: 227 training error: 0.36086406483971273\n",
            "At step: 228 training error: 0.35856635707424045\n",
            "At step: 229 training error: 0.35635462415375774\n",
            "At step: 230 training error: 0.35013986693198984\n",
            "At step: 231 training error: 0.3591665015675416\n",
            "At step: 232 training error: 0.37439901421144817\n",
            "At step: 233 training error: 0.3739678278747406\n",
            "At step: 234 training error: 0.3620266271672086\n",
            "At step: 235 training error: 0.3575827007269254\n",
            "At step: 236 training error: 0.3627582388045305\n",
            "At step: 237 training error: 0.3630484968417247\n",
            "At step: 238 training error: 0.35475628322914243\n",
            "At step: 239 training error: 0.35575231809544916\n",
            "At step: 240 training error: 0.34320291061039737\n",
            "At step: 241 training error: 0.35532461042158614\n",
            "At step: 242 training error: 0.3547656427623095\n",
            "At step: 243 training error: 0.3653275989571939\n",
            "At step: 244 training error: 0.36692120891001945\n",
            "At step: 245 training error: 0.36993279420978153\n",
            "At step: 246 training error: 0.37740309639457154\n",
            "At step: 247 training error: 0.3705953673588867\n",
            "At step: 248 training error: 0.37781763316617933\n",
            "At step: 249 training error: 0.36876475024531286\n",
            "At step: 250 training error: 0.3647555963566806\n",
            "At step: 251 training error: 0.3702836979548587\n",
            "At step: 252 training error: 0.36858366566159173\n",
            "At step: 253 training error: 0.37813457508904696\n",
            "At step: 254 training error: 0.37886504466419\n",
            "At step: 255 training error: 0.37962584447747594\n",
            "At step: 256 training error: 0.3725723669482157\n",
            "At step: 257 training error: 0.3604878101909395\n",
            "At step: 258 training error: 0.3587189297566882\n",
            "At step: 259 training error: 0.3599600202455657\n",
            "At step: 260 training error: 0.3568373038698841\n",
            "At step: 261 training error: 0.34947252512300075\n",
            "At step: 262 training error: 0.3426459447909496\n",
            "At step: 263 training error: 0.34088924663068626\n",
            "At step: 264 training error: 0.3496495798771948\n",
            "At step: 265 training error: 0.35279338803483984\n",
            "At step: 266 training error: 0.3567666307825662\n",
            "At step: 267 training error: 0.3537591260897064\n",
            "At step: 268 training error: 0.3462367542844177\n",
            "At step: 269 training error: 0.34415276478103823\n",
            "At step: 270 training error: 0.3401288060187969\n",
            "At step: 271 training error: 0.3429999805021415\n",
            "At step: 272 training error: 0.337435446903095\n",
            "At step: 273 training error: 0.3297615302814036\n",
            "At step: 274 training error: 0.3245923795311552\n",
            "At step: 275 training error: 0.3273332583707355\n",
            "At step: 276 training error: 0.3421904735363826\n",
            "At step: 277 training error: 0.3438044386736457\n",
            "At step: 278 training error: 0.3490064965072904\n",
            "At step: 279 training error: 0.3422618205740836\n",
            "At step: 280 training error: 0.3394899382497674\n",
            "At step: 281 training error: 0.3541988866608448\n",
            "At step: 282 training error: 0.36177598680544343\n",
            "At step: 283 training error: 0.35381899375568143\n",
            "At step: 284 training error: 0.34818697254702397\n",
            "At step: 285 training error: 0.3461916143319558\n",
            "At step: 286 training error: 0.345552042896612\n",
            "At step: 287 training error: 0.3396543890724105\n",
            "At step: 288 training error: 0.33685997965011577\n",
            "At step: 289 training error: 0.34483598922577813\n",
            "At step: 290 training error: 0.34463875758476753\n",
            "At step: 291 training error: 0.34187851579773715\n",
            "At step: 292 training error: 0.3485233576959148\n",
            "At step: 293 training error: 0.3619899691332172\n",
            "At step: 294 training error: 0.36355955219631997\n",
            "At step: 295 training error: 0.3679338586612927\n",
            "At step: 296 training error: 0.3692397535979095\n",
            "At step: 297 training error: 0.37412019334853763\n",
            "At step: 298 training error: 0.37886525903173707\n",
            "At step: 299 training error: 0.3843860947188163\n",
            "At step: 300 training error: 0.38122644719734944\n",
            "At step: 301 training error: 0.377041864319055\n",
            "At step: 302 training error: 0.38702856635343297\n",
            "At step: 303 training error: 0.38797441069751715\n",
            "At step: 304 training error: 0.3849430899997716\n",
            "At step: 305 training error: 0.3841557135013141\n",
            "At step: 306 training error: 0.3849041596603773\n",
            "At step: 307 training error: 0.37143969061410137\n",
            "At step: 308 training error: 0.3790884544917817\n",
            "At step: 309 training error: 0.37964416867147327\n",
            "At step: 310 training error: 0.3883652802053804\n",
            "At step: 311 training error: 0.3925917899813607\n",
            "At step: 312 training error: 0.396164459440174\n",
            "At step: 313 training error: 0.39568712576517273\n",
            "At step: 314 training error: 0.37925523979938425\n",
            "At step: 315 training error: 0.3770337966473098\n",
            "At step: 316 training error: 0.38486685455212416\n",
            "At step: 317 training error: 0.37727800245644316\n",
            "At step: 318 training error: 0.36600073763738356\n",
            "At step: 319 training error: 0.37338514383156984\n",
            "At step: 320 training error: 0.37601192103973935\n",
            "At step: 321 training error: 0.3746493769167109\n",
            "At step: 322 training error: 0.37442161263569895\n",
            "At step: 323 training error: 0.38729876805782004\n",
            "At step: 324 training error: 0.3769190562596679\n",
            "At step: 325 training error: 0.3731355845072718\n",
            "At step: 326 training error: 0.3707068712242523\n",
            "At step: 327 training error: 0.36895952040323254\n",
            "At step: 328 training error: 0.3629222801726989\n",
            "At step: 329 training error: 0.367279485353588\n",
            "At step: 330 training error: 0.367333133888168\n",
            "At step: 331 training error: 0.3647924379322426\n",
            "At step: 332 training error: 0.3632732208621056\n",
            "At step: 333 training error: 0.36188970362690775\n",
            "At step: 334 training error: 0.36658845144278607\n",
            "At step: 335 training error: 0.37934610715942346\n",
            "At step: 336 training error: 0.3848210476751949\n",
            "At step: 337 training error: 0.3808782456674702\n",
            "At step: 338 training error: 0.3803677788929726\n",
            "At step: 339 training error: 0.3862350816786122\n",
            "At step: 340 training error: 0.37921590655523146\n",
            "At step: 341 training error: 0.3753148381526426\n",
            "At step: 342 training error: 0.3793504232403201\n",
            "At step: 343 training error: 0.37480458957960444\n",
            "At step: 344 training error: 0.3681238368985126\n",
            "At step: 345 training error: 0.36799873933663996\n",
            "At step: 346 training error: 0.35820664732664836\n",
            "At step: 347 training error: 0.36126561684334235\n",
            "At step: 348 training error: 0.35441449030931904\n",
            "At step: 349 training error: 0.3445234605107095\n",
            "At step: 350 training error: 0.3409543413505274\n",
            "At step: 351 training error: 0.3496781444679396\n",
            "At step: 352 training error: 0.3588838611918197\n",
            "At step: 353 training error: 0.3590996363325528\n",
            "At step: 354 training error: 0.36227866101668565\n",
            "At step: 355 training error: 0.3553264027180919\n",
            "At step: 356 training error: 0.3656332180505935\n",
            "At step: 357 training error: 0.36712286592172233\n",
            "At step: 358 training error: 0.37287484178688285\n",
            "At step: 359 training error: 0.3697311147374184\n",
            "At step: 360 training error: 0.37620984182022615\n",
            "At step: 361 training error: 0.3828861109960856\n",
            "At step: 362 training error: 0.37401750083019875\n",
            "At step: 363 training error: 0.3685353969901259\n",
            "At step: 364 training error: 0.3698330083601418\n",
            "At step: 365 training error: 0.3707084229375689\n",
            "At step: 366 training error: 0.3714652769538174\n",
            "At step: 367 training error: 0.3603175393762348\n",
            "At step: 368 training error: 0.3543507021672935\n",
            "At step: 369 training error: 0.34786573431851936\n",
            "At step: 370 training error: 0.3533764907061979\n",
            "At step: 371 training error: 0.3554327893771749\n",
            "At step: 372 training error: 0.35126671029972417\n",
            "At step: 373 training error: 0.3502164886437111\n",
            "At step: 374 training error: 0.3535139679507646\n",
            "At step: 375 training error: 0.3543991594139525\n",
            "At step: 376 training error: 0.36078244382464364\n",
            "At step: 377 training error: 0.3588954861821936\n",
            "At step: 378 training error: 0.35993311810048945\n",
            "At step: 379 training error: 0.3603295748168705\n",
            "At step: 380 training error: 0.36984972374231767\n",
            "At step: 381 training error: 0.3776833504619949\n",
            "At step: 382 training error: 0.3724006177183519\n",
            "At step: 383 training error: 0.3694079203252472\n",
            "At step: 384 training error: 0.37705558310993975\n",
            "At step: 385 training error: 0.37655649150617965\n",
            "At step: 386 training error: 0.38458829905721115\n",
            "At step: 387 training error: 0.3717811875131686\n",
            "At step: 388 training error: 0.36760220654307946\n",
            "At step: 389 training error: 0.3687425269940118\n",
            "At step: 390 training error: 0.3726416139300401\n",
            "At step: 391 training error: 0.371888322929204\n",
            "At step: 392 training error: 0.36993800839968566\n",
            "At step: 393 training error: 0.3782032049672949\n",
            "At step: 394 training error: 0.3675837489944455\n",
            "At step: 395 training error: 0.36669164231427204\n",
            "At step: 396 training error: 0.37450153414990434\n",
            "At step: 397 training error: 0.37219973875543466\n",
            "At step: 398 training error: 0.36102863945228375\n",
            "At step: 399 training error: 0.3506088677489672\n",
            "At step: 400 training error: 0.36119272133727665\n",
            "At step: 401 training error: 0.3666101743382374\n",
            "At step: 402 training error: 0.36213143700120237\n",
            "At step: 403 training error: 0.37129682724967317\n",
            "At step: 404 training error: 0.37225665172065703\n",
            "At step: 405 training error: 0.3747120308786938\n",
            "At step: 406 training error: 0.3777371656605241\n",
            "At step: 407 training error: 0.3829290409805554\n",
            "At step: 408 training error: 0.38647186209757994\n",
            "At step: 409 training error: 0.38205893311028805\n",
            "At step: 410 training error: 0.3800063154594101\n",
            "At step: 411 training error: 0.3815859091390691\n",
            "At step: 412 training error: 0.3858579829917601\n",
            "At step: 413 training error: 0.3745703176074965\n",
            "At step: 414 training error: 0.3724725460897572\n",
            "At step: 415 training error: 0.3796712938815103\n",
            "At step: 416 training error: 0.38320031116841863\n",
            "At step: 417 training error: 0.3808463292649088\n",
            "At step: 418 training error: 0.37804834416129796\n",
            "At step: 419 training error: 0.370810889037873\n",
            "At step: 420 training error: 0.3615310233036532\n",
            "At step: 421 training error: 0.3534940080221202\n",
            "At step: 422 training error: 0.3618924679615017\n",
            "At step: 423 training error: 0.3589032685006395\n",
            "At step: 424 training error: 0.3515103285407684\n",
            "At step: 425 training error: 0.3584939494147512\n",
            "At step: 426 training error: 0.35362850301359006\n",
            "At step: 427 training error: 0.35430689258386106\n",
            "At step: 428 training error: 0.3480206106257579\n",
            "At step: 429 training error: 0.34602238244867745\n",
            "At step: 430 training error: 0.343500547892489\n",
            "At step: 431 training error: 0.3555161722358723\n",
            "At step: 432 training error: 0.3529086886288184\n",
            "At step: 433 training error: 0.3455200064890433\n",
            "At step: 434 training error: 0.34331654745960233\n",
            "At step: 435 training error: 0.34071147805560953\n",
            "At step: 436 training error: 0.3469966864956765\n",
            "At step: 437 training error: 0.3467110754415553\n",
            "At step: 438 training error: 0.34460354053015924\n",
            "At step: 439 training error: 0.3473019620682755\n",
            "At step: 440 training error: 0.35157708775943836\n",
            "At step: 441 training error: 0.36048553793182025\n",
            "At step: 442 training error: 0.362808974719098\n",
            "At step: 443 training error: 0.3633837232156816\n",
            "At step: 444 training error: 0.36081120873397393\n",
            "At step: 445 training error: 0.36189030855234977\n",
            "At step: 446 training error: 0.35148081414635723\n",
            "At step: 447 training error: 0.3533814442973812\n",
            "At step: 448 training error: 0.36469248376826163\n",
            "At step: 449 training error: 0.3672096537525491\n",
            "At step: 450 training error: 0.3637395544424001\n",
            "At step: 451 training error: 0.3744241524391399\n",
            "At step: 452 training error: 0.3661413233633243\n",
            "At step: 453 training error: 0.35856515816199375\n",
            "At step: 454 training error: 0.36259906735003394\n",
            "At step: 455 training error: 0.3562799167208856\n",
            "At step: 456 training error: 0.3702486956811708\n",
            "At step: 457 training error: 0.3777957637280754\n",
            "At step: 458 training error: 0.37708446534322976\n",
            "At step: 459 training error: 0.3700431800047375\n",
            "At step: 460 training error: 0.36925317154235726\n",
            "At step: 461 training error: 0.3669510224282936\n",
            "At step: 462 training error: 0.3621146548105405\n",
            "At step: 463 training error: 0.35682648602491535\n",
            "At step: 464 training error: 0.3557100674417942\n",
            "At step: 465 training error: 0.3478947023891073\n",
            "At step: 466 training error: 0.3419884604620986\n",
            "At step: 467 training error: 0.34345419404140953\n",
            "At step: 468 training error: 0.3491645209416374\n",
            "At step: 469 training error: 0.3437505736317302\n",
            "At step: 470 training error: 0.3457989300623861\n",
            "At step: 471 training error: 0.3495974913041354\n",
            "At step: 472 training error: 0.3504726792459825\n",
            "At step: 473 training error: 0.34940941204612597\n",
            "At step: 474 training error: 0.35034431473616273\n",
            "At step: 475 training error: 0.3501007014834861\n",
            "At step: 476 training error: 0.3520498585372736\n",
            "At step: 477 training error: 0.3724063359994787\n",
            "At step: 478 training error: 0.3747422546574827\n",
            "At step: 479 training error: 0.38298751611203635\n",
            "At step: 480 training error: 0.3801088306054907\n",
            "At step: 481 training error: 0.3691578977536426\n",
            "At step: 482 training error: 0.36477523454934807\n",
            "At step: 483 training error: 0.36827065765380873\n",
            "At step: 484 training error: 0.36217229917187344\n",
            "At step: 485 training error: 0.3634475580493303\n",
            "At step: 486 training error: 0.37034413465841876\n",
            "At step: 487 training error: 0.36149974270653656\n",
            "At step: 488 training error: 0.3524142522252973\n",
            "At step: 489 training error: 0.3506877625685867\n",
            "At step: 490 training error: 0.34171186350853827\n",
            "At step: 491 training error: 0.3462039278821908\n",
            "At step: 492 training error: 0.3528939903568148\n",
            "At step: 493 training error: 0.35426374857878484\n",
            "At step: 494 training error: 0.362348865845975\n",
            "At step: 495 training error: 0.36472793436918893\n",
            "At step: 496 training error: 0.3713193730903595\n",
            "At step: 497 training error: 0.36841317221439485\n",
            "At step: 498 training error: 0.36841240190698715\n",
            "At step: 499 training error: 0.36649374576136845\n",
            "At step: 500 training error: 0.374052275912693\n",
            "At step: 501 training error: 0.3699171973048475\n",
            "At step: 502 training error: 0.36784068298761746\n",
            "At step: 503 training error: 0.36612194851863805\n",
            "At step: 504 training error: 0.36309205369066105\n",
            "At step: 505 training error: 0.35798494868118086\n",
            "At step: 506 training error: 0.35274023163746104\n",
            "At step: 507 training error: 0.3584302524197648\n",
            "At step: 508 training error: 0.3690671283109532\n",
            "At step: 509 training error: 0.37152823826664017\n",
            "At step: 510 training error: 0.37934061935064034\n",
            "At step: 511 training error: 0.3843909950054544\n",
            "At step: 512 training error: 0.38325781523434244\n",
            "At step: 513 training error: 0.3773162905922028\n",
            "At step: 514 training error: 0.37498404207991937\n",
            "At step: 515 training error: 0.3839910551639948\n",
            "At step: 516 training error: 0.3940177803006466\n",
            "At step: 517 training error: 0.3898026346120924\n",
            "At step: 518 training error: 0.37790111543595134\n",
            "At step: 519 training error: 0.3792775381563355\n",
            "At step: 520 training error: 0.37221201209933374\n",
            "At step: 521 training error: 0.3762310434713506\n",
            "At step: 522 training error: 0.378104712909128\n",
            "At step: 523 training error: 0.37270403597635965\n",
            "At step: 524 training error: 0.3681335972708383\n",
            "At step: 525 training error: 0.3661490962481187\n",
            "At step: 526 training error: 0.3745191600987754\n",
            "At step: 527 training error: 0.37721532976903804\n",
            "At step: 528 training error: 0.3734063386779204\n",
            "At step: 529 training error: 0.3817600512676921\n",
            "At step: 530 training error: 0.38298885210579225\n",
            "At step: 531 training error: 0.37257802289490244\n",
            "At step: 532 training error: 0.3753729120732547\n",
            "At step: 533 training error: 0.3728495569096903\n",
            "At step: 534 training error: 0.3755903619903844\n",
            "At step: 535 training error: 0.3689943753786264\n",
            "At step: 536 training error: 0.3742080409054812\n",
            "At step: 537 training error: 0.3650561302839221\n",
            "At step: 538 training error: 0.36160933487171343\n",
            "At step: 539 training error: 0.36104422006833514\n",
            "At step: 540 training error: 0.3574582101809393\n",
            "At step: 541 training error: 0.3578834016307745\n",
            "At step: 542 training error: 0.35247458837562634\n",
            "At step: 543 training error: 0.3712810223038797\n",
            "At step: 544 training error: 0.3661517439007013\n",
            "At step: 545 training error: 0.37042839787828935\n",
            "At step: 546 training error: 0.3724926625478671\n",
            "At step: 547 training error: 0.3746824215106625\n",
            "At step: 548 training error: 0.3625849392225151\n",
            "At step: 549 training error: 0.37085964811153793\n",
            "At step: 550 training error: 0.3645348196697183\n",
            "At step: 551 training error: 0.3652879169401918\n",
            "At step: 552 training error: 0.36225139838330606\n",
            "At step: 553 training error: 0.3609680609677512\n",
            "At step: 554 training error: 0.3623266548303598\n",
            "At step: 555 training error: 0.34827313788788106\n",
            "At step: 556 training error: 0.35148077671942485\n",
            "At step: 557 training error: 0.3555265741302555\n",
            "At step: 558 training error: 0.369216883445561\n",
            "At step: 559 training error: 0.37314842437379886\n",
            "At step: 560 training error: 0.37181042549921867\n",
            "At step: 561 training error: 0.35652788890428094\n",
            "At step: 562 training error: 0.34888502549477457\n",
            "At step: 563 training error: 0.3458845715786763\n",
            "At step: 564 training error: 0.34546148316068914\n",
            "At step: 565 training error: 0.3425126540911788\n",
            "At step: 566 training error: 0.3377285115841683\n",
            "At step: 567 training error: 0.3522089674161558\n",
            "At step: 568 training error: 0.35820515466989555\n",
            "At step: 569 training error: 0.3537211298815014\n",
            "At step: 570 training error: 0.3550110793107526\n",
            "At step: 571 training error: 0.360818598419687\n",
            "At step: 572 training error: 0.372735827162254\n",
            "At step: 573 training error: 0.36920175206228173\n",
            "At step: 574 training error: 0.36663526736047075\n",
            "At step: 575 training error: 0.3660722489520879\n",
            "At step: 576 training error: 0.3732183966202585\n",
            "At step: 577 training error: 0.39422284936738644\n",
            "At step: 578 training error: 0.3814601793029508\n",
            "At step: 579 training error: 0.37871364753468767\n",
            "At step: 580 training error: 0.3717103113422903\n",
            "At step: 581 training error: 0.37243108140022185\n",
            "At step: 582 training error: 0.3736805708798248\n",
            "At step: 583 training error: 0.3673434535055854\n",
            "At step: 584 training error: 0.36990036343765204\n",
            "At step: 585 training error: 0.3676319709021648\n",
            "At step: 586 training error: 0.37681282442903036\n",
            "At step: 587 training error: 0.37116245669309395\n",
            "At step: 588 training error: 0.37172973594229236\n",
            "At step: 589 training error: 0.3669315126223735\n",
            "At step: 590 training error: 0.3761821609130026\n",
            "At step: 591 training error: 0.3811019351809731\n",
            "At step: 592 training error: 0.3796558752683751\n",
            "At step: 593 training error: 0.390248307236211\n",
            "At step: 594 training error: 0.3874718281128996\n",
            "At step: 595 training error: 0.3861678787451297\n",
            "At step: 596 training error: 0.3780149593219108\n",
            "At step: 597 training error: 0.37406757511585537\n",
            "At step: 598 training error: 0.36637420854364694\n",
            "At step: 599 training error: 0.37852195721999415\n",
            "At step: 600 training error: 0.3852589842349164\n",
            "At step: 601 training error: 0.3695679491776177\n",
            "At step: 602 training error: 0.3703282166215641\n",
            "At step: 603 training error: 0.36721846744807846\n",
            "At step: 604 training error: 0.36628383711693574\n",
            "At step: 605 training error: 0.35460227552845186\n",
            "At step: 606 training error: 0.35401803305601265\n",
            "At step: 607 training error: 0.34282604694097696\n",
            "At step: 608 training error: 0.3475619478387633\n",
            "At step: 609 training error: 0.35275692674126774\n",
            "At step: 610 training error: 0.3433614477563822\n",
            "At step: 611 training error: 0.3569689964104293\n",
            "At step: 612 training error: 0.36607525428945836\n",
            "At step: 613 training error: 0.36677961934035047\n",
            "At step: 614 training error: 0.3682585429782853\n",
            "At step: 615 training error: 0.3630536486746186\n",
            "At step: 616 training error: 0.35143925666828063\n",
            "At step: 617 training error: 0.36248249008938815\n",
            "At step: 618 training error: 0.3513798557315664\n",
            "At step: 619 training error: 0.3532991210109189\n",
            "At step: 620 training error: 0.3488851191462164\n",
            "At step: 621 training error: 0.33739169460227497\n",
            "At step: 622 training error: 0.33617751571924137\n",
            "At step: 623 training error: 0.3337958219075424\n",
            "At step: 624 training error: 0.327593281760863\n",
            "At step: 625 training error: 0.33515963287558437\n",
            "At step: 626 training error: 0.33834302028576474\n",
            "At step: 627 training error: 0.33348527145120616\n",
            "At step: 628 training error: 0.3316163632151119\n",
            "At step: 629 training error: 0.33974729626421135\n",
            "At step: 630 training error: 0.3404167964816392\n",
            "At step: 631 training error: 0.33608758233417074\n",
            "At step: 632 training error: 0.33777233283994135\n",
            "At step: 633 training error: 0.34304826570780245\n",
            "At step: 634 training error: 0.34823122223102226\n",
            "At step: 635 training error: 0.3477459362054472\n",
            "At step: 636 training error: 0.348151864300007\n",
            "At step: 637 training error: 0.34933455878653835\n",
            "At step: 638 training error: 0.3568603693614616\n",
            "At step: 639 training error: 0.3560601354829448\n",
            "At step: 640 training error: 0.3509881515638341\n",
            "At step: 641 training error: 0.35000873006277555\n",
            "At step: 642 training error: 0.34521928380100175\n",
            "At step: 643 training error: 0.34632419943941495\n",
            "At step: 644 training error: 0.3416973578781033\n",
            "At step: 645 training error: 0.3399520353839456\n",
            "At step: 646 training error: 0.3330001586147075\n",
            "At step: 647 training error: 0.3359321285299933\n",
            "At step: 648 training error: 0.34020066581001807\n",
            "At step: 649 training error: 0.34917765114430466\n",
            "At step: 650 training error: 0.342321788397401\n",
            "At step: 651 training error: 0.3462459687002553\n",
            "At step: 652 training error: 0.3408134292267038\n",
            "At step: 653 training error: 0.34436328665225036\n",
            "At step: 654 training error: 0.3515806716770663\n",
            "At step: 655 training error: 0.35673939308383273\n",
            "At step: 656 training error: 0.36178307666295245\n",
            "At step: 657 training error: 0.3744332638234173\n",
            "At step: 658 training error: 0.3839172490840012\n",
            "At step: 659 training error: 0.3750105579501987\n",
            "At step: 660 training error: 0.36818353405865556\n",
            "At step: 661 training error: 0.3761295194024036\n",
            "At step: 662 training error: 0.3760605199837285\n",
            "At step: 663 training error: 0.3751347137881063\n",
            "At step: 664 training error: 0.37634537401885604\n",
            "At step: 665 training error: 0.37064303115365155\n",
            "At step: 666 training error: 0.3803378375104608\n",
            "At step: 667 training error: 0.37956188654446654\n",
            "At step: 668 training error: 0.37447750895222415\n",
            "At step: 669 training error: 0.3724767678870814\n",
            "At step: 670 training error: 0.3629493449474196\n",
            "At step: 671 training error: 0.37177015622359644\n",
            "At step: 672 training error: 0.3775582736210424\n",
            "At step: 673 training error: 0.3797147838900103\n",
            "At step: 674 training error: 0.3795984584930252\n",
            "At step: 675 training error: 0.3791760444102349\n",
            "At step: 676 training error: 0.37867275005568446\n",
            "At step: 677 training error: 0.37933731148358996\n",
            "At step: 678 training error: 0.3756580739656896\n",
            "At step: 679 training error: 0.37969660007251904\n",
            "At step: 680 training error: 0.3647423582307712\n",
            "At step: 681 training error: 0.35326714683032095\n",
            "At step: 682 training error: 0.35181695657182216\n",
            "At step: 683 training error: 0.3495354329382289\n",
            "At step: 684 training error: 0.34351212929153185\n",
            "At step: 685 training error: 0.3520011301717693\n",
            "At step: 686 training error: 0.3549823638133838\n",
            "At step: 687 training error: 0.352815512537899\n",
            "At step: 688 training error: 0.3488694624175269\n",
            "At step: 689 training error: 0.35356778081011386\n",
            "At step: 690 training error: 0.36212792517105064\n",
            "At step: 691 training error: 0.3606355370588241\n",
            "At step: 692 training error: 0.35186069638329587\n",
            "At step: 693 training error: 0.3583222696304887\n",
            "At step: 694 training error: 0.35447024486588496\n",
            "At step: 695 training error: 0.3486742441784295\n",
            "At step: 696 training error: 0.3591409743145594\n",
            "At step: 697 training error: 0.35630927642757704\n",
            "At step: 698 training error: 0.35362503651432786\n",
            "At step: 699 training error: 0.35625098013510437\n",
            "At step: 700 training error: 0.34429019730897936\n",
            "At step: 701 training error: 0.34876876989666794\n",
            "At step: 702 training error: 0.33750558499657973\n",
            "At step: 703 training error: 0.3416050812956718\n",
            "At step: 704 training error: 0.3440596023830791\n",
            "At step: 705 training error: 0.35045604779430284\n",
            "At step: 706 training error: 0.35223006524053674\n",
            "At step: 707 training error: 0.3644422596906242\n",
            "At step: 708 training error: 0.36564444042261635\n",
            "At step: 709 training error: 0.36525305560942045\n",
            "At step: 710 training error: 0.3682416684578719\n",
            "At step: 711 training error: 0.3713949963250655\n",
            "At step: 712 training error: 0.36185903223951393\n",
            "At step: 713 training error: 0.3559784762712108\n",
            "At step: 714 training error: 0.3566424760913772\n",
            "At step: 715 training error: 0.35549111602159833\n",
            "At step: 716 training error: 0.34766052041890205\n",
            "At step: 717 training error: 0.3539016741789822\n",
            "At step: 718 training error: 0.36210309658407713\n",
            "At step: 719 training error: 0.35429501055903784\n",
            "At step: 720 training error: 0.34890435433943023\n",
            "At step: 721 training error: 0.3497997031379417\n",
            "At step: 722 training error: 0.35671262153154343\n",
            "At step: 723 training error: 0.3520475299042848\n",
            "At step: 724 training error: 0.3493110559511503\n",
            "At step: 725 training error: 0.3448951159930314\n",
            "At step: 726 training error: 0.33740334965860513\n",
            "At step: 727 training error: 0.3440989216463904\n",
            "At step: 728 training error: 0.3385329017867728\n",
            "At step: 729 training error: 0.34254045002778133\n",
            "At step: 730 training error: 0.3467949421972676\n",
            "At step: 731 training error: 0.34453143905842315\n",
            "At step: 732 training error: 0.34215803395876226\n",
            "At step: 733 training error: 0.33982203682025947\n",
            "At step: 734 training error: 0.3422895633474624\n",
            "At step: 735 training error: 0.33616142854374614\n",
            "At step: 736 training error: 0.33701334002591365\n",
            "At step: 737 training error: 0.3500551537154155\n",
            "At step: 738 training error: 0.3479764746367751\n",
            "At step: 739 training error: 0.349912575756588\n",
            "At step: 740 training error: 0.3451746000247874\n",
            "At step: 741 training error: 0.35687566041223895\n",
            "At step: 742 training error: 0.3541047310444391\n",
            "At step: 743 training error: 0.3479227164042326\n",
            "At step: 744 training error: 0.35870582961044317\n",
            "At step: 745 training error: 0.36022207018144203\n",
            "At step: 746 training error: 0.3531450989078625\n",
            "At step: 747 training error: 0.3514145045582117\n",
            "At step: 748 training error: 0.3527410247196965\n",
            "At step: 749 training error: 0.36163706827905406\n",
            "At step: 750 training error: 0.3495810558798786\n",
            "At step: 751 training error: 0.34687735671129527\n",
            "At step: 752 training error: 0.34378521983797455\n",
            "At step: 753 training error: 0.35070775945527527\n",
            "At step: 754 training error: 0.35056835380597545\n",
            "At step: 755 training error: 0.35641084901512593\n",
            "At step: 756 training error: 0.35035914145909125\n",
            "At step: 757 training error: 0.34951862673677486\n",
            "At step: 758 training error: 0.3469365446260344\n",
            "At step: 759 training error: 0.3423956807653508\n",
            "At step: 760 training error: 0.3479367250183799\n",
            "At step: 761 training error: 0.33379858394199274\n",
            "At step: 762 training error: 0.33996849886008396\n",
            "At step: 763 training error: 0.34321111018626566\n",
            "At step: 764 training error: 0.3440644831829551\n",
            "At step: 765 training error: 0.34967796363487846\n",
            "At step: 766 training error: 0.3461965247700762\n",
            "At step: 767 training error: 0.34445621457049136\n",
            "At step: 768 training error: 0.342375093867338\n",
            "At step: 769 training error: 0.33407600233293694\n",
            "At step: 770 training error: 0.33146287773203525\n",
            "At step: 771 training error: 0.33085427588061483\n",
            "At step: 772 training error: 0.3259790798142615\n",
            "At step: 773 training error: 0.3275854049029527\n",
            "At step: 774 training error: 0.325133043466724\n",
            "At step: 775 training error: 0.3223941370248553\n",
            "At step: 776 training error: 0.3176306035701951\n",
            "At step: 777 training error: 0.3211762828692529\n",
            "At step: 778 training error: 0.32385324448929215\n",
            "At step: 779 training error: 0.3202237867518612\n",
            "At step: 780 training error: 0.33113423310058854\n",
            "At step: 781 training error: 0.33141325198937516\n",
            "At step: 782 training error: 0.32428160145749424\n",
            "At step: 783 training error: 0.3274304805040337\n",
            "At step: 784 training error: 0.3264883033979049\n",
            "At step: 785 training error: 0.3253052360905894\n",
            "At step: 786 training error: 0.331922547105257\n",
            "At step: 787 training error: 0.32985575519594945\n",
            "At step: 788 training error: 0.33548518856135523\n",
            "At step: 789 training error: 0.3349978008526102\n",
            "At step: 790 training error: 0.33809115815480645\n",
            "At step: 791 training error: 0.33888301276077704\n",
            "At step: 792 training error: 0.36166126289428246\n",
            "At step: 793 training error: 0.35236573146564476\n",
            "At step: 794 training error: 0.3654286145430306\n",
            "At step: 795 training error: 0.3547829396593284\n",
            "At step: 796 training error: 0.3527947146751823\n",
            "At step: 797 training error: 0.3529527494358577\n",
            "At step: 798 training error: 0.3501994511875562\n",
            "At step: 799 training error: 0.3508536681252511\n",
            "At step: 800 training error: 0.34476692784835405\n",
            "At step: 801 training error: 0.3388264745744237\n",
            "At step: 802 training error: 0.34075616685324384\n",
            "At step: 803 training error: 0.3532681097834548\n",
            "At step: 804 training error: 0.3498474567324808\n",
            "At step: 805 training error: 0.3367943938362979\n",
            "At step: 806 training error: 0.33891829607298685\n",
            "At step: 807 training error: 0.3415060847733737\n",
            "At step: 808 training error: 0.3532718966364039\n",
            "At step: 809 training error: 0.342698106216773\n",
            "At step: 810 training error: 0.34111740425568626\n",
            "At step: 811 training error: 0.33147128519502844\n",
            "At step: 812 training error: 0.34482201547263225\n",
            "At step: 813 training error: 0.3481809611210521\n",
            "At step: 814 training error: 0.36155403436617434\n",
            "At step: 815 training error: 0.35324130091668327\n",
            "At step: 816 training error: 0.3475719274054333\n",
            "At step: 817 training error: 0.3510052326101888\n",
            "At step: 818 training error: 0.3545394741458023\n",
            "At step: 819 training error: 0.34871233595603834\n",
            "At step: 820 training error: 0.3547879207946385\n",
            "At step: 821 training error: 0.3461666689714481\n",
            "At step: 822 training error: 0.3387071345779802\n",
            "At step: 823 training error: 0.3419198500335144\n",
            "At step: 824 training error: 0.3513831894909081\n",
            "At step: 825 training error: 0.34621510291796237\n",
            "At step: 826 training error: 0.34131940273823463\n",
            "At step: 827 training error: 0.35584071541349255\n",
            "At step: 828 training error: 0.36171122667687877\n",
            "At step: 829 training error: 0.3689732379184914\n",
            "At step: 830 training error: 0.3678111381477398\n",
            "At step: 831 training error: 0.36698821423816835\n",
            "At step: 832 training error: 0.3741896958350923\n",
            "At step: 833 training error: 0.37881386991725596\n",
            "At step: 834 training error: 0.3796321092870978\n",
            "At step: 835 training error: 0.38127988030962684\n",
            "At step: 836 training error: 0.3781732055724526\n",
            "At step: 837 training error: 0.3827626772643752\n",
            "At step: 838 training error: 0.3738229154218849\n",
            "At step: 839 training error: 0.376946599618504\n",
            "At step: 840 training error: 0.38117886456767525\n",
            "At step: 841 training error: 0.3583237993528542\n",
            "At step: 842 training error: 0.3558587710263734\n",
            "At step: 843 training error: 0.35763587400969954\n",
            "At step: 844 training error: 0.3592623762330576\n",
            "At step: 845 training error: 0.3509663415322652\n",
            "At step: 846 training error: 0.3503846359543055\n",
            "At step: 847 training error: 0.3488275017792688\n",
            "At step: 848 training error: 0.34810719928844414\n",
            "At step: 849 training error: 0.3487687204082724\n",
            "At step: 850 training error: 0.3492868301840444\n",
            "At step: 851 training error: 0.3482650154257129\n",
            "At step: 852 training error: 0.3476375243738076\n",
            "At step: 853 training error: 0.3458597537766349\n",
            "At step: 854 training error: 0.34958872065850677\n",
            "At step: 855 training error: 0.33648495128379324\n",
            "At step: 856 training error: 0.3438548728960683\n",
            "At step: 857 training error: 0.3376200286693727\n",
            "At step: 858 training error: 0.3545927287594143\n",
            "At step: 859 training error: 0.3564089516423358\n",
            "At step: 860 training error: 0.35583882219710466\n",
            "At step: 861 training error: 0.3565038092075943\n",
            "At step: 862 training error: 0.36179888200936283\n",
            "At step: 863 training error: 0.357062542165129\n",
            "At step: 864 training error: 0.3565652043519742\n",
            "At step: 865 training error: 0.35768852439798376\n",
            "At step: 866 training error: 0.3548104431641379\n",
            "At step: 867 training error: 0.35350338625908057\n",
            "At step: 868 training error: 0.3520228795616567\n",
            "At step: 869 training error: 0.35125740594045707\n",
            "At step: 870 training error: 0.3570303698250584\n",
            "At step: 871 training error: 0.35451743714260203\n",
            "At step: 872 training error: 0.358890559582642\n",
            "At step: 873 training error: 0.3589979909634778\n",
            "At step: 874 training error: 0.3513537328781223\n",
            "At step: 875 training error: 0.358489636149049\n",
            "At step: 876 training error: 0.35584407082341596\n",
            "At step: 877 training error: 0.3625221321556837\n",
            "At step: 878 training error: 0.36285565759744004\n",
            "At step: 879 training error: 0.3588619436112251\n",
            "At step: 880 training error: 0.36029395547065257\n",
            "At step: 881 training error: 0.36414780023407584\n",
            "At step: 882 training error: 0.36278869876993086\n",
            "At step: 883 training error: 0.35061659289130676\n",
            "At step: 884 training error: 0.3610421968426783\n",
            "At step: 885 training error: 0.3648145323278892\n",
            "At step: 886 training error: 0.3585212434087599\n",
            "At step: 887 training error: 0.35427017535818445\n",
            "At step: 888 training error: 0.3443018681601187\n",
            "At step: 889 training error: 0.33063285901679407\n",
            "At step: 890 training error: 0.3205076157599315\n",
            "At step: 891 training error: 0.32399521384825286\n",
            "At step: 892 training error: 0.3362147272952501\n",
            "At step: 893 training error: 0.33142660430028226\n",
            "At step: 894 training error: 0.3344643043809949\n",
            "At step: 895 training error: 0.33357237615611296\n",
            "At step: 896 training error: 0.33604174817951404\n",
            "At step: 897 training error: 0.337485858477682\n",
            "At step: 898 training error: 0.33208649283802316\n",
            "At step: 899 training error: 0.3347971599909377\n",
            "At step: 900 training error: 0.3312426091795221\n",
            "At step: 901 training error: 0.33635277573821964\n",
            "At step: 902 training error: 0.3347346803032577\n",
            "At step: 903 training error: 0.3385606856753159\n",
            "At step: 904 training error: 0.32564900565190447\n",
            "At step: 905 training error: 0.32191465152535653\n",
            "At step: 906 training error: 0.3261792361187433\n",
            "At step: 907 training error: 0.3315424316021105\n",
            "At step: 908 training error: 0.3298798277631396\n",
            "At step: 909 training error: 0.3339280614469417\n",
            "At step: 910 training error: 0.3400255034142879\n",
            "At step: 911 training error: 0.34144449831526696\n",
            "At step: 912 training error: 0.3449607212908167\n",
            "At step: 913 training error: 0.3353834239731502\n",
            "At step: 914 training error: 0.3374661654927063\n",
            "At step: 915 training error: 0.3360208547636876\n",
            "At step: 916 training error: 0.34721022441845323\n",
            "At step: 917 training error: 0.3464835718501658\n",
            "At step: 918 training error: 0.3452386637244823\n",
            "At step: 919 training error: 0.3340667230134353\n",
            "At step: 920 training error: 0.332206152799223\n",
            "At step: 921 training error: 0.3380200238976534\n",
            "At step: 922 training error: 0.3414724394121668\n",
            "At step: 923 training error: 0.33692834820302603\n",
            "At step: 924 training error: 0.33678175815726413\n",
            "At step: 925 training error: 0.34881787954736776\n",
            "At step: 926 training error: 0.355104206782802\n",
            "At step: 927 training error: 0.35365128472368096\n",
            "At step: 928 training error: 0.3501853803890061\n",
            "At step: 929 training error: 0.3511050565390811\n",
            "At step: 930 training error: 0.3639493828870947\n",
            "At step: 931 training error: 0.35607416938278946\n",
            "At step: 932 training error: 0.34830674633803016\n",
            "At step: 933 training error: 0.34575993774601954\n",
            "At step: 934 training error: 0.3489484493204159\n",
            "At step: 935 training error: 0.3336733693137297\n",
            "At step: 936 training error: 0.33404292908846317\n",
            "At step: 937 training error: 0.3265879476550635\n",
            "At step: 938 training error: 0.3164362143055505\n",
            "At step: 939 training error: 0.313252145129652\n",
            "At step: 940 training error: 0.3221646660522236\n",
            "At step: 941 training error: 0.3383292367490406\n",
            "At step: 942 training error: 0.34106755602432726\n",
            "At step: 943 training error: 0.3425641789569758\n",
            "At step: 944 training error: 0.3480565598072972\n",
            "At step: 945 training error: 0.35750439336114315\n",
            "At step: 946 training error: 0.3541475233737263\n",
            "At step: 947 training error: 0.3547412146853935\n",
            "At step: 948 training error: 0.3519334613929146\n",
            "At step: 949 training error: 0.3596626050079762\n",
            "At step: 950 training error: 0.3628523318923434\n",
            "At step: 951 training error: 0.37673612017638514\n",
            "At step: 952 training error: 0.3699087789816326\n",
            "At step: 953 training error: 0.37018036434676443\n",
            "At step: 954 training error: 0.37820224936062846\n",
            "At step: 955 training error: 0.3821900001224143\n",
            "At step: 956 training error: 0.38578383126322674\n",
            "At step: 957 training error: 0.3684662219128922\n",
            "At step: 958 training error: 0.36215713128354715\n",
            "At step: 959 training error: 0.36278322293192516\n",
            "At step: 960 training error: 0.35706854504350594\n",
            "At step: 961 training error: 0.358827986278966\n",
            "At step: 962 training error: 0.3634801262949112\n",
            "At step: 963 training error: 0.3694861668211334\n",
            "At step: 964 training error: 0.37054505690757533\n",
            "At step: 965 training error: 0.3687247074457606\n",
            "At step: 966 training error: 0.37093197477702844\n",
            "At step: 967 training error: 0.3643804256337116\n",
            "At step: 968 training error: 0.3612568409322802\n",
            "At step: 969 training error: 0.35887676227303017\n",
            "At step: 970 training error: 0.36121915919678105\n",
            "At step: 971 training error: 0.36384993884501055\n",
            "At step: 972 training error: 0.3621476979793617\n",
            "At step: 973 training error: 0.3680901896463992\n",
            "At step: 974 training error: 0.36559975149079593\n",
            "At step: 975 training error: 0.358156000834737\n",
            "At step: 976 training error: 0.35399460840604463\n",
            "At step: 977 training error: 0.35728544966165837\n",
            "At step: 978 training error: 0.35547881079756555\n",
            "At step: 979 training error: 0.3468930902420065\n",
            "At step: 980 training error: 0.34989586257262784\n",
            "At step: 981 training error: 0.3393022004875098\n",
            "At step: 982 training error: 0.34703426116306685\n",
            "At step: 983 training error: 0.3504636292097063\n",
            "At step: 984 training error: 0.3564057036865522\n",
            "At step: 985 training error: 0.36063071898593807\n",
            "At step: 986 training error: 0.35658646346529\n",
            "At step: 987 training error: 0.3470154189002868\n",
            "At step: 988 training error: 0.35168749663056703\n",
            "At step: 989 training error: 0.3497963629947586\n",
            "At step: 990 training error: 0.3600395581269402\n",
            "At step: 991 training error: 0.3532535022751821\n",
            "At step: 992 training error: 0.3465222451579459\n",
            "At step: 993 training error: 0.34982123642063045\n",
            "At step: 994 training error: 0.3347388964314332\n",
            "At step: 995 training error: 0.3240960747292756\n",
            "At step: 996 training error: 0.32842916761423346\n",
            "At step: 997 training error: 0.33530971070724985\n",
            "At step: 998 training error: 0.34261048966536556\n",
            "At step: 999 training error: 0.3421653029483759\n",
            "At step: 1000 training error: 0.3494883291207047\n",
            "At step: 1001 training error: 0.35191853394569456\n",
            "At step: 1002 training error: 0.35855732467391493\n",
            "At step: 1003 training error: 0.364990425746222\n",
            "At step: 1004 training error: 0.3556696185337373\n",
            "At step: 1005 training error: 0.3587488835456126\n",
            "At step: 1006 training error: 0.3620072057957018\n",
            "At step: 1007 training error: 0.3592194387883584\n",
            "At step: 1008 training error: 0.357956931421019\n",
            "At step: 1009 training error: 0.35594109150938236\n",
            "At step: 1010 training error: 0.35304978397179737\n",
            "At step: 1011 training error: 0.3471829893137667\n",
            "At step: 1012 training error: 0.35670926081340093\n",
            "At step: 1013 training error: 0.357327682203284\n",
            "At step: 1014 training error: 0.35493476068843277\n",
            "At step: 1015 training error: 0.3470275118350365\n",
            "At step: 1016 training error: 0.35009513829271494\n",
            "At step: 1017 training error: 0.35492722032538226\n",
            "At step: 1018 training error: 0.35394518400172537\n",
            "At step: 1019 training error: 0.3514348060356945\n",
            "At step: 1020 training error: 0.36299774284117403\n",
            "At step: 1021 training error: 0.36751460451629514\n",
            "At step: 1022 training error: 0.36124151131587146\n",
            "At step: 1023 training error: 0.3683485610519899\n",
            "At step: 1024 training error: 0.3639120101726097\n",
            "At step: 1025 training error: 0.3681053182024173\n",
            "At step: 1026 training error: 0.36491404685506956\n",
            "At step: 1027 training error: 0.3799262353677164\n",
            "At step: 1028 training error: 0.3746671690040154\n",
            "At step: 1029 training error: 0.37081091020316365\n",
            "At step: 1030 training error: 0.37647494215319055\n",
            "At step: 1031 training error: 0.3838252220425962\n",
            "At step: 1032 training error: 0.3750049386400013\n",
            "At step: 1033 training error: 0.37648183013809156\n",
            "At step: 1034 training error: 0.3635855646854729\n",
            "At step: 1035 training error: 0.36242279378254355\n",
            "At step: 1036 training error: 0.35374221596601074\n",
            "At step: 1037 training error: 0.35846232451188464\n",
            "At step: 1038 training error: 0.3558472570032421\n",
            "At step: 1039 training error: 0.35404327836917826\n",
            "At step: 1040 training error: 0.36070603014976044\n",
            "At step: 1041 training error: 0.3640954342410661\n",
            "At step: 1042 training error: 0.36869730484484453\n",
            "At step: 1043 training error: 0.3572128816667898\n",
            "At step: 1044 training error: 0.3586501192270981\n",
            "At step: 1045 training error: 0.35814192551745916\n",
            "At step: 1046 training error: 0.35453619197435443\n",
            "At step: 1047 training error: 0.3504484183678842\n",
            "At step: 1048 training error: 0.35092212372220827\n",
            "At step: 1049 training error: 0.3476019103110082\n",
            "At step: 1050 training error: 0.33941023672458487\n",
            "At step: 1051 training error: 0.34041346934297045\n",
            "At step: 1052 training error: 0.34446107155019307\n",
            "At step: 1053 training error: 0.3373027148921894\n",
            "At step: 1054 training error: 0.34481137004761786\n",
            "At step: 1055 training error: 0.34869856904681934\n",
            "At step: 1056 training error: 0.3538401193844557\n",
            "At step: 1057 training error: 0.3474912966381876\n",
            "At step: 1058 training error: 0.356798424439409\n",
            "At step: 1059 training error: 0.3580760391896863\n",
            "At step: 1060 training error: 0.35286280998527164\n",
            "At step: 1061 training error: 0.3442006322713761\n",
            "At step: 1062 training error: 0.361654069892054\n",
            "At step: 1063 training error: 0.356685430961073\n",
            "At step: 1064 training error: 0.34793726780539536\n",
            "At step: 1065 training error: 0.35002510218551186\n",
            "At step: 1066 training error: 0.36269176910605216\n",
            "At step: 1067 training error: 0.36234279025720584\n",
            "At step: 1068 training error: 0.35543642253555774\n",
            "At step: 1069 training error: 0.3507182035979006\n",
            "At step: 1070 training error: 0.3496033378175433\n",
            "At step: 1071 training error: 0.3412153741405243\n",
            "At step: 1072 training error: 0.33444771484325186\n",
            "At step: 1073 training error: 0.34217903483439044\n",
            "At step: 1074 training error: 0.34025945685170345\n",
            "At step: 1075 training error: 0.33310942663274795\n",
            "At step: 1076 training error: 0.34087373784087804\n",
            "At step: 1077 training error: 0.340354501799594\n",
            "At step: 1078 training error: 0.3493707103880344\n",
            "At step: 1079 training error: 0.34730524574241683\n",
            "At step: 1080 training error: 0.34476419427903515\n",
            "At step: 1081 training error: 0.3304793899851409\n",
            "At step: 1082 training error: 0.3357460426978218\n",
            "At step: 1083 training error: 0.32191100143810353\n",
            "At step: 1084 training error: 0.32096545176452035\n",
            "At step: 1085 training error: 0.3261124104239802\n",
            "At step: 1086 training error: 0.3336952397488624\n",
            "At step: 1087 training error: 0.3349035919293076\n",
            "At step: 1088 training error: 0.33655834149663766\n",
            "At step: 1089 training error: 0.35055993336018093\n",
            "At step: 1090 training error: 0.34893767703541534\n",
            "At step: 1091 training error: 0.3531904291538089\n",
            "At step: 1092 training error: 0.3528953265567405\n",
            "At step: 1093 training error: 0.35528086010736515\n",
            "At step: 1094 training error: 0.36401060667173685\n",
            "At step: 1095 training error: 0.3633230188676119\n",
            "At step: 1096 training error: 0.36991732008460976\n",
            "At step: 1097 training error: 0.3652801941523945\n",
            "At step: 1098 training error: 0.3719630779860863\n",
            "At step: 1099 training error: 0.35874476771383945\n",
            "At step: 1100 training error: 0.3582179817320424\n",
            "At step: 1101 training error: 0.36156613062136134\n",
            "At step: 1102 training error: 0.3499675908982923\n",
            "At step: 1103 training error: 0.35292156971088706\n",
            "At step: 1104 training error: 0.35531794220942514\n",
            "At step: 1105 training error: 0.35604460014339934\n",
            "At step: 1106 training error: 0.3525419123084661\n",
            "At step: 1107 training error: 0.3498366653042376\n",
            "At step: 1108 training error: 0.3594992360364983\n",
            "At step: 1109 training error: 0.35978253988962416\n",
            "At step: 1110 training error: 0.3605216405079602\n",
            "At step: 1111 training error: 0.3629314557512001\n",
            "At step: 1112 training error: 0.3616871466395509\n",
            "At step: 1113 training error: 0.3545196004236612\n",
            "At step: 1114 training error: 0.3645943669284478\n",
            "At step: 1115 training error: 0.3566895805634709\n",
            "At step: 1116 training error: 0.35344932289519376\n",
            "At step: 1117 training error: 0.3548368661663444\n",
            "At step: 1118 training error: 0.3511748501762257\n",
            "At step: 1119 training error: 0.34294123249842606\n",
            "At step: 1120 training error: 0.3430839958250868\n",
            "At step: 1121 training error: 0.35139080475216644\n",
            "At step: 1122 training error: 0.3536082799005532\n",
            "At step: 1123 training error: 0.3535124991452947\n",
            "At step: 1124 training error: 0.3400442857097305\n",
            "At step: 1125 training error: 0.33587871211930365\n",
            "At step: 1126 training error: 0.3435629730598707\n",
            "At step: 1127 training error: 0.33781838718696033\n",
            "At step: 1128 training error: 0.34493566456395325\n",
            "At step: 1129 training error: 0.34665253438150745\n",
            "At step: 1130 training error: 0.341533224501683\n",
            "At step: 1131 training error: 0.3520653329190818\n",
            "At step: 1132 training error: 0.357724492985249\n",
            "At step: 1133 training error: 0.35431210900541804\n",
            "At step: 1134 training error: 0.363345137265397\n",
            "At step: 1135 training error: 0.3685498176082748\n",
            "At step: 1136 training error: 0.36894558711966985\n",
            "At step: 1137 training error: 0.3829036521772034\n",
            "At step: 1138 training error: 0.3801691882232236\n",
            "At step: 1139 training error: 0.39242943161020405\n",
            "At step: 1140 training error: 0.392640025997795\n",
            "At step: 1141 training error: 0.3962180093035364\n",
            "At step: 1142 training error: 0.39545304122496705\n",
            "At step: 1143 training error: 0.39998700595973713\n",
            "At step: 1144 training error: 0.39770532141754045\n",
            "At step: 1145 training error: 0.3941828343575282\n",
            "At step: 1146 training error: 0.37944904399024765\n",
            "At step: 1147 training error: 0.36655458627106774\n",
            "At step: 1148 training error: 0.3770562982292487\n",
            "At step: 1149 training error: 0.37418477100836417\n",
            "At step: 1150 training error: 0.37312159637597836\n",
            "At step: 1151 training error: 0.36844054561774875\n",
            "At step: 1152 training error: 0.37039139818730893\n",
            "At step: 1153 training error: 0.3688315491347771\n",
            "At step: 1154 training error: 0.35739443681519645\n",
            "At step: 1155 training error: 0.3577452154573857\n",
            "At step: 1156 training error: 0.36705551775223816\n",
            "At step: 1157 training error: 0.3610400813181339\n",
            "At step: 1158 training error: 0.35778681254783784\n",
            "At step: 1159 training error: 0.3623343453699661\n",
            "At step: 1160 training error: 0.36595603607463556\n",
            "At step: 1161 training error: 0.3597406045158835\n",
            "At step: 1162 training error: 0.3508329857262235\n",
            "At step: 1163 training error: 0.3502442485075929\n",
            "At step: 1164 training error: 0.349894121615769\n",
            "At step: 1165 training error: 0.353632700737784\n",
            "At step: 1166 training error: 0.3467230885172494\n",
            "At step: 1167 training error: 0.33581415641254686\n",
            "At step: 1168 training error: 0.3366662465127904\n",
            "At step: 1169 training error: 0.338427900392886\n",
            "At step: 1170 training error: 0.3414354912474795\n",
            "At step: 1171 training error: 0.3439661214920487\n",
            "At step: 1172 training error: 0.35861944038549876\n",
            "At step: 1173 training error: 0.35379238816647934\n",
            "At step: 1174 training error: 0.34835302380663147\n",
            "At step: 1175 training error: 0.34849000094884147\n",
            "At step: 1176 training error: 0.34868049945380364\n",
            "At step: 1177 training error: 0.34398211190759154\n",
            "At step: 1178 training error: 0.34734022950818144\n",
            "At step: 1179 training error: 0.3447465816033598\n",
            "At step: 1180 training error: 0.33772607467024157\n",
            "At step: 1181 training error: 0.33443431727597106\n",
            "At step: 1182 training error: 0.3358916935315254\n",
            "At step: 1183 training error: 0.3452431249968076\n",
            "At step: 1184 training error: 0.35451500669122726\n",
            "At step: 1185 training error: 0.36239844915891695\n",
            "At step: 1186 training error: 0.3674678875647397\n",
            "At step: 1187 training error: 0.36930628999580856\n",
            "At step: 1188 training error: 0.37852292079478994\n",
            "At step: 1189 training error: 0.3904686544557035\n",
            "At step: 1190 training error: 0.3872080191143526\n",
            "At step: 1191 training error: 0.3862613293098519\n",
            "At step: 1192 training error: 0.38676477985620783\n",
            "At step: 1193 training error: 0.38185023729794465\n",
            "At step: 1194 training error: 0.3666608580333439\n",
            "At step: 1195 training error: 0.3621501737229744\n",
            "At step: 1196 training error: 0.3598214248032756\n",
            "At step: 1197 training error: 0.35946348038416137\n",
            "At step: 1198 training error: 0.36863005420126665\n",
            "At step: 1199 training error: 0.3596642763354941\n",
            "At step: 1200 training error: 0.3616773883638745\n",
            "At step: 1201 training error: 0.3544280438573377\n",
            "At step: 1202 training error: 0.35778828134203067\n",
            "At step: 1203 training error: 0.36416939483929567\n",
            "At step: 1204 training error: 0.35430005247958285\n",
            "At step: 1205 training error: 0.3647649059457085\n",
            "At step: 1206 training error: 0.3630180839668249\n",
            "At step: 1207 training error: 0.3656086302984365\n",
            "At step: 1208 training error: 0.367300795588978\n",
            "At step: 1209 training error: 0.37063758017817183\n",
            "At step: 1210 training error: 0.3692603679230752\n",
            "At step: 1211 training error: 0.3769273035154675\n",
            "At step: 1212 training error: 0.3741715982800942\n",
            "At step: 1213 training error: 0.3751329317838116\n",
            "At step: 1214 training error: 0.37666958038882836\n",
            "At step: 1215 training error: 0.3750196509063034\n",
            "At step: 1216 training error: 0.36532578826769885\n",
            "At step: 1217 training error: 0.3613080870694658\n",
            "At step: 1218 training error: 0.3646037795566546\n",
            "At step: 1219 training error: 0.3719575858190529\n",
            "At step: 1220 training error: 0.37481648823542013\n",
            "At step: 1221 training error: 0.3743082898190505\n",
            "At step: 1222 training error: 0.36728491517001755\n",
            "At step: 1223 training error: 0.3796186879288682\n",
            "At step: 1224 training error: 0.3800335846745363\n",
            "At step: 1225 training error: 0.37995813450303045\n",
            "At step: 1226 training error: 0.38754918488192147\n",
            "At step: 1227 training error: 0.3822318401840079\n",
            "At step: 1228 training error: 0.3864507919488545\n",
            "At step: 1229 training error: 0.3758379881205359\n",
            "At step: 1230 training error: 0.37386141588352684\n",
            "At step: 1231 training error: 0.36161246056426105\n",
            "At step: 1232 training error: 0.3684949435413884\n",
            "At step: 1233 training error: 0.37351640073989745\n",
            "At step: 1234 training error: 0.36736926933803127\n",
            "At step: 1235 training error: 0.3613829687526793\n",
            "At step: 1236 training error: 0.3621058712132285\n",
            "At step: 1237 training error: 0.36132172401011503\n",
            "At step: 1238 training error: 0.3616336415815828\n",
            "At step: 1239 training error: 0.36856460193859014\n",
            "At step: 1240 training error: 0.36032017215940954\n",
            "At step: 1241 training error: 0.3651006600241358\n",
            "At step: 1242 training error: 0.3665954060059711\n",
            "At step: 1243 training error: 0.3705951169237524\n",
            "At step: 1244 training error: 0.374000289945153\n",
            "At step: 1245 training error: 0.37287620497919555\n",
            "At step: 1246 training error: 0.36640160349176737\n",
            "At step: 1247 training error: 0.3763344986033284\n",
            "At step: 1248 training error: 0.37915311911491184\n",
            "At step: 1249 training error: 0.3739339140291604\n",
            "At step: 1250 training error: 0.3729929742147902\n",
            "At step: 1251 training error: 0.38020043329460473\n",
            "At step: 1252 training error: 0.40039231307851747\n",
            "At step: 1253 training error: 0.40452511624721166\n",
            "At step: 1254 training error: 0.3951213232333087\n",
            "At step: 1255 training error: 0.40117675947393644\n",
            "At step: 1256 training error: 0.3896911079499689\n",
            "At step: 1257 training error: 0.3853073538755118\n",
            "At step: 1258 training error: 0.3784303417458814\n",
            "At step: 1259 training error: 0.38131542201643376\n",
            "At step: 1260 training error: 0.3795107173414819\n",
            "At step: 1261 training error: 0.3737476897701667\n",
            "At step: 1262 training error: 0.36568248366339695\n",
            "At step: 1263 training error: 0.3671713350951454\n",
            "At step: 1264 training error: 0.3585303389449593\n",
            "At step: 1265 training error: 0.35939832224001766\n",
            "At step: 1266 training error: 0.3620512522064358\n",
            "At step: 1267 training error: 0.36515679514210886\n",
            "At step: 1268 training error: 0.36335139651234033\n",
            "At step: 1269 training error: 0.3639582596185357\n",
            "At step: 1270 training error: 0.3646505265814878\n",
            "At step: 1271 training error: 0.36349109172102256\n",
            "At step: 1272 training error: 0.36930476949318425\n",
            "At step: 1273 training error: 0.3657497367116585\n",
            "At step: 1274 training error: 0.3705698985587945\n",
            "At step: 1275 training error: 0.3817220498898439\n",
            "At step: 1276 training error: 0.3751725608464275\n",
            "At step: 1277 training error: 0.37824752472862466\n",
            "At step: 1278 training error: 0.37079082665877655\n",
            "At step: 1279 training error: 0.37162795180628844\n",
            "At step: 1280 training error: 0.3783497247439541\n",
            "At step: 1281 training error: 0.3725397739496124\n",
            "At step: 1282 training error: 0.36331412873853836\n",
            "At step: 1283 training error: 0.3572855392568004\n",
            "At step: 1284 training error: 0.35611825413688475\n",
            "At step: 1285 training error: 0.3529423520043158\n",
            "At step: 1286 training error: 0.3441616803957064\n",
            "At step: 1287 training error: 0.3489304114397418\n",
            "At step: 1288 training error: 0.3433782698881343\n",
            "At step: 1289 training error: 0.33585335912788933\n",
            "At step: 1290 training error: 0.3506484212797376\n",
            "At step: 1291 training error: 0.3509201630960458\n",
            "At step: 1292 training error: 0.34941725051355427\n",
            "At step: 1293 training error: 0.35010924711270924\n",
            "At step: 1294 training error: 0.3616167949292735\n",
            "At step: 1295 training error: 0.3486714992377848\n",
            "At step: 1296 training error: 0.3406800928657912\n",
            "At step: 1297 training error: 0.35418559394756777\n",
            "At step: 1298 training error: 0.3717750177450534\n",
            "At step: 1299 training error: 0.3630535382041274\n",
            "At step: 1300 training error: 0.3552193446617887\n",
            "At step: 1301 training error: 0.3496660440470115\n",
            "At step: 1302 training error: 0.3521390741187333\n",
            "At step: 1303 training error: 0.3492419068918051\n",
            "At step: 1304 training error: 0.35199556292634365\n",
            "At step: 1305 training error: 0.35517403759686195\n",
            "At step: 1306 training error: 0.35762621809328266\n",
            "At step: 1307 training error: 0.349881585247054\n",
            "At step: 1308 training error: 0.3559167517181845\n",
            "At step: 1309 training error: 0.3584144906600346\n",
            "At step: 1310 training error: 0.367418152666006\n",
            "At step: 1311 training error: 0.3582380316756412\n",
            "At step: 1312 training error: 0.35636528180591615\n",
            "At step: 1313 training error: 0.34951874669417804\n",
            "At step: 1314 training error: 0.3501028404217241\n",
            "At step: 1315 training error: 0.3411268998619369\n",
            "At step: 1316 training error: 0.33488244109517373\n",
            "At step: 1317 training error: 0.3407321305434813\n",
            "At step: 1318 training error: 0.35094157000219456\n",
            "At step: 1319 training error: 0.34526962763530156\n",
            "At step: 1320 training error: 0.3486421332887659\n",
            "At step: 1321 training error: 0.34820576874221576\n",
            "At step: 1322 training error: 0.34081137072621037\n",
            "At step: 1323 training error: 0.3356049484177448\n",
            "At step: 1324 training error: 0.3422311090903871\n",
            "At step: 1325 training error: 0.34103157882235924\n",
            "At step: 1326 training error: 0.3435762175599914\n",
            "At step: 1327 training error: 0.34620538520585364\n",
            "At step: 1328 training error: 0.33171990853888145\n",
            "At step: 1329 training error: 0.3319490065716378\n",
            "At step: 1330 training error: 0.33013179344082694\n",
            "At step: 1331 training error: 0.32751031370880174\n",
            "At step: 1332 training error: 0.32663239145010525\n",
            "At step: 1333 training error: 0.3284555134012005\n",
            "At step: 1334 training error: 0.32783945257637204\n",
            "At step: 1335 training error: 0.3221515308814554\n",
            "At step: 1336 training error: 0.3170716795275447\n",
            "At step: 1337 training error: 0.3239541357803006\n",
            "At step: 1338 training error: 0.32226104327892924\n",
            "At step: 1339 training error: 0.32186322157666863\n",
            "At step: 1340 training error: 0.3172704424027721\n",
            "At step: 1341 training error: 0.3189273241429585\n",
            "At step: 1342 training error: 0.3246117236064549\n",
            "At step: 1343 training error: 0.32656044016297536\n",
            "At step: 1344 training error: 0.3303836604055046\n",
            "At step: 1345 training error: 0.33660588332851804\n",
            "At step: 1346 training error: 0.33309005584646184\n",
            "At step: 1347 training error: 0.3406297730426154\n",
            "At step: 1348 training error: 0.33955510555201457\n",
            "At step: 1349 training error: 0.3366779191433226\n",
            "At step: 1350 training error: 0.3346298234987034\n",
            "At step: 1351 training error: 0.3285776528265724\n",
            "At step: 1352 training error: 0.32787547709357645\n",
            "At step: 1353 training error: 0.3291861002482609\n",
            "At step: 1354 training error: 0.3417629632434928\n",
            "At step: 1355 training error: 0.3311485051999807\n",
            "At step: 1356 training error: 0.3362560830146207\n",
            "At step: 1357 training error: 0.34487530104231356\n",
            "At step: 1358 training error: 0.3396467852262462\n",
            "At step: 1359 training error: 0.3315959689940424\n",
            "At step: 1360 training error: 0.32507710431402304\n",
            "At step: 1361 training error: 0.31575905981083247\n",
            "At step: 1362 training error: 0.3269183740959063\n",
            "At step: 1363 training error: 0.3400832607478008\n",
            "At step: 1364 training error: 0.34197521589675844\n",
            "At step: 1365 training error: 0.33711670344779116\n",
            "At step: 1366 training error: 0.3400986557111843\n",
            "At step: 1367 training error: 0.3367835325186112\n",
            "At step: 1368 training error: 0.3386289617411255\n",
            "At step: 1369 training error: 0.3384926311492349\n",
            "At step: 1370 training error: 0.32925243110196045\n",
            "At step: 1371 training error: 0.33464977277014807\n",
            "At step: 1372 training error: 0.3381994010584309\n",
            "At step: 1373 training error: 0.33934148529864006\n",
            "At step: 1374 training error: 0.3442325019375193\n",
            "At step: 1375 training error: 0.3436376520372375\n",
            "At step: 1376 training error: 0.3346407335786745\n",
            "At step: 1377 training error: 0.33319910494645943\n",
            "At step: 1378 training error: 0.32596129662806755\n",
            "At step: 1379 training error: 0.32447202556088567\n",
            "At step: 1380 training error: 0.327632900375323\n",
            "At step: 1381 training error: 0.3194476476581163\n",
            "At step: 1382 training error: 0.3236255002980371\n",
            "At step: 1383 training error: 0.31653614674429853\n",
            "At step: 1384 training error: 0.30735309256101184\n",
            "At step: 1385 training error: 0.31094344605941443\n",
            "At step: 1386 training error: 0.3237563604573771\n",
            "At step: 1387 training error: 0.3237850048019433\n",
            "At step: 1388 training error: 0.33113823873927206\n",
            "At step: 1389 training error: 0.32689194714294406\n",
            "At step: 1390 training error: 0.3177236790832311\n",
            "At step: 1391 training error: 0.3173222084730259\n",
            "At step: 1392 training error: 0.3231763250148991\n",
            "At step: 1393 training error: 0.33279393249795647\n",
            "At step: 1394 training error: 0.3430769880880643\n",
            "At step: 1395 training error: 0.34625316445039694\n",
            "At step: 1396 training error: 0.3482509811250182\n",
            "At step: 1397 training error: 0.35278730545037185\n",
            "At step: 1398 training error: 0.34802041174901993\n",
            "At step: 1399 training error: 0.35694218695612007\n",
            "At step: 1400 training error: 0.34712107238174045\n",
            "At step: 1401 training error: 0.35231578932575114\n",
            "At step: 1402 training error: 0.3611953297885594\n",
            "At step: 1403 training error: 0.35232359423596504\n",
            "At step: 1404 training error: 0.34711571169857147\n",
            "At step: 1405 training error: 0.34948141685208806\n",
            "At step: 1406 training error: 0.3423650631969512\n",
            "At step: 1407 training error: 0.33511262645261114\n",
            "At step: 1408 training error: 0.3376455253219568\n",
            "At step: 1409 training error: 0.32665766683655123\n",
            "At step: 1410 training error: 0.32732371185553777\n",
            "At step: 1411 training error: 0.3432109669027438\n",
            "At step: 1412 training error: 0.3432806342138637\n",
            "At step: 1413 training error: 0.34691842066481304\n",
            "At step: 1414 training error: 0.3485230911320938\n",
            "At step: 1415 training error: 0.34447797027955707\n",
            "At step: 1416 training error: 0.34477988497716433\n",
            "At step: 1417 training error: 0.33768983072754366\n",
            "At step: 1418 training error: 0.3291108579173535\n",
            "At step: 1419 training error: 0.3270429739467898\n",
            "At step: 1420 training error: 0.339038976977281\n",
            "At step: 1421 training error: 0.34500444001578057\n",
            "At step: 1422 training error: 0.3541785752203304\n",
            "At step: 1423 training error: 0.3473047301917319\n",
            "At step: 1424 training error: 0.3474539328689498\n",
            "At step: 1425 training error: 0.351006979869541\n",
            "At step: 1426 training error: 0.3565376386075052\n",
            "At step: 1427 training error: 0.35095682343724105\n",
            "At step: 1428 training error: 0.3487392567215941\n",
            "At step: 1429 training error: 0.3394308912349704\n",
            "At step: 1430 training error: 0.34002090205589797\n",
            "At step: 1431 training error: 0.33815235258077075\n",
            "At step: 1432 training error: 0.3352577793894007\n",
            "At step: 1433 training error: 0.3364374098808404\n",
            "At step: 1434 training error: 0.3371427120686783\n",
            "At step: 1435 training error: 0.33863266775310025\n",
            "At step: 1436 training error: 0.3365694689218395\n",
            "At step: 1437 training error: 0.3436925617937829\n",
            "At step: 1438 training error: 0.3469964699256108\n",
            "At step: 1439 training error: 0.35151250504860826\n",
            "At step: 1440 training error: 0.345539609790397\n",
            "At step: 1441 training error: 0.341149535312621\n",
            "At step: 1442 training error: 0.34725070591451535\n",
            "At step: 1443 training error: 0.3407167634985421\n",
            "At step: 1444 training error: 0.3368102947359774\n",
            "At step: 1445 training error: 0.34377294699732797\n",
            "At step: 1446 training error: 0.33902146694098195\n",
            "At step: 1447 training error: 0.33122174706127594\n",
            "At step: 1448 training error: 0.3236594542007007\n",
            "At step: 1449 training error: 0.3329820552242474\n",
            "At step: 1450 training error: 0.33613989497549923\n",
            "At step: 1451 training error: 0.3415905478446212\n",
            "At step: 1452 training error: 0.3371727835259724\n",
            "At step: 1453 training error: 0.33956111981987736\n",
            "At step: 1454 training error: 0.33991956193593126\n",
            "At step: 1455 training error: 0.3370791218688973\n",
            "At step: 1456 training error: 0.33425230546736323\n",
            "At step: 1457 training error: 0.33558859476150443\n",
            "At step: 1458 training error: 0.33141602634293155\n",
            "At step: 1459 training error: 0.34444248985200254\n",
            "At step: 1460 training error: 0.3467924461382576\n",
            "At step: 1461 training error: 0.342316123567808\n",
            "At step: 1462 training error: 0.3451328368976985\n",
            "At step: 1463 training error: 0.3454951351088527\n",
            "At step: 1464 training error: 0.3448591372424106\n",
            "At step: 1465 training error: 0.35091274505413783\n",
            "At step: 1466 training error: 0.35643309569217196\n",
            "At step: 1467 training error: 0.3550642818337524\n",
            "At step: 1468 training error: 0.3557655872154657\n",
            "At step: 1469 training error: 0.34497598459474466\n",
            "At step: 1470 training error: 0.3550171934849928\n",
            "At step: 1471 training error: 0.35321678188696937\n",
            "At step: 1472 training error: 0.3622324604204716\n",
            "At step: 1473 training error: 0.3497348988664303\n",
            "At step: 1474 training error: 0.3523344059155452\n",
            "At step: 1475 training error: 0.3674920712875719\n",
            "At step: 1476 training error: 0.3724303474547597\n",
            "At step: 1477 training error: 0.37593615496168864\n",
            "At step: 1478 training error: 0.3637608952901145\n",
            "At step: 1479 training error: 0.35858137404346463\n",
            "At step: 1480 training error: 0.360830287653051\n",
            "At step: 1481 training error: 0.35985597683077797\n",
            "At step: 1482 training error: 0.3558827369351517\n",
            "At step: 1483 training error: 0.3520068570406045\n",
            "At step: 1484 training error: 0.35613368234981513\n",
            "At step: 1485 training error: 0.3580080656480987\n",
            "At step: 1486 training error: 0.3598179233573917\n",
            "At step: 1487 training error: 0.361451483659325\n",
            "At step: 1488 training error: 0.3625930835703064\n",
            "At step: 1489 training error: 0.3608898351975515\n",
            "At step: 1490 training error: 0.3670164221032006\n",
            "At step: 1491 training error: 0.3714774186580568\n",
            "At step: 1492 training error: 0.37117978882240127\n",
            "At step: 1493 training error: 0.3666476401305163\n",
            "At step: 1494 training error: 0.35623133926105915\n",
            "At step: 1495 training error: 0.34424130690265115\n",
            "At step: 1496 training error: 0.3394722736058142\n",
            "At step: 1497 training error: 0.3298127326109549\n",
            "At step: 1498 training error: 0.32924410390172426\n",
            "At step: 1499 training error: 0.3236454688719902\n",
            "At step: 1500 training error: 0.33334510967777586\n",
            "At step: 1501 training error: 0.3331109518693152\n",
            "At step: 1502 training error: 0.3364207918822834\n",
            "At step: 1503 training error: 0.3396803640852788\n",
            "At step: 1504 training error: 0.3411310644782989\n",
            "At step: 1505 training error: 0.33587089125115904\n",
            "At step: 1506 training error: 0.3372162756316485\n",
            "At step: 1507 training error: 0.34591007986903793\n",
            "At step: 1508 training error: 0.34198519835340035\n",
            "At step: 1509 training error: 0.35642627924092757\n",
            "At step: 1510 training error: 0.34831309803767047\n",
            "At step: 1511 training error: 0.3404448025922618\n",
            "At step: 1512 training error: 0.34418474651111\n",
            "At step: 1513 training error: 0.3460617573031202\n",
            "At step: 1514 training error: 0.3410689452653333\n",
            "At step: 1515 training error: 0.3414103505318085\n",
            "At step: 1516 training error: 0.33873122881755063\n",
            "At step: 1517 training error: 0.3349274993399663\n",
            "At step: 1518 training error: 0.335994636743942\n",
            "At step: 1519 training error: 0.33099744006701987\n",
            "At step: 1520 training error: 0.3314035898056854\n",
            "At step: 1521 training error: 0.3380899588582614\n",
            "At step: 1522 training error: 0.34386745079685715\n",
            "At step: 1523 training error: 0.341302142580898\n",
            "At step: 1524 training error: 0.3489431725363966\n",
            "At step: 1525 training error: 0.34489678342473784\n",
            "At step: 1526 training error: 0.3501396835995716\n",
            "At step: 1527 training error: 0.3607838207136219\n",
            "At step: 1528 training error: 0.3560210445341186\n",
            "At step: 1529 training error: 0.3662611910494056\n",
            "At step: 1530 training error: 0.37280973209874546\n",
            "At step: 1531 training error: 0.3852455085490886\n",
            "At step: 1532 training error: 0.3937046251222541\n",
            "At step: 1533 training error: 0.38024900242435167\n",
            "At step: 1534 training error: 0.3949266082940913\n",
            "At step: 1535 training error: 0.3851381636998549\n",
            "At step: 1536 training error: 0.3958250427125281\n",
            "At step: 1537 training error: 0.39158802619554656\n",
            "At step: 1538 training error: 0.3905518473737715\n",
            "At step: 1539 training error: 0.38564287766994626\n",
            "At step: 1540 training error: 0.3971129422255357\n",
            "At step: 1541 training error: 0.3978432353037449\n",
            "At step: 1542 training error: 0.400960292194641\n",
            "At step: 1543 training error: 0.3934868569640343\n",
            "At step: 1544 training error: 0.3947312569935274\n",
            "At step: 1545 training error: 0.38895374709313457\n",
            "At step: 1546 training error: 0.37744610259514294\n",
            "At step: 1547 training error: 0.3705930392575708\n",
            "At step: 1548 training error: 0.3652410097748159\n",
            "At step: 1549 training error: 0.378014733327475\n",
            "At step: 1550 training error: 0.38006957989743084\n",
            "At step: 1551 training error: 0.38809285048023845\n",
            "At step: 1552 training error: 0.3990035346608752\n",
            "At step: 1553 training error: 0.38307082344593857\n",
            "At step: 1554 training error: 0.374075704398068\n",
            "At step: 1555 training error: 0.36719269065910765\n",
            "At step: 1556 training error: 0.3613422432528859\n",
            "At step: 1557 training error: 0.36660566933031563\n",
            "At step: 1558 training error: 0.355519866720927\n",
            "At step: 1559 training error: 0.3616483927653693\n",
            "At step: 1560 training error: 0.35260108271288476\n",
            "At step: 1561 training error: 0.351616375604388\n",
            "At step: 1562 training error: 0.3574294538095084\n",
            "At step: 1563 training error: 0.36226228474602185\n",
            "At step: 1564 training error: 0.3472505355616816\n",
            "At step: 1565 training error: 0.3642278392174358\n",
            "At step: 1566 training error: 0.36618622287945135\n",
            "At step: 1567 training error: 0.3566104854961935\n",
            "At step: 1568 training error: 0.3653384514030901\n",
            "At step: 1569 training error: 0.3667776998242047\n",
            "At step: 1570 training error: 0.35370283124030033\n",
            "At step: 1571 training error: 0.34167100939119194\n",
            "At step: 1572 training error: 0.34091468936138564\n",
            "At step: 1573 training error: 0.3485862099385473\n",
            "At step: 1574 training error: 0.36218736332371443\n",
            "At step: 1575 training error: 0.3549658748161977\n",
            "At step: 1576 training error: 0.3660822232032413\n",
            "At step: 1577 training error: 0.364442431002714\n",
            "At step: 1578 training error: 0.3663230021401225\n",
            "At step: 1579 training error: 0.35788840980780307\n",
            "At step: 1580 training error: 0.358552958006657\n",
            "At step: 1581 training error: 0.35990112133408614\n",
            "At step: 1582 training error: 0.35343011948349173\n",
            "At step: 1583 training error: 0.3579509542439761\n",
            "At step: 1584 training error: 0.3670829477399821\n",
            "At step: 1585 training error: 0.3604734692836584\n",
            "At step: 1586 training error: 0.3644375573614827\n",
            "At step: 1587 training error: 0.3579903664608931\n",
            "At step: 1588 training error: 0.36135823479248386\n",
            "At step: 1589 training error: 0.35026392110531157\n",
            "At step: 1590 training error: 0.3652666212420166\n",
            "At step: 1591 training error: 0.3748329879143311\n",
            "At step: 1592 training error: 0.37311362607634774\n",
            "At step: 1593 training error: 0.3688854370704806\n",
            "At step: 1594 training error: 0.36712821406462465\n",
            "At step: 1595 training error: 0.3597683191598193\n",
            "At step: 1596 training error: 0.35311718257659097\n",
            "At step: 1597 training error: 0.34886907748433593\n",
            "At step: 1598 training error: 0.3542588615602786\n",
            "At step: 1599 training error: 0.3579534241281288\n",
            "At step: 1600 training error: 0.3603866371555315\n",
            "At step: 1601 training error: 0.35832060408719063\n",
            "At step: 1602 training error: 0.355369010586285\n",
            "At step: 1603 training error: 0.33951513977672104\n",
            "At step: 1604 training error: 0.3333844004260168\n",
            "At step: 1605 training error: 0.3362010320417552\n",
            "At step: 1606 training error: 0.33778118536741947\n",
            "At step: 1607 training error: 0.34128408811550226\n",
            "At step: 1608 training error: 0.33394089011457107\n",
            "At step: 1609 training error: 0.3410569471537432\n",
            "At step: 1610 training error: 0.33640941161324844\n",
            "At step: 1611 training error: 0.3272063566798573\n",
            "At step: 1612 training error: 0.3176091143920079\n",
            "At step: 1613 training error: 0.3345295398781938\n",
            "At step: 1614 training error: 0.338947328886423\n",
            "At step: 1615 training error: 0.3372189325918614\n",
            "At step: 1616 training error: 0.3378333393917177\n",
            "At step: 1617 training error: 0.333828016196035\n",
            "At step: 1618 training error: 0.340238072936764\n",
            "At step: 1619 training error: 0.3466497699087023\n",
            "At step: 1620 training error: 0.3487307378499062\n",
            "At step: 1621 training error: 0.3468285286173673\n",
            "At step: 1622 training error: 0.36181860786373476\n",
            "At step: 1623 training error: 0.36109053243048095\n",
            "At step: 1624 training error: 0.34968777742456175\n",
            "At step: 1625 training error: 0.3417216864498495\n",
            "At step: 1626 training error: 0.33859894355142667\n",
            "At step: 1627 training error: 0.3426899975463026\n",
            "At step: 1628 training error: 0.3508271175192763\n",
            "At step: 1629 training error: 0.34776431857608675\n",
            "At step: 1630 training error: 0.35944143767360476\n",
            "At step: 1631 training error: 0.35776829785737285\n",
            "At step: 1632 training error: 0.3541068447606074\n",
            "At step: 1633 training error: 0.3606440983600384\n",
            "At step: 1634 training error: 0.3558764215013758\n",
            "At step: 1635 training error: 0.36835854640797444\n",
            "At step: 1636 training error: 0.3616185723683992\n",
            "At step: 1637 training error: 0.3522931028820426\n",
            "At step: 1638 training error: 0.3606669577953557\n",
            "At step: 1639 training error: 0.3573507428366857\n",
            "At step: 1640 training error: 0.3558275995908\n",
            "At step: 1641 training error: 0.36171117402931713\n",
            "At step: 1642 training error: 0.3527697155581696\n",
            "At step: 1643 training error: 0.34645700201733143\n",
            "At step: 1644 training error: 0.3482581670943577\n",
            "At step: 1645 training error: 0.34235715730187566\n",
            "At step: 1646 training error: 0.33562178063281195\n",
            "At step: 1647 training error: 0.32259700315509654\n",
            "At step: 1648 training error: 0.3231895067905542\n",
            "At step: 1649 training error: 0.32908414757639387\n",
            "At step: 1650 training error: 0.33275930733706083\n",
            "At step: 1651 training error: 0.3320480395876773\n",
            "At step: 1652 training error: 0.3310599023060758\n",
            "At step: 1653 training error: 0.3252343759539535\n",
            "At step: 1654 training error: 0.33053729736559184\n",
            "At step: 1655 training error: 0.35048080218336586\n",
            "At step: 1656 training error: 0.34382044207365303\n",
            "At step: 1657 training error: 0.33737888927376386\n",
            "At step: 1658 training error: 0.3358985577580537\n",
            "At step: 1659 training error: 0.3379971332387147\n",
            "At step: 1660 training error: 0.34586162522468283\n",
            "At step: 1661 training error: 0.35388470326412136\n",
            "At step: 1662 training error: 0.3544273919031815\n",
            "At step: 1663 training error: 0.3429673660845185\n",
            "At step: 1664 training error: 0.33704834002803846\n",
            "At step: 1665 training error: 0.33922116646502426\n",
            "At step: 1666 training error: 0.34628681142224765\n",
            "At step: 1667 training error: 0.3387958949931789\n",
            "At step: 1668 training error: 0.3360789440737649\n",
            "At step: 1669 training error: 0.33666545557867156\n",
            "At step: 1670 training error: 0.33822356111378327\n",
            "At step: 1671 training error: 0.3349295869556375\n",
            "At step: 1672 training error: 0.34708886907096304\n",
            "At step: 1673 training error: 0.3463048056439889\n",
            "At step: 1674 training error: 0.3515234886437182\n",
            "At step: 1675 training error: 0.35143783366615716\n",
            "At step: 1676 training error: 0.3470404085983992\n",
            "At step: 1677 training error: 0.3473306831082687\n",
            "At step: 1678 training error: 0.34519017699259474\n",
            "At step: 1679 training error: 0.3445298740999453\n",
            "At step: 1680 training error: 0.34688345604734766\n",
            "At step: 1681 training error: 0.3431608213466287\n",
            "At step: 1682 training error: 0.35380160197328436\n",
            "At step: 1683 training error: 0.3540362073578286\n",
            "At step: 1684 training error: 0.34142559309974\n",
            "At step: 1685 training error: 0.3350825871712024\n",
            "At step: 1686 training error: 0.32698934480966935\n",
            "At step: 1687 training error: 0.3308047906185577\n",
            "At step: 1688 training error: 0.3405641789869435\n",
            "At step: 1689 training error: 0.34030068574648303\n",
            "At step: 1690 training error: 0.3459438199345976\n",
            "At step: 1691 training error: 0.3365464615027894\n",
            "At step: 1692 training error: 0.3275338903933697\n",
            "At step: 1693 training error: 0.3288517505570775\n",
            "At step: 1694 training error: 0.3281263438359434\n",
            "At step: 1695 training error: 0.3319208236255768\n",
            "At step: 1696 training error: 0.32794413325485283\n",
            "At step: 1697 training error: 0.3276975616924266\n",
            "At step: 1698 training error: 0.3345657691864624\n",
            "At step: 1699 training error: 0.33675482203717916\n",
            "At step: 1700 training error: 0.3207629250862996\n",
            "At step: 1701 training error: 0.32364099233423405\n",
            "At step: 1702 training error: 0.32321849891196824\n",
            "At step: 1703 training error: 0.32678703535861403\n",
            "At step: 1704 training error: 0.3272318660619768\n",
            "At step: 1705 training error: 0.3305804916782602\n",
            "At step: 1706 training error: 0.32329867040916704\n",
            "At step: 1707 training error: 0.34839462660904785\n",
            "At step: 1708 training error: 0.3615236772508966\n",
            "At step: 1709 training error: 0.364949093435499\n",
            "At step: 1710 training error: 0.36291620141749636\n",
            "At step: 1711 training error: 0.35623121681657827\n",
            "At step: 1712 training error: 0.3503827396463115\n",
            "At step: 1713 training error: 0.3553478322084208\n",
            "At step: 1714 training error: 0.36106635309555124\n",
            "At step: 1715 training error: 0.3579762865602104\n",
            "At step: 1716 training error: 0.36064647755207413\n",
            "At step: 1717 training error: 0.3475506132719307\n",
            "At step: 1718 training error: 0.3425793994242218\n",
            "At step: 1719 training error: 0.3434011886732331\n",
            "At step: 1720 training error: 0.3409306468923982\n",
            "At step: 1721 training error: 0.3376311195089114\n",
            "At step: 1722 training error: 0.33290680289641655\n",
            "At step: 1723 training error: 0.32983685778913835\n",
            "At step: 1724 training error: 0.3351647975185317\n",
            "At step: 1725 training error: 0.3294014204603242\n",
            "At step: 1726 training error: 0.3389422629695407\n",
            "At step: 1727 training error: 0.33278902617491257\n",
            "At step: 1728 training error: 0.32585040735785076\n",
            "At step: 1729 training error: 0.3318777540912557\n",
            "At step: 1730 training error: 0.34034441212245264\n",
            "At step: 1731 training error: 0.3381085322863414\n",
            "At step: 1732 training error: 0.3422383396109369\n",
            "At step: 1733 training error: 0.3417730502123984\n",
            "At step: 1734 training error: 0.34324788114001964\n",
            "At step: 1735 training error: 0.3403675138433842\n",
            "At step: 1736 training error: 0.3388179127565401\n",
            "At step: 1737 training error: 0.33749281485714483\n",
            "At step: 1738 training error: 0.3431732253828891\n",
            "At step: 1739 training error: 0.357465128545206\n",
            "At step: 1740 training error: 0.3736627702060407\n",
            "At step: 1741 training error: 0.3766916010435868\n",
            "At step: 1742 training error: 0.3681605094489799\n",
            "At step: 1743 training error: 0.36661859159351007\n",
            "At step: 1744 training error: 0.36746412844120996\n",
            "At step: 1745 training error: 0.3641372586085047\n",
            "At step: 1746 training error: 0.3580294382379709\n",
            "At step: 1747 training error: 0.35371195478931544\n",
            "At step: 1748 training error: 0.35208505167673537\n",
            "At step: 1749 training error: 0.36872468657451846\n",
            "At step: 1750 training error: 0.36383051168368\n",
            "At step: 1751 training error: 0.3670614428080353\n",
            "At step: 1752 training error: 0.37634454345364554\n",
            "At step: 1753 training error: 0.37460344829778996\n",
            "At step: 1754 training error: 0.37701548834820126\n",
            "At step: 1755 training error: 0.38129295874628555\n",
            "At step: 1756 training error: 0.38856315041087625\n",
            "At step: 1757 training error: 0.399934220355073\n",
            "At step: 1758 training error: 0.38494574739160087\n",
            "At step: 1759 training error: 0.37691540058274137\n",
            "At step: 1760 training error: 0.3786239603877276\n",
            "At step: 1761 training error: 0.35967472002628553\n",
            "At step: 1762 training error: 0.35512405540274267\n",
            "At step: 1763 training error: 0.35420567472609404\n",
            "At step: 1764 training error: 0.36043474249636176\n",
            "At step: 1765 training error: 0.3554805094084827\n",
            "At step: 1766 training error: 0.3668179649834298\n",
            "At step: 1767 training error: 0.3750671679926764\n",
            "At step: 1768 training error: 0.36919367000839204\n",
            "At step: 1769 training error: 0.3682995850251846\n",
            "At step: 1770 training error: 0.36668891210335075\n",
            "At step: 1771 training error: 0.36734734667831387\n",
            "At step: 1772 training error: 0.3686693212967443\n",
            "At step: 1773 training error: 0.359883456937507\n",
            "At step: 1774 training error: 0.3543287760319961\n",
            "At step: 1775 training error: 0.34391642738203587\n",
            "At step: 1776 training error: 0.35273544391100975\n",
            "At step: 1777 training error: 0.3488418756072469\n",
            "At step: 1778 training error: 0.36184436834297573\n",
            "At step: 1779 training error: 0.3720132497107368\n",
            "At step: 1780 training error: 0.3711191322297681\n",
            "At step: 1781 training error: 0.3639166662317417\n",
            "At step: 1782 training error: 0.3555263471907234\n",
            "At step: 1783 training error: 0.3532191764644983\n",
            "At step: 1784 training error: 0.34982269463245785\n",
            "At step: 1785 training error: 0.3542613916152171\n",
            "At step: 1786 training error: 0.35894691092253345\n",
            "At step: 1787 training error: 0.35532538579595957\n",
            "At step: 1788 training error: 0.3416038182284811\n",
            "At step: 1789 training error: 0.3344795541401665\n",
            "At step: 1790 training error: 0.3307876140166737\n",
            "At step: 1791 training error: 0.3304543272484903\n",
            "At step: 1792 training error: 0.3577404790855173\n",
            "At step: 1793 training error: 0.3458302055066393\n",
            "At step: 1794 training error: 0.35485992654852827\n",
            "At step: 1795 training error: 0.35353278397112403\n",
            "At step: 1796 training error: 0.35013182661816616\n",
            "At step: 1797 training error: 0.34498960385268185\n",
            "At step: 1798 training error: 0.3440118486904625\n",
            "At step: 1799 training error: 0.34342300641388557\n",
            "At step: 1800 training error: 0.34204576136664483\n",
            "At step: 1801 training error: 0.3516069825115641\n",
            "At step: 1802 training error: 0.35808813168349385\n",
            "At step: 1803 training error: 0.35318953259958114\n",
            "At step: 1804 training error: 0.3534044515572899\n",
            "At step: 1805 training error: 0.3506101483032502\n",
            "At step: 1806 training error: 0.3580048289638211\n",
            "At step: 1807 training error: 0.3566933885208068\n",
            "At step: 1808 training error: 0.34125707700260693\n",
            "At step: 1809 training error: 0.3601153908104192\n",
            "At step: 1810 training error: 0.3706212065251435\n",
            "At step: 1811 training error: 0.36448500200030337\n",
            "At step: 1812 training error: 0.35982739057378144\n",
            "At step: 1813 training error: 0.3516876406700836\n",
            "At step: 1814 training error: 0.3476086566274711\n",
            "At step: 1815 training error: 0.3637221816900862\n",
            "At step: 1816 training error: 0.354156939404913\n",
            "At step: 1817 training error: 0.3548615254333167\n",
            "At step: 1818 training error: 0.3485736779408946\n",
            "At step: 1819 training error: 0.34418610892692364\n",
            "At step: 1820 training error: 0.3444124301811846\n",
            "At step: 1821 training error: 0.3496203239592276\n",
            "At step: 1822 training error: 0.35083819521186954\n",
            "At step: 1823 training error: 0.35097338474186757\n",
            "At step: 1824 training error: 0.35458958588178424\n",
            "At step: 1825 training error: 0.3655897673101935\n",
            "At step: 1826 training error: 0.36457914357024546\n",
            "At step: 1827 training error: 0.3574955879418554\n",
            "At step: 1828 training error: 0.3639741855082134\n",
            "At step: 1829 training error: 0.36258990536216856\n",
            "At step: 1830 training error: 0.36906310548478144\n",
            "At step: 1831 training error: 0.3583317287539174\n",
            "At step: 1832 training error: 0.3567173603885\n",
            "At step: 1833 training error: 0.3616914401488573\n",
            "At step: 1834 training error: 0.35767273501764246\n",
            "At step: 1835 training error: 0.36159538346715564\n",
            "At step: 1836 training error: 0.363798833415853\n",
            "At step: 1837 training error: 0.3627100990929503\n",
            "At step: 1838 training error: 0.3662564274849607\n",
            "At step: 1839 training error: 0.36635684510228056\n",
            "At step: 1840 training error: 0.3586419450781144\n",
            "At step: 1841 training error: 0.35096125731773165\n",
            "At step: 1842 training error: 0.3460413629166937\n",
            "At step: 1843 training error: 0.3415594235522096\n",
            "At step: 1844 training error: 0.3283556152663535\n",
            "At step: 1845 training error: 0.32972045518866444\n",
            "At step: 1846 training error: 0.34194384744275774\n",
            "At step: 1847 training error: 0.3496953622791352\n",
            "At step: 1848 training error: 0.33607338245090324\n",
            "At step: 1849 training error: 0.32834135231092737\n",
            "At step: 1850 training error: 0.31734081805185377\n",
            "At step: 1851 training error: 0.3205307318852554\n",
            "At step: 1852 training error: 0.31628446522205494\n",
            "At step: 1853 training error: 0.31799450126917184\n",
            "At step: 1854 training error: 0.3141152765417443\n",
            "At step: 1855 training error: 0.3282301644031217\n",
            "At step: 1856 training error: 0.3256521687745651\n",
            "At step: 1857 training error: 0.31752723117927095\n",
            "At step: 1858 training error: 0.3154373570065079\n",
            "At step: 1859 training error: 0.31264592456850404\n",
            "At step: 1860 training error: 0.3073500488154522\n",
            "At step: 1861 training error: 0.31109609591612775\n",
            "At step: 1862 training error: 0.3137943287515554\n",
            "At step: 1863 training error: 0.3108561636663601\n",
            "At step: 1864 training error: 0.312913548863852\n",
            "At step: 1865 training error: 0.3066362191182487\n",
            "At step: 1866 training error: 0.30957057525661413\n",
            "At step: 1867 training error: 0.3150127794801146\n",
            "At step: 1868 training error: 0.3132620846596308\n",
            "At step: 1869 training error: 0.3153494107390039\n",
            "At step: 1870 training error: 0.3191380503443628\n",
            "At step: 1871 training error: 0.32456717926540657\n",
            "At step: 1872 training error: 0.32975259393208217\n",
            "At step: 1873 training error: 0.3318481709052121\n",
            "At step: 1874 training error: 0.325797375676051\n",
            "At step: 1875 training error: 0.31770130930645707\n",
            "At step: 1876 training error: 0.3142447386018292\n",
            "At step: 1877 training error: 0.31979977604631055\n",
            "At step: 1878 training error: 0.33739222237420086\n",
            "At step: 1879 training error: 0.34239712093245944\n",
            "At step: 1880 training error: 0.33791643363821194\n",
            "At step: 1881 training error: 0.33965847685726525\n",
            "At step: 1882 training error: 0.33608153962301457\n",
            "At step: 1883 training error: 0.334058669981709\n",
            "At step: 1884 training error: 0.342017491219939\n",
            "At step: 1885 training error: 0.3401654093230795\n",
            "At step: 1886 training error: 0.33192735396385736\n",
            "At step: 1887 training error: 0.34709780423456393\n",
            "At step: 1888 training error: 0.3423358433417869\n",
            "At step: 1889 training error: 0.3400974336231868\n",
            "At step: 1890 training error: 0.3279885361318847\n",
            "At step: 1891 training error: 0.3295692848440005\n",
            "At step: 1892 training error: 0.3353838902218898\n",
            "At step: 1893 training error: 0.3319620173241121\n",
            "At step: 1894 training error: 0.3228646523655691\n",
            "At step: 1895 training error: 0.3277392588514626\n",
            "At step: 1896 training error: 0.336889580102111\n",
            "At step: 1897 training error: 0.32507618270370414\n",
            "At step: 1898 training error: 0.3302337021341551\n",
            "At step: 1899 training error: 0.3234729013340577\n",
            "At step: 1900 training error: 0.3239399125895516\n",
            "At step: 1901 training error: 0.3215918696922723\n",
            "At step: 1902 training error: 0.3193022287679588\n",
            "At step: 1903 training error: 0.32728434796245603\n",
            "At step: 1904 training error: 0.33675034346812105\n",
            "At step: 1905 training error: 0.32620394267551955\n",
            "At step: 1906 training error: 0.3322349550133216\n",
            "At step: 1907 training error: 0.3458874229946694\n",
            "At step: 1908 training error: 0.3534045572767405\n",
            "At step: 1909 training error: 0.3512606757765176\n",
            "At step: 1910 training error: 0.3615706283354791\n",
            "At step: 1911 training error: 0.3675490883156113\n",
            "At step: 1912 training error: 0.36530539894757447\n",
            "At step: 1913 training error: 0.36564971386552847\n",
            "At step: 1914 training error: 0.3762084706373689\n",
            "At step: 1915 training error: 0.36472726003483846\n",
            "At step: 1916 training error: 0.35936024677604916\n",
            "At step: 1917 training error: 0.35145451392851645\n",
            "At step: 1918 training error: 0.3524721591338708\n",
            "At step: 1919 training error: 0.351398950444238\n",
            "At step: 1920 training error: 0.3487298139807686\n",
            "At step: 1921 training error: 0.34309706794071165\n",
            "At step: 1922 training error: 0.35360373344270035\n",
            "At step: 1923 training error: 0.3515617635356839\n",
            "At step: 1924 training error: 0.34799398824804073\n",
            "At step: 1925 training error: 0.33986704614412766\n",
            "At step: 1926 training error: 0.3481653234910358\n",
            "At step: 1927 training error: 0.34463847328284686\n",
            "At step: 1928 training error: 0.35252954356189725\n",
            "At step: 1929 training error: 0.36012273699333364\n",
            "At step: 1930 training error: 0.3687908148658582\n",
            "At step: 1931 training error: 0.35804313316832226\n",
            "At step: 1932 training error: 0.3473580002364004\n",
            "At step: 1933 training error: 0.3541334529439079\n",
            "At step: 1934 training error: 0.3597402918280952\n",
            "At step: 1935 training error: 0.3694555639054545\n",
            "At step: 1936 training error: 0.3725344618548603\n",
            "At step: 1937 training error: 0.37478149948540773\n",
            "At step: 1938 training error: 0.3600778766040947\n",
            "At step: 1939 training error: 0.35447224586601017\n",
            "At step: 1940 training error: 0.3531059619801779\n",
            "At step: 1941 training error: 0.3441533175479681\n",
            "At step: 1942 training error: 0.34711463280293847\n",
            "At step: 1943 training error: 0.3458039284882485\n",
            "At step: 1944 training error: 0.34470586710084283\n",
            "At step: 1945 training error: 0.3443654627100129\n",
            "At step: 1946 training error: 0.3401085461723427\n",
            "At step: 1947 training error: 0.3434642101305618\n",
            "At step: 1948 training error: 0.3436003354630003\n",
            "At step: 1949 training error: 0.3428774305808181\n",
            "At step: 1950 training error: 0.34365705152138976\n",
            "At step: 1951 training error: 0.34510600921220214\n",
            "At step: 1952 training error: 0.34073172845541105\n",
            "At step: 1953 training error: 0.3434537349676106\n",
            "At step: 1954 training error: 0.34829351715211876\n",
            "At step: 1955 training error: 0.3619294512711336\n",
            "At step: 1956 training error: 0.3787161193359665\n",
            "At step: 1957 training error: 0.37882106878095817\n",
            "At step: 1958 training error: 0.38224640244870245\n",
            "At step: 1959 training error: 0.37446928417886566\n",
            "At step: 1960 training error: 0.3758924278299574\n",
            "At step: 1961 training error: 0.3720716863125519\n",
            "At step: 1962 training error: 0.3598678523997791\n",
            "At step: 1963 training error: 0.3529285673258721\n",
            "At step: 1964 training error: 0.3520888305555132\n",
            "At step: 1965 training error: 0.34665640294329275\n",
            "At step: 1966 training error: 0.3380429985541706\n",
            "At step: 1967 training error: 0.3402305619024752\n",
            "At step: 1968 training error: 0.3304362588026667\n",
            "At step: 1969 training error: 0.32824517933488073\n",
            "At step: 1970 training error: 0.32910493690420395\n",
            "At step: 1971 training error: 0.31731114092910623\n",
            "At step: 1972 training error: 0.3167839935347549\n",
            "At step: 1973 training error: 0.31204331305954747\n",
            "At step: 1974 training error: 0.319537131051514\n",
            "At step: 1975 training error: 0.31594696407354245\n",
            "At step: 1976 training error: 0.3215468846417499\n",
            "At step: 1977 training error: 0.3253915462127803\n",
            "At step: 1978 training error: 0.3198669545826966\n",
            "At step: 1979 training error: 0.3232212081765481\n",
            "At step: 1980 training error: 0.3308222167718803\n",
            "At step: 1981 training error: 0.3291219317458568\n",
            "At step: 1982 training error: 0.31996290571671837\n",
            "At step: 1983 training error: 0.3287400873821287\n",
            "At step: 1984 training error: 0.33434386095645996\n",
            "At step: 1985 training error: 0.34281126936613565\n",
            "At step: 1986 training error: 0.3378011649102413\n",
            "At step: 1987 training error: 0.3330463741381842\n",
            "At step: 1988 training error: 0.3330717656622125\n",
            "At step: 1989 training error: 0.3183835734358812\n",
            "At step: 1990 training error: 0.3141999034132449\n",
            "At step: 1991 training error: 0.31434739505366416\n",
            "At step: 1992 training error: 0.3112627030514231\n",
            "At step: 1993 training error: 0.3107844968517507\n",
            "At step: 1994 training error: 0.3180901978781898\n",
            "At step: 1995 training error: 0.3246588240186561\n",
            "At step: 1996 training error: 0.33452171935988156\n",
            "At step: 1997 training error: 0.32985905980473795\n",
            "At step: 1998 training error: 0.33291000815975447\n",
            "At step: 1999 training error: 0.32695211362312093\n",
            "At step: 2000 training error: 0.3281577178249442\n",
            "At step: 2001 training error: 0.3294717922745658\n",
            "At step: 2002 training error: 0.34147882225499626\n",
            "At step: 2003 training error: 0.34480955806664065\n",
            "At step: 2004 training error: 0.3517479660086874\n",
            "At step: 2005 training error: 0.3624507747406844\n",
            "At step: 2006 training error: 0.367741612742934\n",
            "At step: 2007 training error: 0.3647791787997688\n",
            "At step: 2008 training error: 0.35604707829096954\n",
            "At step: 2009 training error: 0.3529949291231239\n",
            "At step: 2010 training error: 0.35250730947464104\n",
            "At step: 2011 training error: 0.3534225096722165\n",
            "At step: 2012 training error: 0.34570586343546317\n",
            "At step: 2013 training error: 0.33884965472474243\n",
            "At step: 2014 training error: 0.34009307884254747\n",
            "At step: 2015 training error: 0.3321200220265159\n",
            "At step: 2016 training error: 0.33628994305028753\n",
            "At step: 2017 training error: 0.34259777032028366\n",
            "At step: 2018 training error: 0.33746915818402584\n",
            "At step: 2019 training error: 0.3402642858343494\n",
            "At step: 2020 training error: 0.33587212590265886\n",
            "At step: 2021 training error: 0.3326663129463031\n",
            "At step: 2022 training error: 0.3316458756745546\n",
            "At step: 2023 training error: 0.3292548527623387\n",
            "At step: 2024 training error: 0.324448010046477\n",
            "At step: 2025 training error: 0.3243874238506044\n",
            "At step: 2026 training error: 0.32892435278036253\n",
            "At step: 2027 training error: 0.339071313339359\n",
            "At step: 2028 training error: 0.34106079200059103\n",
            "At step: 2029 training error: 0.3331501863381447\n",
            "At step: 2030 training error: 0.3283469171677959\n",
            "At step: 2031 training error: 0.33508090259827994\n",
            "At step: 2032 training error: 0.33382054900805774\n",
            "At step: 2033 training error: 0.33369556853898563\n",
            "At step: 2034 training error: 0.3336653630806744\n",
            "At step: 2035 training error: 0.3236598180797797\n",
            "At step: 2036 training error: 0.32638318581860054\n",
            "At step: 2037 training error: 0.31926040629260705\n",
            "At step: 2038 training error: 0.3140285577976041\n",
            "At step: 2039 training error: 0.32355954170621565\n",
            "At step: 2040 training error: 0.32479685662636804\n",
            "At step: 2041 training error: 0.3220245773964721\n",
            "At step: 2042 training error: 0.313098921816585\n",
            "At step: 2043 training error: 0.3189752115596407\n",
            "At step: 2044 training error: 0.31851751275787243\n",
            "At step: 2045 training error: 0.31913432014040266\n",
            "At step: 2046 training error: 0.32991145105217723\n",
            "At step: 2047 training error: 0.32111009731804024\n",
            "At step: 2048 training error: 0.3182617717318396\n",
            "At step: 2049 training error: 0.31616878558271266\n",
            "At step: 2050 training error: 0.3144598828667104\n",
            "At step: 2051 training error: 0.31233232271056804\n",
            "At step: 2052 training error: 0.3079065849583663\n",
            "At step: 2053 training error: 0.30424474910788096\n",
            "At step: 2054 training error: 0.2945141056564299\n",
            "At step: 2055 training error: 0.2936279851509546\n",
            "At step: 2056 training error: 0.2907319435601457\n",
            "At step: 2057 training error: 0.3006948936743787\n",
            "At step: 2058 training error: 0.30593006159892916\n",
            "At step: 2059 training error: 0.3185597464423091\n",
            "At step: 2060 training error: 0.32033994526536097\n",
            "At step: 2061 training error: 0.3132691058692326\n",
            "At step: 2062 training error: 0.30423157321612715\n",
            "At step: 2063 training error: 0.2991858211057318\n",
            "At step: 2064 training error: 0.2947096961791489\n",
            "At step: 2065 training error: 0.30470799947237687\n",
            "At step: 2066 training error: 0.3157437400630434\n",
            "At step: 2067 training error: 0.32895218137019244\n",
            "At step: 2068 training error: 0.33565387613845127\n",
            "At step: 2069 training error: 0.3228877642115657\n",
            "At step: 2070 training error: 0.32989565714869634\n",
            "At step: 2071 training error: 0.3249381734150814\n",
            "At step: 2072 training error: 0.32128151073343736\n",
            "At step: 2073 training error: 0.3231557467617786\n",
            "At step: 2074 training error: 0.32471674035177567\n",
            "At step: 2075 training error: 0.33221098052790027\n",
            "At step: 2076 training error: 0.3366776190579121\n",
            "At step: 2077 training error: 0.3464855357838946\n",
            "At step: 2078 training error: 0.343097908675932\n",
            "At step: 2079 training error: 0.34478736919672637\n",
            "At step: 2080 training error: 0.3363086497100984\n",
            "At step: 2081 training error: 0.3355146819477261\n",
            "At step: 2082 training error: 0.3302498618649574\n",
            "At step: 2083 training error: 0.33148469651019324\n",
            "At step: 2084 training error: 0.33808589815317563\n",
            "At step: 2085 training error: 0.32957656278112485\n",
            "At step: 2086 training error: 0.3352545284601245\n",
            "At step: 2087 training error: 0.3378905169635594\n",
            "At step: 2088 training error: 0.3339193738426584\n",
            "At step: 2089 training error: 0.3286738510676748\n",
            "At step: 2090 training error: 0.33039832380067724\n",
            "At step: 2091 training error: 0.3357201699025867\n",
            "At step: 2092 training error: 0.33847702335722807\n",
            "At step: 2093 training error: 0.32731330646145473\n",
            "At step: 2094 training error: 0.34822872807817595\n",
            "At step: 2095 training error: 0.3486514938948107\n",
            "At step: 2096 training error: 0.3505827438914681\n",
            "At step: 2097 training error: 0.35160988869345394\n",
            "At step: 2098 training error: 0.35233811207258287\n",
            "At step: 2099 training error: 0.3406917200201759\n",
            "At step: 2100 training error: 0.3302468875471011\n",
            "At step: 2101 training error: 0.3240551460212217\n",
            "At step: 2102 training error: 0.32356230239858313\n",
            "At step: 2103 training error: 0.32266812391763044\n",
            "At step: 2104 training error: 0.3311576485948712\n",
            "At step: 2105 training error: 0.332988687664667\n",
            "At step: 2106 training error: 0.33904429279182136\n",
            "At step: 2107 training error: 0.33239319446460186\n",
            "At step: 2108 training error: 0.3358608726622208\n",
            "At step: 2109 training error: 0.3404991578130325\n",
            "At step: 2110 training error: 0.34108041708539344\n",
            "At step: 2111 training error: 0.336959300730775\n",
            "At step: 2112 training error: 0.33314991883478967\n",
            "At step: 2113 training error: 0.3388437493223894\n",
            "At step: 2114 training error: 0.32240920855129\n",
            "At step: 2115 training error: 0.3247376747628428\n",
            "At step: 2116 training error: 0.33018095788563073\n",
            "At step: 2117 training error: 0.32353303513245446\n",
            "At step: 2118 training error: 0.3297755482809154\n",
            "At step: 2119 training error: 0.3446617104409945\n",
            "At step: 2120 training error: 0.3447202409722805\n",
            "At step: 2121 training error: 0.3454597754977263\n",
            "At step: 2122 training error: 0.3470126785191528\n",
            "At step: 2123 training error: 0.35293556743971977\n",
            "At step: 2124 training error: 0.34189344774588787\n",
            "At step: 2125 training error: 0.34518259576045407\n",
            "At step: 2126 training error: 0.349916822418195\n",
            "At step: 2127 training error: 0.36456968656762323\n",
            "At step: 2128 training error: 0.354131646468096\n",
            "At step: 2129 training error: 0.35097432975255316\n",
            "At step: 2130 training error: 0.3532466950267737\n",
            "At step: 2131 training error: 0.34479030761038926\n",
            "At step: 2132 training error: 0.35283509578393973\n",
            "At step: 2133 training error: 0.3478430157178809\n",
            "At step: 2134 training error: 0.3471940506021\n",
            "At step: 2135 training error: 0.3476350389432646\n",
            "At step: 2136 training error: 0.3484598925371132\n",
            "At step: 2137 training error: 0.3377795538447741\n",
            "At step: 2138 training error: 0.3389119529942217\n",
            "At step: 2139 training error: 0.33053860560443293\n",
            "At step: 2140 training error: 0.3328623593938116\n",
            "At step: 2141 training error: 0.33308662208437134\n",
            "At step: 2142 training error: 0.3366862237391963\n",
            "At step: 2143 training error: 0.3347984899038343\n",
            "At step: 2144 training error: 0.33761073092193\n",
            "At step: 2145 training error: 0.33299066131262073\n",
            "At step: 2146 training error: 0.3391401846069665\n",
            "At step: 2147 training error: 0.3404105468788714\n",
            "At step: 2148 training error: 0.3391695162359446\n",
            "At step: 2149 training error: 0.3425319072195563\n",
            "At step: 2150 training error: 0.3364399609681239\n",
            "At step: 2151 training error: 0.34705237561387603\n",
            "At step: 2152 training error: 0.3511894286253008\n",
            "At step: 2153 training error: 0.33676424389608556\n",
            "At step: 2154 training error: 0.33115309081433236\n",
            "At step: 2155 training error: 0.33644903618484856\n",
            "At step: 2156 training error: 0.3295849671751399\n",
            "At step: 2157 training error: 0.3217538812949043\n",
            "At step: 2158 training error: 0.3335436314808788\n",
            "At step: 2159 training error: 0.3388448245923979\n",
            "At step: 2160 training error: 0.32570499902084843\n",
            "At step: 2161 training error: 0.3320252070589441\n",
            "At step: 2162 training error: 0.33038362789972286\n",
            "At step: 2163 training error: 0.34297359843331443\n",
            "At step: 2164 training error: 0.3454866323129553\n",
            "At step: 2165 training error: 0.3567309426134028\n",
            "At step: 2166 training error: 0.3549519360725387\n",
            "At step: 2167 training error: 0.352123833286341\n",
            "At step: 2168 training error: 0.34352696187830106\n",
            "At step: 2169 training error: 0.3551180877075698\n",
            "At step: 2170 training error: 0.3560819092576834\n",
            "At step: 2171 training error: 0.3702215193275016\n",
            "At step: 2172 training error: 0.35264885839247095\n",
            "At step: 2173 training error: 0.36530845700373227\n",
            "At step: 2174 training error: 0.3486732307112531\n",
            "At step: 2175 training error: 0.35553335512664\n",
            "At step: 2176 training error: 0.3560573108873099\n",
            "At step: 2177 training error: 0.3655165373377568\n",
            "At step: 2178 training error: 0.3604437973875086\n",
            "At step: 2179 training error: 0.34965216967462875\n",
            "At step: 2180 training error: 0.35086182491398876\n",
            "At step: 2181 training error: 0.3551485580345065\n",
            "At step: 2182 training error: 0.35296935552221864\n",
            "At step: 2183 training error: 0.36056836820047417\n",
            "At step: 2184 training error: 0.35245343745564045\n",
            "At step: 2185 training error: 0.3538847079026336\n",
            "At step: 2186 training error: 0.36415177111225516\n",
            "At step: 2187 training error: 0.3587073557674598\n",
            "At step: 2188 training error: 0.353507572769844\n",
            "At step: 2189 training error: 0.35400004331618856\n",
            "At step: 2190 training error: 0.3437779662366207\n",
            "At step: 2191 training error: 0.3427087316484311\n",
            "At step: 2192 training error: 0.3428345624549842\n",
            "At step: 2193 training error: 0.3487603474312424\n",
            "At step: 2194 training error: 0.3513930265101649\n",
            "At step: 2195 training error: 0.35331243912803023\n",
            "At step: 2196 training error: 0.353112866783474\n",
            "At step: 2197 training error: 0.353367629052282\n",
            "At step: 2198 training error: 0.35129602222968687\n",
            "At step: 2199 training error: 0.3511710528911959\n",
            "At step: 2200 training error: 0.3578630246977531\n",
            "At step: 2201 training error: 0.36465609080784367\n",
            "At step: 2202 training error: 0.3701555170790525\n",
            "At step: 2203 training error: 0.36659813979493605\n",
            "At step: 2204 training error: 0.3703493878534129\n",
            "At step: 2205 training error: 0.3773301981930831\n",
            "At step: 2206 training error: 0.37724926968471495\n",
            "At step: 2207 training error: 0.3776637935331786\n",
            "At step: 2208 training error: 0.37731842403828175\n",
            "At step: 2209 training error: 0.3698383568256383\n",
            "At step: 2210 training error: 0.362851662938292\n",
            "At step: 2211 training error: 0.36795864369804665\n",
            "At step: 2212 training error: 0.37234795979497026\n",
            "At step: 2213 training error: 0.3724430421761651\n",
            "At step: 2214 training error: 0.35923639644414285\n",
            "At step: 2215 training error: 0.3673365799214935\n",
            "At step: 2216 training error: 0.37216914735754075\n",
            "At step: 2217 training error: 0.3725154298038503\n",
            "At step: 2218 training error: 0.37045191925004034\n",
            "At step: 2219 training error: 0.37086952934480855\n",
            "At step: 2220 training error: 0.3710899905182345\n",
            "At step: 2221 training error: 0.37270855278700826\n",
            "At step: 2222 training error: 0.37103090148731005\n",
            "At step: 2223 training error: 0.37292149782879536\n",
            "At step: 2224 training error: 0.37483235294206324\n",
            "At step: 2225 training error: 0.3646283079509459\n",
            "At step: 2226 training error: 0.3724006171301265\n",
            "At step: 2227 training error: 0.368867485851209\n",
            "At step: 2228 training error: 0.36862368331119333\n",
            "At step: 2229 training error: 0.3659282476167613\n",
            "At step: 2230 training error: 0.3679498441924781\n",
            "At step: 2231 training error: 0.36122257997964263\n",
            "At step: 2232 training error: 0.3595892322256343\n",
            "At step: 2233 training error: 0.360704559723437\n",
            "At step: 2234 training error: 0.35674063889195645\n",
            "At step: 2235 training error: 0.3543415160362615\n",
            "At step: 2236 training error: 0.35608549217545205\n",
            "At step: 2237 training error: 0.365320658062697\n",
            "At step: 2238 training error: 0.37062729653537296\n",
            "At step: 2239 training error: 0.3671723506137309\n",
            "At step: 2240 training error: 0.3643084763766187\n",
            "At step: 2241 training error: 0.361246641405566\n",
            "At step: 2242 training error: 0.3637655953891604\n",
            "At step: 2243 training error: 0.35795402717371483\n",
            "At step: 2244 training error: 0.35270486776568266\n",
            "At step: 2245 training error: 0.3567087508453668\n",
            "At step: 2246 training error: 0.35842856750108476\n",
            "At step: 2247 training error: 0.36726306687457494\n",
            "At step: 2248 training error: 0.36712031928006306\n",
            "At step: 2249 training error: 0.365449083018566\n",
            "At step: 2250 training error: 0.3679337210132899\n",
            "At step: 2251 training error: 0.356084347613242\n",
            "At step: 2252 training error: 0.3464510794243326\n",
            "At step: 2253 training error: 0.3399786547981242\n",
            "At step: 2254 training error: 0.33396942899208953\n",
            "At step: 2255 training error: 0.3241148742957485\n",
            "At step: 2256 training error: 0.3229788041661399\n",
            "At step: 2257 training error: 0.3305622801612894\n",
            "At step: 2258 training error: 0.34342898959212886\n",
            "At step: 2259 training error: 0.35143259201374666\n",
            "At step: 2260 training error: 0.33957707292637856\n",
            "At step: 2261 training error: 0.34158827747412296\n",
            "At step: 2262 training error: 0.3407489678800903\n",
            "At step: 2263 training error: 0.3485820608290623\n",
            "At step: 2264 training error: 0.35333161633182475\n",
            "At step: 2265 training error: 0.3500120678880996\n",
            "At step: 2266 training error: 0.3375812478028021\n",
            "At step: 2267 training error: 0.3430969137847109\n",
            "At step: 2268 training error: 0.3470442106018239\n",
            "At step: 2269 training error: 0.34692948031178317\n",
            "At step: 2270 training error: 0.3485896150822024\n",
            "At step: 2271 training error: 0.340340181691863\n",
            "At step: 2272 training error: 0.3366904162164913\n",
            "At step: 2273 training error: 0.33915591943352963\n",
            "At step: 2274 training error: 0.334109369661635\n",
            "At step: 2275 training error: 0.32012131705539437\n",
            "At step: 2276 training error: 0.314416563509909\n",
            "At step: 2277 training error: 0.3200180196260659\n",
            "At step: 2278 training error: 0.31884000295848164\n",
            "At step: 2279 training error: 0.31582274877928673\n",
            "At step: 2280 training error: 0.3207034683896518\n",
            "At step: 2281 training error: 0.32671550391414583\n",
            "At step: 2282 training error: 0.3253166494339709\n",
            "At step: 2283 training error: 0.3167096269516948\n",
            "At step: 2284 training error: 0.3129698490290814\n",
            "At step: 2285 training error: 0.3337488334004955\n",
            "At step: 2286 training error: 0.34295049433520264\n",
            "At step: 2287 training error: 0.3367479353500673\n",
            "At step: 2288 training error: 0.3306339642516701\n",
            "At step: 2289 training error: 0.3215507378536201\n",
            "At step: 2290 training error: 0.3321257861868837\n",
            "At step: 2291 training error: 0.34106922529315525\n",
            "At step: 2292 training error: 0.34197329870646875\n",
            "At step: 2293 training error: 0.33530451377656634\n",
            "At step: 2294 training error: 0.3365808469350857\n",
            "At step: 2295 training error: 0.3395811994602997\n",
            "At step: 2296 training error: 0.3524764132920823\n",
            "At step: 2297 training error: 0.3409873123671505\n",
            "At step: 2298 training error: 0.3356088468052024\n",
            "At step: 2299 training error: 0.33513711736247676\n",
            "At step: 2300 training error: 0.34475651406914043\n",
            "At step: 2301 training error: 0.3505385943899961\n",
            "At step: 2302 training error: 0.3497418426874685\n",
            "At step: 2303 training error: 0.3504327855141752\n",
            "At step: 2304 training error: 0.35113539279821904\n",
            "At step: 2305 training error: 0.34505502057690257\n",
            "At step: 2306 training error: 0.33067682265424725\n",
            "At step: 2307 training error: 0.33355694296007327\n",
            "At step: 2308 training error: 0.3314052828585514\n",
            "At step: 2309 training error: 0.3400943204520359\n",
            "At step: 2310 training error: 0.35086698337817673\n",
            "At step: 2311 training error: 0.34514581149141416\n",
            "At step: 2312 training error: 0.32846506525038044\n",
            "At step: 2313 training error: 0.3360612542434367\n",
            "At step: 2314 training error: 0.33445033590122747\n",
            "At step: 2315 training error: 0.3414011478177098\n",
            "At step: 2316 training error: 0.33784092033621516\n",
            "At step: 2317 training error: 0.34435781663365855\n",
            "At step: 2318 training error: 0.3513290786339538\n",
            "At step: 2319 training error: 0.35802353608543697\n",
            "At step: 2320 training error: 0.3474669453071764\n",
            "At step: 2321 training error: 0.3586177206974931\n",
            "At step: 2322 training error: 0.3570227062326891\n",
            "At step: 2323 training error: 0.3615895943870675\n",
            "At step: 2324 training error: 0.3666075728456958\n",
            "At step: 2325 training error: 0.36852452254378704\n",
            "At step: 2326 training error: 0.3744212463538844\n",
            "At step: 2327 training error: 0.3771558123331942\n",
            "At step: 2328 training error: 0.38205296501983255\n",
            "At step: 2329 training error: 0.3757232695677594\n",
            "At step: 2330 training error: 0.3822538834449245\n",
            "At step: 2331 training error: 0.3672747856751357\n",
            "At step: 2332 training error: 0.3648272873890947\n",
            "At step: 2333 training error: 0.36800895484314156\n",
            "At step: 2334 training error: 0.3620075276661799\n",
            "At step: 2335 training error: 0.35167699808311553\n",
            "At step: 2336 training error: 0.34576668635171803\n",
            "At step: 2337 training error: 0.3444943671235166\n",
            "At step: 2338 training error: 0.342094530502931\n",
            "At step: 2339 training error: 0.34492884209682734\n",
            "At step: 2340 training error: 0.3395333650761721\n",
            "At step: 2341 training error: 0.3325156499196699\n",
            "At step: 2342 training error: 0.3286820833371691\n",
            "At step: 2343 training error: 0.3200090290037269\n",
            "At step: 2344 training error: 0.34018392219568694\n",
            "At step: 2345 training error: 0.3426960070519051\n",
            "At step: 2346 training error: 0.33319605760499615\n",
            "At step: 2347 training error: 0.33387121214708626\n",
            "At step: 2348 training error: 0.33930751119799335\n",
            "At step: 2349 training error: 0.3520617972490955\n",
            "At step: 2350 training error: 0.35486680486469807\n",
            "At step: 2351 training error: 0.36349057711246385\n",
            "At step: 2352 training error: 0.3711551162773894\n",
            "At step: 2353 training error: 0.38184300894529805\n",
            "At step: 2354 training error: 0.37171652053514775\n",
            "At step: 2355 training error: 0.3707795685777429\n",
            "At step: 2356 training error: 0.3605831681288576\n",
            "At step: 2357 training error: 0.35801754037043754\n",
            "At step: 2358 training error: 0.35549520354160635\n",
            "At step: 2359 training error: 0.36205012445922935\n",
            "At step: 2360 training error: 0.3521832575652426\n",
            "At step: 2361 training error: 0.34858652320869904\n",
            "At step: 2362 training error: 0.35269719686943174\n",
            "At step: 2363 training error: 0.34487445094422725\n",
            "At step: 2364 training error: 0.3410430025540321\n",
            "At step: 2365 training error: 0.33186671523501576\n",
            "At step: 2366 training error: 0.342234892499468\n",
            "At step: 2367 training error: 0.34850764925673017\n",
            "At step: 2368 training error: 0.35353140588057524\n",
            "At step: 2369 training error: 0.34369174009297015\n",
            "At step: 2370 training error: 0.33770556952288466\n",
            "At step: 2371 training error: 0.33141498300886113\n",
            "At step: 2372 training error: 0.3338228441083799\n",
            "At step: 2373 training error: 0.3282792093746858\n",
            "At step: 2374 training error: 0.3366839157990818\n",
            "At step: 2375 training error: 0.34383499228446024\n",
            "At step: 2376 training error: 0.3543246793021621\n",
            "At step: 2377 training error: 0.35363514990586653\n",
            "At step: 2378 training error: 0.35357724433613613\n",
            "At step: 2379 training error: 0.3616293816679568\n",
            "At step: 2380 training error: 0.36150456269946674\n",
            "At step: 2381 training error: 0.36165383970085174\n",
            "At step: 2382 training error: 0.3552285188285289\n",
            "At step: 2383 training error: 0.3599194027489216\n",
            "At step: 2384 training error: 0.3571328638550661\n",
            "At step: 2385 training error: 0.36881666317408\n",
            "At step: 2386 training error: 0.36697788927814745\n",
            "At step: 2387 training error: 0.36538047002704577\n",
            "At step: 2388 training error: 0.35800149019675215\n",
            "At step: 2389 training error: 0.37543697504550033\n",
            "At step: 2390 training error: 0.373109199982595\n",
            "At step: 2391 training error: 0.3702292985025906\n",
            "At step: 2392 training error: 0.3609336955820538\n",
            "At step: 2393 training error: 0.3546026090855484\n",
            "At step: 2394 training error: 0.35782518670586816\n",
            "At step: 2395 training error: 0.3516393020393193\n",
            "At step: 2396 training error: 0.3446619785477717\n",
            "At step: 2397 training error: 0.34100712263443267\n",
            "At step: 2398 training error: 0.33001614722103845\n",
            "At step: 2399 training error: 0.32096339437603844\n",
            "At step: 2400 training error: 0.3308192433410482\n",
            "At step: 2401 training error: 0.3310885283397721\n",
            "At step: 2402 training error: 0.33896950385187913\n",
            "At step: 2403 training error: 0.33447305014605827\n",
            "At step: 2404 training error: 0.3407858029216704\n",
            "At step: 2405 training error: 0.3387622440456391\n",
            "At step: 2406 training error: 0.3368763267849158\n",
            "At step: 2407 training error: 0.3468936116800719\n",
            "At step: 2408 training error: 0.34960634860212464\n",
            "At step: 2409 training error: 0.3654915831813157\n",
            "At step: 2410 training error: 0.3568502296867416\n",
            "At step: 2411 training error: 0.3628626091334682\n",
            "At step: 2412 training error: 0.37184317192268046\n",
            "At step: 2413 training error: 0.37018027384575947\n",
            "At step: 2414 training error: 0.37655719390133957\n",
            "At step: 2415 training error: 0.36026629853216063\n",
            "At step: 2416 training error: 0.3719612635693951\n",
            "At step: 2417 training error: 0.3703104119578758\n",
            "At step: 2418 training error: 0.3639403703230074\n",
            "At step: 2419 training error: 0.35759854636585053\n",
            "At step: 2420 training error: 0.36499912055065703\n",
            "At step: 2421 training error: 0.37234294912468796\n",
            "At step: 2422 training error: 0.35935911282798083\n",
            "At step: 2423 training error: 0.3626710298642197\n",
            "At step: 2424 training error: 0.3631248702143057\n",
            "At step: 2425 training error: 0.37143568272395305\n",
            "At step: 2426 training error: 0.3636792971343417\n",
            "At step: 2427 training error: 0.36474927924667744\n",
            "At step: 2428 training error: 0.3571032498653449\n",
            "At step: 2429 training error: 0.35778042293310724\n",
            "At step: 2430 training error: 0.3609487580711849\n",
            "At step: 2431 training error: 0.349483360355169\n",
            "At step: 2432 training error: 0.35947366260559804\n",
            "At step: 2433 training error: 0.354367345736994\n",
            "At step: 2434 training error: 0.3500640169609685\n",
            "At step: 2435 training error: 0.3491665899843292\n",
            "At step: 2436 training error: 0.3590393912442199\n",
            "At step: 2437 training error: 0.35588003735146645\n",
            "At step: 2438 training error: 0.35788545778597347\n",
            "At step: 2439 training error: 0.36022654910515134\n",
            "At step: 2440 training error: 0.3522794949291872\n",
            "At step: 2441 training error: 0.3489786888919901\n",
            "At step: 2442 training error: 0.3501024063637356\n",
            "At step: 2443 training error: 0.3493130249290269\n",
            "At step: 2444 training error: 0.35107329802039083\n",
            "At step: 2445 training error: 0.3467935695651354\n",
            "At step: 2446 training error: 0.34497125429778724\n",
            "At step: 2447 training error: 0.34531978491005466\n",
            "At step: 2448 training error: 0.34372249558464796\n",
            "At step: 2449 training error: 0.3481800854271909\n",
            "At step: 2450 training error: 0.3444718678184306\n",
            "At step: 2451 training error: 0.3439321639325156\n",
            "At step: 2452 training error: 0.34054234808767764\n",
            "At step: 2453 training error: 0.34063018872247175\n",
            "At step: 2454 training error: 0.3342444301578131\n",
            "At step: 2455 training error: 0.3351489499422232\n",
            "At step: 2456 training error: 0.34039853757929806\n",
            "At step: 2457 training error: 0.3287791183389833\n",
            "At step: 2458 training error: 0.3275769465573089\n",
            "At step: 2459 training error: 0.33730995868290653\n",
            "At step: 2460 training error: 0.33368605474433005\n",
            "At step: 2461 training error: 0.33384180437627076\n",
            "At step: 2462 training error: 0.33530244521383257\n",
            "At step: 2463 training error: 0.3364176959595246\n",
            "At step: 2464 training error: 0.3447189388163695\n",
            "At step: 2465 training error: 0.3493060216196761\n",
            "At step: 2466 training error: 0.3431793130058264\n",
            "At step: 2467 training error: 0.33987284928933104\n",
            "At step: 2468 training error: 0.3277916857343088\n",
            "At step: 2469 training error: 0.31898812127098564\n",
            "At step: 2470 training error: 0.31755913201272734\n",
            "At step: 2471 training error: 0.3269905695963321\n",
            "At step: 2472 training error: 0.3176235355399473\n",
            "At step: 2473 training error: 0.3163432758160396\n",
            "At step: 2474 training error: 0.3110149942340709\n",
            "At step: 2475 training error: 0.30983493670110046\n",
            "At step: 2476 training error: 0.3072714346821745\n",
            "At step: 2477 training error: 0.30667134845194977\n",
            "At step: 2478 training error: 0.3106688883403978\n",
            "At step: 2479 training error: 0.31964539190965685\n",
            "At step: 2480 training error: 0.32306685325070283\n",
            "At step: 2481 training error: 0.33731021889054674\n",
            "At step: 2482 training error: 0.33738393085051865\n",
            "At step: 2483 training error: 0.3477531458147338\n",
            "At step: 2484 training error: 0.34722190405569114\n",
            "At step: 2485 training error: 0.3430191951086992\n",
            "At step: 2486 training error: 0.3423739049548993\n",
            "At step: 2487 training error: 0.342719108925671\n",
            "At step: 2488 training error: 0.3483462428724934\n",
            "At step: 2489 training error: 0.3417355942874247\n",
            "At step: 2490 training error: 0.347010075654759\n",
            "At step: 2491 training error: 0.3399349958891989\n",
            "At step: 2492 training error: 0.33332520019567496\n",
            "At step: 2493 training error: 0.332764492383803\n",
            "At step: 2494 training error: 0.34320260273402103\n",
            "At step: 2495 training error: 0.34018912902636234\n",
            "At step: 2496 training error: 0.34517522123890515\n",
            "At step: 2497 training error: 0.34206993126270685\n",
            "At step: 2498 training error: 0.34196843789204184\n",
            "At step: 2499 training error: 0.3429755245323569\n",
            "At step: 2500 training error: 0.35290392984917873\n",
            "At step: 2501 training error: 0.3552541089744248\n",
            "At step: 2502 training error: 0.3530149523925441\n",
            "At step: 2503 training error: 0.35027286216147074\n",
            "At step: 2504 training error: 0.34211404373646226\n",
            "At step: 2505 training error: 0.3516087877272535\n",
            "At step: 2506 training error: 0.363407239664192\n",
            "At step: 2507 training error: 0.3597908793667711\n",
            "At step: 2508 training error: 0.35524702605432557\n",
            "At step: 2509 training error: 0.34978552365783466\n",
            "At step: 2510 training error: 0.3483159128340123\n",
            "At step: 2511 training error: 0.3447197616893704\n",
            "At step: 2512 training error: 0.3448891240094257\n",
            "At step: 2513 training error: 0.362102596560388\n",
            "At step: 2514 training error: 0.3598266043931621\n",
            "At step: 2515 training error: 0.359722889611163\n",
            "At step: 2516 training error: 0.3587754999140546\n",
            "At step: 2517 training error: 0.35424725720698014\n",
            "At step: 2518 training error: 0.35389689990979106\n",
            "At step: 2519 training error: 0.3424468971099636\n",
            "At step: 2520 training error: 0.352752849528051\n",
            "At step: 2521 training error: 0.3552374074145596\n",
            "At step: 2522 training error: 0.35239724789922433\n",
            "At step: 2523 training error: 0.3571257932097772\n",
            "At step: 2524 training error: 0.35963337518750466\n",
            "At step: 2525 training error: 0.3551395844294542\n",
            "At step: 2526 training error: 0.35495707832477225\n",
            "At step: 2527 training error: 0.3509608952055482\n",
            "At step: 2528 training error: 0.3509840634798661\n",
            "At step: 2529 training error: 0.3579461138125495\n",
            "At step: 2530 training error: 0.35316195605945366\n",
            "At step: 2531 training error: 0.3636891110595863\n",
            "At step: 2532 training error: 0.3533761793291585\n",
            "At step: 2533 training error: 0.3496176728833721\n",
            "At step: 2534 training error: 0.3448747200439367\n",
            "At step: 2535 training error: 0.34831094881392793\n",
            "At step: 2536 training error: 0.35545640613698615\n",
            "At step: 2537 training error: 0.3585087585320589\n",
            "At step: 2538 training error: 0.36008556251694424\n",
            "At step: 2539 training error: 0.35913605911820645\n",
            "At step: 2540 training error: 0.3518359676094319\n",
            "At step: 2541 training error: 0.3591924335513481\n",
            "At step: 2542 training error: 0.3597903597060525\n",
            "At step: 2543 training error: 0.36084928904675967\n",
            "At step: 2544 training error: 0.3668733108835333\n",
            "At step: 2545 training error: 0.36277689697204435\n",
            "At step: 2546 training error: 0.3505579378437198\n",
            "At step: 2547 training error: 0.348232245710499\n",
            "At step: 2548 training error: 0.3586394020320688\n",
            "At step: 2549 training error: 0.3512646005120734\n",
            "At step: 2550 training error: 0.34766786939711697\n",
            "At step: 2551 training error: 0.3416179598187239\n",
            "At step: 2552 training error: 0.34372063698442706\n",
            "At step: 2553 training error: 0.34936315238594\n",
            "At step: 2554 training error: 0.3467525249577863\n",
            "At step: 2555 training error: 0.34831937483362413\n",
            "At step: 2556 training error: 0.34911278906257454\n",
            "At step: 2557 training error: 0.35128814399806935\n",
            "At step: 2558 training error: 0.3420982719859149\n",
            "At step: 2559 training error: 0.34258593995483866\n",
            "At step: 2560 training error: 0.35283243203911696\n",
            "At step: 2561 training error: 0.3532973958426943\n",
            "At step: 2562 training error: 0.3555357844028255\n",
            "At step: 2563 training error: 0.34902578569031645\n",
            "At step: 2564 training error: 0.3492807556480163\n",
            "At step: 2565 training error: 0.3606200954766677\n",
            "At step: 2566 training error: 0.3473307035267433\n",
            "At step: 2567 training error: 0.3483173278809196\n",
            "At step: 2568 training error: 0.34794853779574714\n",
            "At step: 2569 training error: 0.3482597254250309\n",
            "At step: 2570 training error: 0.33453297178214825\n",
            "At step: 2571 training error: 0.33744230439570666\n",
            "At step: 2572 training error: 0.33498614948984806\n",
            "At step: 2573 training error: 0.3311990247914914\n",
            "At step: 2574 training error: 0.3382323201108843\n",
            "At step: 2575 training error: 0.346423126741651\n",
            "At step: 2576 training error: 0.34711281731828114\n",
            "At step: 2577 training error: 0.3413050452564449\n",
            "At step: 2578 training error: 0.32847098793430507\n",
            "At step: 2579 training error: 0.32575963452185397\n",
            "At step: 2580 training error: 0.32874495000525306\n",
            "At step: 2581 training error: 0.3177466795952884\n",
            "At step: 2582 training error: 0.3207280984594032\n",
            "At step: 2583 training error: 0.3267256089432472\n",
            "At step: 2584 training error: 0.3307875249236952\n",
            "At step: 2585 training error: 0.32972864986861294\n",
            "At step: 2586 training error: 0.32632261629340426\n",
            "At step: 2587 training error: 0.3218669708123202\n",
            "At step: 2588 training error: 0.3221305072129335\n",
            "At step: 2589 training error: 0.32182779025202113\n",
            "At step: 2590 training error: 0.3200827049974254\n",
            "At step: 2591 training error: 0.3212910370573715\n",
            "At step: 2592 training error: 0.324892014342397\n",
            "At step: 2593 training error: 0.33484155550922773\n",
            "At step: 2594 training error: 0.3337807414243113\n",
            "At step: 2595 training error: 0.3347674829701017\n",
            "At step: 2596 training error: 0.32982774250596303\n",
            "At step: 2597 training error: 0.33753232564512914\n",
            "At step: 2598 training error: 0.3490648666711154\n",
            "At step: 2599 training error: 0.343997194360276\n",
            "At step: 2600 training error: 0.3528049081020012\n",
            "At step: 2601 training error: 0.3535216656835325\n",
            "At step: 2602 training error: 0.33881240140950736\n",
            "At step: 2603 training error: 0.3375986552265621\n",
            "At step: 2604 training error: 0.35123482841616743\n",
            "At step: 2605 training error: 0.35895040016367386\n",
            "At step: 2606 training error: 0.3702455074325722\n",
            "At step: 2607 training error: 0.3624749417256147\n",
            "At step: 2608 training error: 0.35559104875254827\n",
            "At step: 2609 training error: 0.3520355039694549\n",
            "At step: 2610 training error: 0.3457721613526432\n",
            "At step: 2611 training error: 0.3463788296444608\n",
            "At step: 2612 training error: 0.34502155453997774\n",
            "At step: 2613 training error: 0.34400198442528807\n",
            "At step: 2614 training error: 0.3441959568768381\n",
            "At step: 2615 training error: 0.34230730929690056\n",
            "At step: 2616 training error: 0.33170387027410364\n",
            "At step: 2617 training error: 0.32922796944868854\n",
            "At step: 2618 training error: 0.3378377892438333\n",
            "At step: 2619 training error: 0.3448399681389367\n",
            "At step: 2620 training error: 0.34766136713295753\n",
            "At step: 2621 training error: 0.36136801652833234\n",
            "At step: 2622 training error: 0.38145266768293384\n",
            "At step: 2623 training error: 0.3868934723914652\n",
            "At step: 2624 training error: 0.3946989162443779\n",
            "At step: 2625 training error: 0.3951028008712527\n",
            "At step: 2626 training error: 0.3906029949925022\n",
            "At step: 2627 training error: 0.3926467444370901\n",
            "At step: 2628 training error: 0.3843664355113473\n",
            "At step: 2629 training error: 0.38353433437419837\n",
            "At step: 2630 training error: 0.3722928808118468\n",
            "At step: 2631 training error: 0.3797003744253261\n",
            "At step: 2632 training error: 0.3695302986246565\n",
            "At step: 2633 training error: 0.36934196246612083\n",
            "At step: 2634 training error: 0.36664667721628824\n",
            "At step: 2635 training error: 0.35511236779033856\n",
            "At step: 2636 training error: 0.35388861464272914\n",
            "At step: 2637 training error: 0.3414255444207608\n",
            "At step: 2638 training error: 0.3316782677304095\n",
            "At step: 2639 training error: 0.33302931009105163\n",
            "At step: 2640 training error: 0.33048405110207996\n",
            "At step: 2641 training error: 0.34480355813315655\n",
            "At step: 2642 training error: 0.3464400078023113\n",
            "At step: 2643 training error: 0.35724205572613865\n",
            "At step: 2644 training error: 0.34022320899815084\n",
            "At step: 2645 training error: 0.34644343633401187\n",
            "At step: 2646 training error: 0.33739284035334804\n",
            "At step: 2647 training error: 0.34272622890686005\n",
            "At step: 2648 training error: 0.3390960597233558\n",
            "At step: 2649 training error: 0.342193074903796\n",
            "At step: 2650 training error: 0.34206362188443223\n",
            "At step: 2651 training error: 0.33998600192657125\n",
            "At step: 2652 training error: 0.3480534991410095\n",
            "At step: 2653 training error: 0.36260292422005086\n",
            "At step: 2654 training error: 0.36259136339071263\n",
            "At step: 2655 training error: 0.3640089698318843\n",
            "At step: 2656 training error: 0.3657386814559635\n",
            "At step: 2657 training error: 0.3661412196218294\n",
            "At step: 2658 training error: 0.36145310641721634\n",
            "At step: 2659 training error: 0.35623486181404523\n",
            "At step: 2660 training error: 0.359054967057291\n",
            "At step: 2661 training error: 0.3624315183799995\n",
            "At step: 2662 training error: 0.3531316725772515\n",
            "At step: 2663 training error: 0.3554291831855242\n",
            "At step: 2664 training error: 0.35471521481375673\n",
            "At step: 2665 training error: 0.34789305630574613\n",
            "At step: 2666 training error: 0.3500241283861243\n",
            "At step: 2667 training error: 0.346964106070223\n",
            "At step: 2668 training error: 0.35030509345915944\n",
            "At step: 2669 training error: 0.3479217699580073\n",
            "At step: 2670 training error: 0.35315189862219837\n",
            "At step: 2671 training error: 0.35828191876526116\n",
            "At step: 2672 training error: 0.3515902160340657\n",
            "At step: 2673 training error: 0.3548939348850809\n",
            "At step: 2674 training error: 0.35020206675669047\n",
            "At step: 2675 training error: 0.34916717115933316\n",
            "At step: 2676 training error: 0.3378840992965388\n",
            "At step: 2677 training error: 0.3278507399898328\n",
            "At step: 2678 training error: 0.33767215748865875\n",
            "At step: 2679 training error: 0.3364695384474611\n",
            "At step: 2680 training error: 0.3276443385853312\n",
            "At step: 2681 training error: 0.33930104587799303\n",
            "At step: 2682 training error: 0.3307060591831406\n",
            "At step: 2683 training error: 0.34062620899533835\n",
            "At step: 2684 training error: 0.3374783303638029\n",
            "At step: 2685 training error: 0.33965830761154836\n",
            "At step: 2686 training error: 0.3533047110158769\n",
            "At step: 2687 training error: 0.35046930520340985\n",
            "At step: 2688 training error: 0.3575363768833505\n",
            "At step: 2689 training error: 0.3543790140520942\n",
            "At step: 2690 training error: 0.3472199439245118\n",
            "At step: 2691 training error: 0.3434934039125006\n",
            "At step: 2692 training error: 0.34100934411989287\n",
            "At step: 2693 training error: 0.3365462834058476\n",
            "At step: 2694 training error: 0.32670752296960087\n",
            "At step: 2695 training error: 0.32821090546462106\n",
            "At step: 2696 training error: 0.3201801385763342\n",
            "At step: 2697 training error: 0.33917397583704956\n",
            "At step: 2698 training error: 0.33615081779332007\n",
            "At step: 2699 training error: 0.3446226485131069\n",
            "At step: 2700 training error: 0.3406690168426301\n",
            "At step: 2701 training error: 0.3336269892481048\n",
            "At step: 2702 training error: 0.34273334435748226\n",
            "At step: 2703 training error: 0.33275901799966\n",
            "At step: 2704 training error: 0.33757403596268026\n",
            "At step: 2705 training error: 0.3394206707280983\n",
            "At step: 2706 training error: 0.3328518795001582\n",
            "At step: 2707 training error: 0.3323034691786466\n",
            "At step: 2708 training error: 0.3295152362904531\n",
            "At step: 2709 training error: 0.33381745067365864\n",
            "At step: 2710 training error: 0.33214652703335923\n",
            "At step: 2711 training error: 0.33225735865046546\n",
            "At step: 2712 training error: 0.3324362743141044\n",
            "At step: 2713 training error: 0.3316425011839031\n",
            "At step: 2714 training error: 0.3408442263029655\n",
            "At step: 2715 training error: 0.3360706022459756\n",
            "At step: 2716 training error: 0.32869958113036657\n",
            "At step: 2717 training error: 0.3286691501217703\n",
            "At step: 2718 training error: 0.3267361732465467\n",
            "At step: 2719 training error: 0.3341027127749086\n",
            "At step: 2720 training error: 0.32991306984494695\n",
            "At step: 2721 training error: 0.32222638668549247\n",
            "At step: 2722 training error: 0.3263008911447275\n",
            "At step: 2723 training error: 0.3382936389386247\n",
            "At step: 2724 training error: 0.3433593032234512\n",
            "At step: 2725 training error: 0.34613539266963456\n",
            "At step: 2726 training error: 0.3514833426350179\n",
            "At step: 2727 training error: 0.3513006843820809\n",
            "At step: 2728 training error: 0.3621893645119902\n",
            "At step: 2729 training error: 0.35594194226228354\n",
            "At step: 2730 training error: 0.3583267848932263\n",
            "At step: 2731 training error: 0.3532922852115358\n",
            "At step: 2732 training error: 0.3660097068101812\n",
            "At step: 2733 training error: 0.36844806875377695\n",
            "At step: 2734 training error: 0.3684028867416458\n",
            "At step: 2735 training error: 0.3672461854262167\n",
            "At step: 2736 training error: 0.3553264808503208\n",
            "At step: 2737 training error: 0.3613200040949801\n",
            "At step: 2738 training error: 0.35413695699822995\n",
            "At step: 2739 training error: 0.3479674473536088\n",
            "At step: 2740 training error: 0.34894579220025074\n",
            "At step: 2741 training error: 0.3576986321369855\n",
            "At step: 2742 training error: 0.35597366344494924\n",
            "At step: 2743 training error: 0.3545539947529531\n",
            "At step: 2744 training error: 0.3473982738428066\n",
            "At step: 2745 training error: 0.3432737455444505\n",
            "At step: 2746 training error: 0.34937225766842456\n",
            "At step: 2747 training error: 0.3517111590161623\n",
            "At step: 2748 training error: 0.34908796265437425\n",
            "At step: 2749 training error: 0.3462105965122297\n",
            "At step: 2750 training error: 0.35245813516453944\n",
            "At step: 2751 training error: 0.3509160283382821\n",
            "At step: 2752 training error: 0.3427227079429269\n",
            "At step: 2753 training error: 0.33751447896293213\n",
            "At step: 2754 training error: 0.33209636864189274\n",
            "At step: 2755 training error: 0.33970556102562904\n",
            "At step: 2756 training error: 0.3478474191765112\n",
            "At step: 2757 training error: 0.34371912543211686\n",
            "At step: 2758 training error: 0.3506167590197077\n",
            "At step: 2759 training error: 0.3474497814999597\n",
            "At step: 2760 training error: 0.3643219240311411\n",
            "At step: 2761 training error: 0.3577181640205159\n",
            "At step: 2762 training error: 0.36142338665760776\n",
            "At step: 2763 training error: 0.3700299933063439\n",
            "At step: 2764 training error: 0.36712397438523553\n",
            "At step: 2765 training error: 0.3687139564866287\n",
            "At step: 2766 training error: 0.3727624879641862\n",
            "At step: 2767 training error: 0.36989163928768143\n",
            "At step: 2768 training error: 0.3654481807966957\n",
            "At step: 2769 training error: 0.36700930847113844\n",
            "At step: 2770 training error: 0.361925615523578\n",
            "At step: 2771 training error: 0.34712766075870727\n",
            "At step: 2772 training error: 0.3472622629005281\n",
            "At step: 2773 training error: 0.3467639382774525\n",
            "At step: 2774 training error: 0.35364852871160246\n",
            "At step: 2775 training error: 0.3547259576847601\n",
            "At step: 2776 training error: 0.338381694017238\n",
            "At step: 2777 training error: 0.33579788385220316\n",
            "At step: 2778 training error: 0.3419051331603049\n",
            "At step: 2779 training error: 0.3391894552012802\n",
            "At step: 2780 training error: 0.3313975282136438\n",
            "At step: 2781 training error: 0.32519809206728195\n",
            "At step: 2782 training error: 0.32655276973149794\n",
            "At step: 2783 training error: 0.3310593648738304\n",
            "At step: 2784 training error: 0.32991207892241536\n",
            "At step: 2785 training error: 0.32701785691652596\n",
            "At step: 2786 training error: 0.32758453432365964\n",
            "At step: 2787 training error: 0.32568584810632706\n",
            "At step: 2788 training error: 0.3236708808318815\n",
            "At step: 2789 training error: 0.3337510456963408\n",
            "At step: 2790 training error: 0.33538937426810045\n",
            "At step: 2791 training error: 0.34153966421676984\n",
            "At step: 2792 training error: 0.3367720757918867\n",
            "At step: 2793 training error: 0.34567812699461575\n",
            "At step: 2794 training error: 0.35163341371918083\n",
            "At step: 2795 training error: 0.3534638463494538\n",
            "At step: 2796 training error: 0.3512088389384821\n",
            "At step: 2797 training error: 0.3389682471317783\n",
            "At step: 2798 training error: 0.32612092650113217\n",
            "At step: 2799 training error: 0.3197592109102093\n",
            "At step: 2800 training error: 0.31682458598503527\n",
            "At step: 2801 training error: 0.3316803421031812\n",
            "At step: 2802 training error: 0.3293182559816687\n",
            "At step: 2803 training error: 0.33149299056904546\n",
            "At step: 2804 training error: 0.3350326176252154\n",
            "At step: 2805 training error: 0.33432681515737556\n",
            "At step: 2806 training error: 0.3390509803399754\n",
            "At step: 2807 training error: 0.3275535391387989\n",
            "At step: 2808 training error: 0.3224832216982777\n",
            "At step: 2809 training error: 0.33523556351456085\n",
            "At step: 2810 training error: 0.3435701300939384\n",
            "At step: 2811 training error: 0.34470227331120756\n",
            "At step: 2812 training error: 0.34767433277882015\n",
            "At step: 2813 training error: 0.3548575410576349\n",
            "At step: 2814 training error: 0.3600635691598629\n",
            "At step: 2815 training error: 0.3554488116354817\n",
            "At step: 2816 training error: 0.34797872606265495\n",
            "At step: 2817 training error: 0.34682910347880685\n",
            "At step: 2818 training error: 0.34357271298962344\n",
            "At step: 2819 training error: 0.33312024487489467\n",
            "At step: 2820 training error: 0.33695584786416366\n",
            "At step: 2821 training error: 0.33614328945029637\n",
            "At step: 2822 training error: 0.33219615075791775\n",
            "At step: 2823 training error: 0.33428055695321995\n",
            "At step: 2824 training error: 0.3348131970731103\n",
            "At step: 2825 training error: 0.3319532637976352\n",
            "At step: 2826 training error: 0.33005515009501746\n",
            "At step: 2827 training error: 0.31979723950495803\n",
            "At step: 2828 training error: 0.3231113358915556\n",
            "At step: 2829 training error: 0.3270775359304826\n",
            "At step: 2830 training error: 0.331893289348562\n",
            "At step: 2831 training error: 0.33414169439863256\n",
            "At step: 2832 training error: 0.3294066753321317\n",
            "At step: 2833 training error: 0.3378417711324676\n",
            "At step: 2834 training error: 0.3293882389587487\n",
            "At step: 2835 training error: 0.3205846338963462\n",
            "At step: 2836 training error: 0.32707620480821664\n",
            "At step: 2837 training error: 0.3302976730045453\n",
            "At step: 2838 training error: 0.3306774447360821\n",
            "At step: 2839 training error: 0.3338386844982982\n",
            "At step: 2840 training error: 0.3341788906450395\n",
            "At step: 2841 training error: 0.33695636435968407\n",
            "At step: 2842 training error: 0.3410042740707797\n",
            "At step: 2843 training error: 0.33779129818921577\n",
            "At step: 2844 training error: 0.3283607985340762\n",
            "At step: 2845 training error: 0.32903350038138224\n",
            "At step: 2846 training error: 0.3291524213803175\n",
            "At step: 2847 training error: 0.32918161442147126\n",
            "At step: 2848 training error: 0.33281340714161695\n",
            "At step: 2849 training error: 0.33717621316487656\n",
            "At step: 2850 training error: 0.32814436505527356\n",
            "At step: 2851 training error: 0.3195577823943836\n",
            "At step: 2852 training error: 0.3302211125738435\n",
            "At step: 2853 training error: 0.3206015390614204\n",
            "At step: 2854 training error: 0.32161141263235216\n",
            "At step: 2855 training error: 0.32096225581152216\n",
            "At step: 2856 training error: 0.33116384631873946\n",
            "At step: 2857 training error: 0.3361934109447277\n",
            "At step: 2858 training error: 0.329101170836656\n",
            "At step: 2859 training error: 0.3194721840549699\n",
            "At step: 2860 training error: 0.3161323652292575\n",
            "At step: 2861 training error: 0.3207229470214687\n",
            "At step: 2862 training error: 0.33082228556500387\n",
            "At step: 2863 training error: 0.33980354019457826\n",
            "At step: 2864 training error: 0.3382564752502637\n",
            "At step: 2865 training error: 0.3318392644308662\n",
            "At step: 2866 training error: 0.33324022207518356\n",
            "At step: 2867 training error: 0.324613215658937\n",
            "At step: 2868 training error: 0.3379334004909473\n",
            "At step: 2869 training error: 0.3521796537159605\n",
            "At step: 2870 training error: 0.35524670098031497\n",
            "At step: 2871 training error: 0.3532311831912315\n",
            "At step: 2872 training error: 0.35049046977207\n",
            "At step: 2873 training error: 0.3510124341031122\n",
            "At step: 2874 training error: 0.3439476539481637\n",
            "At step: 2875 training error: 0.3409700611190631\n",
            "At step: 2876 training error: 0.33052488671033714\n",
            "At step: 2877 training error: 0.31907326862893265\n",
            "At step: 2878 training error: 0.3372245582573995\n",
            "At step: 2879 training error: 0.32790971066689883\n",
            "At step: 2880 training error: 0.33248477056653114\n",
            "At step: 2881 training error: 0.3383229614012083\n",
            "At step: 2882 training error: 0.3394282802502441\n",
            "At step: 2883 training error: 0.3524439840753641\n",
            "At step: 2884 training error: 0.3402074565580531\n",
            "At step: 2885 training error: 0.3391796496921234\n",
            "At step: 2886 training error: 0.34055947683479465\n",
            "At step: 2887 training error: 0.34677586930631354\n",
            "At step: 2888 training error: 0.340871824145793\n",
            "At step: 2889 training error: 0.33906764067326906\n",
            "At step: 2890 training error: 0.3439249026569721\n",
            "At step: 2891 training error: 0.34207501337973656\n",
            "At step: 2892 training error: 0.3438822079830598\n",
            "At step: 2893 training error: 0.3354769323630228\n",
            "At step: 2894 training error: 0.3435051479112983\n",
            "At step: 2895 training error: 0.3379754316188949\n",
            "At step: 2896 training error: 0.335386895757787\n",
            "At step: 2897 training error: 0.33793680702750245\n",
            "At step: 2898 training error: 0.3434248196195344\n",
            "At step: 2899 training error: 0.3379232417453243\n",
            "At step: 2900 training error: 0.32572291800447506\n",
            "At step: 2901 training error: 0.3198918789883067\n",
            "At step: 2902 training error: 0.31477989120058397\n",
            "At step: 2903 training error: 0.31930855899906974\n",
            "At step: 2904 training error: 0.3113962123961205\n",
            "At step: 2905 training error: 0.3132874422653496\n",
            "At step: 2906 training error: 0.30950463403359907\n",
            "At step: 2907 training error: 0.3115672122316624\n",
            "At step: 2908 training error: 0.3157782052200857\n",
            "At step: 2909 training error: 0.31182108399950453\n",
            "At step: 2910 training error: 0.3046622043349734\n",
            "At step: 2911 training error: 0.313364868332048\n",
            "At step: 2912 training error: 0.32290120767534386\n",
            "At step: 2913 training error: 0.3162216060238752\n",
            "At step: 2914 training error: 0.32204898747411814\n",
            "At step: 2915 training error: 0.31328787949887743\n",
            "At step: 2916 training error: 0.3036833866362656\n",
            "At step: 2917 training error: 0.30934613913454906\n",
            "At step: 2918 training error: 0.3008598615343075\n",
            "At step: 2919 training error: 0.3143511347519909\n",
            "At step: 2920 training error: 0.30376672978393515\n",
            "At step: 2921 training error: 0.31600324666516855\n",
            "At step: 2922 training error: 0.31702919040790983\n",
            "At step: 2923 training error: 0.3113186179855078\n",
            "At step: 2924 training error: 0.31123234418022977\n",
            "At step: 2925 training error: 0.3158827642154275\n",
            "At step: 2926 training error: 0.32401689292803304\n",
            "At step: 2927 training error: 0.3389969089719754\n",
            "At step: 2928 training error: 0.3344608924993323\n",
            "At step: 2929 training error: 0.33291957258126137\n",
            "At step: 2930 training error: 0.3467115366897259\n",
            "At step: 2931 training error: 0.3432348995090749\n",
            "At step: 2932 training error: 0.3395563880326475\n",
            "At step: 2933 training error: 0.3411525269498934\n",
            "At step: 2934 training error: 0.34233118141098473\n",
            "At step: 2935 training error: 0.32892219445099\n",
            "At step: 2936 training error: 0.33027922253827113\n",
            "At step: 2937 training error: 0.32385743962268093\n",
            "At step: 2938 training error: 0.3172546053730091\n",
            "At step: 2939 training error: 0.31238148996415577\n",
            "At step: 2940 training error: 0.3028772132213474\n",
            "At step: 2941 training error: 0.3083749550430832\n",
            "At step: 2942 training error: 0.3007310008701485\n",
            "At step: 2943 training error: 0.30461169461487075\n",
            "At step: 2944 training error: 0.3088224130013293\n",
            "At step: 2945 training error: 0.29818796993392793\n",
            "At step: 2946 training error: 0.2958787574018656\n",
            "At step: 2947 training error: 0.2982086370078621\n",
            "At step: 2948 training error: 0.305146888569825\n",
            "At step: 2949 training error: 0.30846756517951707\n",
            "At step: 2950 training error: 0.3121712975636267\n",
            "At step: 2951 training error: 0.31469194142565704\n",
            "At step: 2952 training error: 0.3143573909508534\n",
            "At step: 2953 training error: 0.3225626762895116\n",
            "At step: 2954 training error: 0.3218831175255963\n",
            "At step: 2955 training error: 0.323955426425294\n",
            "At step: 2956 training error: 0.3232373246738628\n",
            "At step: 2957 training error: 0.3200276281846435\n",
            "At step: 2958 training error: 0.32334534990511976\n",
            "At step: 2959 training error: 0.32429813924539014\n",
            "At step: 2960 training error: 0.3154444846623828\n",
            "At step: 2961 training error: 0.3096674173717875\n",
            "At step: 2962 training error: 0.31269463389004465\n",
            "At step: 2963 training error: 0.3152434581223322\n",
            "At step: 2964 training error: 0.31655875327970584\n",
            "At step: 2965 training error: 0.3137534640223625\n",
            "At step: 2966 training error: 0.3092825160689836\n",
            "At step: 2967 training error: 0.31967350458763055\n",
            "At step: 2968 training error: 0.310200881843374\n",
            "At step: 2969 training error: 0.3143525724225801\n",
            "At step: 2970 training error: 0.30575139237286697\n",
            "At step: 2971 training error: 0.31226967539784334\n",
            "At step: 2972 training error: 0.3193588722947432\n",
            "At step: 2973 training error: 0.31362755604601766\n",
            "At step: 2974 training error: 0.31969266545982683\n",
            "At step: 2975 training error: 0.3255635150824475\n",
            "At step: 2976 training error: 0.3258207023758505\n",
            "At step: 2977 training error: 0.3271351773758255\n",
            "At step: 2978 training error: 0.32638250365621957\n",
            "At step: 2979 training error: 0.3397298726736535\n",
            "At step: 2980 training error: 0.3396193588383529\n",
            "At step: 2981 training error: 0.33593591541575807\n",
            "At step: 2982 training error: 0.33483854634529997\n",
            "At step: 2983 training error: 0.3290013480527564\n",
            "At step: 2984 training error: 0.33031464618850415\n",
            "At step: 2985 training error: 0.3238156579655143\n",
            "At step: 2986 training error: 0.3247229332448598\n",
            "At step: 2987 training error: 0.32899378607974095\n",
            "At step: 2988 training error: 0.34447371071950145\n",
            "At step: 2989 training error: 0.33770652405425333\n",
            "At step: 2990 training error: 0.3368658035445712\n",
            "At step: 2991 training error: 0.3460272593095647\n",
            "At step: 2992 training error: 0.3355831390804609\n",
            "At step: 2993 training error: 0.33637769843258325\n",
            "At step: 2994 training error: 0.33442955900845367\n",
            "At step: 2995 training error: 0.33028919380013594\n",
            "At step: 2996 training error: 0.3273185374817188\n",
            "At step: 2997 training error: 0.3284419010037528\n",
            "At step: 2998 training error: 0.3173017497241715\n",
            "At step: 2999 training error: 0.3139664433503525\n",
            "At step: 3000 training error: 0.3186846940232286\n",
            "At step: 3001 training error: 0.32352471421908646\n",
            "At step: 3002 training error: 0.3142457520104466\n",
            "At step: 3003 training error: 0.3092035694650565\n",
            "At step: 3004 training error: 0.30441953019551155\n",
            "At step: 3005 training error: 0.31739599091155385\n",
            "At step: 3006 training error: 0.3150829875442093\n",
            "At step: 3007 training error: 0.3138233624825033\n",
            "At step: 3008 training error: 0.31597278948099805\n",
            "At step: 3009 training error: 0.31565083034359576\n",
            "At step: 3010 training error: 0.3172551815822843\n",
            "At step: 3011 training error: 0.31844467941885335\n",
            "At step: 3012 training error: 0.3246352458960196\n",
            "At step: 3013 training error: 0.3141041370493439\n",
            "At step: 3014 training error: 0.30482978882695116\n",
            "At step: 3015 training error: 0.31689828678730336\n",
            "At step: 3016 training error: 0.3221874746054318\n",
            "At step: 3017 training error: 0.31874081863672\n",
            "At step: 3018 training error: 0.3191613750642909\n",
            "At step: 3019 training error: 0.3181518321918439\n",
            "At step: 3020 training error: 0.30769073956022963\n",
            "At step: 3021 training error: 0.3047774240979318\n",
            "At step: 3022 training error: 0.3059717296946371\n",
            "At step: 3023 training error: 0.3013900348285611\n",
            "At step: 3024 training error: 0.29853330966175984\n",
            "At step: 3025 training error: 0.29712551957668165\n",
            "At step: 3026 training error: 0.30248206554221996\n",
            "At step: 3027 training error: 0.310063081414431\n",
            "At step: 3028 training error: 0.31152574317933607\n",
            "At step: 3029 training error: 0.3048374378603096\n",
            "At step: 3030 training error: 0.3108062021557616\n",
            "At step: 3031 training error: 0.304820753810055\n",
            "At step: 3032 training error: 0.3006162632365907\n",
            "At step: 3033 training error: 0.3209875144935921\n",
            "At step: 3034 training error: 0.328414655151783\n",
            "At step: 3035 training error: 0.3291756329632117\n",
            "At step: 3036 training error: 0.3250485307382571\n",
            "At step: 3037 training error: 0.3259777033932548\n",
            "At step: 3038 training error: 0.3368077399144699\n",
            "At step: 3039 training error: 0.3394867465238158\n",
            "At step: 3040 training error: 0.34369437742560915\n",
            "At step: 3041 training error: 0.3456394817539036\n",
            "At step: 3042 training error: 0.3440124791091986\n",
            "At step: 3043 training error: 0.34072768107615337\n",
            "At step: 3044 training error: 0.3364562591371998\n",
            "At step: 3045 training error: 0.32483290925119496\n",
            "At step: 3046 training error: 0.3196847994064936\n",
            "At step: 3047 training error: 0.3117529388990094\n",
            "At step: 3048 training error: 0.30210264059190733\n",
            "At step: 3049 training error: 0.29865917317625446\n",
            "At step: 3050 training error: 0.300515726770472\n",
            "At step: 3051 training error: 0.3134264521229165\n",
            "At step: 3052 training error: 0.32364409974837816\n",
            "At step: 3053 training error: 0.32379122877411437\n",
            "At step: 3054 training error: 0.3219744008564125\n",
            "At step: 3055 training error: 0.31889921271278826\n",
            "At step: 3056 training error: 0.32767237646781044\n",
            "At step: 3057 training error: 0.32519866864760966\n",
            "At step: 3058 training error: 0.33334439468897675\n",
            "At step: 3059 training error: 0.33352605532542434\n",
            "At step: 3060 training error: 0.32958321571315596\n",
            "At step: 3061 training error: 0.3282296454130372\n",
            "At step: 3062 training error: 0.3286957883186621\n",
            "At step: 3063 training error: 0.3209537142605647\n",
            "At step: 3064 training error: 0.32720836882272397\n",
            "At step: 3065 training error: 0.32811694638381256\n",
            "At step: 3066 training error: 0.32754438257966473\n",
            "At step: 3067 training error: 0.32051531324883076\n",
            "At step: 3068 training error: 0.3107876718322975\n",
            "At step: 3069 training error: 0.32312333132980053\n",
            "At step: 3070 training error: 0.31872451871670227\n",
            "At step: 3071 training error: 0.31539780571559745\n",
            "At step: 3072 training error: 0.3290933660811981\n",
            "At step: 3073 training error: 0.3235670278000662\n",
            "At step: 3074 training error: 0.31833277895249956\n",
            "At step: 3075 training error: 0.31785913489944984\n",
            "At step: 3076 training error: 0.33374457268400115\n",
            "At step: 3077 training error: 0.3312648754610195\n",
            "At step: 3078 training error: 0.3292884788167043\n",
            "At step: 3079 training error: 0.3283907476897829\n",
            "At step: 3080 training error: 0.328446314675205\n",
            "At step: 3081 training error: 0.32119496960088195\n",
            "At step: 3082 training error: 0.3202797044285174\n",
            "At step: 3083 training error: 0.3249497848773795\n",
            "At step: 3084 training error: 0.32286145370973096\n",
            "At step: 3085 training error: 0.3280964443497089\n",
            "At step: 3086 training error: 0.3199037597380717\n",
            "At step: 3087 training error: 0.323379040205517\n",
            "At step: 3088 training error: 0.3345372874954656\n",
            "At step: 3089 training error: 0.3426143659756355\n",
            "At step: 3090 training error: 0.34886575831893263\n",
            "At step: 3091 training error: 0.3680350761710344\n",
            "At step: 3092 training error: 0.3546992749423818\n",
            "At step: 3093 training error: 0.35872981662310716\n",
            "At step: 3094 training error: 0.3583396306805535\n",
            "At step: 3095 training error: 0.3587114660189831\n",
            "At step: 3096 training error: 0.35755737230814716\n",
            "At step: 3097 training error: 0.35800091243466814\n",
            "At step: 3098 training error: 0.3463170360965846\n",
            "At step: 3099 training error: 0.34082727731158674\n",
            "At step: 3100 training error: 0.33690044324574875\n",
            "At step: 3101 training error: 0.34150149126459173\n",
            "At step: 3102 training error: 0.3338969250325703\n",
            "At step: 3103 training error: 0.3388900830892015\n",
            "At step: 3104 training error: 0.3234373846573048\n",
            "At step: 3105 training error: 0.31723881337760973\n",
            "At step: 3106 training error: 0.3240451648078845\n",
            "At step: 3107 training error: 0.3214597184656045\n",
            "At step: 3108 training error: 0.32475589966056667\n",
            "At step: 3109 training error: 0.3188457392950068\n",
            "At step: 3110 training error: 0.32348145838915043\n",
            "At step: 3111 training error: 0.3252059578514557\n",
            "At step: 3112 training error: 0.32510514688824704\n",
            "At step: 3113 training error: 0.32401861060878734\n",
            "At step: 3114 training error: 0.3239720017047598\n",
            "At step: 3115 training error: 0.3249900406051316\n",
            "At step: 3116 training error: 0.3327773391416288\n",
            "At step: 3117 training error: 0.3233493583721438\n",
            "At step: 3118 training error: 0.32686387143356854\n",
            "At step: 3119 training error: 0.33316074763145603\n",
            "At step: 3120 training error: 0.3284066100979847\n",
            "At step: 3121 training error: 0.32995330473717116\n",
            "At step: 3122 training error: 0.33480164257929435\n",
            "At step: 3123 training error: 0.3470680473720028\n",
            "At step: 3124 training error: 0.33653456083085803\n",
            "At step: 3125 training error: 0.3336680884845923\n",
            "At step: 3126 training error: 0.3322575200896876\n",
            "At step: 3127 training error: 0.33396836375687206\n",
            "At step: 3128 training error: 0.3282798298839858\n",
            "At step: 3129 training error: 0.32739473532199\n",
            "At step: 3130 training error: 0.32373157873256486\n",
            "At step: 3131 training error: 0.3228056354664857\n",
            "At step: 3132 training error: 0.3392983396663934\n",
            "At step: 3133 training error: 0.33684750338987496\n",
            "At step: 3134 training error: 0.3231828000562004\n",
            "At step: 3135 training error: 0.3278700906478302\n",
            "At step: 3136 training error: 0.33418083529264814\n",
            "At step: 3137 training error: 0.3278361063615762\n",
            "At step: 3138 training error: 0.33432450190063323\n",
            "At step: 3139 training error: 0.3296458768055226\n",
            "At step: 3140 training error: 0.33337193796212355\n",
            "At step: 3141 training error: 0.3278442459549017\n",
            "At step: 3142 training error: 0.32456277734409184\n",
            "At step: 3143 training error: 0.33544924061175546\n",
            "At step: 3144 training error: 0.3305258654847426\n",
            "At step: 3145 training error: 0.3483384180733399\n",
            "At step: 3146 training error: 0.3410785875958207\n",
            "At step: 3147 training error: 0.34467208718175696\n",
            "At step: 3148 training error: 0.33519757585078946\n",
            "At step: 3149 training error: 0.3337735530467082\n",
            "At step: 3150 training error: 0.3405578578182993\n",
            "At step: 3151 training error: 0.3398160145943453\n",
            "At step: 3152 training error: 0.34063546426600433\n",
            "At step: 3153 training error: 0.34758995271927495\n",
            "At step: 3154 training error: 0.35118459337162455\n",
            "At step: 3155 training error: 0.35618828586184526\n",
            "At step: 3156 training error: 0.3593791143489842\n",
            "At step: 3157 training error: 0.3601237908428042\n",
            "At step: 3158 training error: 0.35556085137028753\n",
            "At step: 3159 training error: 0.3515273903213023\n",
            "At step: 3160 training error: 0.3524520334298983\n",
            "At step: 3161 training error: 0.3448538456579982\n",
            "At step: 3162 training error: 0.3428332551870584\n",
            "At step: 3163 training error: 0.33233028594916963\n",
            "At step: 3164 training error: 0.32727377770662086\n",
            "At step: 3165 training error: 0.33217527286580145\n",
            "At step: 3166 training error: 0.3390898317848362\n",
            "At step: 3167 training error: 0.3309441407663789\n",
            "At step: 3168 training error: 0.32450260834769046\n",
            "At step: 3169 training error: 0.3346218468940236\n",
            "At step: 3170 training error: 0.32127738660690575\n",
            "At step: 3171 training error: 0.3208907335022768\n",
            "At step: 3172 training error: 0.31568840978839924\n",
            "At step: 3173 training error: 0.31815268449249734\n",
            "At step: 3174 training error: 0.32434431352416665\n",
            "At step: 3175 training error: 0.3349519316472194\n",
            "At step: 3176 training error: 0.33183164470225224\n",
            "At step: 3177 training error: 0.33968149651836027\n",
            "At step: 3178 training error: 0.327878240754752\n",
            "At step: 3179 training error: 0.33028918463630763\n",
            "At step: 3180 training error: 0.321802397992928\n",
            "At step: 3181 training error: 0.3246704997809194\n",
            "At step: 3182 training error: 0.3286405458984915\n",
            "At step: 3183 training error: 0.32742953035962785\n",
            "At step: 3184 training error: 0.3273848607648996\n",
            "At step: 3185 training error: 0.32963107642918965\n",
            "At step: 3186 training error: 0.33554034835362956\n",
            "At step: 3187 training error: 0.3460134883661206\n",
            "At step: 3188 training error: 0.34642007250072643\n",
            "At step: 3189 training error: 0.3496681017048828\n",
            "At step: 3190 training error: 0.35413973720144776\n",
            "At step: 3191 training error: 0.3537250895480962\n",
            "At step: 3192 training error: 0.3602780150876223\n",
            "At step: 3193 training error: 0.3593725770542383\n",
            "At step: 3194 training error: 0.36510374188415157\n",
            "At step: 3195 training error: 0.3643958184607117\n",
            "At step: 3196 training error: 0.36576719806748825\n",
            "At step: 3197 training error: 0.3571942865658809\n",
            "At step: 3198 training error: 0.3698039700763688\n",
            "At step: 3199 training error: 0.3665779019378755\n",
            "At step: 3200 training error: 0.35669011013050406\n",
            "At step: 3201 training error: 0.35404319386725375\n",
            "At step: 3202 training error: 0.34285959419059975\n",
            "At step: 3203 training error: 0.3465279739137673\n",
            "At step: 3204 training error: 0.3420005774885937\n",
            "At step: 3205 training error: 0.3324612952069348\n",
            "At step: 3206 training error: 0.33297111495024134\n",
            "At step: 3207 training error: 0.3327787926631124\n",
            "At step: 3208 training error: 0.33503256567796774\n",
            "At step: 3209 training error: 0.322706983009519\n",
            "At step: 3210 training error: 0.3160633711834315\n",
            "At step: 3211 training error: 0.31814298941425756\n",
            "At step: 3212 training error: 0.3280845054506199\n",
            "At step: 3213 training error: 0.32579843865323355\n",
            "At step: 3214 training error: 0.33772487831402775\n",
            "At step: 3215 training error: 0.339501534169047\n",
            "At step: 3216 training error: 0.33521676155573266\n",
            "At step: 3217 training error: 0.3273940247070235\n",
            "At step: 3218 training error: 0.34244825037072196\n",
            "At step: 3219 training error: 0.33926441412025293\n",
            "At step: 3220 training error: 0.33000646246180215\n",
            "At step: 3221 training error: 0.32852697115332524\n",
            "At step: 3222 training error: 0.33433480547283034\n",
            "At step: 3223 training error: 0.324535268143788\n",
            "At step: 3224 training error: 0.33827843726711077\n",
            "At step: 3225 training error: 0.33031143047682476\n",
            "At step: 3226 training error: 0.3309373880956784\n",
            "At step: 3227 training error: 0.330072963572978\n",
            "At step: 3228 training error: 0.32920615983050167\n",
            "At step: 3229 training error: 0.32916370544012474\n",
            "At step: 3230 training error: 0.32469508064316543\n",
            "At step: 3231 training error: 0.32712125968770644\n",
            "At step: 3232 training error: 0.3239880691511979\n",
            "At step: 3233 training error: 0.32703503823136326\n",
            "At step: 3234 training error: 0.3298414304068718\n",
            "At step: 3235 training error: 0.3298822629522832\n",
            "At step: 3236 training error: 0.3260796082307401\n",
            "At step: 3237 training error: 0.32088999815678154\n",
            "At step: 3238 training error: 0.3168703692765926\n",
            "At step: 3239 training error: 0.3250024641738062\n",
            "At step: 3240 training error: 0.33670389960492003\n",
            "At step: 3241 training error: 0.3342835139896748\n",
            "At step: 3242 training error: 0.33651020021876465\n",
            "At step: 3243 training error: 0.3350519082357113\n",
            "At step: 3244 training error: 0.3356600995935414\n",
            "At step: 3245 training error: 0.33690387170500824\n",
            "At step: 3246 training error: 0.3381643207437048\n",
            "At step: 3247 training error: 0.35029967498572806\n",
            "At step: 3248 training error: 0.35658398158665505\n",
            "At step: 3249 training error: 0.3483085219638216\n",
            "At step: 3250 training error: 0.3496763638227813\n",
            "At step: 3251 training error: 0.3485124111352768\n",
            "At step: 3252 training error: 0.34161081440130864\n",
            "At step: 3253 training error: 0.35550203994184487\n",
            "At step: 3254 training error: 0.3491732886725353\n",
            "At step: 3255 training error: 0.33985343283203506\n",
            "At step: 3256 training error: 0.3360471622260294\n",
            "At step: 3257 training error: 0.3357535142554653\n",
            "At step: 3258 training error: 0.32899398899932036\n",
            "At step: 3259 training error: 0.32388427354424265\n",
            "At step: 3260 training error: 0.32712557823432414\n",
            "At step: 3261 training error: 0.33342340508434626\n",
            "At step: 3262 training error: 0.3303587372049615\n",
            "At step: 3263 training error: 0.3258891172745783\n",
            "At step: 3264 training error: 0.32873794463561556\n",
            "At step: 3265 training error: 0.3232035712279881\n",
            "At step: 3266 training error: 0.3211502905656076\n",
            "At step: 3267 training error: 0.32705695072648017\n",
            "At step: 3268 training error: 0.33217014550187396\n",
            "At step: 3269 training error: 0.341803859872971\n",
            "At step: 3270 training error: 0.33987407434249806\n",
            "At step: 3271 training error: 0.3369625935097572\n",
            "At step: 3272 training error: 0.34350140307003363\n",
            "At step: 3273 training error: 0.34899765152221385\n",
            "At step: 3274 training error: 0.34604185985885433\n",
            "At step: 3275 training error: 0.3375732849996992\n",
            "At step: 3276 training error: 0.3311511505904702\n",
            "At step: 3277 training error: 0.3322118892582169\n",
            "At step: 3278 training error: 0.3311282104687336\n",
            "At step: 3279 training error: 0.32680198851958564\n",
            "At step: 3280 training error: 0.3252167836894311\n",
            "At step: 3281 training error: 0.3269630064774516\n",
            "At step: 3282 training error: 0.328514054184632\n",
            "At step: 3283 training error: 0.3324004275465823\n",
            "At step: 3284 training error: 0.3333915684146054\n",
            "At step: 3285 training error: 0.332582032716277\n",
            "At step: 3286 training error: 0.3389622079218432\n",
            "At step: 3287 training error: 0.34830374602816405\n",
            "At step: 3288 training error: 0.34699025827411906\n",
            "At step: 3289 training error: 0.3434400625564425\n",
            "At step: 3290 training error: 0.3371299046119499\n",
            "At step: 3291 training error: 0.3353525515906977\n",
            "At step: 3292 training error: 0.3392515796312352\n",
            "At step: 3293 training error: 0.33338418807727926\n",
            "At step: 3294 training error: 0.32694176681913534\n",
            "At step: 3295 training error: 0.32909555563309634\n",
            "At step: 3296 training error: 0.32931169418756945\n",
            "At step: 3297 training error: 0.32649682257097223\n",
            "At step: 3298 training error: 0.3270790669331645\n",
            "At step: 3299 training error: 0.3278270722981569\n",
            "At step: 3300 training error: 0.33308942197884817\n",
            "At step: 3301 training error: 0.3293285504630114\n",
            "At step: 3302 training error: 0.3283390491690953\n",
            "At step: 3303 training error: 0.32800368303574556\n",
            "At step: 3304 training error: 0.3302381182423725\n",
            "At step: 3305 training error: 0.32924357820643874\n",
            "At step: 3306 training error: 0.34899949090029775\n",
            "At step: 3307 training error: 0.33926592937707917\n",
            "At step: 3308 training error: 0.3469605868867188\n",
            "At step: 3309 training error: 0.3440150302858935\n",
            "At step: 3310 training error: 0.3396394549307401\n",
            "At step: 3311 training error: 0.3386254093481772\n",
            "At step: 3312 training error: 0.341687109739582\n",
            "At step: 3313 training error: 0.34463041345848117\n",
            "At step: 3314 training error: 0.3468576218433031\n",
            "At step: 3315 training error: 0.3442585496735473\n",
            "At step: 3316 training error: 0.3458642270956772\n",
            "At step: 3317 training error: 0.34014166559887027\n",
            "At step: 3318 training error: 0.33972193949531365\n",
            "At step: 3319 training error: 0.34590645071496895\n",
            "At step: 3320 training error: 0.3484131502493231\n",
            "At step: 3321 training error: 0.35111308689000936\n",
            "At step: 3322 training error: 0.35068509481260474\n",
            "At step: 3323 training error: 0.34477739697813753\n",
            "At step: 3324 training error: 0.3502347017246075\n",
            "At step: 3325 training error: 0.34132534479038046\n",
            "At step: 3326 training error: 0.33680616049259554\n",
            "At step: 3327 training error: 0.33732852382916345\n",
            "At step: 3328 training error: 0.33170522447631706\n",
            "At step: 3329 training error: 0.32687170438889657\n",
            "At step: 3330 training error: 0.33144431645417816\n",
            "At step: 3331 training error: 0.3367138156398374\n",
            "At step: 3332 training error: 0.3442361305928114\n",
            "At step: 3333 training error: 0.3444258197680229\n",
            "At step: 3334 training error: 0.34155151897720154\n",
            "At step: 3335 training error: 0.3442660727991463\n",
            "At step: 3336 training error: 0.3522165672510251\n",
            "At step: 3337 training error: 0.3561105729056507\n",
            "At step: 3338 training error: 0.36093893600395366\n",
            "At step: 3339 training error: 0.35880763420550266\n",
            "At step: 3340 training error: 0.3596933262536167\n",
            "At step: 3341 training error: 0.3598805934062955\n",
            "At step: 3342 training error: 0.3592089091183887\n",
            "At step: 3343 training error: 0.3668761507383237\n",
            "At step: 3344 training error: 0.36367225699141065\n",
            "At step: 3345 training error: 0.3520030792795566\n",
            "At step: 3346 training error: 0.34785139441508955\n",
            "At step: 3347 training error: 0.34881148030954445\n",
            "At step: 3348 training error: 0.3436196639598749\n",
            "At step: 3349 training error: 0.3498874431570417\n",
            "At step: 3350 training error: 0.35396196223801024\n",
            "At step: 3351 training error: 0.348743081627345\n",
            "At step: 3352 training error: 0.34606146473210364\n",
            "At step: 3353 training error: 0.3474263339689839\n",
            "At step: 3354 training error: 0.3362806668536081\n",
            "At step: 3355 training error: 0.3337259522733502\n",
            "At step: 3356 training error: 0.3390223012934943\n",
            "At step: 3357 training error: 0.3444286981170945\n",
            "At step: 3358 training error: 0.3517788058250785\n",
            "At step: 3359 training error: 0.3464022541939465\n",
            "At step: 3360 training error: 0.34851383596618335\n",
            "At step: 3361 training error: 0.33423677145261244\n",
            "At step: 3362 training error: 0.32775281578713966\n",
            "At step: 3363 training error: 0.31901620379402823\n",
            "At step: 3364 training error: 0.31945137706809634\n",
            "At step: 3365 training error: 0.31822081306234207\n",
            "At step: 3366 training error: 0.33036234915255647\n",
            "At step: 3367 training error: 0.32613097352328024\n",
            "At step: 3368 training error: 0.3287551237606287\n",
            "At step: 3369 training error: 0.3237838039588695\n",
            "At step: 3370 training error: 0.3239267003055105\n",
            "At step: 3371 training error: 0.31889915530394874\n",
            "At step: 3372 training error: 0.3224797741901614\n",
            "At step: 3373 training error: 0.33107172489424763\n",
            "At step: 3374 training error: 0.3319813640112146\n",
            "At step: 3375 training error: 0.3379867738657458\n",
            "At step: 3376 training error: 0.33219966775893395\n",
            "At step: 3377 training error: 0.33130814325209457\n",
            "At step: 3378 training error: 0.32019028216059175\n",
            "At step: 3379 training error: 0.3178375972600713\n",
            "At step: 3380 training error: 0.3210925388641072\n",
            "At step: 3381 training error: 0.3271048334048307\n",
            "At step: 3382 training error: 0.3305806579077163\n",
            "At step: 3383 training error: 0.3355349632367708\n",
            "At step: 3384 training error: 0.3322648935694251\n",
            "At step: 3385 training error: 0.34021770675746676\n",
            "At step: 3386 training error: 0.3461685696480972\n",
            "At step: 3387 training error: 0.3422876043856875\n",
            "At step: 3388 training error: 0.3450420639177297\n",
            "At step: 3389 training error: 0.3498817975173058\n",
            "At step: 3390 training error: 0.34743043466689\n",
            "At step: 3391 training error: 0.35886830631504646\n",
            "At step: 3392 training error: 0.3593519580286299\n",
            "At step: 3393 training error: 0.35863784278296945\n",
            "At step: 3394 training error: 0.3682750791162763\n",
            "At step: 3395 training error: 0.3736791130997343\n",
            "At step: 3396 training error: 0.3776606688947095\n",
            "At step: 3397 training error: 0.3689740706669585\n",
            "At step: 3398 training error: 0.36087645123942613\n",
            "At step: 3399 training error: 0.3660366972253909\n",
            "At step: 3400 training error: 0.361778592463976\n",
            "At step: 3401 training error: 0.3683525261657928\n",
            "At step: 3402 training error: 0.3652286236523336\n",
            "At step: 3403 training error: 0.36013426268722193\n",
            "At step: 3404 training error: 0.3533947260394059\n",
            "At step: 3405 training error: 0.34812208133721223\n",
            "At step: 3406 training error: 0.34122501275711453\n",
            "At step: 3407 training error: 0.3444283084879\n",
            "At step: 3408 training error: 0.3506591541439304\n",
            "At step: 3409 training error: 0.35322276503041083\n",
            "At step: 3410 training error: 0.37841891867399363\n",
            "At step: 3411 training error: 0.37723523072624754\n",
            "At step: 3412 training error: 0.3769426500447379\n",
            "At step: 3413 training error: 0.36205910264921665\n",
            "At step: 3414 training error: 0.3548205180641355\n",
            "At step: 3415 training error: 0.3449856516472906\n",
            "At step: 3416 training error: 0.3481581528249825\n",
            "At step: 3417 training error: 0.3382137475110678\n",
            "At step: 3418 training error: 0.347993808090599\n",
            "At step: 3419 training error: 0.3426040154744911\n",
            "At step: 3420 training error: 0.3333911267209693\n",
            "At step: 3421 training error: 0.3361055125880718\n",
            "At step: 3422 training error: 0.33181203147078525\n",
            "At step: 3423 training error: 0.3207846684648929\n",
            "At step: 3424 training error: 0.3300657833718398\n",
            "At step: 3425 training error: 0.32795032152483566\n",
            "At step: 3426 training error: 0.3251460366387799\n",
            "At step: 3427 training error: 0.329384567543272\n",
            "At step: 3428 training error: 0.3375289114707531\n",
            "At step: 3429 training error: 0.33427778553333176\n",
            "At step: 3430 training error: 0.33337088650678565\n",
            "At step: 3431 training error: 0.34301236477550856\n",
            "At step: 3432 training error: 0.34461894084203937\n",
            "At step: 3433 training error: 0.34696443393611537\n",
            "At step: 3434 training error: 0.35826078431205\n",
            "At step: 3435 training error: 0.3509015109135498\n",
            "At step: 3436 training error: 0.3521658338559258\n",
            "At step: 3437 training error: 0.35773181042616975\n",
            "At step: 3438 training error: 0.35127851507163327\n",
            "At step: 3439 training error: 0.3466474243669022\n",
            "At step: 3440 training error: 0.3396191754650526\n",
            "At step: 3441 training error: 0.3389876546252556\n",
            "At step: 3442 training error: 0.34448977242814416\n",
            "At step: 3443 training error: 0.34214702839938166\n",
            "At step: 3444 training error: 0.337423898171183\n",
            "At step: 3445 training error: 0.3415261239484586\n",
            "At step: 3446 training error: 0.33434397229982665\n",
            "At step: 3447 training error: 0.3369247592339217\n",
            "At step: 3448 training error: 0.3374440813623879\n",
            "At step: 3449 training error: 0.33454170635508634\n",
            "At step: 3450 training error: 0.3386925601977826\n",
            "At step: 3451 training error: 0.34466262439808615\n",
            "At step: 3452 training error: 0.3338409642180762\n",
            "At step: 3453 training error: 0.33985082133637584\n",
            "At step: 3454 training error: 0.33492846449169894\n",
            "At step: 3455 training error: 0.3344081600124825\n",
            "At step: 3456 training error: 0.32342245044994705\n",
            "At step: 3457 training error: 0.32718238599833727\n",
            "At step: 3458 training error: 0.32340531232484676\n",
            "At step: 3459 training error: 0.3264643235541707\n",
            "At step: 3460 training error: 0.32920781909307817\n",
            "At step: 3461 training error: 0.3276337301098915\n",
            "At step: 3462 training error: 0.3402403243981392\n",
            "At step: 3463 training error: 0.34284789317821096\n",
            "At step: 3464 training error: 0.3438062684063464\n",
            "At step: 3465 training error: 0.3419499680628492\n",
            "At step: 3466 training error: 0.3332435930510415\n",
            "At step: 3467 training error: 0.3299514406438907\n",
            "At step: 3468 training error: 0.33222804175299875\n",
            "At step: 3469 training error: 0.34161320555831437\n",
            "At step: 3470 training error: 0.33781355306234884\n",
            "At step: 3471 training error: 0.3353129495855582\n",
            "At step: 3472 training error: 0.33465542710524426\n",
            "At step: 3473 training error: 0.3270824727361518\n",
            "At step: 3474 training error: 0.35526951536547013\n",
            "At step: 3475 training error: 0.3643113631436335\n",
            "At step: 3476 training error: 0.36307555033758515\n",
            "At step: 3477 training error: 0.35770335057461056\n",
            "At step: 3478 training error: 0.356551621305085\n",
            "At step: 3479 training error: 0.34938879983068266\n",
            "At step: 3480 training error: 0.3467220094833996\n",
            "At step: 3481 training error: 0.34569897681452766\n",
            "At step: 3482 training error: 0.3417572985642711\n",
            "At step: 3483 training error: 0.34378768354122935\n",
            "At step: 3484 training error: 0.3340219477901463\n",
            "At step: 3485 training error: 0.32560279574381557\n",
            "At step: 3486 training error: 0.32964440500321723\n",
            "At step: 3487 training error: 0.3460051722893773\n",
            "At step: 3488 training error: 0.33751032042068574\n",
            "At step: 3489 training error: 0.3402974654306905\n",
            "At step: 3490 training error: 0.33409739437767\n",
            "At step: 3491 training error: 0.33176617056267105\n",
            "At step: 3492 training error: 0.3292821359341101\n",
            "At step: 3493 training error: 0.3263690475282345\n",
            "At step: 3494 training error: 0.3346878322255983\n",
            "At step: 3495 training error: 0.33835775726327655\n",
            "At step: 3496 training error: 0.3417784094096734\n",
            "At step: 3497 training error: 0.3482546139690524\n",
            "At step: 3498 training error: 0.3485801739196129\n",
            "At step: 3499 training error: 0.33619457299584643\n",
            "At step: 3500 training error: 0.3426852474803919\n",
            "At step: 3501 training error: 0.34337751175359715\n",
            "At step: 3502 training error: 0.3369163409660979\n",
            "At step: 3503 training error: 0.3325941306426059\n",
            "At step: 3504 training error: 0.333817821916029\n",
            "At step: 3505 training error: 0.32293010744927675\n",
            "At step: 3506 training error: 0.32314976605881823\n",
            "At step: 3507 training error: 0.32252865109637113\n",
            "At step: 3508 training error: 0.33056780229507005\n",
            "At step: 3509 training error: 0.3313469405237698\n",
            "At step: 3510 training error: 0.32874368642123664\n",
            "At step: 3511 training error: 0.3272774263525521\n",
            "At step: 3512 training error: 0.3270084817794879\n",
            "At step: 3513 training error: 0.3248717390905737\n",
            "At step: 3514 training error: 0.3361001625728759\n",
            "At step: 3515 training error: 0.33311270804172805\n",
            "At step: 3516 training error: 0.3344767946734923\n",
            "At step: 3517 training error: 0.33349107126384164\n",
            "At step: 3518 training error: 0.3292959503789424\n",
            "At step: 3519 training error: 0.32050622502857684\n",
            "At step: 3520 training error: 0.3214993114840996\n",
            "At step: 3521 training error: 0.3270753911482438\n",
            "At step: 3522 training error: 0.3311460369846431\n",
            "At step: 3523 training error: 0.3298134109610756\n",
            "At step: 3524 training error: 0.3397517004172182\n",
            "At step: 3525 training error: 0.33705277633059666\n",
            "At step: 3526 training error: 0.3353073619033129\n",
            "At step: 3527 training error: 0.33605196403652293\n",
            "At step: 3528 training error: 0.33596641701762686\n",
            "At step: 3529 training error: 0.3264556884576074\n",
            "At step: 3530 training error: 0.3257253833142642\n",
            "At step: 3531 training error: 0.32487077985119456\n",
            "At step: 3532 training error: 0.3101423096920673\n",
            "At step: 3533 training error: 0.32099802823114515\n",
            "At step: 3534 training error: 0.3199989992686004\n",
            "At step: 3535 training error: 0.3216800452444967\n",
            "At step: 3536 training error: 0.3159987397034913\n",
            "At step: 3537 training error: 0.3221339886748752\n",
            "At step: 3538 training error: 0.30424521542529465\n",
            "At step: 3539 training error: 0.29959515352504934\n",
            "At step: 3540 training error: 0.2894820519070342\n",
            "At step: 3541 training error: 0.28492628674412734\n",
            "At step: 3542 training error: 0.2934771722308485\n",
            "At step: 3543 training error: 0.297651250094308\n",
            "At step: 3544 training error: 0.2937440682866591\n",
            "At step: 3545 training error: 0.3177347062241913\n",
            "At step: 3546 training error: 0.3222375048173116\n",
            "At step: 3547 training error: 0.32455353078835286\n",
            "At step: 3548 training error: 0.3294296053145397\n",
            "At step: 3549 training error: 0.3268051541391643\n",
            "At step: 3550 training error: 0.31578567274983177\n",
            "At step: 3551 training error: 0.31258726203026715\n",
            "At step: 3552 training error: 0.31665776392709505\n",
            "At step: 3553 training error: 0.3208150395599338\n",
            "At step: 3554 training error: 0.32737890829136707\n",
            "At step: 3555 training error: 0.3242954581470699\n",
            "At step: 3556 training error: 0.3224378030823673\n",
            "At step: 3557 training error: 0.32592728627402184\n",
            "At step: 3558 training error: 0.32707691778988845\n",
            "At step: 3559 training error: 0.33775921783096485\n",
            "At step: 3560 training error: 0.3365976971711392\n",
            "At step: 3561 training error: 0.3295504918847658\n",
            "At step: 3562 training error: 0.3278600542968553\n",
            "At step: 3563 training error: 0.3253409378520546\n",
            "At step: 3564 training error: 0.3305648304300697\n",
            "At step: 3565 training error: 0.3383163318840495\n",
            "At step: 3566 training error: 0.34404472452140383\n",
            "At step: 3567 training error: 0.33741512042613864\n",
            "At step: 3568 training error: 0.337270510453095\n",
            "At step: 3569 training error: 0.3417638891066512\n",
            "At step: 3570 training error: 0.3477349915381682\n",
            "At step: 3571 training error: 0.3398769942493204\n",
            "At step: 3572 training error: 0.33898365636838423\n",
            "At step: 3573 training error: 0.34293236556443024\n",
            "At step: 3574 training error: 0.3488180271997143\n",
            "At step: 3575 training error: 0.3543697651921946\n",
            "At step: 3576 training error: 0.34227792541978536\n",
            "At step: 3577 training error: 0.3530242950229574\n",
            "At step: 3578 training error: 0.34332074720977285\n",
            "At step: 3579 training error: 0.3450459576004168\n",
            "At step: 3580 training error: 0.3426879291326303\n",
            "At step: 3581 training error: 0.34262734934222505\n",
            "At step: 3582 training error: 0.3374309559212779\n",
            "At step: 3583 training error: 0.3339984710145986\n",
            "At step: 3584 training error: 0.3292941938951355\n",
            "At step: 3585 training error: 0.3307453298305044\n",
            "At step: 3586 training error: 0.33224138717101764\n",
            "At step: 3587 training error: 0.32629417418926515\n",
            "At step: 3588 training error: 0.3206785219834606\n",
            "At step: 3589 training error: 0.3216118546806937\n",
            "At step: 3590 training error: 0.32455704798823554\n",
            "At step: 3591 training error: 0.32534221555348497\n",
            "At step: 3592 training error: 0.33966864839693656\n",
            "At step: 3593 training error: 0.33557401243154383\n",
            "At step: 3594 training error: 0.33388344166205053\n",
            "At step: 3595 training error: 0.3422108260905905\n",
            "At step: 3596 training error: 0.34144241666711217\n",
            "At step: 3597 training error: 0.3523913264967592\n",
            "At step: 3598 training error: 0.36036727093571436\n",
            "At step: 3599 training error: 0.3552150773383258\n",
            "At step: 3600 training error: 0.3451743946146563\n",
            "At step: 3601 training error: 0.3369712729983062\n",
            "At step: 3602 training error: 0.3416556183179168\n",
            "At step: 3603 training error: 0.34088144021090416\n",
            "At step: 3604 training error: 0.3353029552675328\n",
            "At step: 3605 training error: 0.32760906732041334\n",
            "At step: 3606 training error: 0.3260916961813426\n",
            "At step: 3607 training error: 0.3222995013407068\n",
            "At step: 3608 training error: 0.3323859794046651\n",
            "At step: 3609 training error: 0.34003152222934746\n",
            "At step: 3610 training error: 0.33721258959179096\n",
            "At step: 3611 training error: 0.3445126715310253\n",
            "At step: 3612 training error: 0.3514243233363853\n",
            "At step: 3613 training error: 0.3543708236881063\n",
            "At step: 3614 training error: 0.3719206953451717\n",
            "At step: 3615 training error: 0.36167601615874917\n",
            "At step: 3616 training error: 0.36236479653489234\n",
            "At step: 3617 training error: 0.3578707942155528\n",
            "At step: 3618 training error: 0.3516585914922946\n",
            "At step: 3619 training error: 0.3360068469601895\n",
            "At step: 3620 training error: 0.34636085647054826\n",
            "At step: 3621 training error: 0.33952306587195846\n",
            "At step: 3622 training error: 0.36155825325386626\n",
            "At step: 3623 training error: 0.35641496123330896\n",
            "At step: 3624 training error: 0.3520002359991856\n",
            "At step: 3625 training error: 0.3485000663380579\n",
            "At step: 3626 training error: 0.33502571196953623\n",
            "At step: 3627 training error: 0.336720090659254\n",
            "At step: 3628 training error: 0.344076124224917\n",
            "At step: 3629 training error: 0.3378354447712026\n",
            "At step: 3630 training error: 0.34156904553867523\n",
            "At step: 3631 training error: 0.33451054183652484\n",
            "At step: 3632 training error: 0.3338703962157946\n",
            "At step: 3633 training error: 0.3365885184115619\n",
            "At step: 3634 training error: 0.3438007137751616\n",
            "At step: 3635 training error: 0.33765329876783656\n",
            "At step: 3636 training error: 0.3349803093060131\n",
            "At step: 3637 training error: 0.3329743542066282\n",
            "At step: 3638 training error: 0.3346689093453666\n",
            "At step: 3639 training error: 0.3254209828350316\n",
            "At step: 3640 training error: 0.32923763107584925\n",
            "At step: 3641 training error: 0.3401552784327381\n",
            "At step: 3642 training error: 0.3400954273410947\n",
            "At step: 3643 training error: 0.3380737279670468\n",
            "At step: 3644 training error: 0.32616676221070506\n",
            "At step: 3645 training error: 0.3192234303767183\n",
            "At step: 3646 training error: 0.31398094202933435\n",
            "At step: 3647 training error: 0.31733880745278104\n",
            "At step: 3648 training error: 0.3161479592757173\n",
            "At step: 3649 training error: 0.32392833611431304\n",
            "At step: 3650 training error: 0.3261506876846224\n",
            "At step: 3651 training error: 0.3177287023068829\n",
            "At step: 3652 training error: 0.31478967072537484\n",
            "At step: 3653 training error: 0.30979225886228245\n",
            "At step: 3654 training error: 0.30815607240567444\n",
            "At step: 3655 training error: 0.3165454071542439\n",
            "At step: 3656 training error: 0.3127719711037692\n",
            "At step: 3657 training error: 0.3094586843062979\n",
            "At step: 3658 training error: 0.3218887523017736\n",
            "At step: 3659 training error: 0.32472599917658107\n",
            "At step: 3660 training error: 0.32253218705877357\n",
            "At step: 3661 training error: 0.313199618054225\n",
            "At step: 3662 training error: 0.31184119451398845\n",
            "At step: 3663 training error: 0.3167993459785642\n",
            "At step: 3664 training error: 0.3131016631296111\n",
            "At step: 3665 training error: 0.31170249182436216\n",
            "At step: 3666 training error: 0.3075506129863865\n",
            "At step: 3667 training error: 0.31020964471757645\n",
            "At step: 3668 training error: 0.318549556171014\n",
            "At step: 3669 training error: 0.3134488735361952\n",
            "At step: 3670 training error: 0.3151447923756133\n",
            "At step: 3671 training error: 0.3119475124294549\n",
            "At step: 3672 training error: 0.3144268133537303\n",
            "At step: 3673 training error: 0.3151492852871015\n",
            "At step: 3674 training error: 0.3194890646476952\n",
            "At step: 3675 training error: 0.33242499905092\n",
            "At step: 3676 training error: 0.33614544959912085\n",
            "At step: 3677 training error: 0.33267863379031165\n",
            "At step: 3678 training error: 0.329636898685228\n",
            "At step: 3679 training error: 0.33461257277036976\n",
            "At step: 3680 training error: 0.3429474137118396\n",
            "At step: 3681 training error: 0.3310204578980748\n",
            "At step: 3682 training error: 0.3390578448241922\n",
            "At step: 3683 training error: 0.3324257029817237\n",
            "At step: 3684 training error: 0.32425266252620216\n",
            "At step: 3685 training error: 0.3182538111415003\n",
            "At step: 3686 training error: 0.3183146399813057\n",
            "At step: 3687 training error: 0.32037491609324675\n",
            "At step: 3688 training error: 0.32144301473147285\n",
            "At step: 3689 training error: 0.3234763412975789\n",
            "At step: 3690 training error: 0.3270982100593924\n",
            "At step: 3691 training error: 0.32143178263464345\n",
            "At step: 3692 training error: 0.33260020514982924\n",
            "At step: 3693 training error: 0.33332399116885364\n",
            "At step: 3694 training error: 0.3281083148451008\n",
            "At step: 3695 training error: 0.3343534392453446\n",
            "At step: 3696 training error: 0.3377143826416838\n",
            "At step: 3697 training error: 0.34304738219828995\n",
            "At step: 3698 training error: 0.3458323859832351\n",
            "At step: 3699 training error: 0.33751372107886085\n",
            "At step: 3700 training error: 0.34304779813641695\n",
            "At step: 3701 training error: 0.33381077784617874\n",
            "At step: 3702 training error: 0.3272946103209531\n",
            "At step: 3703 training error: 0.33051896553025983\n",
            "At step: 3704 training error: 0.3244808006418679\n",
            "At step: 3705 training error: 0.31899697452579756\n",
            "At step: 3706 training error: 0.3267308569430688\n",
            "At step: 3707 training error: 0.3202389937367914\n",
            "At step: 3708 training error: 0.3155464242205236\n",
            "At step: 3709 training error: 0.3325073665357605\n",
            "At step: 3710 training error: 0.3310598200500255\n",
            "At step: 3711 training error: 0.3315787140602401\n",
            "At step: 3712 training error: 0.3242075668644124\n",
            "At step: 3713 training error: 0.32814746919265925\n",
            "At step: 3714 training error: 0.3319632871773171\n",
            "At step: 3715 training error: 0.337297269183435\n",
            "At step: 3716 training error: 0.3350317115960787\n",
            "At step: 3717 training error: 0.33481548109719034\n",
            "At step: 3718 training error: 0.34588531094702035\n",
            "At step: 3719 training error: 0.3276231579295075\n",
            "At step: 3720 training error: 0.3303294589732321\n",
            "At step: 3721 training error: 0.3254751589776416\n",
            "At step: 3722 training error: 0.3267330487373713\n",
            "At step: 3723 training error: 0.3215960553606981\n",
            "At step: 3724 training error: 0.3230728731318495\n",
            "At step: 3725 training error: 0.32189757540580166\n",
            "At step: 3726 training error: 0.3232741992198069\n",
            "At step: 3727 training error: 0.32629468524077665\n",
            "At step: 3728 training error: 0.32001193569535996\n",
            "At step: 3729 training error: 0.3170973962224074\n",
            "At step: 3730 training error: 0.31092162478068724\n",
            "At step: 3731 training error: 0.315256508374232\n",
            "At step: 3732 training error: 0.3338571960195735\n",
            "At step: 3733 training error: 0.3293015370636659\n",
            "At step: 3734 training error: 0.3234983120679635\n",
            "At step: 3735 training error: 0.3306832339191152\n",
            "At step: 3736 training error: 0.33457480803455547\n",
            "At step: 3737 training error: 0.3360038584403655\n",
            "At step: 3738 training error: 0.33529901043702287\n",
            "At step: 3739 training error: 0.32716796982159024\n",
            "At step: 3740 training error: 0.32349052539811424\n",
            "At step: 3741 training error: 0.3289121222839446\n",
            "At step: 3742 training error: 0.3434678913350083\n",
            "At step: 3743 training error: 0.3400962802660314\n",
            "At step: 3744 training error: 0.32943235100540635\n",
            "At step: 3745 training error: 0.3284870678920707\n",
            "At step: 3746 training error: 0.3274422663354634\n",
            "At step: 3747 training error: 0.3272196818162168\n",
            "At step: 3748 training error: 0.3235967399011396\n",
            "At step: 3749 training error: 0.32521553870859227\n",
            "At step: 3750 training error: 0.32214927270042765\n",
            "At step: 3751 training error: 0.32278313300695405\n",
            "At step: 3752 training error: 0.3231316819372276\n",
            "At step: 3753 training error: 0.3327030246007314\n",
            "At step: 3754 training error: 0.3335050361673774\n",
            "At step: 3755 training error: 0.3394588136604767\n",
            "At step: 3756 training error: 0.3467353188943132\n",
            "At step: 3757 training error: 0.34743106079813063\n",
            "At step: 3758 training error: 0.33926562617927986\n",
            "At step: 3759 training error: 0.3383822503232381\n",
            "At step: 3760 training error: 0.3401319118705312\n",
            "At step: 3761 training error: 0.3383838451132398\n",
            "At step: 3762 training error: 0.33047768495180085\n",
            "At step: 3763 training error: 0.3349028678789593\n",
            "At step: 3764 training error: 0.32593952996963216\n",
            "At step: 3765 training error: 0.3166082120342155\n",
            "At step: 3766 training error: 0.30528573378488744\n",
            "At step: 3767 training error: 0.3039837910788125\n",
            "At step: 3768 training error: 0.308962776982037\n",
            "At step: 3769 training error: 0.3087516767486441\n",
            "At step: 3770 training error: 0.30696159220163843\n",
            "At step: 3771 training error: 0.2987937624710923\n",
            "At step: 3772 training error: 0.30812202380647363\n",
            "At step: 3773 training error: 0.3087300416637128\n",
            "At step: 3774 training error: 0.32081189157670925\n",
            "At step: 3775 training error: 0.3141422018907249\n",
            "At step: 3776 training error: 0.3213382635288274\n",
            "At step: 3777 training error: 0.3230348473965619\n",
            "At step: 3778 training error: 0.32838658858908315\n",
            "At step: 3779 training error: 0.33885913033684467\n",
            "At step: 3780 training error: 0.34254730597611255\n",
            "At step: 3781 training error: 0.342356530100094\n",
            "At step: 3782 training error: 0.3386752000205937\n",
            "At step: 3783 training error: 0.3454236720975634\n",
            "At step: 3784 training error: 0.35213649087146665\n",
            "At step: 3785 training error: 0.35057290550194065\n",
            "At step: 3786 training error: 0.35855742364014054\n",
            "At step: 3787 training error: 0.36500115258634547\n",
            "At step: 3788 training error: 0.3701633772126079\n",
            "At step: 3789 training error: 0.3633740050749575\n",
            "At step: 3790 training error: 0.3539377860010244\n",
            "At step: 3791 training error: 0.3491753273867497\n",
            "At step: 3792 training error: 0.3531869096707105\n",
            "At step: 3793 training error: 0.3651541886565463\n",
            "At step: 3794 training error: 0.36244533844182353\n",
            "At step: 3795 training error: 0.36250623939389093\n",
            "At step: 3796 training error: 0.35842094420885884\n",
            "At step: 3797 training error: 0.3574200779024068\n",
            "At step: 3798 training error: 0.36302470754300464\n",
            "At step: 3799 training error: 0.37511347087399455\n",
            "At step: 3800 training error: 0.37163751542843293\n",
            "At step: 3801 training error: 0.3609581862705549\n",
            "At step: 3802 training error: 0.35541006436001527\n",
            "At step: 3803 training error: 0.3552104627011311\n",
            "At step: 3804 training error: 0.36225662579269563\n",
            "At step: 3805 training error: 0.3485138465517777\n",
            "At step: 3806 training error: 0.35438130060899825\n",
            "At step: 3807 training error: 0.3520867056188032\n",
            "At step: 3808 training error: 0.3512338223873266\n",
            "At step: 3809 training error: 0.3471115211882546\n",
            "At step: 3810 training error: 0.3370643277927235\n",
            "At step: 3811 training error: 0.3682069116603136\n",
            "At step: 3812 training error: 0.3629709610102128\n",
            "At step: 3813 training error: 0.3662079495793545\n",
            "At step: 3814 training error: 0.35592055380637666\n",
            "At step: 3815 training error: 0.355595540820273\n",
            "At step: 3816 training error: 0.36068536586129224\n",
            "At step: 3817 training error: 0.35640411885405743\n",
            "At step: 3818 training error: 0.35923291958401327\n",
            "At step: 3819 training error: 0.3510066891089782\n",
            "At step: 3820 training error: 0.34821191101237603\n",
            "At step: 3821 training error: 0.3414982818129294\n",
            "At step: 3822 training error: 0.3393214852909714\n",
            "At step: 3823 training error: 0.34288445804003675\n",
            "At step: 3824 training error: 0.3428601599821922\n",
            "At step: 3825 training error: 0.34908838200909537\n",
            "At step: 3826 training error: 0.34571617610966676\n",
            "At step: 3827 training error: 0.34396425559739496\n",
            "At step: 3828 training error: 0.34235485718843994\n",
            "At step: 3829 training error: 0.32684893190874126\n",
            "At step: 3830 training error: 0.3220416438222498\n",
            "At step: 3831 training error: 0.3277200005805812\n",
            "At step: 3832 training error: 0.3239732269839312\n",
            "At step: 3833 training error: 0.31631938499859363\n",
            "At step: 3834 training error: 0.3052647155153083\n",
            "At step: 3835 training error: 0.31745881816075017\n",
            "At step: 3836 training error: 0.31477953030355765\n",
            "At step: 3837 training error: 0.31444177058128275\n",
            "At step: 3838 training error: 0.3187925438700723\n",
            "At step: 3839 training error: 0.32660295716896404\n",
            "At step: 3840 training error: 0.3295580582793412\n",
            "At step: 3841 training error: 0.32525166155159924\n",
            "At step: 3842 training error: 0.3331911960054255\n",
            "At step: 3843 training error: 0.3369412094395661\n",
            "At step: 3844 training error: 0.3250383163244767\n",
            "At step: 3845 training error: 0.31518924264476283\n",
            "At step: 3846 training error: 0.3194919730307672\n",
            "At step: 3847 training error: 0.3279414534454037\n",
            "At step: 3848 training error: 0.32319556183446857\n",
            "At step: 3849 training error: 0.3326457789051135\n",
            "At step: 3850 training error: 0.3346925958605929\n",
            "At step: 3851 training error: 0.3335325025963968\n",
            "At step: 3852 training error: 0.3287109207890764\n",
            "At step: 3853 training error: 0.33333319552644264\n",
            "At step: 3854 training error: 0.3425348386497009\n",
            "At step: 3855 training error: 0.3381943778315268\n",
            "At step: 3856 training error: 0.3520832542421469\n",
            "At step: 3857 training error: 0.34716465575561445\n",
            "At step: 3858 training error: 0.3529677523198766\n",
            "At step: 3859 training error: 0.35068721407442743\n",
            "At step: 3860 training error: 0.3488670609243939\n",
            "At step: 3861 training error: 0.3502281559435302\n",
            "At step: 3862 training error: 0.35147790655719746\n",
            "At step: 3863 training error: 0.33511128494715736\n",
            "At step: 3864 training error: 0.3318530190548644\n",
            "At step: 3865 training error: 0.32919302376184806\n",
            "At step: 3866 training error: 0.3267338175236304\n",
            "At step: 3867 training error: 0.32666320649176417\n",
            "At step: 3868 training error: 0.3311274113276723\n",
            "At step: 3869 training error: 0.327292259613911\n",
            "At step: 3870 training error: 0.3213433552267559\n",
            "At step: 3871 training error: 0.3355035184106862\n",
            "At step: 3872 training error: 0.3411936629258065\n",
            "At step: 3873 training error: 0.35272653067932186\n",
            "At step: 3874 training error: 0.3485870641124228\n",
            "At step: 3875 training error: 0.3395429170173081\n",
            "At step: 3876 training error: 0.3331060517352749\n",
            "At step: 3877 training error: 0.3358042663768915\n",
            "At step: 3878 training error: 0.3258880056983213\n",
            "At step: 3879 training error: 0.3251518086620906\n",
            "At step: 3880 training error: 0.3282015561791906\n",
            "At step: 3881 training error: 0.3275645693834255\n",
            "At step: 3882 training error: 0.33021322509293516\n",
            "At step: 3883 training error: 0.32706854990233836\n",
            "At step: 3884 training error: 0.3319219491631694\n",
            "At step: 3885 training error: 0.33505590878922403\n",
            "At step: 3886 training error: 0.33570749737258976\n",
            "At step: 3887 training error: 0.3523736878486814\n",
            "At step: 3888 training error: 0.3377855688615856\n",
            "At step: 3889 training error: 0.32554598126779694\n",
            "At step: 3890 training error: 0.32592229186751515\n",
            "At step: 3891 training error: 0.33779648164884607\n",
            "At step: 3892 training error: 0.3430238101826468\n",
            "At step: 3893 training error: 0.3584085452997727\n",
            "At step: 3894 training error: 0.3567180158821822\n",
            "At step: 3895 training error: 0.3527616259891716\n",
            "At step: 3896 training error: 0.35336797166248285\n",
            "At step: 3897 training error: 0.3530264718276476\n",
            "At step: 3898 training error: 0.34723075294435574\n",
            "At step: 3899 training error: 0.3378173070270272\n",
            "At step: 3900 training error: 0.33077076697709795\n",
            "At step: 3901 training error: 0.3312151680454575\n",
            "At step: 3902 training error: 0.3281433561454842\n",
            "At step: 3903 training error: 0.3300510560698274\n",
            "At step: 3904 training error: 0.3303988393151871\n",
            "At step: 3905 training error: 0.3260765267817946\n",
            "At step: 3906 training error: 0.32129457578032794\n",
            "At step: 3907 training error: 0.3170657642604479\n",
            "At step: 3908 training error: 0.3189434074700386\n",
            "At step: 3909 training error: 0.3273548492741411\n",
            "At step: 3910 training error: 0.3311735924078463\n",
            "At step: 3911 training error: 0.34234746160971463\n",
            "At step: 3912 training error: 0.33987949754418734\n",
            "At step: 3913 training error: 0.33028062238803696\n",
            "At step: 3914 training error: 0.3306310626493839\n",
            "At step: 3915 training error: 0.3213843717125815\n",
            "At step: 3916 training error: 0.32811049944720866\n",
            "At step: 3917 training error: 0.3341963574959381\n",
            "At step: 3918 training error: 0.3235219092679153\n",
            "At step: 3919 training error: 0.3189219184399627\n",
            "At step: 3920 training error: 0.3178909403684543\n",
            "At step: 3921 training error: 0.31538648096805844\n",
            "At step: 3922 training error: 0.3151506893365418\n",
            "At step: 3923 training error: 0.3024834358981779\n",
            "At step: 3924 training error: 0.31280304794866337\n",
            "At step: 3925 training error: 0.30335996458978526\n",
            "At step: 3926 training error: 0.30156607678213176\n",
            "At step: 3927 training error: 0.300230823430586\n",
            "At step: 3928 training error: 0.30233127613192035\n",
            "At step: 3929 training error: 0.30032269209116125\n",
            "At step: 3930 training error: 0.2937340877384982\n",
            "At step: 3931 training error: 0.29624366922031586\n",
            "At step: 3932 training error: 0.30750700307171475\n",
            "At step: 3933 training error: 0.3036546865285442\n",
            "At step: 3934 training error: 0.31394165880290187\n",
            "At step: 3935 training error: 0.31051581434499786\n",
            "At step: 3936 training error: 0.30694649029350857\n",
            "At step: 3937 training error: 0.31361467076107\n",
            "At step: 3938 training error: 0.3139941541649138\n",
            "At step: 3939 training error: 0.3205980989587451\n",
            "At step: 3940 training error: 0.3324450963838546\n",
            "At step: 3941 training error: 0.335004791707609\n",
            "At step: 3942 training error: 0.3368445417451841\n",
            "At step: 3943 training error: 0.32973351039721616\n",
            "At step: 3944 training error: 0.32759148067179034\n",
            "At step: 3945 training error: 0.3178948881572419\n",
            "At step: 3946 training error: 0.3184279305545333\n",
            "At step: 3947 training error: 0.3222065042261181\n",
            "At step: 3948 training error: 0.32593613352884776\n",
            "At step: 3949 training error: 0.32727635843775843\n",
            "At step: 3950 training error: 0.32540465783428946\n",
            "At step: 3951 training error: 0.32547980601554144\n",
            "At step: 3952 training error: 0.32005212266525873\n",
            "At step: 3953 training error: 0.32567134223969885\n",
            "At step: 3954 training error: 0.32435045081040165\n",
            "At step: 3955 training error: 0.32773251309521856\n",
            "At step: 3956 training error: 0.3339815594091138\n",
            "At step: 3957 training error: 0.3372942847822852\n",
            "At step: 3958 training error: 0.3350810527116072\n",
            "At step: 3959 training error: 0.33227900699668744\n",
            "At step: 3960 training error: 0.3361445576410275\n",
            "At step: 3961 training error: 0.3429388293631843\n",
            "At step: 3962 training error: 0.35118295678444567\n",
            "At step: 3963 training error: 0.34773717099525364\n",
            "At step: 3964 training error: 0.3474018930853754\n",
            "At step: 3965 training error: 0.3376766798803656\n",
            "At step: 3966 training error: 0.33469286036228185\n",
            "At step: 3967 training error: 0.3290287388555238\n",
            "At step: 3968 training error: 0.32580196332785677\n",
            "At step: 3969 training error: 0.327212482802972\n",
            "At step: 3970 training error: 0.3269861861394838\n",
            "At step: 3971 training error: 0.32646714767223556\n",
            "At step: 3972 training error: 0.33168642586422803\n",
            "At step: 3973 training error: 0.3254543753085484\n",
            "At step: 3974 training error: 0.33157018207693933\n",
            "At step: 3975 training error: 0.3348986199118832\n",
            "At step: 3976 training error: 0.339923427774233\n",
            "At step: 3977 training error: 0.3388884750435134\n",
            "At step: 3978 training error: 0.33352734862811634\n",
            "At step: 3979 training error: 0.3239545615157218\n",
            "At step: 3980 training error: 0.32348726984323006\n",
            "At step: 3981 training error: 0.3237038674222848\n",
            "At step: 3982 training error: 0.3208895689482398\n",
            "At step: 3983 training error: 0.3183406093516819\n",
            "At step: 3984 training error: 0.3104643195148388\n",
            "At step: 3985 training error: 0.32583946239779754\n",
            "At step: 3986 training error: 0.33689676085995013\n",
            "At step: 3987 training error: 0.33511443872343627\n",
            "At step: 3988 training error: 0.3273088845254806\n",
            "At step: 3989 training error: 0.31471090665145207\n",
            "At step: 3990 training error: 0.31806601557980524\n",
            "At step: 3991 training error: 0.3205961831267833\n",
            "At step: 3992 training error: 0.3250606102590619\n",
            "At step: 3993 training error: 0.33002238930949496\n",
            "At step: 3994 training error: 0.3324031693111771\n",
            "At step: 3995 training error: 0.3306746993574507\n",
            "At step: 3996 training error: 0.325667048810463\n",
            "At step: 3997 training error: 0.33290089092054764\n",
            "At step: 3998 training error: 0.326186989492529\n",
            "At step: 3999 training error: 0.32484035489470303\n",
            "At step: 4000 training error: 0.3298970866718413\n",
            "At step: 4001 training error: 0.3299395237692353\n",
            "At step: 4002 training error: 0.33429220759496225\n",
            "At step: 4003 training error: 0.33094727464015516\n",
            "At step: 4004 training error: 0.32696587326537635\n",
            "At step: 4005 training error: 0.3328812215569442\n",
            "At step: 4006 training error: 0.3227986265925211\n",
            "At step: 4007 training error: 0.32732342961067357\n",
            "At step: 4008 training error: 0.3199303636039908\n",
            "At step: 4009 training error: 0.31599011050690434\n",
            "At step: 4010 training error: 0.3117873331006164\n",
            "At step: 4011 training error: 0.32329049746784383\n",
            "At step: 4012 training error: 0.3245296278791207\n",
            "At step: 4013 training error: 0.31956389139266933\n",
            "At step: 4014 training error: 0.330937733157356\n",
            "At step: 4015 training error: 0.33002550235255834\n",
            "At step: 4016 training error: 0.3326640860199566\n",
            "At step: 4017 training error: 0.32996940556956045\n",
            "At step: 4018 training error: 0.32208364503483977\n",
            "At step: 4019 training error: 0.34129107920479157\n",
            "At step: 4020 training error: 0.34016567858184066\n",
            "At step: 4021 training error: 0.3510272323858754\n",
            "At step: 4022 training error: 0.3472478089472595\n",
            "At step: 4023 training error: 0.3399700956804187\n",
            "At step: 4024 training error: 0.3341158698179019\n",
            "At step: 4025 training error: 0.3364274777469477\n",
            "At step: 4026 training error: 0.33732818359670763\n",
            "At step: 4027 training error: 0.3249446139188217\n",
            "At step: 4028 training error: 0.32756613127195033\n",
            "At step: 4029 training error: 0.3319489323746343\n",
            "At step: 4030 training error: 0.32730257671366975\n",
            "At step: 4031 training error: 0.33037778325282674\n",
            "At step: 4032 training error: 0.3355215374146274\n",
            "At step: 4033 training error: 0.32897965604909246\n",
            "At step: 4034 training error: 0.3227745021392314\n",
            "At step: 4035 training error: 0.3245010566434761\n",
            "At step: 4036 training error: 0.32824592514793294\n",
            "At step: 4037 training error: 0.3344416718028376\n",
            "At step: 4038 training error: 0.33678461726225367\n",
            "At step: 4039 training error: 0.33431851820142877\n",
            "At step: 4040 training error: 0.3319710589239009\n",
            "At step: 4041 training error: 0.32385173741086987\n",
            "At step: 4042 training error: 0.31583367044422545\n",
            "At step: 4043 training error: 0.30989277766899753\n",
            "At step: 4044 training error: 0.3114314149790129\n",
            "At step: 4045 training error: 0.30529898924028104\n",
            "At step: 4046 training error: 0.2995562456889494\n",
            "At step: 4047 training error: 0.3094206343973728\n",
            "At step: 4048 training error: 0.31996544393547266\n",
            "At step: 4049 training error: 0.32449097558019513\n",
            "At step: 4050 training error: 0.3281184507891284\n",
            "At step: 4051 training error: 0.33256146666617703\n",
            "At step: 4052 training error: 0.32832812359446123\n",
            "At step: 4053 training error: 0.3312287903247725\n",
            "At step: 4054 training error: 0.3410554565922397\n",
            "At step: 4055 training error: 0.3320955145989978\n",
            "At step: 4056 training error: 0.3216970453608842\n",
            "At step: 4057 training error: 0.3308419198663545\n",
            "At step: 4058 training error: 0.32332429890641345\n",
            "At step: 4059 training error: 0.31987312963705755\n",
            "At step: 4060 training error: 0.3320038321652018\n",
            "At step: 4061 training error: 0.33815781169488024\n",
            "At step: 4062 training error: 0.33425458053882023\n",
            "At step: 4063 training error: 0.3312561666113319\n",
            "At step: 4064 training error: 0.33945239393255655\n",
            "At step: 4065 training error: 0.3394540614751602\n",
            "At step: 4066 training error: 0.3396225172997771\n",
            "At step: 4067 training error: 0.3535121202093811\n",
            "At step: 4068 training error: 0.3532934350257536\n",
            "At step: 4069 training error: 0.3619483176083801\n",
            "At step: 4070 training error: 0.3436410275326501\n",
            "At step: 4071 training error: 0.34358409609018187\n",
            "At step: 4072 training error: 0.342753260980419\n",
            "At step: 4073 training error: 0.33295019528435454\n",
            "At step: 4074 training error: 0.33562161887938124\n",
            "At step: 4075 training error: 0.33117901771157504\n",
            "At step: 4076 training error: 0.33415675975968273\n",
            "At step: 4077 training error: 0.332504878439771\n",
            "At step: 4078 training error: 0.33616279850348346\n",
            "At step: 4079 training error: 0.3350209502493403\n",
            "At step: 4080 training error: 0.33168800486340405\n",
            "At step: 4081 training error: 0.324774134204855\n",
            "At step: 4082 training error: 0.31150780596452565\n",
            "At step: 4083 training error: 0.3171542206693057\n",
            "At step: 4084 training error: 0.3086387004041093\n",
            "At step: 4085 training error: 0.31015914364850244\n",
            "At step: 4086 training error: 0.3119768613645909\n",
            "At step: 4087 training error: 0.3110128331044908\n",
            "At step: 4088 training error: 0.3038231734131618\n",
            "At step: 4089 training error: 0.310367317681027\n",
            "At step: 4090 training error: 0.31120532143941004\n",
            "At step: 4091 training error: 0.3205338589813468\n",
            "At step: 4092 training error: 0.3240924823138118\n",
            "At step: 4093 training error: 0.32436872786320786\n",
            "At step: 4094 training error: 0.3210826422820214\n",
            "At step: 4095 training error: 0.3086487471345336\n",
            "At step: 4096 training error: 0.3081397522716348\n",
            "At step: 4097 training error: 0.31134333077317805\n",
            "At step: 4098 training error: 0.31470546308447994\n",
            "At step: 4099 training error: 0.3109975844904576\n",
            "At step: 4100 training error: 0.3032479591331628\n",
            "At step: 4101 training error: 0.3049622787587985\n",
            "At step: 4102 training error: 0.3024465663411733\n",
            "At step: 4103 training error: 0.3053547251372023\n",
            "At step: 4104 training error: 0.3143787114609123\n",
            "At step: 4105 training error: 0.3199488791180016\n",
            "At step: 4106 training error: 0.32068225368886216\n",
            "At step: 4107 training error: 0.3201614943658006\n",
            "At step: 4108 training error: 0.32546077491368314\n",
            "At step: 4109 training error: 0.33039829353530425\n",
            "At step: 4110 training error: 0.3220542367057167\n",
            "At step: 4111 training error: 0.31649995810667597\n",
            "At step: 4112 training error: 0.3270755198766209\n",
            "At step: 4113 training error: 0.32143146780911913\n",
            "At step: 4114 training error: 0.3260417342032417\n",
            "At step: 4115 training error: 0.3194637450759586\n",
            "At step: 4116 training error: 0.31341486436713856\n",
            "At step: 4117 training error: 0.31192664926691965\n",
            "At step: 4118 training error: 0.3042372633265991\n",
            "At step: 4119 training error: 0.30257016811663184\n",
            "At step: 4120 training error: 0.3091089820422997\n",
            "At step: 4121 training error: 0.3117427517744606\n",
            "At step: 4122 training error: 0.31533166648200756\n",
            "At step: 4123 training error: 0.3089142568716529\n",
            "At step: 4124 training error: 0.30355127335026977\n",
            "At step: 4125 training error: 0.3135571086375188\n",
            "At step: 4126 training error: 0.3140101146418076\n",
            "At step: 4127 training error: 0.31054972950670967\n",
            "At step: 4128 training error: 0.31465375460580286\n",
            "At step: 4129 training error: 0.32196891632504676\n",
            "At step: 4130 training error: 0.3206577375153232\n",
            "At step: 4131 training error: 0.3222139245819792\n",
            "At step: 4132 training error: 0.3288700641116419\n",
            "At step: 4133 training error: 0.32852890447047894\n",
            "At step: 4134 training error: 0.33289926243483503\n",
            "At step: 4135 training error: 0.32167705537639624\n",
            "At step: 4136 training error: 0.32100874983322486\n",
            "At step: 4137 training error: 0.32302518694750215\n",
            "At step: 4138 training error: 0.32286113291004087\n",
            "At step: 4139 training error: 0.31843277042573404\n",
            "At step: 4140 training error: 0.32762078371249437\n",
            "At step: 4141 training error: 0.32036256711838706\n",
            "At step: 4142 training error: 0.3336094940448611\n",
            "At step: 4143 training error: 0.33660112826389416\n",
            "At step: 4144 training error: 0.3386388809230465\n",
            "At step: 4145 training error: 0.3458328491363051\n",
            "At step: 4146 training error: 0.33924247133100305\n",
            "At step: 4147 training error: 0.3435660139506783\n",
            "At step: 4148 training error: 0.3460909625687602\n",
            "At step: 4149 training error: 0.3531975418468294\n",
            "At step: 4150 training error: 0.3454487031407515\n",
            "At step: 4151 training error: 0.3567385485389502\n",
            "At step: 4152 training error: 0.34756432636441553\n",
            "At step: 4153 training error: 0.33339263624888\n",
            "At step: 4154 training error: 0.3307971307888911\n",
            "At step: 4155 training error: 0.3279704902163229\n",
            "At step: 4156 training error: 0.32572296992701233\n",
            "At step: 4157 training error: 0.34533920546879404\n",
            "At step: 4158 training error: 0.3421997803739727\n",
            "At step: 4159 training error: 0.34027926694679433\n",
            "At step: 4160 training error: 0.3296639365789715\n",
            "At step: 4161 training error: 0.3323232089035747\n",
            "At step: 4162 training error: 0.33635573703494426\n",
            "At step: 4163 training error: 0.333030251758501\n",
            "At step: 4164 training error: 0.3323946797306825\n",
            "At step: 4165 training error: 0.3311549133069836\n",
            "At step: 4166 training error: 0.3374030323556672\n",
            "At step: 4167 training error: 0.32328596445005486\n",
            "At step: 4168 training error: 0.3152646844277083\n",
            "At step: 4169 training error: 0.31503476406551595\n",
            "At step: 4170 training error: 0.3085489282790928\n",
            "At step: 4171 training error: 0.30955699564414807\n",
            "At step: 4172 training error: 0.3218904940947658\n",
            "At step: 4173 training error: 0.32672152403433413\n",
            "At step: 4174 training error: 0.33732680410562066\n",
            "At step: 4175 training error: 0.3514026313190559\n",
            "At step: 4176 training error: 0.35279131141802994\n",
            "At step: 4177 training error: 0.3479600920824887\n",
            "At step: 4178 training error: 0.345944088818657\n",
            "At step: 4179 training error: 0.33753030100715953\n",
            "At step: 4180 training error: 0.3455902774041962\n",
            "At step: 4181 training error: 0.3406990979834629\n",
            "At step: 4182 training error: 0.3443036499118832\n",
            "At step: 4183 training error: 0.3413503078155551\n",
            "At step: 4184 training error: 0.34853177104106875\n",
            "At step: 4185 training error: 0.3462357248838374\n",
            "At step: 4186 training error: 0.3391695964897029\n",
            "At step: 4187 training error: 0.3393244123526694\n",
            "At step: 4188 training error: 0.33324809618399437\n",
            "At step: 4189 training error: 0.32929234509893024\n",
            "At step: 4190 training error: 0.322705108342983\n",
            "At step: 4191 training error: 0.32870713773869165\n",
            "At step: 4192 training error: 0.32297895224939727\n",
            "At step: 4193 training error: 0.329036915177948\n",
            "At step: 4194 training error: 0.3263555565435551\n",
            "At step: 4195 training error: 0.3253832659367731\n",
            "At step: 4196 training error: 0.33294227739303345\n",
            "At step: 4197 training error: 0.331924613575149\n",
            "At step: 4198 training error: 0.33912175294607205\n",
            "At step: 4199 training error: 0.332676954404181\n",
            "At step: 4200 training error: 0.33164579320304344\n",
            "At step: 4201 training error: 0.3210288715528389\n",
            "At step: 4202 training error: 0.31978968638845334\n",
            "At step: 4203 training error: 0.31492241905829693\n",
            "At step: 4204 training error: 0.3143570419429235\n",
            "At step: 4205 training error: 0.3231711965439492\n",
            "At step: 4206 training error: 0.31204247080237635\n",
            "At step: 4207 training error: 0.3050969806190236\n",
            "At step: 4208 training error: 0.3078696820410068\n",
            "At step: 4209 training error: 0.3205696284337002\n",
            "At step: 4210 training error: 0.33087070166960514\n",
            "At step: 4211 training error: 0.33522505305493455\n",
            "At step: 4212 training error: 0.3287605916699044\n",
            "At step: 4213 training error: 0.3392060938268737\n",
            "At step: 4214 training error: 0.32993398334545265\n",
            "At step: 4215 training error: 0.34606212703032907\n",
            "At step: 4216 training error: 0.3359930401202356\n",
            "At step: 4217 training error: 0.34193530268664996\n",
            "At step: 4218 training error: 0.3451697499668097\n",
            "At step: 4219 training error: 0.3394838050064315\n",
            "At step: 4220 training error: 0.3372126080905957\n",
            "At step: 4221 training error: 0.32681522057265056\n",
            "At step: 4222 training error: 0.32558545454184973\n",
            "At step: 4223 training error: 0.329310257785377\n",
            "At step: 4224 training error: 0.33821533363857115\n",
            "At step: 4225 training error: 0.35876995241576803\n",
            "At step: 4226 training error: 0.3499445810309981\n",
            "At step: 4227 training error: 0.3528618215368162\n",
            "At step: 4228 training error: 0.35210856798802154\n",
            "At step: 4229 training error: 0.34083843205271547\n",
            "At step: 4230 training error: 0.33720497365207275\n",
            "At step: 4231 training error: 0.3342737037601702\n",
            "At step: 4232 training error: 0.3402931616931866\n",
            "At step: 4233 training error: 0.3289164480015573\n",
            "At step: 4234 training error: 0.3236536575321935\n",
            "At step: 4235 training error: 0.32011594820763484\n",
            "At step: 4236 training error: 0.3196834975733989\n",
            "At step: 4237 training error: 0.334561609506831\n",
            "At step: 4238 training error: 0.3345276460972669\n",
            "At step: 4239 training error: 0.32653504802613154\n",
            "At step: 4240 training error: 0.32230858033103593\n",
            "At step: 4241 training error: 0.31293242674073274\n",
            "At step: 4242 training error: 0.30298319836296167\n",
            "At step: 4243 training error: 0.30577910584718304\n",
            "At step: 4244 training error: 0.31992403024056343\n",
            "At step: 4245 training error: 0.3326808392139969\n",
            "At step: 4246 training error: 0.3242524822153277\n",
            "At step: 4247 training error: 0.31486469097698533\n",
            "At step: 4248 training error: 0.31877758467524286\n",
            "At step: 4249 training error: 0.31039372117283304\n",
            "At step: 4250 training error: 0.32273872143084886\n",
            "At step: 4251 training error: 0.3246335676019279\n",
            "At step: 4252 training error: 0.33844606754588824\n",
            "At step: 4253 training error: 0.3334107620288032\n",
            "At step: 4254 training error: 0.33332837137376153\n",
            "At step: 4255 training error: 0.3360040072088904\n",
            "At step: 4256 training error: 0.3372087468248841\n",
            "At step: 4257 training error: 0.3342381643935896\n",
            "At step: 4258 training error: 0.3376478186357423\n",
            "At step: 4259 training error: 0.33278259068774496\n",
            "At step: 4260 training error: 0.34573939438419726\n",
            "At step: 4261 training error: 0.3341408247352052\n",
            "At step: 4262 training error: 0.32805151348825995\n",
            "At step: 4263 training error: 0.32965498614718847\n",
            "At step: 4264 training error: 0.3341367095009065\n",
            "At step: 4265 training error: 0.3276111558572963\n",
            "At step: 4266 training error: 0.339688005405192\n",
            "At step: 4267 training error: 0.33742346015421565\n",
            "At step: 4268 training error: 0.33460973902880853\n",
            "At step: 4269 training error: 0.32460913697907984\n",
            "At step: 4270 training error: 0.3146346545060076\n",
            "At step: 4271 training error: 0.30985493817815557\n",
            "At step: 4272 training error: 0.3115533219198525\n",
            "At step: 4273 training error: 0.3172321400775324\n",
            "At step: 4274 training error: 0.3171646947951699\n",
            "At step: 4275 training error: 0.312772799733898\n",
            "At step: 4276 training error: 0.3255804830842108\n",
            "At step: 4277 training error: 0.32454863172671045\n",
            "At step: 4278 training error: 0.33029692446529046\n",
            "At step: 4279 training error: 0.33104999694866216\n",
            "At step: 4280 training error: 0.32855653020072395\n",
            "At step: 4281 training error: 0.3275056907437452\n",
            "At step: 4282 training error: 0.3309256026496764\n",
            "At step: 4283 training error: 0.32983820968489297\n",
            "At step: 4284 training error: 0.33483770674466806\n",
            "At step: 4285 training error: 0.33403784998184355\n",
            "At step: 4286 training error: 0.32675710225338395\n",
            "At step: 4287 training error: 0.3183887800904154\n",
            "At step: 4288 training error: 0.3179477817156902\n",
            "At step: 4289 training error: 0.32297274854281194\n",
            "At step: 4290 training error: 0.3159094960128306\n",
            "At step: 4291 training error: 0.3263816246090206\n",
            "At step: 4292 training error: 0.32340533393773496\n",
            "At step: 4293 training error: 0.32415552072623155\n",
            "At step: 4294 training error: 0.32651812763947574\n",
            "At step: 4295 training error: 0.3371460328077621\n",
            "At step: 4296 training error: 0.3447022070733195\n",
            "At step: 4297 training error: 0.3336872550723924\n",
            "At step: 4298 training error: 0.32744920618167705\n",
            "At step: 4299 training error: 0.3240108234166225\n",
            "At step: 4300 training error: 0.3266899592726932\n",
            "At step: 4301 training error: 0.33050586061296355\n",
            "At step: 4302 training error: 0.33911068912591735\n",
            "At step: 4303 training error: 0.3423627809001949\n",
            "At step: 4304 training error: 0.3411018062932553\n",
            "At step: 4305 training error: 0.32730408382783077\n",
            "At step: 4306 training error: 0.3243819422687584\n",
            "At step: 4307 training error: 0.3239982296392776\n",
            "At step: 4308 training error: 0.3153829918231295\n",
            "At step: 4309 training error: 0.3162393311870086\n",
            "At step: 4310 training error: 0.3218066748950968\n",
            "At step: 4311 training error: 0.32378568642297956\n",
            "At step: 4312 training error: 0.321496626300377\n",
            "At step: 4313 training error: 0.33564099559246474\n",
            "At step: 4314 training error: 0.3318278325405214\n",
            "At step: 4315 training error: 0.32385672990876374\n",
            "At step: 4316 training error: 0.31813494797727376\n",
            "At step: 4317 training error: 0.3085956565887856\n",
            "At step: 4318 training error: 0.32484002216395697\n",
            "At step: 4319 training error: 0.32472231245163496\n",
            "At step: 4320 training error: 0.33440628640587977\n",
            "At step: 4321 training error: 0.33375664052953535\n",
            "At step: 4322 training error: 0.3445703653744966\n",
            "At step: 4323 training error: 0.3488055201344214\n",
            "At step: 4324 training error: 0.34659093493201576\n",
            "At step: 4325 training error: 0.3498586396376285\n",
            "At step: 4326 training error: 0.33903186986223793\n",
            "At step: 4327 training error: 0.34293801622402736\n",
            "At step: 4328 training error: 0.32794092202211717\n",
            "At step: 4329 training error: 0.3375992581639498\n",
            "At step: 4330 training error: 0.3377727835933446\n",
            "At step: 4331 training error: 0.3357286755976942\n",
            "At step: 4332 training error: 0.3411776351949978\n",
            "At step: 4333 training error: 0.3393371063060075\n",
            "At step: 4334 training error: 0.3319683467785861\n",
            "At step: 4335 training error: 0.32885143747887335\n",
            "At step: 4336 training error: 0.3438772503257105\n",
            "At step: 4337 training error: 0.3427652812359143\n",
            "At step: 4338 training error: 0.3446701702145536\n",
            "At step: 4339 training error: 0.34663050331475714\n",
            "At step: 4340 training error: 0.35808578293855303\n",
            "At step: 4341 training error: 0.35744646689268206\n",
            "At step: 4342 training error: 0.35646109696667855\n",
            "At step: 4343 training error: 0.3551334340158467\n",
            "At step: 4344 training error: 0.34552478622180244\n",
            "At step: 4345 training error: 0.33850171484057234\n",
            "At step: 4346 training error: 0.3488101748636978\n",
            "At step: 4347 training error: 0.3535582829165971\n",
            "At step: 4348 training error: 0.3508951258607648\n",
            "At step: 4349 training error: 0.35477538295508515\n",
            "At step: 4350 training error: 0.35879745567963967\n",
            "At step: 4351 training error: 0.34599464290214454\n",
            "At step: 4352 training error: 0.3602900377692977\n",
            "At step: 4353 training error: 0.3609046684310264\n",
            "At step: 4354 training error: 0.356012269468929\n",
            "At step: 4355 training error: 0.3645590614315808\n",
            "At step: 4356 training error: 0.3571141466338978\n",
            "At step: 4357 training error: 0.34903232980776244\n",
            "At step: 4358 training error: 0.33383024318466736\n",
            "At step: 4359 training error: 0.3308960219685123\n",
            "At step: 4360 training error: 0.32942261650498017\n",
            "At step: 4361 training error: 0.3303631611153673\n",
            "At step: 4362 training error: 0.34392708692258234\n",
            "At step: 4363 training error: 0.3450295257740855\n",
            "At step: 4364 training error: 0.3333993779182263\n",
            "At step: 4365 training error: 0.33419555462614536\n",
            "At step: 4366 training error: 0.3320284088330464\n",
            "At step: 4367 training error: 0.3384593152202925\n",
            "At step: 4368 training error: 0.3445912163328997\n",
            "At step: 4369 training error: 0.34060503852266216\n",
            "At step: 4370 training error: 0.3491921977825285\n",
            "At step: 4371 training error: 0.3578506798651834\n",
            "At step: 4372 training error: 0.34545348378040674\n",
            "At step: 4373 training error: 0.35285718692314005\n",
            "At step: 4374 training error: 0.35486633417425306\n",
            "At step: 4375 training error: 0.362238284700085\n",
            "At step: 4376 training error: 0.37038696024925577\n",
            "At step: 4377 training error: 0.3546370289438966\n",
            "At step: 4378 training error: 0.3604238140090937\n",
            "At step: 4379 training error: 0.3686293269114541\n",
            "At step: 4380 training error: 0.37293049821303226\n",
            "At step: 4381 training error: 0.35970829516712033\n",
            "At step: 4382 training error: 0.36434495978884496\n",
            "At step: 4383 training error: 0.3619412813515417\n",
            "At step: 4384 training error: 0.3547533582625729\n",
            "At step: 4385 training error: 0.35177047597132644\n",
            "At step: 4386 training error: 0.35000705791536185\n",
            "At step: 4387 training error: 0.3501190195425449\n",
            "At step: 4388 training error: 0.34859912335813664\n",
            "At step: 4389 training error: 0.3396487998769461\n",
            "At step: 4390 training error: 0.3409405194093947\n",
            "At step: 4391 training error: 0.34870314368680555\n",
            "At step: 4392 training error: 0.3453575749392064\n",
            "At step: 4393 training error: 0.34106799142537003\n",
            "At step: 4394 training error: 0.34226805535201466\n",
            "At step: 4395 training error: 0.3487109307635677\n",
            "At step: 4396 training error: 0.3352565613880281\n",
            "At step: 4397 training error: 0.3343668511498492\n",
            "At step: 4398 training error: 0.3254679257860913\n",
            "At step: 4399 training error: 0.3336571515635192\n",
            "At step: 4400 training error: 0.32476985538798336\n",
            "At step: 4401 training error: 0.32682881674338976\n",
            "At step: 4402 training error: 0.32930521713217586\n",
            "At step: 4403 training error: 0.32729211031742206\n",
            "At step: 4404 training error: 0.32055827217375066\n",
            "At step: 4405 training error: 0.3180059015852176\n",
            "At step: 4406 training error: 0.33172460142787485\n",
            "At step: 4407 training error: 0.3265274891134326\n",
            "At step: 4408 training error: 0.3372623895855116\n",
            "At step: 4409 training error: 0.33531644527043064\n",
            "At step: 4410 training error: 0.33684032478044124\n",
            "At step: 4411 training error: 0.3297826731623269\n",
            "At step: 4412 training error: 0.33691629108383153\n",
            "At step: 4413 training error: 0.34521878381205323\n",
            "At step: 4414 training error: 0.351568327642225\n",
            "At step: 4415 training error: 0.3462463411822689\n",
            "At step: 4416 training error: 0.3482980859467197\n",
            "At step: 4417 training error: 0.3492311914670258\n",
            "At step: 4418 training error: 0.3500690444748461\n",
            "At step: 4419 training error: 0.33600949108585804\n",
            "At step: 4420 training error: 0.3427080200367359\n",
            "At step: 4421 training error: 0.35347056524716813\n",
            "At step: 4422 training error: 0.34537444945807166\n",
            "At step: 4423 training error: 0.3419941499838203\n",
            "At step: 4424 training error: 0.3549703616303236\n",
            "At step: 4425 training error: 0.3517509439550402\n",
            "At step: 4426 training error: 0.34869356657758593\n",
            "At step: 4427 training error: 0.3517854221090215\n",
            "At step: 4428 training error: 0.35831067183287646\n",
            "At step: 4429 training error: 0.3704630495982114\n",
            "At step: 4430 training error: 0.3624090151788781\n",
            "At step: 4431 training error: 0.3656171336436722\n",
            "At step: 4432 training error: 0.36773019647157407\n",
            "At step: 4433 training error: 0.35660390988636287\n",
            "At step: 4434 training error: 0.3585976360098706\n",
            "At step: 4435 training error: 0.3489166750696387\n",
            "At step: 4436 training error: 0.3470798226539386\n",
            "At step: 4437 training error: 0.3521414043011567\n",
            "At step: 4438 training error: 0.35545361272172593\n",
            "At step: 4439 training error: 0.35178336077321676\n",
            "At step: 4440 training error: 0.3598433627525465\n",
            "At step: 4441 training error: 0.3552388830079624\n",
            "At step: 4442 training error: 0.348805236404723\n",
            "At step: 4443 training error: 0.35795241002850103\n",
            "At step: 4444 training error: 0.35311047233026405\n",
            "At step: 4445 training error: 0.34992192142429945\n",
            "At step: 4446 training error: 0.3510298097047011\n",
            "At step: 4447 training error: 0.3412318437065606\n",
            "At step: 4448 training error: 0.33544283788658735\n",
            "At step: 4449 training error: 0.32593307100192614\n",
            "At step: 4450 training error: 0.32216272725873346\n",
            "At step: 4451 training error: 0.3349207156292915\n",
            "At step: 4452 training error: 0.3253534924569816\n",
            "At step: 4453 training error: 0.3372478695495982\n",
            "At step: 4454 training error: 0.33722755695662554\n",
            "At step: 4455 training error: 0.3240472442697913\n",
            "At step: 4456 training error: 0.31944551904022905\n",
            "At step: 4457 training error: 0.31261258632446337\n",
            "At step: 4458 training error: 0.31740848802096977\n",
            "At step: 4459 training error: 0.31088014862824975\n",
            "At step: 4460 training error: 0.31607649225672174\n",
            "At step: 4461 training error: 0.3226578953757496\n",
            "At step: 4462 training error: 0.30648682688354406\n",
            "At step: 4463 training error: 0.30187405792768146\n",
            "At step: 4464 training error: 0.3030397409321451\n",
            "At step: 4465 training error: 0.2955539067533236\n",
            "At step: 4466 training error: 0.30141545719521523\n",
            "At step: 4467 training error: 0.3146308244541828\n",
            "At step: 4468 training error: 0.31734062938742513\n",
            "At step: 4469 training error: 0.31246328627078057\n",
            "At step: 4470 training error: 0.31442309314650563\n",
            "At step: 4471 training error: 0.32354163506738076\n",
            "At step: 4472 training error: 0.322255398427141\n",
            "At step: 4473 training error: 0.32025001341192344\n",
            "At step: 4474 training error: 0.3250736695690732\n",
            "At step: 4475 training error: 0.3179228549813036\n",
            "At step: 4476 training error: 0.3111287943236454\n",
            "At step: 4477 training error: 0.30711888767998907\n",
            "At step: 4478 training error: 0.3160892818507762\n",
            "At step: 4479 training error: 0.31528237768766676\n",
            "At step: 4480 training error: 0.3161327568263575\n",
            "At step: 4481 training error: 0.31404787685105073\n",
            "At step: 4482 training error: 0.32101903189404674\n",
            "At step: 4483 training error: 0.3144578583197852\n",
            "At step: 4484 training error: 0.3126621897835379\n",
            "At step: 4485 training error: 0.3128721367343139\n",
            "At step: 4486 training error: 0.3144600271940295\n",
            "At step: 4487 training error: 0.31768580435974614\n",
            "At step: 4488 training error: 0.31390017898771466\n",
            "At step: 4489 training error: 0.3042983047777094\n",
            "At step: 4490 training error: 0.3151465160370474\n",
            "At step: 4491 training error: 0.3142410273032129\n",
            "At step: 4492 training error: 0.3163528328405976\n",
            "At step: 4493 training error: 0.31576111508031546\n",
            "At step: 4494 training error: 0.3159893109977068\n",
            "At step: 4495 training error: 0.307211544616879\n",
            "At step: 4496 training error: 0.3249525685760399\n",
            "At step: 4497 training error: 0.3264498062057869\n",
            "At step: 4498 training error: 0.3352839075985114\n",
            "At step: 4499 training error: 0.3309272187489628\n",
            "At step: 4500 training error: 0.3301785572420634\n",
            "At step: 4501 training error: 0.32665463190591004\n",
            "At step: 4502 training error: 0.32949814137126104\n",
            "At step: 4503 training error: 0.3285689631943838\n",
            "At step: 4504 training error: 0.32874519469354463\n",
            "At step: 4505 training error: 0.31732267858382845\n",
            "At step: 4506 training error: 0.312092558213989\n",
            "At step: 4507 training error: 0.3034011280013992\n",
            "At step: 4508 training error: 0.31962346473723696\n",
            "At step: 4509 training error: 0.325762099834122\n",
            "At step: 4510 training error: 0.31193701867570456\n",
            "At step: 4511 training error: 0.3123089647160453\n",
            "At step: 4512 training error: 0.3205783420656153\n",
            "At step: 4513 training error: 0.32779957154180667\n",
            "At step: 4514 training error: 0.34530743342016157\n",
            "At step: 4515 training error: 0.3492661192554617\n",
            "At step: 4516 training error: 0.34331981307675485\n",
            "At step: 4517 training error: 0.337227054738361\n",
            "At step: 4518 training error: 0.3384307791588285\n",
            "At step: 4519 training error: 0.33100689518504295\n",
            "At step: 4520 training error: 0.3302766005879726\n",
            "At step: 4521 training error: 0.33021468637429136\n",
            "At step: 4522 training error: 0.3377912383757941\n",
            "At step: 4523 training error: 0.32204390984247067\n",
            "At step: 4524 training error: 0.3213529227966312\n",
            "At step: 4525 training error: 0.32420832458182125\n",
            "At step: 4526 training error: 0.32738612674666967\n",
            "At step: 4527 training error: 0.3250566654028543\n",
            "At step: 4528 training error: 0.32289438131205966\n",
            "At step: 4529 training error: 0.31377631287584645\n",
            "At step: 4530 training error: 0.32644658579274277\n",
            "At step: 4531 training error: 0.3275151180514183\n",
            "At step: 4532 training error: 0.32731039044515636\n",
            "At step: 4533 training error: 0.3328956796703914\n",
            "At step: 4534 training error: 0.32860660390028046\n",
            "At step: 4535 training error: 0.32547496308474966\n",
            "At step: 4536 training error: 0.3289272186058104\n",
            "At step: 4537 training error: 0.32389149006255546\n",
            "At step: 4538 training error: 0.32099956040742883\n",
            "At step: 4539 training error: 0.31064283991841396\n",
            "At step: 4540 training error: 0.3252115707604397\n",
            "At step: 4541 training error: 0.31966968842538523\n",
            "At step: 4542 training error: 0.32431395171115956\n",
            "At step: 4543 training error: 0.3185740573947353\n",
            "At step: 4544 training error: 0.3173596026128832\n",
            "At step: 4545 training error: 0.31117733607323744\n",
            "At step: 4546 training error: 0.3142817213811113\n",
            "At step: 4547 training error: 0.32177682558224\n",
            "At step: 4548 training error: 0.32644312523274316\n",
            "At step: 4549 training error: 0.33059305932247607\n",
            "At step: 4550 training error: 0.3240292566946442\n",
            "At step: 4551 training error: 0.3332558794666665\n",
            "At step: 4552 training error: 0.33237148441069103\n",
            "At step: 4553 training error: 0.3307118286327655\n",
            "At step: 4554 training error: 0.32487189036691805\n",
            "At step: 4555 training error: 0.32879394998980743\n",
            "At step: 4556 training error: 0.3335115133152728\n",
            "At step: 4557 training error: 0.3375169288792726\n",
            "At step: 4558 training error: 0.3289206600587539\n",
            "At step: 4559 training error: 0.32147665252667346\n",
            "At step: 4560 training error: 0.3077343813884248\n",
            "At step: 4561 training error: 0.3065181581393918\n",
            "At step: 4562 training error: 0.3124896482757021\n",
            "At step: 4563 training error: 0.3131518994559533\n",
            "At step: 4564 training error: 0.32123970928762424\n",
            "At step: 4565 training error: 0.32807791721482366\n",
            "At step: 4566 training error: 0.3276460307365575\n",
            "At step: 4567 training error: 0.32851155991285647\n",
            "At step: 4568 training error: 0.3235094394071441\n",
            "At step: 4569 training error: 0.3284434153389924\n",
            "At step: 4570 training error: 0.3323107671274772\n",
            "At step: 4571 training error: 0.3356981202727855\n",
            "At step: 4572 training error: 0.32727583145316413\n",
            "At step: 4573 training error: 0.32243265966434115\n",
            "At step: 4574 training error: 0.3324839258516883\n",
            "At step: 4575 training error: 0.334449097810953\n",
            "At step: 4576 training error: 0.3324052222754167\n",
            "At step: 4577 training error: 0.3254733060556144\n",
            "At step: 4578 training error: 0.3273755963697145\n",
            "At step: 4579 training error: 0.31785206884671835\n",
            "At step: 4580 training error: 0.31607114976320144\n",
            "At step: 4581 training error: 0.30973679476020965\n",
            "At step: 4582 training error: 0.3121379199029959\n",
            "At step: 4583 training error: 0.3131176186689393\n",
            "At step: 4584 training error: 0.3142085022026178\n",
            "At step: 4585 training error: 0.31420515857289977\n",
            "At step: 4586 training error: 0.3050348243632811\n",
            "At step: 4587 training error: 0.3087256647443043\n",
            "At step: 4588 training error: 0.30845386092225563\n",
            "At step: 4589 training error: 0.32246575718384995\n",
            "At step: 4590 training error: 0.32131953835708954\n",
            "At step: 4591 training error: 0.3206829005094777\n",
            "At step: 4592 training error: 0.31880295412635845\n",
            "At step: 4593 training error: 0.3202007971631752\n",
            "At step: 4594 training error: 0.3272174620247864\n",
            "At step: 4595 training error: 0.3282428473393481\n",
            "At step: 4596 training error: 0.3216537363288841\n",
            "At step: 4597 training error: 0.33787880686743144\n",
            "At step: 4598 training error: 0.34106304796809683\n",
            "At step: 4599 training error: 0.3390441081842376\n",
            "At step: 4600 training error: 0.3354060296736353\n",
            "At step: 4601 training error: 0.3327628847386209\n",
            "At step: 4602 training error: 0.3354587986685372\n",
            "At step: 4603 training error: 0.34131984732850307\n",
            "At step: 4604 training error: 0.33836282477663\n",
            "At step: 4605 training error: 0.33413677819702625\n",
            "At step: 4606 training error: 0.3401353348275093\n",
            "At step: 4607 training error: 0.3278635952959485\n",
            "At step: 4608 training error: 0.3329738357329928\n",
            "At step: 4609 training error: 0.33244166637709605\n",
            "At step: 4610 training error: 0.33162145362789325\n",
            "At step: 4611 training error: 0.32881928881060585\n",
            "At step: 4612 training error: 0.3229195439017331\n",
            "At step: 4613 training error: 0.3185125847292\n",
            "At step: 4614 training error: 0.3155689775026667\n",
            "At step: 4615 training error: 0.3077747883397278\n",
            "At step: 4616 training error: 0.3127997743153281\n",
            "At step: 4617 training error: 0.3182007779730084\n",
            "At step: 4618 training error: 0.3199718654587059\n",
            "At step: 4619 training error: 0.31553820601444016\n",
            "At step: 4620 training error: 0.3149897346874172\n",
            "At step: 4621 training error: 0.31389413583907916\n",
            "At step: 4622 training error: 0.31733292186365364\n",
            "At step: 4623 training error: 0.3173437991227355\n",
            "At step: 4624 training error: 0.3152280311981409\n",
            "At step: 4625 training error: 0.31941221555014\n",
            "At step: 4626 training error: 0.3117484268635167\n",
            "At step: 4627 training error: 0.31555088043680923\n",
            "At step: 4628 training error: 0.31637478729260193\n",
            "At step: 4629 training error: 0.3103900546441189\n",
            "At step: 4630 training error: 0.31645105673871166\n",
            "At step: 4631 training error: 0.3267132840908932\n",
            "At step: 4632 training error: 0.32528255183737903\n",
            "At step: 4633 training error: 0.32849088866521564\n",
            "At step: 4634 training error: 0.33627486797307976\n",
            "At step: 4635 training error: 0.32573067681734824\n",
            "At step: 4636 training error: 0.32539125021586923\n",
            "At step: 4637 training error: 0.3269225314185458\n",
            "At step: 4638 training error: 0.3313813732924413\n",
            "At step: 4639 training error: 0.3417884489911989\n",
            "At step: 4640 training error: 0.3378754820525877\n",
            "At step: 4641 training error: 0.337764816561961\n",
            "At step: 4642 training error: 0.34096474635471047\n",
            "At step: 4643 training error: 0.3383642613186474\n",
            "At step: 4644 training error: 0.33525159579153974\n",
            "At step: 4645 training error: 0.33937044809546824\n",
            "At step: 4646 training error: 0.3291426893174646\n",
            "At step: 4647 training error: 0.3286747443479239\n",
            "At step: 4648 training error: 0.3201071340892768\n",
            "At step: 4649 training error: 0.3306767064515201\n",
            "At step: 4650 training error: 0.32508253532560916\n",
            "At step: 4651 training error: 0.31698085376114016\n",
            "At step: 4652 training error: 0.3201637578163582\n",
            "At step: 4653 training error: 0.3192439270117282\n",
            "At step: 4654 training error: 0.3172544630516257\n",
            "At step: 4655 training error: 0.3151113335253938\n",
            "At step: 4656 training error: 0.3193971787427223\n",
            "At step: 4657 training error: 0.31162949922398075\n",
            "At step: 4658 training error: 0.3076179985900478\n",
            "At step: 4659 training error: 0.30032186102330816\n",
            "At step: 4660 training error: 0.32030990725402564\n",
            "At step: 4661 training error: 0.33019748872509264\n",
            "At step: 4662 training error: 0.33088768014495645\n",
            "At step: 4663 training error: 0.3332365184907887\n",
            "At step: 4664 training error: 0.3477059499043921\n",
            "At step: 4665 training error: 0.34202262062382943\n",
            "At step: 4666 training error: 0.33876060262889895\n",
            "At step: 4667 training error: 0.33786553395375224\n",
            "At step: 4668 training error: 0.33636524855482347\n",
            "At step: 4669 training error: 0.3377051315389896\n",
            "At step: 4670 training error: 0.34500810982449437\n",
            "At step: 4671 training error: 0.34436296543506323\n",
            "At step: 4672 training error: 0.3455690513876057\n",
            "At step: 4673 training error: 0.36243138336438796\n",
            "At step: 4674 training error: 0.35116634780608097\n",
            "At step: 4675 training error: 0.35782258824772095\n",
            "At step: 4676 training error: 0.35710132814106843\n",
            "At step: 4677 training error: 0.34252694590450583\n",
            "At step: 4678 training error: 0.3360313203629096\n",
            "At step: 4679 training error: 0.3316271225168136\n",
            "At step: 4680 training error: 0.3267576927126224\n",
            "At step: 4681 training error: 0.3276306457001148\n",
            "At step: 4682 training error: 0.3294102581461143\n",
            "At step: 4683 training error: 0.34056725536631816\n",
            "At step: 4684 training error: 0.33619864256414617\n",
            "At step: 4685 training error: 0.3305525541126996\n",
            "At step: 4686 training error: 0.3332221683458137\n",
            "At step: 4687 training error: 0.3328364898923504\n",
            "At step: 4688 training error: 0.32569159790179547\n",
            "At step: 4689 training error: 0.321785175070794\n",
            "At step: 4690 training error: 0.3223627592787346\n",
            "At step: 4691 training error: 0.33184526528700115\n",
            "At step: 4692 training error: 0.33355549837147497\n",
            "At step: 4693 training error: 0.3340049345670143\n",
            "At step: 4694 training error: 0.34286908589064746\n",
            "At step: 4695 training error: 0.34100639462732746\n",
            "At step: 4696 training error: 0.345885283136179\n",
            "At step: 4697 training error: 0.3488822301272519\n",
            "At step: 4698 training error: 0.35067167151961093\n",
            "At step: 4699 training error: 0.3440576257198664\n",
            "At step: 4700 training error: 0.3307161571718611\n",
            "At step: 4701 training error: 0.3276135926656634\n",
            "At step: 4702 training error: 0.33305972359528013\n",
            "At step: 4703 training error: 0.3481576593115828\n",
            "At step: 4704 training error: 0.3519802711235714\n",
            "At step: 4705 training error: 0.34922229051527437\n",
            "At step: 4706 training error: 0.3368511650025592\n",
            "At step: 4707 training error: 0.3270571955203404\n",
            "At step: 4708 training error: 0.32517515051418644\n",
            "At step: 4709 training error: 0.3373186031794809\n",
            "At step: 4710 training error: 0.33661481743400606\n",
            "At step: 4711 training error: 0.3293130694961862\n",
            "At step: 4712 training error: 0.33272494215872594\n",
            "At step: 4713 training error: 0.3257438212350854\n",
            "At step: 4714 training error: 0.3280949580842298\n",
            "At step: 4715 training error: 0.34933238264299077\n",
            "At step: 4716 training error: 0.356076631328282\n",
            "At step: 4717 training error: 0.3366631232657854\n",
            "At step: 4718 training error: 0.3260044887613472\n",
            "At step: 4719 training error: 0.3272330972226213\n",
            "At step: 4720 training error: 0.33116220353009085\n",
            "At step: 4721 training error: 0.33584152419834273\n",
            "At step: 4722 training error: 0.3412899562548163\n",
            "At step: 4723 training error: 0.3409661051715671\n",
            "At step: 4724 training error: 0.338943713675676\n",
            "At step: 4725 training error: 0.33942127270167277\n",
            "At step: 4726 training error: 0.32521429006573044\n",
            "At step: 4727 training error: 0.33426353601518133\n",
            "At step: 4728 training error: 0.33350897097883564\n",
            "At step: 4729 training error: 0.3307082970800765\n",
            "At step: 4730 training error: 0.33905385950765493\n",
            "At step: 4731 training error: 0.35066607230532837\n",
            "At step: 4732 training error: 0.3421910608526013\n",
            "At step: 4733 training error: 0.34467757199822935\n",
            "At step: 4734 training error: 0.3467359949657359\n",
            "At step: 4735 training error: 0.3432184685082313\n",
            "At step: 4736 training error: 0.345143941449155\n",
            "At step: 4737 training error: 0.3551847597247073\n",
            "At step: 4738 training error: 0.35246422706606295\n",
            "At step: 4739 training error: 0.34945886256644315\n",
            "At step: 4740 training error: 0.34482502359776895\n",
            "At step: 4741 training error: 0.3499099903932628\n",
            "At step: 4742 training error: 0.34024988509426796\n",
            "At step: 4743 training error: 0.3291967010136884\n",
            "At step: 4744 training error: 0.31934236584645453\n",
            "At step: 4745 training error: 0.32315625420066224\n",
            "At step: 4746 training error: 0.3258189542077257\n",
            "At step: 4747 training error: 0.3206784494206034\n",
            "At step: 4748 training error: 0.3154923248902614\n",
            "At step: 4749 training error: 0.30606354922591217\n",
            "At step: 4750 training error: 0.3207299806055708\n",
            "At step: 4751 training error: 0.3057211996335859\n",
            "At step: 4752 training error: 0.31510788328264294\n",
            "At step: 4753 training error: 0.3165094562517538\n",
            "At step: 4754 training error: 0.3131731958587117\n",
            "At step: 4755 training error: 0.3105104418420255\n",
            "At step: 4756 training error: 0.3114093275538108\n",
            "At step: 4757 training error: 0.3123679586801031\n",
            "At step: 4758 training error: 0.32371712510741324\n",
            "At step: 4759 training error: 0.33860261678439846\n",
            "At step: 4760 training error: 0.33759605967546624\n",
            "At step: 4761 training error: 0.33761230092483213\n",
            "At step: 4762 training error: 0.32942956266967716\n",
            "At step: 4763 training error: 0.33707003571663335\n",
            "At step: 4764 training error: 0.34503887232846114\n",
            "At step: 4765 training error: 0.3408321218938003\n",
            "At step: 4766 training error: 0.34565957356017385\n",
            "At step: 4767 training error: 0.3383990945865222\n",
            "At step: 4768 training error: 0.3343058914805319\n",
            "At step: 4769 training error: 0.3251279406543345\n",
            "At step: 4770 training error: 0.31964412951038357\n",
            "At step: 4771 training error: 0.32078460891238203\n",
            "At step: 4772 training error: 0.3298982755081725\n",
            "At step: 4773 training error: 0.3305140944645801\n",
            "At step: 4774 training error: 0.34011965131589234\n",
            "At step: 4775 training error: 0.3394800081305317\n",
            "At step: 4776 training error: 0.3508249990914908\n",
            "At step: 4777 training error: 0.3386868980294014\n",
            "At step: 4778 training error: 0.33675501842396083\n",
            "At step: 4779 training error: 0.3346247313692469\n",
            "At step: 4780 training error: 0.32251995560707103\n",
            "At step: 4781 training error: 0.325381646565443\n",
            "At step: 4782 training error: 0.32985832048518593\n",
            "At step: 4783 training error: 0.3241694126059021\n",
            "At step: 4784 training error: 0.3191920159691015\n",
            "At step: 4785 training error: 0.31417575681914894\n",
            "At step: 4786 training error: 0.3127947105798131\n",
            "At step: 4787 training error: 0.3093782121048373\n",
            "At step: 4788 training error: 0.30928568811314916\n",
            "At step: 4789 training error: 0.3170466210123998\n",
            "At step: 4790 training error: 0.31300935431545607\n",
            "At step: 4791 training error: 0.3174413051020942\n",
            "At step: 4792 training error: 0.31559358846800317\n",
            "At step: 4793 training error: 0.31682651118315586\n",
            "At step: 4794 training error: 0.31712664585531825\n",
            "At step: 4795 training error: 0.3280749804249899\n",
            "At step: 4796 training error: 0.3258994675825695\n",
            "At step: 4797 training error: 0.3229995072013386\n",
            "At step: 4798 training error: 0.32400876951439633\n",
            "At step: 4799 training error: 0.33151931015340486\n",
            "At step: 4800 training error: 0.3311225613954419\n",
            "At step: 4801 training error: 0.3281052466718703\n",
            "At step: 4802 training error: 0.3302514614775848\n",
            "At step: 4803 training error: 0.33572107009623775\n",
            "At step: 4804 training error: 0.32357061125544945\n",
            "At step: 4805 training error: 0.3243757045518755\n",
            "At step: 4806 training error: 0.32443536673977297\n",
            "At step: 4807 training error: 0.3269724147395341\n",
            "At step: 4808 training error: 0.3255513935738325\n",
            "At step: 4809 training error: 0.3245134604767434\n",
            "At step: 4810 training error: 0.32054731388606583\n",
            "At step: 4811 training error: 0.31676510920892936\n",
            "At step: 4812 training error: 0.3135425410458078\n",
            "At step: 4813 training error: 0.3053566939396407\n",
            "At step: 4814 training error: 0.2986261030840685\n",
            "At step: 4815 training error: 0.30444596295435433\n",
            "At step: 4816 training error: 0.3088638587048962\n",
            "At step: 4817 training error: 0.32235915896678824\n",
            "At step: 4818 training error: 0.3224495488223475\n",
            "At step: 4819 training error: 0.31440612157048586\n",
            "At step: 4820 training error: 0.3098056777017128\n",
            "At step: 4821 training error: 0.3051970538233728\n",
            "At step: 4822 training error: 0.3038351419491221\n",
            "At step: 4823 training error: 0.319371449904677\n",
            "At step: 4824 training error: 0.3303656275869528\n",
            "At step: 4825 training error: 0.3290277673239311\n",
            "At step: 4826 training error: 0.32361804808281436\n",
            "At step: 4827 training error: 0.3317345637922836\n",
            "At step: 4828 training error: 0.3325789540857096\n",
            "At step: 4829 training error: 0.330928725938145\n",
            "At step: 4830 training error: 0.3390592531885714\n",
            "At step: 4831 training error: 0.3262426215458616\n",
            "At step: 4832 training error: 0.3138658610799695\n",
            "At step: 4833 training error: 0.3264326317104261\n",
            "At step: 4834 training error: 0.33936634401972826\n",
            "At step: 4835 training error: 0.3342137739514048\n",
            "At step: 4836 training error: 0.32908995610826147\n",
            "At step: 4837 training error: 0.3357934831104421\n",
            "At step: 4838 training error: 0.3323905477381218\n",
            "At step: 4839 training error: 0.33114805139953696\n",
            "At step: 4840 training error: 0.3330202099834111\n",
            "At step: 4841 training error: 0.33110695164674425\n",
            "At step: 4842 training error: 0.33627535831859945\n",
            "At step: 4843 training error: 0.3309006209936396\n",
            "At step: 4844 training error: 0.3283942781634889\n",
            "At step: 4845 training error: 0.3211272761106517\n",
            "At step: 4846 training error: 0.3285129274093509\n",
            "At step: 4847 training error: 0.33009513840738586\n",
            "At step: 4848 training error: 0.3360781022755998\n",
            "At step: 4849 training error: 0.32717621556145515\n",
            "At step: 4850 training error: 0.31081378033003704\n",
            "At step: 4851 training error: 0.3128517796845206\n",
            "At step: 4852 training error: 0.31099315090737933\n",
            "At step: 4853 training error: 0.31618766466688325\n",
            "At step: 4854 training error: 0.31805043606358874\n",
            "At step: 4855 training error: 0.3165087329982242\n",
            "At step: 4856 training error: 0.3096354908654936\n",
            "At step: 4857 training error: 0.3158636697693859\n",
            "At step: 4858 training error: 0.3151449473222994\n",
            "At step: 4859 training error: 0.3075977601280844\n",
            "At step: 4860 training error: 0.3040759872160783\n",
            "At step: 4861 training error: 0.2980365203409693\n",
            "At step: 4862 training error: 0.3026774217938983\n",
            "At step: 4863 training error: 0.2989105417629444\n",
            "At step: 4864 training error: 0.30644662435153913\n",
            "At step: 4865 training error: 0.2994480617863551\n",
            "At step: 4866 training error: 0.29789983586167823\n",
            "At step: 4867 training error: 0.29577538314391216\n",
            "At step: 4868 training error: 0.29001321007265635\n",
            "At step: 4869 training error: 0.2919529477051803\n",
            "At step: 4870 training error: 0.2920076575853734\n",
            "At step: 4871 training error: 0.2986522354681557\n",
            "At step: 4872 training error: 0.311900169366659\n",
            "At step: 4873 training error: 0.31716550647015274\n",
            "At step: 4874 training error: 0.3188449861605756\n",
            "At step: 4875 training error: 0.3270558592898686\n",
            "At step: 4876 training error: 0.3362043229641548\n",
            "At step: 4877 training error: 0.33028051063131675\n",
            "At step: 4878 training error: 0.32852737973862806\n",
            "At step: 4879 training error: 0.33354904799521284\n",
            "At step: 4880 training error: 0.3227851503048019\n",
            "At step: 4881 training error: 0.32499112430174065\n",
            "At step: 4882 training error: 0.32386042459527\n",
            "At step: 4883 training error: 0.325731007370148\n",
            "At step: 4884 training error: 0.3249965660446259\n",
            "At step: 4885 training error: 0.320429986582829\n",
            "At step: 4886 training error: 0.31672446993672104\n",
            "At step: 4887 training error: 0.3223831026195039\n",
            "At step: 4888 training error: 0.32710761014603695\n",
            "At step: 4889 training error: 0.3319765479562879\n",
            "At step: 4890 training error: 0.31938303941329954\n",
            "At step: 4891 training error: 0.3147434901170381\n",
            "At step: 4892 training error: 0.31471281277240426\n",
            "At step: 4893 training error: 0.3134559160297731\n",
            "At step: 4894 training error: 0.3173108151159497\n",
            "At step: 4895 training error: 0.3201432343289957\n",
            "At step: 4896 training error: 0.32227824060863375\n",
            "At step: 4897 training error: 0.31217381623938906\n",
            "At step: 4898 training error: 0.3135883030165713\n",
            "At step: 4899 training error: 0.304642284867652\n",
            "At step: 4900 training error: 0.3017394365686937\n",
            "At step: 4901 training error: 0.2941402537151734\n",
            "At step: 4902 training error: 0.2971673569507367\n",
            "At step: 4903 training error: 0.30262900778345686\n",
            "At step: 4904 training error: 0.3060569290252719\n",
            "At step: 4905 training error: 0.31662250028600913\n",
            "At step: 4906 training error: 0.3192003889074603\n",
            "At step: 4907 training error: 0.3284852190429428\n",
            "At step: 4908 training error: 0.3280365897868934\n",
            "At step: 4909 training error: 0.3259842569621013\n",
            "At step: 4910 training error: 0.31969061970458956\n",
            "At step: 4911 training error: 0.3235036847362539\n",
            "At step: 4912 training error: 0.32243763864503716\n",
            "At step: 4913 training error: 0.3257413093657881\n",
            "At step: 4914 training error: 0.3318348558965305\n",
            "At step: 4915 training error: 0.3243327091043082\n",
            "At step: 4916 training error: 0.3143143618644749\n",
            "At step: 4917 training error: 0.31049111873632856\n",
            "At step: 4918 training error: 0.31190878987266973\n",
            "At step: 4919 training error: 0.3123653445067747\n",
            "At step: 4920 training error: 0.3174376159812113\n",
            "At step: 4921 training error: 0.3076022004104072\n",
            "At step: 4922 training error: 0.30707275985996896\n",
            "At step: 4923 training error: 0.3043357764060435\n",
            "At step: 4924 training error: 0.29998929932738105\n",
            "At step: 4925 training error: 0.29188802137148184\n",
            "At step: 4926 training error: 0.28883435329351187\n",
            "At step: 4927 training error: 0.28829120826407384\n",
            "At step: 4928 training error: 0.2988628219436688\n",
            "At step: 4929 training error: 0.29759254027961163\n",
            "At step: 4930 training error: 0.311661769970902\n",
            "At step: 4931 training error: 0.31481109218968234\n",
            "At step: 4932 training error: 0.32059794160542304\n",
            "At step: 4933 training error: 0.31396223552618113\n",
            "At step: 4934 training error: 0.3186169983016104\n",
            "At step: 4935 training error: 0.33434661406082555\n",
            "At step: 4936 training error: 0.3300285419671657\n",
            "At step: 4937 training error: 0.3282740328612508\n",
            "At step: 4938 training error: 0.3266369519054772\n",
            "At step: 4939 training error: 0.32524856913845557\n",
            "At step: 4940 training error: 0.33809294107712523\n",
            "At step: 4941 training error: 0.3300153914137044\n",
            "At step: 4942 training error: 0.31848915684103263\n",
            "At step: 4943 training error: 0.31882543011085496\n",
            "At step: 4944 training error: 0.31441696512927236\n",
            "At step: 4945 training error: 0.305758159206885\n",
            "At step: 4946 training error: 0.3020442574700817\n",
            "At step: 4947 training error: 0.2980116562607497\n",
            "At step: 4948 training error: 0.2973509167927535\n",
            "At step: 4949 training error: 0.30761731226153555\n",
            "At step: 4950 training error: 0.3155469046798625\n",
            "At step: 4951 training error: 0.3105795397104224\n",
            "At step: 4952 training error: 0.3181865292820865\n",
            "At step: 4953 training error: 0.32052676606932307\n",
            "At step: 4954 training error: 0.30878123647336314\n",
            "At step: 4955 training error: 0.3145818256188735\n",
            "At step: 4956 training error: 0.3021466857344585\n",
            "At step: 4957 training error: 0.2992487904296661\n",
            "At step: 4958 training error: 0.3032075885717497\n",
            "At step: 4959 training error: 0.3127422609708416\n",
            "At step: 4960 training error: 0.32328314630953925\n",
            "At step: 4961 training error: 0.3227055522238368\n",
            "At step: 4962 training error: 0.3185495873897353\n",
            "At step: 4963 training error: 0.31196911069109934\n",
            "At step: 4964 training error: 0.30889575286524007\n",
            "At step: 4965 training error: 0.31113676528389894\n",
            "At step: 4966 training error: 0.30416940335687126\n",
            "At step: 4967 training error: 0.3079801760016958\n",
            "At step: 4968 training error: 0.30489218483071295\n",
            "At step: 4969 training error: 0.30967271796843665\n",
            "At step: 4970 training error: 0.3160564057821408\n",
            "At step: 4971 training error: 0.31079255819492657\n",
            "At step: 4972 training error: 0.32207648051517695\n",
            "At step: 4973 training error: 0.32883800502050003\n",
            "At step: 4974 training error: 0.33024209641169705\n",
            "At step: 4975 training error: 0.32525411336738047\n",
            "At step: 4976 training error: 0.3261945565072001\n",
            "At step: 4977 training error: 0.3306388299840132\n",
            "At step: 4978 training error: 0.3212154840061671\n",
            "At step: 4979 training error: 0.3149768705955079\n",
            "At step: 4980 training error: 0.32009275063031756\n",
            "At step: 4981 training error: 0.32989304052643265\n",
            "At step: 4982 training error: 0.32489189875697144\n",
            "At step: 4983 training error: 0.31582306294130835\n",
            "At step: 4984 training error: 0.316953085523401\n",
            "At step: 4985 training error: 0.31637244108518425\n",
            "At step: 4986 training error: 0.32625005764257153\n",
            "At step: 4987 training error: 0.3230204025305949\n",
            "At step: 4988 training error: 0.33326414896258594\n",
            "At step: 4989 training error: 0.3243853937296215\n",
            "At step: 4990 training error: 0.3367985978468779\n",
            "At step: 4991 training error: 0.33495874727434455\n",
            "At step: 4992 training error: 0.3401104877554608\n",
            "At step: 4993 training error: 0.3350912815216206\n",
            "At step: 4994 training error: 0.33655981260938594\n",
            "At step: 4995 training error: 0.33844005096388624\n",
            "At step: 4996 training error: 0.34387490659955194\n",
            "At step: 4997 training error: 0.34381532642928264\n",
            "At step: 4998 training error: 0.33326977041737704\n",
            "At step: 4999 training error: 0.33153723406537705\n",
            "At step: 5000 training error: 0.3310117819735561\n",
            "At step: 5001 training error: 0.3404003501583215\n",
            "At step: 5002 training error: 0.3332067168023589\n",
            "At step: 5003 training error: 0.326759212361226\n",
            "At step: 5004 training error: 0.3299573140157856\n",
            "At step: 5005 training error: 0.32457064280684533\n",
            "At step: 5006 training error: 0.31825121480267793\n",
            "At step: 5007 training error: 0.32306029412466775\n",
            "At step: 5008 training error: 0.3220681229271677\n",
            "At step: 5009 training error: 0.32787401182963655\n",
            "At step: 5010 training error: 0.33316339810210704\n",
            "At step: 5011 training error: 0.33291738285154554\n",
            "At step: 5012 training error: 0.3350475074025713\n",
            "At step: 5013 training error: 0.3341299801473669\n",
            "At step: 5014 training error: 0.3323125333212197\n",
            "At step: 5015 training error: 0.33623800934144404\n",
            "At step: 5016 training error: 0.3344885162573653\n",
            "At step: 5017 training error: 0.33265460171638084\n",
            "At step: 5018 training error: 0.3328418998978575\n",
            "At step: 5019 training error: 0.3263811130590736\n",
            "At step: 5020 training error: 0.32588635787108106\n",
            "At step: 5021 training error: 0.33420234720821995\n",
            "At step: 5022 training error: 0.34632646758977653\n",
            "At step: 5023 training error: 0.3589916183802133\n",
            "At step: 5024 training error: 0.34135763338551706\n",
            "At step: 5025 training error: 0.3395048966148424\n",
            "At step: 5026 training error: 0.32617162415559714\n",
            "At step: 5027 training error: 0.3300236119371592\n",
            "At step: 5028 training error: 0.3398166524888391\n",
            "At step: 5029 training error: 0.3411834499016134\n",
            "At step: 5030 training error: 0.3415109629732981\n",
            "At step: 5031 training error: 0.3327958111323306\n",
            "At step: 5032 training error: 0.33157409840133883\n",
            "At step: 5033 training error: 0.33141996638964966\n",
            "At step: 5034 training error: 0.32793660593037566\n",
            "At step: 5035 training error: 0.3194782131528238\n",
            "At step: 5036 training error: 0.32274557202980025\n",
            "At step: 5037 training error: 0.3357986814349172\n",
            "At step: 5038 training error: 0.3275422980229018\n",
            "At step: 5039 training error: 0.3263782747891961\n",
            "At step: 5040 training error: 0.32838169469647127\n",
            "At step: 5041 training error: 0.33213724551176355\n",
            "At step: 5042 training error: 0.33176291693369786\n",
            "At step: 5043 training error: 0.33075257444002026\n",
            "At step: 5044 training error: 0.3333635220213526\n",
            "At step: 5045 training error: 0.3270726059967448\n",
            "At step: 5046 training error: 0.3351966956178776\n",
            "At step: 5047 training error: 0.32886462647663023\n",
            "At step: 5048 training error: 0.32591901805333906\n",
            "At step: 5049 training error: 0.3337853847686978\n",
            "At step: 5050 training error: 0.3333014615766772\n",
            "At step: 5051 training error: 0.33058034649097534\n",
            "At step: 5052 training error: 0.3333856850077055\n",
            "At step: 5053 training error: 0.3336814659905845\n",
            "At step: 5054 training error: 0.3301471513433522\n",
            "At step: 5055 training error: 0.3280556147788928\n",
            "At step: 5056 training error: 0.3268882321915636\n",
            "At step: 5057 training error: 0.32453679105692285\n",
            "At step: 5058 training error: 0.3250677630011678\n",
            "At step: 5059 training error: 0.3361412097187876\n",
            "At step: 5060 training error: 0.34462216203922913\n",
            "At step: 5061 training error: 0.3450452719806947\n",
            "At step: 5062 training error: 0.347174427947263\n",
            "At step: 5063 training error: 0.3417329788168961\n",
            "At step: 5064 training error: 0.32827565785953045\n",
            "At step: 5065 training error: 0.3371463029849874\n",
            "At step: 5066 training error: 0.33041244748991316\n",
            "At step: 5067 training error: 0.32519242598080816\n",
            "At step: 5068 training error: 0.32714941489410077\n",
            "At step: 5069 training error: 0.32429128112185357\n",
            "At step: 5070 training error: 0.32138550235668306\n",
            "At step: 5071 training error: 0.32236043733185277\n",
            "At step: 5072 training error: 0.3129679912358478\n",
            "At step: 5073 training error: 0.304435416385972\n",
            "At step: 5074 training error: 0.30067667690404903\n",
            "At step: 5075 training error: 0.30303507529682694\n",
            "At step: 5076 training error: 0.2978222754311454\n",
            "At step: 5077 training error: 0.31029777870908476\n",
            "At step: 5078 training error: 0.3121586212891882\n",
            "At step: 5079 training error: 0.3101730892889722\n",
            "At step: 5080 training error: 0.30827018778431775\n",
            "At step: 5081 training error: 0.3057853595192752\n",
            "At step: 5082 training error: 0.317124391337412\n",
            "At step: 5083 training error: 0.3094781540372164\n",
            "At step: 5084 training error: 0.32040267165004144\n",
            "At step: 5085 training error: 0.3181579588934217\n",
            "At step: 5086 training error: 0.3146258969771987\n",
            "At step: 5087 training error: 0.3093489240301333\n",
            "At step: 5088 training error: 0.31340052116865336\n",
            "At step: 5089 training error: 0.30617362422735905\n",
            "At step: 5090 training error: 0.30187437357015134\n",
            "At step: 5091 training error: 0.3097510379250318\n",
            "At step: 5092 training error: 0.3138997634103635\n",
            "At step: 5093 training error: 0.32035818477601397\n",
            "At step: 5094 training error: 0.3188981201171909\n",
            "At step: 5095 training error: 0.3175910944522925\n",
            "At step: 5096 training error: 0.31978830444457934\n",
            "At step: 5097 training error: 0.31611645433797764\n",
            "At step: 5098 training error: 0.316274192508184\n",
            "At step: 5099 training error: 0.31463184198322447\n",
            "At step: 5100 training error: 0.3177440362672133\n",
            "At step: 5101 training error: 0.3175772772050979\n",
            "At step: 5102 training error: 0.3204316789341254\n",
            "At step: 5103 training error: 0.31577282670841594\n",
            "At step: 5104 training error: 0.31384090477186005\n",
            "At step: 5105 training error: 0.3152519703660846\n",
            "At step: 5106 training error: 0.30684933152205085\n",
            "At step: 5107 training error: 0.3107840194830526\n",
            "At step: 5108 training error: 0.3105263116280552\n",
            "At step: 5109 training error: 0.2958758075655484\n",
            "At step: 5110 training error: 0.291532027804009\n",
            "At step: 5111 training error: 0.2932283824144271\n",
            "At step: 5112 training error: 0.3106260627547502\n",
            "At step: 5113 training error: 0.3037821121331333\n",
            "At step: 5114 training error: 0.299768238474965\n",
            "At step: 5115 training error: 0.3063545089301889\n",
            "At step: 5116 training error: 0.3053725635507277\n",
            "At step: 5117 training error: 0.29732896018027\n",
            "At step: 5118 training error: 0.31008367545377946\n",
            "At step: 5119 training error: 0.3199810666401621\n",
            "At step: 5120 training error: 0.31589486596137517\n",
            "At step: 5121 training error: 0.3094713152556003\n",
            "At step: 5122 training error: 0.3151326239713774\n",
            "At step: 5123 training error: 0.3139192147082237\n",
            "At step: 5124 training error: 0.308351188380142\n",
            "At step: 5125 training error: 0.3038850335838958\n",
            "At step: 5126 training error: 0.3004188907791398\n",
            "At step: 5127 training error: 0.29511828273341323\n",
            "At step: 5128 training error: 0.2998045614017472\n",
            "At step: 5129 training error: 0.3002617410198738\n",
            "At step: 5130 training error: 0.3085678562389158\n",
            "At step: 5131 training error: 0.29989081846881205\n",
            "At step: 5132 training error: 0.29981608834550266\n",
            "At step: 5133 training error: 0.3051904276917917\n",
            "At step: 5134 training error: 0.3077596728134859\n",
            "At step: 5135 training error: 0.30058640941196113\n",
            "At step: 5136 training error: 0.3108007913174913\n",
            "At step: 5137 training error: 0.3129459407139041\n",
            "At step: 5138 training error: 0.3211294885725006\n",
            "At step: 5139 training error: 0.3148632029357387\n",
            "At step: 5140 training error: 0.31960001020315454\n",
            "At step: 5141 training error: 0.3280459145571468\n",
            "At step: 5142 training error: 0.3353262266647877\n",
            "At step: 5143 training error: 0.3245274933941959\n",
            "At step: 5144 training error: 0.32754959953911883\n",
            "At step: 5145 training error: 0.33255938018074505\n",
            "At step: 5146 training error: 0.3420456588450807\n",
            "At step: 5147 training error: 0.32703225735108465\n",
            "At step: 5148 training error: 0.31938593214877975\n",
            "At step: 5149 training error: 0.30994595386912943\n",
            "At step: 5150 training error: 0.3081872806597115\n",
            "At step: 5151 training error: 0.3087327589173811\n",
            "At step: 5152 training error: 0.3192215793450652\n",
            "At step: 5153 training error: 0.3166613513514816\n",
            "At step: 5154 training error: 0.3096437493833165\n",
            "At step: 5155 training error: 0.3126469632607333\n",
            "At step: 5156 training error: 0.30698012143721487\n",
            "At step: 5157 training error: 0.300015608726389\n",
            "At step: 5158 training error: 0.2953323249233983\n",
            "At step: 5159 training error: 0.30805285072433347\n",
            "At step: 5160 training error: 0.3113394942386355\n",
            "At step: 5161 training error: 0.312607681172462\n",
            "At step: 5162 training error: 0.31482120884648546\n",
            "At step: 5163 training error: 0.3061269560997608\n",
            "At step: 5164 training error: 0.30938185707532795\n",
            "At step: 5165 training error: 0.31239561398703114\n",
            "At step: 5166 training error: 0.30887204787106104\n",
            "At step: 5167 training error: 0.30746507396608763\n",
            "At step: 5168 training error: 0.297555492482686\n",
            "At step: 5169 training error: 0.28735047423522136\n",
            "At step: 5170 training error: 0.28972822200942033\n",
            "At step: 5171 training error: 0.2950626310827109\n",
            "At step: 5172 training error: 0.300794743794329\n",
            "At step: 5173 training error: 0.29568073394437727\n",
            "At step: 5174 training error: 0.3093134276340047\n",
            "At step: 5175 training error: 0.31487190410995636\n",
            "At step: 5176 training error: 0.30581094836234946\n",
            "At step: 5177 training error: 0.3065665913822768\n",
            "At step: 5178 training error: 0.30687858435567\n",
            "At step: 5179 training error: 0.30955238978597865\n",
            "At step: 5180 training error: 0.30958002139634183\n",
            "At step: 5181 training error: 0.30612990462126105\n",
            "At step: 5182 training error: 0.3164553687064276\n",
            "At step: 5183 training error: 0.3233005779303367\n",
            "At step: 5184 training error: 0.32937838785681695\n",
            "At step: 5185 training error: 0.3346084351569979\n",
            "At step: 5186 training error: 0.34815299994268956\n",
            "At step: 5187 training error: 0.3440386996898393\n",
            "At step: 5188 training error: 0.3486402008676107\n",
            "At step: 5189 training error: 0.34687072048639744\n",
            "At step: 5190 training error: 0.34683938119831353\n",
            "At step: 5191 training error: 0.33947168603229855\n",
            "At step: 5192 training error: 0.3316671674657711\n",
            "At step: 5193 training error: 0.32621552672625015\n",
            "At step: 5194 training error: 0.3239244446318513\n",
            "At step: 5195 training error: 0.3269588559680723\n",
            "At step: 5196 training error: 0.32786760610072035\n",
            "At step: 5197 training error: 0.3272426962764497\n",
            "At step: 5198 training error: 0.3167064464488335\n",
            "At step: 5199 training error: 0.33666140840166886\n",
            "At step: 5200 training error: 0.33378951309619287\n",
            "At step: 5201 training error: 0.3371277534115958\n",
            "At step: 5202 training error: 0.3379195456896735\n",
            "At step: 5203 training error: 0.3463387434611839\n",
            "At step: 5204 training error: 0.3321015560640572\n",
            "At step: 5205 training error: 0.33147158101420326\n",
            "At step: 5206 training error: 0.3240925322646756\n",
            "At step: 5207 training error: 0.322681278761091\n",
            "At step: 5208 training error: 0.32551395748492856\n",
            "At step: 5209 training error: 0.3209525902621245\n",
            "At step: 5210 training error: 0.32549948390637545\n",
            "At step: 5211 training error: 0.3216907304018197\n",
            "At step: 5212 training error: 0.31228999384683714\n",
            "At step: 5213 training error: 0.30743224289387727\n",
            "At step: 5214 training error: 0.3261457409091664\n",
            "At step: 5215 training error: 0.33072640776887974\n",
            "At step: 5216 training error: 0.330643574575504\n",
            "At step: 5217 training error: 0.32789067499450725\n",
            "At step: 5218 training error: 0.3266711518073621\n",
            "At step: 5219 training error: 0.33067418006472155\n",
            "At step: 5220 training error: 0.3368839969274657\n",
            "At step: 5221 training error: 0.3373799833232481\n",
            "At step: 5222 training error: 0.32837372720724667\n",
            "At step: 5223 training error: 0.3263929175563518\n",
            "At step: 5224 training error: 0.32379040039386126\n",
            "At step: 5225 training error: 0.3213077123124659\n",
            "At step: 5226 training error: 0.3253884351532023\n",
            "At step: 5227 training error: 0.3186594880272515\n",
            "At step: 5228 training error: 0.31973508574760656\n",
            "At step: 5229 training error: 0.3221436125168409\n",
            "At step: 5230 training error: 0.3228809667646312\n",
            "At step: 5231 training error: 0.30934638087436395\n",
            "At step: 5232 training error: 0.29425748138577734\n",
            "At step: 5233 training error: 0.2996039652423314\n",
            "At step: 5234 training error: 0.30396000406391166\n",
            "At step: 5235 training error: 0.3017338567268151\n",
            "At step: 5236 training error: 0.30569683515416635\n",
            "At step: 5237 training error: 0.31000600079911783\n",
            "At step: 5238 training error: 0.30528676811417405\n",
            "At step: 5239 training error: 0.3197738253773077\n",
            "At step: 5240 training error: 0.31503148171514606\n",
            "At step: 5241 training error: 0.31275313733639865\n",
            "At step: 5242 training error: 0.31825000098158057\n",
            "At step: 5243 training error: 0.33417884704994594\n",
            "At step: 5244 training error: 0.3315685378640291\n",
            "At step: 5245 training error: 0.33855215144934797\n",
            "At step: 5246 training error: 0.3298621507119622\n",
            "At step: 5247 training error: 0.3295289389238483\n",
            "At step: 5248 training error: 0.33073366841656837\n",
            "At step: 5249 training error: 0.32432139153716627\n",
            "At step: 5250 training error: 0.3346461154857542\n",
            "At step: 5251 training error: 0.33344635109304954\n",
            "At step: 5252 training error: 0.33125270750323377\n",
            "At step: 5253 training error: 0.328321995122782\n",
            "At step: 5254 training error: 0.31961781916251275\n",
            "At step: 5255 training error: 0.32698457953021387\n",
            "At step: 5256 training error: 0.3147106726905057\n",
            "At step: 5257 training error: 0.330506733858993\n",
            "At step: 5258 training error: 0.3253010587143507\n",
            "At step: 5259 training error: 0.3187695789165432\n",
            "At step: 5260 training error: 0.3229858172688348\n",
            "At step: 5261 training error: 0.3289285617861535\n",
            "At step: 5262 training error: 0.32661535475848064\n",
            "At step: 5263 training error: 0.321373224894012\n",
            "At step: 5264 training error: 0.3144855664141208\n",
            "At step: 5265 training error: 0.307074348231853\n",
            "At step: 5266 training error: 0.3081336693498353\n",
            "At step: 5267 training error: 0.3024034629719\n",
            "At step: 5268 training error: 0.30423104713491345\n",
            "At step: 5269 training error: 0.30379971552310087\n",
            "At step: 5270 training error: 0.2998471711828813\n",
            "At step: 5271 training error: 0.2967314794607687\n",
            "At step: 5272 training error: 0.2928896281682051\n",
            "At step: 5273 training error: 0.2858001677348212\n",
            "At step: 5274 training error: 0.28497170839361785\n",
            "At step: 5275 training error: 0.2853841768458452\n",
            "At step: 5276 training error: 0.28031559160668457\n",
            "At step: 5277 training error: 0.27002948093159096\n",
            "At step: 5278 training error: 0.26244430311761924\n",
            "At step: 5279 training error: 0.26898298732436954\n",
            "At step: 5280 training error: 0.2827527436716607\n",
            "At step: 5281 training error: 0.2803706927391947\n",
            "At step: 5282 training error: 0.2711378752460069\n",
            "At step: 5283 training error: 0.2801801905331328\n",
            "At step: 5284 training error: 0.2931406283479902\n",
            "At step: 5285 training error: 0.2933892906716523\n",
            "At step: 5286 training error: 0.30216299216998577\n",
            "At step: 5287 training error: 0.302751027936358\n",
            "At step: 5288 training error: 0.30436963118940386\n",
            "At step: 5289 training error: 0.293325572253216\n",
            "At step: 5290 training error: 0.2937053470857261\n",
            "At step: 5291 training error: 0.2915057886381678\n",
            "At step: 5292 training error: 0.2986555513736146\n",
            "At step: 5293 training error: 0.30554350425722604\n",
            "At step: 5294 training error: 0.31549276713930385\n",
            "At step: 5295 training error: 0.3234704785198837\n",
            "At step: 5296 training error: 0.3223102603574012\n",
            "At step: 5297 training error: 0.32268274551292064\n",
            "At step: 5298 training error: 0.3226581111547066\n",
            "At step: 5299 training error: 0.3414047452402707\n",
            "At step: 5300 training error: 0.33883247287062185\n",
            "At step: 5301 training error: 0.33545264199986413\n",
            "At step: 5302 training error: 0.33609116900976926\n",
            "At step: 5303 training error: 0.3270808553464693\n",
            "At step: 5304 training error: 0.317832877307387\n",
            "At step: 5305 training error: 0.31304480658665607\n",
            "At step: 5306 training error: 0.3090867845566431\n",
            "At step: 5307 training error: 0.3003242815634489\n",
            "At step: 5308 training error: 0.3001134630058314\n",
            "At step: 5309 training error: 0.3044266250963866\n",
            "At step: 5310 training error: 0.31379636465214034\n",
            "At step: 5311 training error: 0.3136761147304953\n",
            "At step: 5312 training error: 0.30481603800150536\n",
            "At step: 5313 training error: 0.3005313614426002\n",
            "At step: 5314 training error: 0.2994970516281806\n",
            "At step: 5315 training error: 0.3051974166940518\n",
            "At step: 5316 training error: 0.31425533312904563\n",
            "At step: 5317 training error: 0.3067586896199832\n",
            "At step: 5318 training error: 0.3106418915954087\n",
            "At step: 5319 training error: 0.3087433780765404\n",
            "At step: 5320 training error: 0.3058099018215303\n",
            "At step: 5321 training error: 0.31044795542657977\n",
            "At step: 5322 training error: 0.30796174130253173\n",
            "At step: 5323 training error: 0.3065050507675886\n",
            "At step: 5324 training error: 0.3111911947929572\n",
            "At step: 5325 training error: 0.3119606893017999\n",
            "At step: 5326 training error: 0.3109276598371353\n",
            "At step: 5327 training error: 0.3006397683625536\n",
            "At step: 5328 training error: 0.30338833761536466\n",
            "At step: 5329 training error: 0.3158904506965848\n",
            "At step: 5330 training error: 0.32339672158878247\n",
            "At step: 5331 training error: 0.32335367899620354\n",
            "At step: 5332 training error: 0.31507019346245685\n",
            "At step: 5333 training error: 0.31121847772516414\n",
            "At step: 5334 training error: 0.318294238354946\n",
            "At step: 5335 training error: 0.3147427324169969\n",
            "At step: 5336 training error: 0.33333457980495435\n",
            "At step: 5337 training error: 0.33138749034702525\n",
            "At step: 5338 training error: 0.3353211959461454\n",
            "At step: 5339 training error: 0.34405728014003806\n",
            "At step: 5340 training error: 0.34970982959927\n",
            "At step: 5341 training error: 0.34141137508407465\n",
            "At step: 5342 training error: 0.3339716550689598\n",
            "At step: 5343 training error: 0.33273104870690867\n",
            "At step: 5344 training error: 0.32816361776529385\n",
            "At step: 5345 training error: 0.3320862237761481\n",
            "At step: 5346 training error: 0.3188534377861344\n",
            "At step: 5347 training error: 0.3200344852664926\n",
            "At step: 5348 training error: 0.3158592820962802\n",
            "At step: 5349 training error: 0.3156984427243107\n",
            "At step: 5350 training error: 0.3211203812593288\n",
            "At step: 5351 training error: 0.3240366800503981\n",
            "At step: 5352 training error: 0.3150773524712189\n",
            "At step: 5353 training error: 0.3146314855010948\n",
            "At step: 5354 training error: 0.3081938228824463\n",
            "At step: 5355 training error: 0.3112729670958841\n",
            "At step: 5356 training error: 0.3038998465121229\n",
            "At step: 5357 training error: 0.29714034006432494\n",
            "At step: 5358 training error: 0.3070682063846405\n",
            "At step: 5359 training error: 0.301317803529123\n",
            "At step: 5360 training error: 0.28886289784220603\n",
            "At step: 5361 training error: 0.283643234793903\n",
            "At step: 5362 training error: 0.2728905318421128\n",
            "At step: 5363 training error: 0.2887375256498247\n",
            "At step: 5364 training error: 0.2937532134313737\n",
            "At step: 5365 training error: 0.29352567240091376\n",
            "At step: 5366 training error: 0.2932560446996445\n",
            "At step: 5367 training error: 0.2959977713761591\n",
            "At step: 5368 training error: 0.3059813026603676\n",
            "At step: 5369 training error: 0.3058263960454063\n",
            "At step: 5370 training error: 0.30528337260462424\n",
            "At step: 5371 training error: 0.3056230739666551\n",
            "At step: 5372 training error: 0.3029137233942407\n",
            "At step: 5373 training error: 0.307239011081911\n",
            "At step: 5374 training error: 0.3061292417544059\n",
            "At step: 5375 training error: 0.3079898178399696\n",
            "At step: 5376 training error: 0.3058236464888794\n",
            "At step: 5377 training error: 0.30427557948927725\n",
            "At step: 5378 training error: 0.3116374014126944\n",
            "At step: 5379 training error: 0.3162102216801553\n",
            "At step: 5380 training error: 0.3217202268630515\n",
            "At step: 5381 training error: 0.31690521760442886\n",
            "At step: 5382 training error: 0.30571387940018346\n",
            "At step: 5383 training error: 0.30745671448184486\n",
            "At step: 5384 training error: 0.3086044667395927\n",
            "At step: 5385 training error: 0.30631180759390336\n",
            "At step: 5386 training error: 0.31462597504838347\n",
            "At step: 5387 training error: 0.3136205297385307\n",
            "At step: 5388 training error: 0.3140698664426318\n",
            "At step: 5389 training error: 0.31655708675280214\n",
            "At step: 5390 training error: 0.31611778301218607\n",
            "At step: 5391 training error: 0.3183613060553474\n",
            "At step: 5392 training error: 0.3144472152282544\n",
            "At step: 5393 training error: 0.30757040800585234\n",
            "At step: 5394 training error: 0.30902629819729316\n",
            "At step: 5395 training error: 0.31466667416740013\n",
            "At step: 5396 training error: 0.32065439592586387\n",
            "At step: 5397 training error: 0.31762593138721307\n",
            "At step: 5398 training error: 0.3326316291102834\n",
            "At step: 5399 training error: 0.3188275233416642\n",
            "At step: 5400 training error: 0.31494136732670386\n",
            "At step: 5401 training error: 0.316351779052337\n",
            "At step: 5402 training error: 0.315853492534507\n",
            "At step: 5403 training error: 0.3136714073899072\n",
            "At step: 5404 training error: 0.3122594403049852\n",
            "At step: 5405 training error: 0.3139621991531402\n",
            "At step: 5406 training error: 0.3097057949613773\n",
            "At step: 5407 training error: 0.32131687480687937\n",
            "At step: 5408 training error: 0.312925799575539\n",
            "At step: 5409 training error: 0.3110352053324398\n",
            "At step: 5410 training error: 0.3138839914358862\n",
            "At step: 5411 training error: 0.31248322114880156\n",
            "At step: 5412 training error: 0.31818139821029967\n",
            "At step: 5413 training error: 0.31526477572592926\n",
            "At step: 5414 training error: 0.3273931806722607\n",
            "At step: 5415 training error: 0.32661857553403456\n",
            "At step: 5416 training error: 0.3264977108903037\n",
            "At step: 5417 training error: 0.3206869723739291\n",
            "At step: 5418 training error: 0.3163351662761461\n",
            "At step: 5419 training error: 0.3035205790398748\n",
            "At step: 5420 training error: 0.300556782563334\n",
            "At step: 5421 training error: 0.3006001927919688\n",
            "At step: 5422 training error: 0.3032584360720208\n",
            "At step: 5423 training error: 0.2964582026084761\n",
            "At step: 5424 training error: 0.29586708156642544\n",
            "At step: 5425 training error: 0.2986162624879272\n",
            "At step: 5426 training error: 0.2995217002918648\n",
            "At step: 5427 training error: 0.3117209472260738\n",
            "At step: 5428 training error: 0.3106712106200889\n",
            "At step: 5429 training error: 0.3104735992782228\n",
            "At step: 5430 training error: 0.3098161260626602\n",
            "At step: 5431 training error: 0.30999515664140426\n",
            "At step: 5432 training error: 0.30670132037570014\n",
            "At step: 5433 training error: 0.3015034059023613\n",
            "At step: 5434 training error: 0.3072377098171015\n",
            "At step: 5435 training error: 0.3065454673512883\n",
            "At step: 5436 training error: 0.30466308638735834\n",
            "At step: 5437 training error: 0.30963206841812463\n",
            "At step: 5438 training error: 0.30186208645598916\n",
            "At step: 5439 training error: 0.3029059172599542\n",
            "At step: 5440 training error: 0.2968303139238888\n",
            "At step: 5441 training error: 0.29858400165681803\n",
            "At step: 5442 training error: 0.3005505947967675\n",
            "At step: 5443 training error: 0.31185785910585473\n",
            "At step: 5444 training error: 0.313258085841267\n",
            "At step: 5445 training error: 0.3024903418687399\n",
            "At step: 5446 training error: 0.30471184100381965\n",
            "At step: 5447 training error: 0.3162574434679566\n",
            "At step: 5448 training error: 0.31267381558239155\n",
            "At step: 5449 training error: 0.3134954571247139\n",
            "At step: 5450 training error: 0.3128495701429659\n",
            "At step: 5451 training error: 0.3110115374150764\n",
            "At step: 5452 training error: 0.31667391940693423\n",
            "At step: 5453 training error: 0.31633955482913434\n",
            "At step: 5454 training error: 0.31210100710392386\n",
            "At step: 5455 training error: 0.3095122426855875\n",
            "At step: 5456 training error: 0.31032237672837526\n",
            "At step: 5457 training error: 0.32365399359388325\n",
            "At step: 5458 training error: 0.32431053397454984\n",
            "At step: 5459 training error: 0.3186712283551237\n",
            "At step: 5460 training error: 0.31262597107270584\n",
            "At step: 5461 training error: 0.3094189968469434\n",
            "At step: 5462 training error: 0.31638788388616285\n",
            "At step: 5463 training error: 0.309671809973317\n",
            "At step: 5464 training error: 0.30276049097147717\n",
            "At step: 5465 training error: 0.3063483016890892\n",
            "At step: 5466 training error: 0.31573652659486284\n",
            "At step: 5467 training error: 0.32389465636256565\n",
            "At step: 5468 training error: 0.31964481164926095\n",
            "At step: 5469 training error: 0.32816808204021064\n",
            "At step: 5470 training error: 0.34669317759170304\n",
            "At step: 5471 training error: 0.3425987601414687\n",
            "At step: 5472 training error: 0.33550184295538305\n",
            "At step: 5473 training error: 0.3403243935398038\n",
            "At step: 5474 training error: 0.34243432801380197\n",
            "At step: 5475 training error: 0.32692473232888636\n",
            "At step: 5476 training error: 0.3353105876667956\n",
            "At step: 5477 training error: 0.33719663890747087\n",
            "At step: 5478 training error: 0.3360429857538195\n",
            "At step: 5479 training error: 0.3285225029059046\n",
            "At step: 5480 training error: 0.3240546077716406\n",
            "At step: 5481 training error: 0.31401848165148066\n",
            "At step: 5482 training error: 0.30907843108823446\n",
            "At step: 5483 training error: 0.313368063508628\n",
            "At step: 5484 training error: 0.30912380479055135\n",
            "At step: 5485 training error: 0.3109645299694106\n",
            "At step: 5486 training error: 0.3090253573504383\n",
            "At step: 5487 training error: 0.30917365956575993\n",
            "At step: 5488 training error: 0.31955008593567913\n",
            "At step: 5489 training error: 0.31297322524489407\n",
            "At step: 5490 training error: 0.3115466226509061\n",
            "At step: 5491 training error: 0.3169946627196398\n",
            "At step: 5492 training error: 0.3223528166258358\n",
            "At step: 5493 training error: 0.3107963954555423\n",
            "At step: 5494 training error: 0.30156777778523075\n",
            "At step: 5495 training error: 0.29908778085223237\n",
            "At step: 5496 training error: 0.3060587763232634\n",
            "At step: 5497 training error: 0.3041263157266256\n",
            "At step: 5498 training error: 0.30713053020942327\n",
            "At step: 5499 training error: 0.31060248903557036\n",
            "At step: 5500 training error: 0.3149892548208127\n",
            "At step: 5501 training error: 0.32314612346818716\n",
            "At step: 5502 training error: 0.3286693304027458\n",
            "At step: 5503 training error: 0.33151584258713357\n",
            "At step: 5504 training error: 0.32286143433400305\n",
            "At step: 5505 training error: 0.32394022672379674\n",
            "At step: 5506 training error: 0.3237196271665698\n",
            "At step: 5507 training error: 0.32521118365210644\n",
            "At step: 5508 training error: 0.323577833626003\n",
            "At step: 5509 training error: 0.326546980046658\n",
            "At step: 5510 training error: 0.32009727700168267\n",
            "At step: 5511 training error: 0.32008497027115224\n",
            "At step: 5512 training error: 0.322748183471744\n",
            "At step: 5513 training error: 0.32441977520610116\n",
            "At step: 5514 training error: 0.3301175660614246\n",
            "At step: 5515 training error: 0.330989957925328\n",
            "At step: 5516 training error: 0.3364333311576524\n",
            "At step: 5517 training error: 0.3413063705819456\n",
            "At step: 5518 training error: 0.3481529949800945\n",
            "At step: 5519 training error: 0.35866412066538184\n",
            "At step: 5520 training error: 0.34758651474868646\n",
            "At step: 5521 training error: 0.34282594898175184\n",
            "At step: 5522 training error: 0.3371336912636123\n",
            "At step: 5523 training error: 0.3381974992627718\n",
            "At step: 5524 training error: 0.33896392798688374\n",
            "At step: 5525 training error: 0.3435176049151752\n",
            "At step: 5526 training error: 0.33230450941215256\n",
            "At step: 5527 training error: 0.33199640205371794\n",
            "At step: 5528 training error: 0.3264965771609812\n",
            "At step: 5529 training error: 0.31813340032075815\n",
            "At step: 5530 training error: 0.32102945423347107\n",
            "At step: 5531 training error: 0.3262216082928803\n",
            "At step: 5532 training error: 0.3333474096295631\n",
            "At step: 5533 training error: 0.3352217002412644\n",
            "At step: 5534 training error: 0.3235910647763486\n",
            "At step: 5535 training error: 0.3256698664988933\n",
            "At step: 5536 training error: 0.3215180859425333\n",
            "At step: 5537 training error: 0.336330694605249\n",
            "At step: 5538 training error: 0.33643342352188843\n",
            "At step: 5539 training error: 0.3314559906272767\n",
            "At step: 5540 training error: 0.34623950835880574\n",
            "At step: 5541 training error: 0.34687517751588104\n",
            "At step: 5542 training error: 0.33947688294446304\n",
            "At step: 5543 training error: 0.3282387267758352\n",
            "At step: 5544 training error: 0.3142644707989184\n",
            "At step: 5545 training error: 0.31555573406596715\n",
            "At step: 5546 training error: 0.3056478873355678\n",
            "At step: 5547 training error: 0.3059087692475669\n",
            "At step: 5548 training error: 0.30294107463567704\n",
            "At step: 5549 training error: 0.30956906010916024\n",
            "At step: 5550 training error: 0.31772832534641443\n",
            "At step: 5551 training error: 0.3140634399407918\n",
            "At step: 5552 training error: 0.31077083668094135\n",
            "At step: 5553 training error: 0.31491015823122787\n",
            "At step: 5554 training error: 0.3114349299055562\n",
            "At step: 5555 training error: 0.31642552772007676\n",
            "At step: 5556 training error: 0.3255340891616513\n",
            "At step: 5557 training error: 0.32524579793433805\n",
            "At step: 5558 training error: 0.31811634422511886\n",
            "At step: 5559 training error: 0.3250330201856011\n",
            "At step: 5560 training error: 0.3256738716458251\n",
            "At step: 5561 training error: 0.33624028947386564\n",
            "At step: 5562 training error: 0.3314430142209225\n",
            "At step: 5563 training error: 0.3301996651531358\n",
            "At step: 5564 training error: 0.3390657415738456\n",
            "At step: 5565 training error: 0.32359814795739983\n",
            "At step: 5566 training error: 0.3272220851114043\n",
            "At step: 5567 training error: 0.32442636940588887\n",
            "At step: 5568 training error: 0.33447881505744514\n",
            "At step: 5569 training error: 0.3226389760358342\n",
            "At step: 5570 training error: 0.3171720455875184\n",
            "At step: 5571 training error: 0.3244983916309392\n",
            "At step: 5572 training error: 0.3234422668361745\n",
            "At step: 5573 training error: 0.32386604862985735\n",
            "At step: 5574 training error: 0.3367937003778558\n",
            "At step: 5575 training error: 0.33164160757459693\n",
            "At step: 5576 training error: 0.3317588106446399\n",
            "At step: 5577 training error: 0.3291682469894118\n",
            "At step: 5578 training error: 0.3180362007906202\n",
            "At step: 5579 training error: 0.3175771146846472\n",
            "At step: 5580 training error: 0.3267126893146892\n",
            "At step: 5581 training error: 0.3213598453456914\n",
            "At step: 5582 training error: 0.32412484103697553\n",
            "At step: 5583 training error: 0.31381757557832707\n",
            "At step: 5584 training error: 0.3050946564927641\n",
            "At step: 5585 training error: 0.3062626232016568\n",
            "At step: 5586 training error: 0.3122726338663528\n",
            "At step: 5587 training error: 0.30655751755173655\n",
            "At step: 5588 training error: 0.30969269075877304\n",
            "At step: 5589 training error: 0.306319446756982\n",
            "At step: 5590 training error: 0.3093449171894814\n",
            "At step: 5591 training error: 0.31739203651741443\n",
            "At step: 5592 training error: 0.31754393367897404\n",
            "At step: 5593 training error: 0.32409923560174025\n",
            "At step: 5594 training error: 0.3200868993775667\n",
            "At step: 5595 training error: 0.31452450193726395\n",
            "At step: 5596 training error: 0.3129553724145897\n",
            "At step: 5597 training error: 0.3066068145836372\n",
            "At step: 5598 training error: 0.30222914955591335\n",
            "At step: 5599 training error: 0.2994857556841214\n",
            "At step: 5600 training error: 0.3033406555243429\n",
            "At step: 5601 training error: 0.31317306828163494\n",
            "At step: 5602 training error: 0.31410929278077837\n",
            "At step: 5603 training error: 0.31346462269443987\n",
            "At step: 5604 training error: 0.30734065926456294\n",
            "At step: 5605 training error: 0.30844846293199657\n",
            "At step: 5606 training error: 0.2991537390979567\n",
            "At step: 5607 training error: 0.29407831734719536\n",
            "At step: 5608 training error: 0.30234553637400585\n",
            "At step: 5609 training error: 0.2944584190462784\n",
            "At step: 5610 training error: 0.29455861696126856\n",
            "At step: 5611 training error: 0.29990609859663026\n",
            "At step: 5612 training error: 0.3107980641223593\n",
            "At step: 5613 training error: 0.3082370086532315\n",
            "At step: 5614 training error: 0.3215465898535006\n",
            "At step: 5615 training error: 0.3223683065073238\n",
            "At step: 5616 training error: 0.3303625489091545\n",
            "At step: 5617 training error: 0.3358191274086959\n",
            "At step: 5618 training error: 0.34161842707722406\n",
            "At step: 5619 training error: 0.3384561717409906\n",
            "At step: 5620 training error: 0.33551090679163226\n",
            "At step: 5621 training error: 0.33297015882924647\n",
            "At step: 5622 training error: 0.32199827669092584\n",
            "At step: 5623 training error: 0.31918809087621997\n",
            "At step: 5624 training error: 0.3191962627753827\n",
            "At step: 5625 training error: 0.32787248804181246\n",
            "At step: 5626 training error: 0.33180562955265736\n",
            "At step: 5627 training error: 0.3364281631596541\n",
            "At step: 5628 training error: 0.3375052125673338\n",
            "At step: 5629 training error: 0.32543268424930755\n",
            "At step: 5630 training error: 0.32053115498178325\n",
            "At step: 5631 training error: 0.33132781230507247\n",
            "At step: 5632 training error: 0.3290800663895162\n",
            "At step: 5633 training error: 0.3179914690487049\n",
            "At step: 5634 training error: 0.31617966212145404\n",
            "At step: 5635 training error: 0.32086930241155354\n",
            "At step: 5636 training error: 0.31716723874208774\n",
            "At step: 5637 training error: 0.31326334692061436\n",
            "At step: 5638 training error: 0.31694664692606045\n",
            "At step: 5639 training error: 0.33385691007706275\n",
            "At step: 5640 training error: 0.3274329949492442\n",
            "At step: 5641 training error: 0.31253888643031774\n",
            "At step: 5642 training error: 0.30793501749702507\n",
            "At step: 5643 training error: 0.30076331135238826\n",
            "At step: 5644 training error: 0.2905747361374575\n",
            "At step: 5645 training error: 0.2938603098491221\n",
            "At step: 5646 training error: 0.29225709926061294\n",
            "At step: 5647 training error: 0.29024298403956306\n",
            "At step: 5648 training error: 0.2952030553376267\n",
            "At step: 5649 training error: 0.2997522557706096\n",
            "At step: 5650 training error: 0.30306068631122063\n",
            "At step: 5651 training error: 0.31517632047184385\n",
            "At step: 5652 training error: 0.324903458353094\n",
            "At step: 5653 training error: 0.3200197682450606\n",
            "At step: 5654 training error: 0.3171988265048563\n",
            "At step: 5655 training error: 0.3174183367023164\n",
            "At step: 5656 training error: 0.31147345326276266\n",
            "At step: 5657 training error: 0.31901160817577\n",
            "At step: 5658 training error: 0.3114180663692546\n",
            "At step: 5659 training error: 0.31835029101530876\n",
            "At step: 5660 training error: 0.32338126920526367\n",
            "At step: 5661 training error: 0.32386429442082976\n",
            "At step: 5662 training error: 0.33135995506761656\n",
            "At step: 5663 training error: 0.34063804627261474\n",
            "At step: 5664 training error: 0.3435551252867368\n",
            "At step: 5665 training error: 0.3514647646425122\n",
            "At step: 5666 training error: 0.3447369138292423\n",
            "At step: 5667 training error: 0.3462593518100985\n",
            "At step: 5668 training error: 0.3441493762209288\n",
            "At step: 5669 training error: 0.34733097951330844\n",
            "At step: 5670 training error: 0.33863112570325\n",
            "At step: 5671 training error: 0.3429170390934027\n",
            "At step: 5672 training error: 0.34223266794006524\n",
            "At step: 5673 training error: 0.3409580765979152\n",
            "At step: 5674 training error: 0.3406027544316763\n",
            "At step: 5675 training error: 0.33388600816744957\n",
            "At step: 5676 training error: 0.33933489604142936\n",
            "At step: 5677 training error: 0.3437291313957405\n",
            "At step: 5678 training error: 0.3380993043513567\n",
            "At step: 5679 training error: 0.33594562925777716\n",
            "At step: 5680 training error: 0.34060625339662054\n",
            "At step: 5681 training error: 0.32938465594176725\n",
            "At step: 5682 training error: 0.3317267412489651\n",
            "At step: 5683 training error: 0.32236633970854794\n",
            "At step: 5684 training error: 0.32143778263548756\n",
            "At step: 5685 training error: 0.32730840737664046\n",
            "At step: 5686 training error: 0.32265939035912866\n",
            "At step: 5687 training error: 0.31649338280460093\n",
            "At step: 5688 training error: 0.3297273762587526\n",
            "At step: 5689 training error: 0.33294533688476485\n",
            "At step: 5690 training error: 0.33145708870299734\n",
            "At step: 5691 training error: 0.32666220046240435\n",
            "At step: 5692 training error: 0.32658858939134366\n",
            "At step: 5693 training error: 0.3154815280758094\n",
            "At step: 5694 training error: 0.31142519956276826\n",
            "At step: 5695 training error: 0.31353205645321597\n",
            "At step: 5696 training error: 0.31887717548395644\n",
            "At step: 5697 training error: 0.31914244885226195\n",
            "At step: 5698 training error: 0.3168746280094898\n",
            "At step: 5699 training error: 0.3157128033776401\n",
            "At step: 5700 training error: 0.3134742379356985\n",
            "At step: 5701 training error: 0.31724884482051224\n",
            "At step: 5702 training error: 0.3214013355938582\n",
            "At step: 5703 training error: 0.31534092981813966\n",
            "At step: 5704 training error: 0.3087989179665674\n",
            "At step: 5705 training error: 0.3199384594132807\n",
            "At step: 5706 training error: 0.3205050835199745\n",
            "At step: 5707 training error: 0.3215869893905337\n",
            "At step: 5708 training error: 0.3266262410665302\n",
            "At step: 5709 training error: 0.32691646998889845\n",
            "At step: 5710 training error: 0.32035745862938186\n",
            "At step: 5711 training error: 0.3311608436209406\n",
            "At step: 5712 training error: 0.32860420168600707\n",
            "At step: 5713 training error: 0.3369989476690183\n",
            "At step: 5714 training error: 0.32684698243866483\n",
            "At step: 5715 training error: 0.31768128988399064\n",
            "At step: 5716 training error: 0.3078226876757352\n",
            "At step: 5717 training error: 0.3051860752365609\n",
            "At step: 5718 training error: 0.3026960316287273\n",
            "At step: 5719 training error: 0.2989278968850046\n",
            "At step: 5720 training error: 0.3020587897165382\n",
            "At step: 5721 training error: 0.31093466712736884\n",
            "At step: 5722 training error: 0.32551831980924983\n",
            "At step: 5723 training error: 0.33253887417639094\n",
            "At step: 5724 training error: 0.32824785853852456\n",
            "At step: 5725 training error: 0.31617895924965705\n",
            "At step: 5726 training error: 0.3019513692632327\n",
            "At step: 5727 training error: 0.3008267574928631\n",
            "At step: 5728 training error: 0.30365665025555894\n",
            "At step: 5729 training error: 0.2961113349444844\n",
            "At step: 5730 training error: 0.29819029129153923\n",
            "At step: 5731 training error: 0.3018493249209924\n",
            "At step: 5732 training error: 0.29279955195230994\n",
            "At step: 5733 training error: 0.310031948279455\n",
            "At step: 5734 training error: 0.3059517978512663\n",
            "At step: 5735 training error: 0.30890849339182697\n",
            "At step: 5736 training error: 0.3086977680969546\n",
            "At step: 5737 training error: 0.2965932157915548\n",
            "At step: 5738 training error: 0.2974110141797463\n",
            "At step: 5739 training error: 0.29813268989129804\n",
            "At step: 5740 training error: 0.2931909654316816\n",
            "At step: 5741 training error: 0.286566007813263\n",
            "At step: 5742 training error: 0.29668241347065866\n",
            "At step: 5743 training error: 0.2998849921321879\n",
            "At step: 5744 training error: 0.30890735866144775\n",
            "At step: 5745 training error: 0.31699718144579575\n",
            "At step: 5746 training error: 0.32005409047191413\n",
            "At step: 5747 training error: 0.3167770523934502\n",
            "At step: 5748 training error: 0.31489129629115703\n",
            "At step: 5749 training error: 0.3022414623963571\n",
            "At step: 5750 training error: 0.2883980956448757\n",
            "At step: 5751 training error: 0.2814975772520772\n",
            "At step: 5752 training error: 0.29636816988521697\n",
            "At step: 5753 training error: 0.29119919767210983\n",
            "At step: 5754 training error: 0.29381864571530397\n",
            "At step: 5755 training error: 0.30261885360605556\n",
            "At step: 5756 training error: 0.31288845962502726\n",
            "At step: 5757 training error: 0.3197596550980066\n",
            "At step: 5758 training error: 0.30604592964751953\n",
            "At step: 5759 training error: 0.2944853095341187\n",
            "At step: 5760 training error: 0.2976690039335039\n",
            "At step: 5761 training error: 0.31130552061794564\n",
            "At step: 5762 training error: 0.30512603705124075\n",
            "At step: 5763 training error: 0.314521799590063\n",
            "At step: 5764 training error: 0.30516677624385596\n",
            "At step: 5765 training error: 0.3079542383411453\n",
            "At step: 5766 training error: 0.3152688157131626\n",
            "At step: 5767 training error: 0.3137014353634119\n",
            "At step: 5768 training error: 0.31729160271424894\n",
            "At step: 5769 training error: 0.31793670625423265\n",
            "At step: 5770 training error: 0.3258429640302469\n",
            "At step: 5771 training error: 0.32219889679115593\n",
            "At step: 5772 training error: 0.3167704618874138\n",
            "At step: 5773 training error: 0.32889290745814315\n",
            "At step: 5774 training error: 0.31802435882203023\n",
            "At step: 5775 training error: 0.31743125423721247\n",
            "At step: 5776 training error: 0.3158780976080551\n",
            "At step: 5777 training error: 0.32233179220482583\n",
            "At step: 5778 training error: 0.3126067306186305\n",
            "At step: 5779 training error: 0.3075015408950625\n",
            "At step: 5780 training error: 0.31481829737964573\n",
            "At step: 5781 training error: 0.31796791916621475\n",
            "At step: 5782 training error: 0.3260299773229609\n",
            "At step: 5783 training error: 0.3276637840366728\n",
            "At step: 5784 training error: 0.32613634236594974\n",
            "At step: 5785 training error: 0.33126036762228384\n",
            "At step: 5786 training error: 0.3424878198536044\n",
            "At step: 5787 training error: 0.3526594889354614\n",
            "At step: 5788 training error: 0.35224540390177295\n",
            "At step: 5789 training error: 0.3529205456671658\n",
            "At step: 5790 training error: 0.3560319851725382\n",
            "At step: 5791 training error: 0.34630435470921517\n",
            "At step: 5792 training error: 0.34370559135249856\n",
            "At step: 5793 training error: 0.32935446077282177\n",
            "At step: 5794 training error: 0.32643669402373665\n",
            "At step: 5795 training error: 0.317958699360286\n",
            "At step: 5796 training error: 0.33526269707453105\n",
            "At step: 5797 training error: 0.3311923018496886\n",
            "At step: 5798 training error: 0.32454868259286485\n",
            "At step: 5799 training error: 0.33107519484135206\n",
            "At step: 5800 training error: 0.3296269632508837\n",
            "At step: 5801 training error: 0.3309342592685616\n",
            "At step: 5802 training error: 0.3292923663906675\n",
            "At step: 5803 training error: 0.3296359342184754\n",
            "At step: 5804 training error: 0.32744314650465456\n",
            "At step: 5805 training error: 0.3379971206344675\n",
            "At step: 5806 training error: 0.3470835343394936\n",
            "At step: 5807 training error: 0.35792173714893283\n",
            "At step: 5808 training error: 0.3555287618536989\n",
            "At step: 5809 training error: 0.3483647325554353\n",
            "At step: 5810 training error: 0.348065819743441\n",
            "At step: 5811 training error: 0.3437061970567094\n",
            "At step: 5812 training error: 0.34424035627400995\n",
            "At step: 5813 training error: 0.33554726226477766\n",
            "At step: 5814 training error: 0.350411618377509\n",
            "At step: 5815 training error: 0.341708148475793\n",
            "At step: 5816 training error: 0.3251216324642152\n",
            "At step: 5817 training error: 0.3172633239836436\n",
            "At step: 5818 training error: 0.30366052989342973\n",
            "At step: 5819 training error: 0.3117312341321865\n",
            "At step: 5820 training error: 0.3020748826768175\n",
            "At step: 5821 training error: 0.304266016675785\n",
            "At step: 5822 training error: 0.29643551882755487\n",
            "At step: 5823 training error: 0.30798929790188756\n",
            "At step: 5824 training error: 0.30357560408257905\n",
            "At step: 5825 training error: 0.3091601579100779\n",
            "At step: 5826 training error: 0.3054690857444341\n",
            "At step: 5827 training error: 0.3073121797519187\n",
            "At step: 5828 training error: 0.29900739957226974\n",
            "At step: 5829 training error: 0.3104151085750023\n",
            "At step: 5830 training error: 0.3264908618938362\n",
            "At step: 5831 training error: 0.3197071169968609\n",
            "At step: 5832 training error: 0.3266418445605928\n",
            "At step: 5833 training error: 0.32127788591055334\n",
            "At step: 5834 training error: 0.3165605233845565\n",
            "At step: 5835 training error: 0.32209276564510014\n",
            "At step: 5836 training error: 0.3319843335410222\n",
            "At step: 5837 training error: 0.33105336203140495\n",
            "At step: 5838 training error: 0.3270710969514334\n",
            "At step: 5839 training error: 0.32902226622751096\n",
            "At step: 5840 training error: 0.3302111316054421\n",
            "At step: 5841 training error: 0.33328901795692273\n",
            "At step: 5842 training error: 0.3371181509449811\n",
            "At step: 5843 training error: 0.3383111777682694\n",
            "At step: 5844 training error: 0.3339316282316091\n",
            "At step: 5845 training error: 0.33253419675107126\n",
            "At step: 5846 training error: 0.32572948884244474\n",
            "At step: 5847 training error: 0.3219219390322624\n",
            "At step: 5848 training error: 0.3298149126332627\n",
            "At step: 5849 training error: 0.33067151165988135\n",
            "At step: 5850 training error: 0.32239290188916137\n",
            "At step: 5851 training error: 0.3183011712252752\n",
            "At step: 5852 training error: 0.32489569132055246\n",
            "At step: 5853 training error: 0.3199803740155454\n",
            "At step: 5854 training error: 0.3266943621121059\n",
            "At step: 5855 training error: 0.3283596913337253\n",
            "At step: 5856 training error: 0.32188089585221624\n",
            "At step: 5857 training error: 0.318139625946231\n",
            "At step: 5858 training error: 0.3106831189165011\n",
            "At step: 5859 training error: 0.3222932697929479\n",
            "At step: 5860 training error: 0.32349393462777587\n",
            "At step: 5861 training error: 0.31964769518259584\n",
            "At step: 5862 training error: 0.3165957695856463\n",
            "At step: 5863 training error: 0.31935058972879937\n",
            "At step: 5864 training error: 0.31136848397534744\n",
            "At step: 5865 training error: 0.31382392129084086\n",
            "At step: 5866 training error: 0.3215963825556608\n",
            "At step: 5867 training error: 0.322533152563942\n",
            "At step: 5868 training error: 0.3193749614030227\n",
            "At step: 5869 training error: 0.3168639989549368\n",
            "At step: 5870 training error: 0.3156967003132168\n",
            "At step: 5871 training error: 0.3164199033055275\n",
            "At step: 5872 training error: 0.32420774137036035\n",
            "At step: 5873 training error: 0.336232333929285\n",
            "At step: 5874 training error: 0.3396533651554037\n",
            "At step: 5875 training error: 0.34113266261052927\n",
            "At step: 5876 training error: 0.33151160224067455\n",
            "At step: 5877 training error: 0.3175679883340529\n",
            "At step: 5878 training error: 0.3142495370967517\n",
            "At step: 5879 training error: 0.314665260969293\n",
            "At step: 5880 training error: 0.3208757294583566\n",
            "At step: 5881 training error: 0.31398198674809985\n",
            "At step: 5882 training error: 0.3126096861469636\n",
            "At step: 5883 training error: 0.3137145740082736\n",
            "At step: 5884 training error: 0.3155119838483572\n",
            "At step: 5885 training error: 0.30916561805770393\n",
            "At step: 5886 training error: 0.3078779411728149\n",
            "At step: 5887 training error: 0.3142940628842382\n",
            "At step: 5888 training error: 0.3173911786496704\n",
            "At step: 5889 training error: 0.31240236271228194\n",
            "At step: 5890 training error: 0.3073384083974199\n",
            "At step: 5891 training error: 0.29829030176245325\n",
            "At step: 5892 training error: 0.2899137181050934\n",
            "At step: 5893 training error: 0.289529726491497\n",
            "At step: 5894 training error: 0.2938263630483383\n",
            "At step: 5895 training error: 0.3012408655213438\n",
            "At step: 5896 training error: 0.3085426049873022\n",
            "At step: 5897 training error: 0.3007486253465893\n",
            "At step: 5898 training error: 0.2973479880890459\n",
            "At step: 5899 training error: 0.3017118081888673\n",
            "At step: 5900 training error: 0.2984824743657846\n",
            "At step: 5901 training error: 0.30391229545009696\n",
            "At step: 5902 training error: 0.3042530517995057\n",
            "At step: 5903 training error: 0.3101922890732484\n",
            "At step: 5904 training error: 0.3077296180019553\n",
            "At step: 5905 training error: 0.3068644819607806\n",
            "At step: 5906 training error: 0.29847813408028373\n",
            "At step: 5907 training error: 0.30846500798889176\n",
            "At step: 5908 training error: 0.30928239039061023\n",
            "At step: 5909 training error: 0.31543535391859157\n",
            "At step: 5910 training error: 0.32410076958960543\n",
            "At step: 5911 training error: 0.32083520593098847\n",
            "At step: 5912 training error: 0.31197170134472696\n",
            "At step: 5913 training error: 0.307529689070236\n",
            "At step: 5914 training error: 0.30450740714293306\n",
            "At step: 5915 training error: 0.29483550883257725\n",
            "At step: 5916 training error: 0.2950455398953991\n",
            "At step: 5917 training error: 0.2992459691185717\n",
            "At step: 5918 training error: 0.29677269836769776\n",
            "At step: 5919 training error: 0.3000249934593513\n",
            "At step: 5920 training error: 0.29016136449341046\n",
            "At step: 5921 training error: 0.286909826160049\n",
            "At step: 5922 training error: 0.2858624344812018\n",
            "At step: 5923 training error: 0.2859264395624681\n",
            "At step: 5924 training error: 0.2882722203577472\n",
            "At step: 5925 training error: 0.28949257469235956\n",
            "At step: 5926 training error: 0.3075000068154472\n",
            "At step: 5927 training error: 0.2999341832821177\n",
            "At step: 5928 training error: 0.2942307899880824\n",
            "At step: 5929 training error: 0.312155832150765\n",
            "At step: 5930 training error: 0.31768934069016813\n",
            "At step: 5931 training error: 0.3173781028401899\n",
            "At step: 5932 training error: 0.3076903285197379\n",
            "At step: 5933 training error: 0.30643857511154843\n",
            "At step: 5934 training error: 0.30413633626846615\n",
            "At step: 5935 training error: 0.3135786530990618\n",
            "At step: 5936 training error: 0.31769060025775553\n",
            "At step: 5937 training error: 0.31473552936193566\n",
            "At step: 5938 training error: 0.32917622435061933\n",
            "At step: 5939 training error: 0.3297211473409718\n",
            "At step: 5940 training error: 0.32545046113008425\n",
            "At step: 5941 training error: 0.32314120784982947\n",
            "At step: 5942 training error: 0.33117062034476064\n",
            "At step: 5943 training error: 0.3368974434948647\n",
            "At step: 5944 training error: 0.3353000359449627\n",
            "At step: 5945 training error: 0.3357280530626031\n",
            "At step: 5946 training error: 0.3252980219609633\n",
            "At step: 5947 training error: 0.32296762586770944\n",
            "At step: 5948 training error: 0.3280301199525145\n",
            "At step: 5949 training error: 0.3337561537708573\n",
            "At step: 5950 training error: 0.32700057576409114\n",
            "At step: 5951 training error: 0.3284805192599273\n",
            "At step: 5952 training error: 0.3200781760604408\n",
            "At step: 5953 training error: 0.32335115414537047\n",
            "At step: 5954 training error: 0.32500599624235554\n",
            "At step: 5955 training error: 0.32324801979533657\n",
            "At step: 5956 training error: 0.32449342655441155\n",
            "At step: 5957 training error: 0.3331010073059705\n",
            "At step: 5958 training error: 0.33317762166826104\n",
            "At step: 5959 training error: 0.3274223208739374\n",
            "At step: 5960 training error: 0.31818085558683074\n",
            "At step: 5961 training error: 0.3128847328935587\n",
            "At step: 5962 training error: 0.32185136084354204\n",
            "At step: 5963 training error: 0.33806307624350135\n",
            "At step: 5964 training error: 0.3355071236687661\n",
            "At step: 5965 training error: 0.344172328712235\n",
            "At step: 5966 training error: 0.3582429450136018\n",
            "At step: 5967 training error: 0.35772942825059895\n",
            "At step: 5968 training error: 0.35852244148748\n",
            "At step: 5969 training error: 0.34890944275727886\n",
            "At step: 5970 training error: 0.3618793966248726\n",
            "At step: 5971 training error: 0.35956288993209073\n",
            "At step: 5972 training error: 0.3560091989811296\n",
            "At step: 5973 training error: 0.3497934156246691\n",
            "At step: 5974 training error: 0.35830428007113685\n",
            "At step: 5975 training error: 0.35866356765001345\n",
            "At step: 5976 training error: 0.3563621028138856\n",
            "At step: 5977 training error: 0.35526452919413803\n",
            "At step: 5978 training error: 0.349070128054956\n",
            "At step: 5979 training error: 0.343457342088686\n",
            "At step: 5980 training error: 0.3384724730079709\n",
            "At step: 5981 training error: 0.3327528593969725\n",
            "At step: 5982 training error: 0.33440504525480513\n",
            "At step: 5983 training error: 0.3268243270389155\n",
            "At step: 5984 training error: 0.33556125482040566\n",
            "At step: 5985 training error: 0.3353537974860356\n",
            "At step: 5986 training error: 0.33052334828378727\n",
            "At step: 5987 training error: 0.32295193517799436\n",
            "At step: 5988 training error: 0.32925938135788796\n",
            "At step: 5989 training error: 0.3296603616362581\n",
            "At step: 5990 training error: 0.3223280837850579\n",
            "At step: 5991 training error: 0.3090666697030923\n",
            "At step: 5992 training error: 0.30653545628396894\n",
            "At step: 5993 training error: 0.3055037561033071\n",
            "At step: 5994 training error: 0.3085921995160991\n",
            "At step: 5995 training error: 0.2970373618612698\n",
            "At step: 5996 training error: 0.2942111829471359\n",
            "At step: 5997 training error: 0.28986237065220327\n",
            "At step: 5998 training error: 0.2840561319251085\n",
            "At step: 5999 training error: 0.2881506918550899\n",
            "At step: 6000 training error: 0.2883840014982674\n",
            "At step: 6001 training error: 0.29207284626192165\n",
            "At step: 6002 training error: 0.3005879278037518\n",
            "At step: 6003 training error: 0.2858591001300526\n",
            "At step: 6004 training error: 0.2860701811675367\n",
            "At step: 6005 training error: 0.29095108712022544\n",
            "At step: 6006 training error: 0.29067319219541327\n",
            "At step: 6007 training error: 0.2894532991604713\n",
            "At step: 6008 training error: 0.28457211461211324\n",
            "At step: 6009 training error: 0.2873734920566947\n",
            "At step: 6010 training error: 0.28447703152534787\n",
            "At step: 6011 training error: 0.2823596404235585\n",
            "At step: 6012 training error: 0.28495170645534695\n",
            "At step: 6013 training error: 0.28863773701898177\n",
            "At step: 6014 training error: 0.2772321370364596\n",
            "At step: 6015 training error: 0.2823390500171143\n",
            "At step: 6016 training error: 0.2870525564054929\n",
            "At step: 6017 training error: 0.2850792647220215\n",
            "At step: 6018 training error: 0.2894047221527596\n",
            "At step: 6019 training error: 0.2864400600686523\n",
            "At step: 6020 training error: 0.28729928444647307\n",
            "At step: 6021 training error: 0.29311025810167224\n",
            "At step: 6022 training error: 0.29163161246594654\n",
            "At step: 6023 training error: 0.294714511167845\n",
            "At step: 6024 training error: 0.29653420754480886\n",
            "At step: 6025 training error: 0.30161837154059934\n",
            "At step: 6026 training error: 0.30645412707109393\n",
            "At step: 6027 training error: 0.31450334636044985\n",
            "At step: 6028 training error: 0.30433784765201866\n",
            "At step: 6029 training error: 0.29874948918314975\n",
            "At step: 6030 training error: 0.2993034493989549\n",
            "At step: 6031 training error: 0.30058064724469113\n",
            "At step: 6032 training error: 0.2913921902465809\n",
            "At step: 6033 training error: 0.2915700958763538\n",
            "At step: 6034 training error: 0.2950575875251798\n",
            "At step: 6035 training error: 0.29211291473491063\n",
            "At step: 6036 training error: 0.29452643425196917\n",
            "At step: 6037 training error: 0.293483716469858\n",
            "At step: 6038 training error: 0.28855635518197975\n",
            "At step: 6039 training error: 0.28926642496548527\n",
            "At step: 6040 training error: 0.28764091186257273\n",
            "At step: 6041 training error: 0.2970448975676066\n",
            "At step: 6042 training error: 0.31188823977478064\n",
            "At step: 6043 training error: 0.30474004033124114\n",
            "At step: 6044 training error: 0.297442744259128\n",
            "At step: 6045 training error: 0.30929292600981984\n",
            "At step: 6046 training error: 0.31355069842249006\n",
            "At step: 6047 training error: 0.32195938979668354\n",
            "At step: 6048 training error: 0.32282088975337037\n",
            "At step: 6049 training error: 0.32120615862747876\n",
            "At step: 6050 training error: 0.33041928631239054\n",
            "At step: 6051 training error: 0.3379580325169023\n",
            "At step: 6052 training error: 0.33033459952635447\n",
            "At step: 6053 training error: 0.3398248481528293\n",
            "At step: 6054 training error: 0.33810957439823475\n",
            "At step: 6055 training error: 0.33252044279312315\n",
            "At step: 6056 training error: 0.32949971879925993\n",
            "At step: 6057 training error: 0.33392734675948726\n",
            "At step: 6058 training error: 0.32344638957159194\n",
            "At step: 6059 training error: 0.324747580503869\n",
            "At step: 6060 training error: 0.3209186017359544\n",
            "At step: 6061 training error: 0.3259754275385926\n",
            "At step: 6062 training error: 0.3214882110312796\n",
            "At step: 6063 training error: 0.3175827750655552\n",
            "At step: 6064 training error: 0.33218125486314565\n",
            "At step: 6065 training error: 0.32474301405104367\n",
            "At step: 6066 training error: 0.31266259592370915\n",
            "At step: 6067 training error: 0.308602314787968\n",
            "At step: 6068 training error: 0.30843271190045446\n",
            "At step: 6069 training error: 0.30970831563662193\n",
            "At step: 6070 training error: 0.30986228607630834\n",
            "At step: 6071 training error: 0.30820599955241\n",
            "At step: 6072 training error: 0.305237792571123\n",
            "At step: 6073 training error: 0.32192895807992294\n",
            "At step: 6074 training error: 0.31822201859618704\n",
            "At step: 6075 training error: 0.32081142336249735\n",
            "At step: 6076 training error: 0.3187572772270324\n",
            "At step: 6077 training error: 0.32457510047286925\n",
            "At step: 6078 training error: 0.31864445117590817\n",
            "At step: 6079 training error: 0.3259644420055717\n",
            "At step: 6080 training error: 0.3200062112773394\n",
            "At step: 6081 training error: 0.3164711641573358\n",
            "At step: 6082 training error: 0.31961216736880943\n",
            "At step: 6083 training error: 0.3127554499752881\n",
            "At step: 6084 training error: 0.31732343103059657\n",
            "At step: 6085 training error: 0.3259952474782224\n",
            "At step: 6086 training error: 0.3213204519584008\n",
            "At step: 6087 training error: 0.3150444369249864\n",
            "At step: 6088 training error: 0.3083309448180245\n",
            "At step: 6089 training error: 0.3095848383777498\n",
            "At step: 6090 training error: 0.3161187299003689\n",
            "At step: 6091 training error: 0.31265638149115005\n",
            "At step: 6092 training error: 0.3183043035865137\n",
            "At step: 6093 training error: 0.30618240282318954\n",
            "At step: 6094 training error: 0.30642238382984893\n",
            "At step: 6095 training error: 0.30672187178282484\n",
            "At step: 6096 training error: 0.31452152958724444\n",
            "At step: 6097 training error: 0.309247235840616\n",
            "At step: 6098 training error: 0.30496503782702195\n",
            "At step: 6099 training error: 0.30485774172072283\n",
            "At step: 6100 training error: 0.3046631986294683\n",
            "At step: 6101 training error: 0.29654601623488847\n",
            "At step: 6102 training error: 0.30515382297560534\n",
            "At step: 6103 training error: 0.3023643717886427\n",
            "At step: 6104 training error: 0.3027373670722771\n",
            "At step: 6105 training error: 0.29952953406234334\n",
            "At step: 6106 training error: 0.3010646410002331\n",
            "At step: 6107 training error: 0.3162342353861684\n",
            "At step: 6108 training error: 0.31277262760948926\n",
            "At step: 6109 training error: 0.3139389937557172\n",
            "At step: 6110 training error: 0.31171623478184207\n",
            "At step: 6111 training error: 0.31129159343778323\n",
            "At step: 6112 training error: 0.3118708685950286\n",
            "At step: 6113 training error: 0.32332500158421307\n",
            "At step: 6114 training error: 0.32184064140041485\n",
            "At step: 6115 training error: 0.31881015110340827\n",
            "At step: 6116 training error: 0.3103657785855242\n",
            "At step: 6117 training error: 0.30449008629431407\n",
            "At step: 6118 training error: 0.3017951726914131\n",
            "At step: 6119 training error: 0.30202435459076\n",
            "At step: 6120 training error: 0.2955681770594689\n",
            "At step: 6121 training error: 0.2996740630652626\n",
            "At step: 6122 training error: 0.29321409804757026\n",
            "At step: 6123 training error: 0.29583791318737024\n",
            "At step: 6124 training error: 0.3006066306810617\n",
            "At step: 6125 training error: 0.29112171208909254\n",
            "At step: 6126 training error: 0.2832097503721885\n",
            "At step: 6127 training error: 0.29229787054899936\n",
            "At step: 6128 training error: 0.2862812323678315\n",
            "At step: 6129 training error: 0.2936711389078154\n",
            "At step: 6130 training error: 0.2946144400616012\n",
            "At step: 6131 training error: 0.29215098852936766\n",
            "At step: 6132 training error: 0.28515130872287947\n",
            "At step: 6133 training error: 0.29127983608025887\n",
            "At step: 6134 training error: 0.29984691625308724\n",
            "At step: 6135 training error: 0.30954844195222087\n",
            "At step: 6136 training error: 0.3139430570795596\n",
            "At step: 6137 training error: 0.31314296949190085\n",
            "At step: 6138 training error: 0.3123353849996939\n",
            "At step: 6139 training error: 0.30576303415614764\n",
            "At step: 6140 training error: 0.30648222330671354\n",
            "At step: 6141 training error: 0.30839193453616204\n",
            "At step: 6142 training error: 0.31869186300050734\n",
            "At step: 6143 training error: 0.31897061975928587\n",
            "At step: 6144 training error: 0.31320983392956353\n",
            "At step: 6145 training error: 0.30747433264322754\n",
            "At step: 6146 training error: 0.3074628144074851\n",
            "At step: 6147 training error: 0.3067980229493377\n",
            "At step: 6148 training error: 0.3079337732033967\n",
            "At step: 6149 training error: 0.30484988224099513\n",
            "At step: 6150 training error: 0.31305156253812016\n",
            "At step: 6151 training error: 0.30990737262979245\n",
            "At step: 6152 training error: 0.3131681661939997\n",
            "At step: 6153 training error: 0.31236863835912526\n",
            "At step: 6154 training error: 0.316145964632824\n",
            "At step: 6155 training error: 0.31597944990767324\n",
            "At step: 6156 training error: 0.3277991400615788\n",
            "At step: 6157 training error: 0.32592345052675303\n",
            "At step: 6158 training error: 0.3110119567298209\n",
            "At step: 6159 training error: 0.31423795083029954\n",
            "At step: 6160 training error: 0.31877933213311715\n",
            "At step: 6161 training error: 0.33617519267414947\n",
            "At step: 6162 training error: 0.33177527514424204\n",
            "At step: 6163 training error: 0.32357602981306965\n",
            "At step: 6164 training error: 0.3345888334578952\n",
            "At step: 6165 training error: 0.3273106711891671\n",
            "At step: 6166 training error: 0.3346377785218072\n",
            "At step: 6167 training error: 0.3351423174339535\n",
            "At step: 6168 training error: 0.34652506584011894\n",
            "At step: 6169 training error: 0.3521521457862954\n",
            "At step: 6170 training error: 0.35217436541285146\n",
            "At step: 6171 training error: 0.351379898136407\n",
            "At step: 6172 training error: 0.35646052390837246\n",
            "At step: 6173 training error: 0.35437161986721666\n",
            "At step: 6174 training error: 0.3511382615059689\n",
            "At step: 6175 training error: 0.3358846293679115\n",
            "At step: 6176 training error: 0.33075698463724623\n",
            "At step: 6177 training error: 0.33639645803825113\n",
            "At step: 6178 training error: 0.34424122266136714\n",
            "At step: 6179 training error: 0.3403454142493091\n",
            "At step: 6180 training error: 0.348355316758153\n",
            "At step: 6181 training error: 0.3405361506151494\n",
            "At step: 6182 training error: 0.3341520376354293\n",
            "At step: 6183 training error: 0.3323891022596219\n",
            "At step: 6184 training error: 0.3209297399768609\n",
            "At step: 6185 training error: 0.3105293110588109\n",
            "At step: 6186 training error: 0.304265627706592\n",
            "At step: 6187 training error: 0.3105715052522196\n",
            "At step: 6188 training error: 0.32173866795169087\n",
            "At step: 6189 training error: 0.31505202632520146\n",
            "At step: 6190 training error: 0.31091310355769264\n",
            "At step: 6191 training error: 0.3200034186515142\n",
            "At step: 6192 training error: 0.31828180901992104\n",
            "At step: 6193 training error: 0.31481789796678133\n",
            "At step: 6194 training error: 0.3172667589247176\n",
            "At step: 6195 training error: 0.3201832158179988\n",
            "At step: 6196 training error: 0.32073536360480676\n",
            "At step: 6197 training error: 0.32625760136661097\n",
            "At step: 6198 training error: 0.3265310441462299\n",
            "At step: 6199 training error: 0.3258440394843727\n",
            "At step: 6200 training error: 0.3222069822375242\n",
            "At step: 6201 training error: 0.31324640270262805\n",
            "At step: 6202 training error: 0.3096368478082399\n",
            "At step: 6203 training error: 0.30559538272690717\n",
            "At step: 6204 training error: 0.3012355873483964\n",
            "At step: 6205 training error: 0.2968622521232859\n",
            "At step: 6206 training error: 0.2978976773631444\n",
            "At step: 6207 training error: 0.28965844392179085\n",
            "At step: 6208 training error: 0.2893708046328941\n",
            "At step: 6209 training error: 0.2871320463549671\n",
            "At step: 6210 training error: 0.29050634420829896\n",
            "At step: 6211 training error: 0.2888022135525674\n",
            "At step: 6212 training error: 0.290794094489645\n",
            "At step: 6213 training error: 0.2928453507565679\n",
            "At step: 6214 training error: 0.30185553043102686\n",
            "At step: 6215 training error: 0.3039682500000032\n",
            "At step: 6216 training error: 0.3047232012935602\n",
            "At step: 6217 training error: 0.3076873989541494\n",
            "At step: 6218 training error: 0.30576361393146556\n",
            "At step: 6219 training error: 0.30748983010871234\n",
            "At step: 6220 training error: 0.3196940025215699\n",
            "At step: 6221 training error: 0.3124686770890717\n",
            "At step: 6222 training error: 0.3133652549803144\n",
            "At step: 6223 training error: 0.3219297430188897\n",
            "At step: 6224 training error: 0.319490294933906\n",
            "At step: 6225 training error: 0.3200748319766532\n",
            "At step: 6226 training error: 0.3222899592693054\n",
            "At step: 6227 training error: 0.319944147411198\n",
            "At step: 6228 training error: 0.317549557473658\n",
            "At step: 6229 training error: 0.3139168653023836\n",
            "At step: 6230 training error: 0.3169447422093905\n",
            "At step: 6231 training error: 0.3190607523340967\n",
            "At step: 6232 training error: 0.3087139368376889\n",
            "At step: 6233 training error: 0.31135604347581075\n",
            "At step: 6234 training error: 0.312415703910991\n",
            "At step: 6235 training error: 0.31582756371027265\n",
            "At step: 6236 training error: 0.31365995529160506\n",
            "At step: 6237 training error: 0.3153901425459159\n",
            "At step: 6238 training error: 0.3129379879821861\n",
            "At step: 6239 training error: 0.3263980282619089\n",
            "At step: 6240 training error: 0.33735798967878616\n",
            "At step: 6241 training error: 0.3234615776298972\n",
            "At step: 6242 training error: 0.315787533032672\n",
            "At step: 6243 training error: 0.31319508831597015\n",
            "At step: 6244 training error: 0.3098648641628771\n",
            "At step: 6245 training error: 0.29997048203865284\n",
            "At step: 6246 training error: 0.29916673427595497\n",
            "At step: 6247 training error: 0.3063047038248087\n",
            "At step: 6248 training error: 0.31662735648587254\n",
            "At step: 6249 training error: 0.3076036436725798\n",
            "At step: 6250 training error: 0.3052693698751562\n",
            "At step: 6251 training error: 0.31453182687728987\n",
            "At step: 6252 training error: 0.32005235069522686\n",
            "At step: 6253 training error: 0.3116624670255305\n",
            "At step: 6254 training error: 0.30102288090814844\n",
            "At step: 6255 training error: 0.30190239422702725\n",
            "At step: 6256 training error: 0.3022931463672314\n",
            "At step: 6257 training error: 0.3058419922559142\n",
            "At step: 6258 training error: 0.3190905983153398\n",
            "At step: 6259 training error: 0.3205171161249173\n",
            "At step: 6260 training error: 0.3207402988355208\n",
            "At step: 6261 training error: 0.31295236765569157\n",
            "At step: 6262 training error: 0.31202480034195584\n",
            "At step: 6263 training error: 0.30603113353355654\n",
            "At step: 6264 training error: 0.3166677365666557\n",
            "At step: 6265 training error: 0.32090198402078823\n",
            "At step: 6266 training error: 0.3319138892597656\n",
            "At step: 6267 training error: 0.3282391601055267\n",
            "At step: 6268 training error: 0.3223991227321528\n",
            "At step: 6269 training error: 0.343471409456442\n",
            "At step: 6270 training error: 0.33896724006096907\n",
            "At step: 6271 training error: 0.3351002246707946\n",
            "At step: 6272 training error: 0.3316509856848949\n",
            "At step: 6273 training error: 0.32175466974370515\n",
            "At step: 6274 training error: 0.31454958151111795\n",
            "At step: 6275 training error: 0.314376635852506\n",
            "At step: 6276 training error: 0.30442898655788586\n",
            "At step: 6277 training error: 0.3181012818992257\n",
            "At step: 6278 training error: 0.3157479663758113\n",
            "At step: 6279 training error: 0.3179462316774775\n",
            "At step: 6280 training error: 0.31291651985191243\n",
            "At step: 6281 training error: 0.3174343220916056\n",
            "At step: 6282 training error: 0.30671767436572533\n",
            "At step: 6283 training error: 0.30030038345765636\n",
            "At step: 6284 training error: 0.3128589863176325\n",
            "At step: 6285 training error: 0.30674435029063485\n",
            "At step: 6286 training error: 0.29936599468495984\n",
            "At step: 6287 training error: 0.2937291783478083\n",
            "At step: 6288 training error: 0.30053074528433815\n",
            "At step: 6289 training error: 0.28987853716435547\n",
            "At step: 6290 training error: 0.2902795573883724\n",
            "At step: 6291 training error: 0.30101145461323947\n",
            "At step: 6292 training error: 0.29290604018662664\n",
            "At step: 6293 training error: 0.3049874046843698\n",
            "At step: 6294 training error: 0.29847074112109795\n",
            "At step: 6295 training error: 0.2943057114084061\n",
            "At step: 6296 training error: 0.299749159400855\n",
            "At step: 6297 training error: 0.3014134790717827\n",
            "At step: 6298 training error: 0.3046939424601622\n",
            "At step: 6299 training error: 0.3101049663582753\n",
            "At step: 6300 training error: 0.31357871087591516\n",
            "At step: 6301 training error: 0.32154960646063213\n",
            "At step: 6302 training error: 0.3231721322903283\n",
            "At step: 6303 training error: 0.33674457113646056\n",
            "At step: 6304 training error: 0.33252165029427977\n",
            "At step: 6305 training error: 0.32824334429846774\n",
            "At step: 6306 training error: 0.3279964768642898\n",
            "At step: 6307 training error: 0.31794636001548265\n",
            "At step: 6308 training error: 0.3131686885556698\n",
            "At step: 6309 training error: 0.3108025848407501\n",
            "At step: 6310 training error: 0.30669853972872146\n",
            "At step: 6311 training error: 0.3043582475262549\n",
            "At step: 6312 training error: 0.308364155898072\n",
            "At step: 6313 training error: 0.31576510571518546\n",
            "At step: 6314 training error: 0.3123403706500414\n",
            "At step: 6315 training error: 0.3132035568855105\n",
            "At step: 6316 training error: 0.31139154836157107\n",
            "At step: 6317 training error: 0.30641721639896147\n",
            "At step: 6318 training error: 0.31546174405655425\n",
            "At step: 6319 training error: 0.3063643963974673\n",
            "At step: 6320 training error: 0.2991910022885358\n",
            "At step: 6321 training error: 0.30838027952385555\n",
            "At step: 6322 training error: 0.3053979045848937\n",
            "At step: 6323 training error: 0.30057632692610536\n",
            "At step: 6324 training error: 0.3058307898772747\n",
            "At step: 6325 training error: 0.3028204617140949\n",
            "At step: 6326 training error: 0.2998171617039074\n",
            "At step: 6327 training error: 0.3068885393948747\n",
            "At step: 6328 training error: 0.30735919089884794\n",
            "At step: 6329 training error: 0.2962610745009857\n",
            "At step: 6330 training error: 0.299510087296574\n",
            "At step: 6331 training error: 0.3059410571946374\n",
            "At step: 6332 training error: 0.3104417063629534\n",
            "At step: 6333 training error: 0.31087772207732983\n",
            "At step: 6334 training error: 0.3127391763098208\n",
            "At step: 6335 training error: 0.31153401868609015\n",
            "At step: 6336 training error: 0.3076830219602436\n",
            "At step: 6337 training error: 0.3009437652087324\n",
            "At step: 6338 training error: 0.31529643527665446\n",
            "At step: 6339 training error: 0.3180719275074612\n",
            "At step: 6340 training error: 0.3121216924321437\n",
            "At step: 6341 training error: 0.31929860677628075\n",
            "At step: 6342 training error: 0.3095807547239309\n",
            "At step: 6343 training error: 0.3171820452632102\n",
            "At step: 6344 training error: 0.3160106215254751\n",
            "At step: 6345 training error: 0.3115175062462408\n",
            "At step: 6346 training error: 0.312520694993123\n",
            "At step: 6347 training error: 0.32165473308925213\n",
            "At step: 6348 training error: 0.3205521657614433\n",
            "At step: 6349 training error: 0.31752434999602697\n",
            "At step: 6350 training error: 0.32374240063195864\n",
            "At step: 6351 training error: 0.324156685760019\n",
            "At step: 6352 training error: 0.3238133972236074\n",
            "At step: 6353 training error: 0.3272983170223553\n",
            "At step: 6354 training error: 0.3127843579876708\n",
            "At step: 6355 training error: 0.3216429116817987\n",
            "At step: 6356 training error: 0.3256538152341959\n",
            "At step: 6357 training error: 0.3200187688986161\n",
            "At step: 6358 training error: 0.32164993606885145\n",
            "At step: 6359 training error: 0.31324245311266885\n",
            "At step: 6360 training error: 0.3058796229349595\n",
            "At step: 6361 training error: 0.32056548050238637\n",
            "At step: 6362 training error: 0.31700543410406296\n",
            "At step: 6363 training error: 0.31536112828340285\n",
            "At step: 6364 training error: 0.3111584687323861\n",
            "At step: 6365 training error: 0.3157055448487486\n",
            "At step: 6366 training error: 0.3180427340048138\n",
            "At step: 6367 training error: 0.3076243375660862\n",
            "At step: 6368 training error: 0.3024517657447726\n",
            "At step: 6369 training error: 0.3090980928131903\n",
            "At step: 6370 training error: 0.3112417266448958\n",
            "At step: 6371 training error: 0.30305107380305585\n",
            "At step: 6372 training error: 0.2983901973718829\n",
            "At step: 6373 training error: 0.3018074280970002\n",
            "At step: 6374 training error: 0.3231741719839457\n",
            "At step: 6375 training error: 0.31622033713999953\n",
            "At step: 6376 training error: 0.31184992348517315\n",
            "At step: 6377 training error: 0.30664007957240924\n",
            "At step: 6378 training error: 0.29912556463470574\n",
            "At step: 6379 training error: 0.2961480703294069\n",
            "At step: 6380 training error: 0.29836393547321244\n",
            "At step: 6381 training error: 0.30013730772092834\n",
            "At step: 6382 training error: 0.29928293710566717\n",
            "At step: 6383 training error: 0.30130163705227253\n",
            "At step: 6384 training error: 0.2902381045791472\n",
            "At step: 6385 training error: 0.28720767528500624\n",
            "At step: 6386 training error: 0.2877871625044796\n",
            "At step: 6387 training error: 0.2865273184989324\n",
            "At step: 6388 training error: 0.290344640672616\n",
            "At step: 6389 training error: 0.2901272869023521\n",
            "At step: 6390 training error: 0.2767481155430207\n",
            "At step: 6391 training error: 0.28860370581375877\n",
            "At step: 6392 training error: 0.29393050224873546\n",
            "At step: 6393 training error: 0.30088152855872646\n",
            "At step: 6394 training error: 0.3044260698343625\n",
            "At step: 6395 training error: 0.30721327687796623\n",
            "At step: 6396 training error: 0.3110840818826914\n",
            "At step: 6397 training error: 0.30376688575394883\n",
            "At step: 6398 training error: 0.30972954501597144\n",
            "At step: 6399 training error: 0.30351755197870195\n",
            "At step: 6400 training error: 0.31237319851026096\n",
            "At step: 6401 training error: 0.3032698503810598\n",
            "At step: 6402 training error: 0.30908077923883126\n",
            "At step: 6403 training error: 0.3124298643653093\n",
            "At step: 6404 training error: 0.3157361594067535\n",
            "At step: 6405 training error: 0.3112853967299945\n",
            "At step: 6406 training error: 0.3134003747835482\n",
            "At step: 6407 training error: 0.3092698927514455\n",
            "At step: 6408 training error: 0.30837182526228035\n",
            "At step: 6409 training error: 0.31064421388006197\n",
            "At step: 6410 training error: 0.3236893610726182\n",
            "At step: 6411 training error: 0.3206954115584136\n",
            "At step: 6412 training error: 0.3180199279639564\n",
            "At step: 6413 training error: 0.3170047843264152\n",
            "At step: 6414 training error: 0.31150471254272766\n",
            "At step: 6415 training error: 0.30652208002716125\n",
            "At step: 6416 training error: 0.3089615319729728\n",
            "At step: 6417 training error: 0.30656748247311805\n",
            "At step: 6418 training error: 0.30189995569019024\n",
            "At step: 6419 training error: 0.29600119930146146\n",
            "At step: 6420 training error: 0.297037776049294\n",
            "At step: 6421 training error: 0.306533591447431\n",
            "At step: 6422 training error: 0.3124964990240098\n",
            "At step: 6423 training error: 0.31052403783945437\n",
            "At step: 6424 training error: 0.31671471868796786\n",
            "At step: 6425 training error: 0.318133021646418\n",
            "At step: 6426 training error: 0.3171858383936029\n",
            "At step: 6427 training error: 0.318989503471826\n",
            "At step: 6428 training error: 0.31441744822292905\n",
            "At step: 6429 training error: 0.3103517999159412\n",
            "At step: 6430 training error: 0.30874343874911647\n",
            "At step: 6431 training error: 0.301538037178211\n",
            "At step: 6432 training error: 0.3095292015615816\n",
            "At step: 6433 training error: 0.3077123332369712\n",
            "At step: 6434 training error: 0.3166341050845191\n",
            "At step: 6435 training error: 0.313078968835546\n",
            "At step: 6436 training error: 0.30680082327711466\n",
            "At step: 6437 training error: 0.3216198279236118\n",
            "At step: 6438 training error: 0.3138041717298465\n",
            "At step: 6439 training error: 0.3151985827481251\n",
            "At step: 6440 training error: 0.321638612340333\n",
            "At step: 6441 training error: 0.3135045389804293\n",
            "At step: 6442 training error: 0.3131053549141118\n",
            "At step: 6443 training error: 0.31109086293033444\n",
            "At step: 6444 training error: 0.3035738490997448\n",
            "At step: 6445 training error: 0.30349752800024843\n",
            "At step: 6446 training error: 0.2997862391269656\n",
            "At step: 6447 training error: 0.2928966238720636\n",
            "At step: 6448 training error: 0.2992754364489309\n",
            "At step: 6449 training error: 0.28992083334443985\n",
            "At step: 6450 training error: 0.28543281005775734\n",
            "At step: 6451 training error: 0.2918357090164006\n",
            "At step: 6452 training error: 0.3005862760775459\n",
            "At step: 6453 training error: 0.29948689625005126\n",
            "At step: 6454 training error: 0.2964264450634966\n",
            "At step: 6455 training error: 0.3046983503577213\n",
            "At step: 6456 training error: 0.3114195635785791\n",
            "At step: 6457 training error: 0.30038350011316367\n",
            "At step: 6458 training error: 0.29283555613221895\n",
            "At step: 6459 training error: 0.3011746818446834\n",
            "At step: 6460 training error: 0.30132372338988306\n",
            "At step: 6461 training error: 0.3015618734102239\n",
            "At step: 6462 training error: 0.30731770236945133\n",
            "At step: 6463 training error: 0.30503158187134605\n",
            "At step: 6464 training error: 0.3148463504974955\n",
            "At step: 6465 training error: 0.30863780651115114\n",
            "At step: 6466 training error: 0.3007341145223193\n",
            "At step: 6467 training error: 0.29571444317932094\n",
            "At step: 6468 training error: 0.286817033654819\n",
            "At step: 6469 training error: 0.29276456220223657\n",
            "At step: 6470 training error: 0.29279432709398745\n",
            "At step: 6471 training error: 0.28919154235198224\n",
            "At step: 6472 training error: 0.2984145778407591\n",
            "At step: 6473 training error: 0.3102203512963277\n",
            "At step: 6474 training error: 0.30638001190326464\n",
            "At step: 6475 training error: 0.31611898457897014\n",
            "At step: 6476 training error: 0.3131563968485072\n",
            "At step: 6477 training error: 0.32682852546326596\n",
            "At step: 6478 training error: 0.33570595628324046\n",
            "At step: 6479 training error: 0.33436403602267134\n",
            "At step: 6480 training error: 0.33200125091165367\n",
            "At step: 6481 training error: 0.3316695668496449\n",
            "At step: 6482 training error: 0.3310450361013979\n",
            "At step: 6483 training error: 0.326715769294189\n",
            "At step: 6484 training error: 0.33428172165666564\n",
            "At step: 6485 training error: 0.3514084443984654\n",
            "At step: 6486 training error: 0.34768125636327935\n",
            "At step: 6487 training error: 0.3540817171860083\n",
            "At step: 6488 training error: 0.34274491204157076\n",
            "At step: 6489 training error: 0.3440042128601539\n",
            "At step: 6490 training error: 0.3429169010202531\n",
            "At step: 6491 training error: 0.34470219660352597\n",
            "At step: 6492 training error: 0.330337089115125\n",
            "At step: 6493 training error: 0.3202839522281009\n",
            "At step: 6494 training error: 0.32038111978066497\n",
            "At step: 6495 training error: 0.3242884014029551\n",
            "At step: 6496 training error: 0.31941641173238594\n",
            "At step: 6497 training error: 0.31782824895496214\n",
            "At step: 6498 training error: 0.31870764122587614\n",
            "At step: 6499 training error: 0.31670096437027134\n",
            "At step: 6500 training error: 0.32176143208802377\n",
            "At step: 6501 training error: 0.3203688388356517\n",
            "At step: 6502 training error: 0.32022774663023473\n",
            "At step: 6503 training error: 0.32095939582932975\n",
            "At step: 6504 training error: 0.31654610943940303\n",
            "At step: 6505 training error: 0.32244649143374926\n",
            "At step: 6506 training error: 0.33564114578804927\n",
            "At step: 6507 training error: 0.3418097363423874\n",
            "At step: 6508 training error: 0.3300183019968707\n",
            "At step: 6509 training error: 0.340496206716323\n",
            "At step: 6510 training error: 0.33100181967290915\n",
            "At step: 6511 training error: 0.32941111379900617\n",
            "At step: 6512 training error: 0.33661571849318067\n",
            "At step: 6513 training error: 0.32800372864020316\n",
            "At step: 6514 training error: 0.3159679321261158\n",
            "At step: 6515 training error: 0.3078875371777751\n",
            "At step: 6516 training error: 0.3074996437521335\n",
            "At step: 6517 training error: 0.30684062091728714\n",
            "At step: 6518 training error: 0.30178027336355423\n",
            "At step: 6519 training error: 0.31392400701306766\n",
            "At step: 6520 training error: 0.32020988211998724\n",
            "At step: 6521 training error: 0.31012166551141784\n",
            "At step: 6522 training error: 0.3105504005503614\n",
            "At step: 6523 training error: 0.30891614354180486\n",
            "At step: 6524 training error: 0.30216113182951243\n",
            "At step: 6525 training error: 0.30350621695004665\n",
            "At step: 6526 training error: 0.3051796787445273\n",
            "At step: 6527 training error: 0.29830733498700107\n",
            "At step: 6528 training error: 0.28810069122933396\n",
            "At step: 6529 training error: 0.29987208870692134\n",
            "At step: 6530 training error: 0.3010326921559421\n",
            "At step: 6531 training error: 0.3024476185324866\n",
            "At step: 6532 training error: 0.29630102831248356\n",
            "At step: 6533 training error: 0.3088903258370783\n",
            "At step: 6534 training error: 0.3101360662684088\n",
            "At step: 6535 training error: 0.3121549584901486\n",
            "At step: 6536 training error: 0.3162047189255443\n",
            "At step: 6537 training error: 0.32602048732032124\n",
            "At step: 6538 training error: 0.33892691908796196\n",
            "At step: 6539 training error: 0.3377786088580546\n",
            "At step: 6540 training error: 0.3424969064163116\n",
            "At step: 6541 training error: 0.3320152001382219\n",
            "At step: 6542 training error: 0.3432551474722699\n",
            "At step: 6543 training error: 0.32920348102811076\n",
            "At step: 6544 training error: 0.32594530115155124\n",
            "At step: 6545 training error: 0.31749350256478487\n",
            "At step: 6546 training error: 0.3300165393827676\n",
            "At step: 6547 training error: 0.32558956267055295\n",
            "At step: 6548 training error: 0.32008129969235366\n",
            "At step: 6549 training error: 0.31368470784472574\n",
            "At step: 6550 training error: 0.3162015852736926\n",
            "At step: 6551 training error: 0.30956385752377735\n",
            "At step: 6552 training error: 0.310717748810598\n",
            "At step: 6553 training error: 0.3202485486416762\n",
            "At step: 6554 training error: 0.3138701136729216\n",
            "At step: 6555 training error: 0.3065655403618204\n",
            "At step: 6556 training error: 0.3009088104841617\n",
            "At step: 6557 training error: 0.30575151379466065\n",
            "At step: 6558 training error: 0.2992892644137123\n",
            "At step: 6559 training error: 0.30023036749085724\n",
            "At step: 6560 training error: 0.2983228478632208\n",
            "At step: 6561 training error: 0.30421202425199406\n",
            "At step: 6562 training error: 0.3040975396641711\n",
            "At step: 6563 training error: 0.30166942105768174\n",
            "At step: 6564 training error: 0.3046088486369587\n",
            "At step: 6565 training error: 0.2984797075423193\n",
            "At step: 6566 training error: 0.2979737674565607\n",
            "At step: 6567 training error: 0.307639207276613\n",
            "At step: 6568 training error: 0.3211478764843112\n",
            "At step: 6569 training error: 0.3060714158760033\n",
            "At step: 6570 training error: 0.3151346301528618\n",
            "At step: 6571 training error: 0.30581407365210056\n",
            "At step: 6572 training error: 0.30666522423683495\n",
            "At step: 6573 training error: 0.3067643114886793\n",
            "At step: 6574 training error: 0.3142149359235609\n",
            "At step: 6575 training error: 0.32111027077188753\n",
            "At step: 6576 training error: 0.32177509834942547\n",
            "At step: 6577 training error: 0.32130709887315995\n",
            "At step: 6578 training error: 0.31600844506775433\n",
            "At step: 6579 training error: 0.31562704849340895\n",
            "At step: 6580 training error: 0.3121106622093764\n",
            "At step: 6581 training error: 0.3182588204714619\n",
            "At step: 6582 training error: 0.31848609062808025\n",
            "At step: 6583 training error: 0.32130167714373487\n",
            "At step: 6584 training error: 0.31526169284386135\n",
            "At step: 6585 training error: 0.3081068790351089\n",
            "At step: 6586 training error: 0.31014785433994896\n",
            "At step: 6587 training error: 0.3029032103079747\n",
            "At step: 6588 training error: 0.30133606195563434\n",
            "At step: 6589 training error: 0.30643048442705834\n",
            "At step: 6590 training error: 0.300267231667383\n",
            "At step: 6591 training error: 0.2971219658087653\n",
            "At step: 6592 training error: 0.2978540046155695\n",
            "At step: 6593 training error: 0.30126987325889015\n",
            "At step: 6594 training error: 0.3080620586189493\n",
            "At step: 6595 training error: 0.30840854722708416\n",
            "At step: 6596 training error: 0.3118835516503662\n",
            "At step: 6597 training error: 0.3119334102802876\n",
            "At step: 6598 training error: 0.3091066289946153\n",
            "At step: 6599 training error: 0.3160882175948265\n",
            "At step: 6600 training error: 0.3062428818518713\n",
            "At step: 6601 training error: 0.31260352831019805\n",
            "At step: 6602 training error: 0.31653467844129646\n",
            "At step: 6603 training error: 0.3144021422868388\n",
            "At step: 6604 training error: 0.3122065317877622\n",
            "At step: 6605 training error: 0.3271890033943695\n",
            "At step: 6606 training error: 0.3247666346740264\n",
            "At step: 6607 training error: 0.3297154861537585\n",
            "At step: 6608 training error: 0.33423773352831854\n",
            "At step: 6609 training error: 0.3198868737970198\n",
            "At step: 6610 training error: 0.3125936259433145\n",
            "At step: 6611 training error: 0.31604486485173655\n",
            "At step: 6612 training error: 0.30647157215994664\n",
            "At step: 6613 training error: 0.29919789365543437\n",
            "At step: 6614 training error: 0.30410231577688174\n",
            "At step: 6615 training error: 0.3099899529977992\n",
            "At step: 6616 training error: 0.3146635093101969\n",
            "At step: 6617 training error: 0.30668491423536287\n",
            "At step: 6618 training error: 0.3041042440841981\n",
            "At step: 6619 training error: 0.3161397006125478\n",
            "At step: 6620 training error: 0.31798275290020256\n",
            "At step: 6621 training error: 0.3070764103187261\n",
            "At step: 6622 training error: 0.3015494331677336\n",
            "At step: 6623 training error: 0.29377192430636\n",
            "At step: 6624 training error: 0.29669111621802324\n",
            "At step: 6625 training error: 0.299897535369256\n",
            "At step: 6626 training error: 0.30212637273416415\n",
            "At step: 6627 training error: 0.2916855388122255\n",
            "At step: 6628 training error: 0.2927895493623926\n",
            "At step: 6629 training error: 0.2973211936434856\n",
            "At step: 6630 training error: 0.30604133060277305\n",
            "At step: 6631 training error: 0.30036766418765903\n",
            "At step: 6632 training error: 0.30232596017360364\n",
            "At step: 6633 training error: 0.30038165146289153\n",
            "At step: 6634 training error: 0.29336071309462936\n",
            "At step: 6635 training error: 0.2903380942844454\n",
            "At step: 6636 training error: 0.2971608603016157\n",
            "At step: 6637 training error: 0.2924369743044531\n",
            "At step: 6638 training error: 0.29840171921736636\n",
            "At step: 6639 training error: 0.2986211469011542\n",
            "At step: 6640 training error: 0.30820365996271903\n",
            "At step: 6641 training error: 0.3117569673976558\n",
            "At step: 6642 training error: 0.30507642078430464\n",
            "At step: 6643 training error: 0.2989673386103243\n",
            "At step: 6644 training error: 0.303687146933288\n",
            "At step: 6645 training error: 0.2994164361725422\n",
            "At step: 6646 training error: 0.3031575190606891\n",
            "At step: 6647 training error: 0.30815595728266637\n",
            "At step: 6648 training error: 0.3026952969981094\n",
            "At step: 6649 training error: 0.3082212362603005\n",
            "At step: 6650 training error: 0.29319990646568883\n",
            "At step: 6651 training error: 0.2908834803182294\n",
            "At step: 6652 training error: 0.2871438436163546\n",
            "At step: 6653 training error: 0.2769416912396825\n",
            "At step: 6654 training error: 0.2861292574524444\n",
            "At step: 6655 training error: 0.2964694824864242\n",
            "At step: 6656 training error: 0.2950572402382715\n",
            "At step: 6657 training error: 0.30364655737776464\n",
            "At step: 6658 training error: 0.3105432870585063\n",
            "At step: 6659 training error: 0.3143007695525257\n",
            "At step: 6660 training error: 0.3218679785852711\n",
            "At step: 6661 training error: 0.3204865524342947\n",
            "At step: 6662 training error: 0.318874932697651\n",
            "At step: 6663 training error: 0.3226303476088392\n",
            "At step: 6664 training error: 0.31659373307503513\n",
            "At step: 6665 training error: 0.3191164704163855\n",
            "At step: 6666 training error: 0.306466271921552\n",
            "At step: 6667 training error: 0.31284278339488963\n",
            "At step: 6668 training error: 0.3162026834322972\n",
            "At step: 6669 training error: 0.3012689646867381\n",
            "At step: 6670 training error: 0.2964684933355985\n",
            "At step: 6671 training error: 0.2955631448933922\n",
            "At step: 6672 training error: 0.2872004382038601\n",
            "At step: 6673 training error: 0.27875091315273925\n",
            "At step: 6674 training error: 0.27923288696365056\n",
            "At step: 6675 training error: 0.2879218302760217\n",
            "At step: 6676 training error: 0.28572188332888726\n",
            "At step: 6677 training error: 0.2958195184040795\n",
            "At step: 6678 training error: 0.304453106867402\n",
            "At step: 6679 training error: 0.3147882478186831\n",
            "At step: 6680 training error: 0.3102489654832406\n",
            "At step: 6681 training error: 0.311408441983661\n",
            "At step: 6682 training error: 0.30503774542011014\n",
            "At step: 6683 training error: 0.29609022750861264\n",
            "At step: 6684 training error: 0.30213326622164555\n",
            "At step: 6685 training error: 0.31194428006342223\n",
            "At step: 6686 training error: 0.3249825588511892\n",
            "At step: 6687 training error: 0.32447051827881684\n",
            "At step: 6688 training error: 0.3108932447148735\n",
            "At step: 6689 training error: 0.3114026238742004\n",
            "At step: 6690 training error: 0.30181764392073956\n",
            "At step: 6691 training error: 0.30104368150119487\n",
            "At step: 6692 training error: 0.29731022803906715\n",
            "At step: 6693 training error: 0.2969670857199789\n",
            "At step: 6694 training error: 0.29537667788502975\n",
            "At step: 6695 training error: 0.29061001316123797\n",
            "At step: 6696 training error: 0.3050613588855098\n",
            "At step: 6697 training error: 0.306238503652203\n",
            "At step: 6698 training error: 0.30883414795805997\n",
            "At step: 6699 training error: 0.3121821157886159\n",
            "At step: 6700 training error: 0.31904303607212314\n",
            "At step: 6701 training error: 0.3265447797671136\n",
            "At step: 6702 training error: 0.33292976224684395\n",
            "At step: 6703 training error: 0.3320214349907336\n",
            "At step: 6704 training error: 0.3285429243969974\n",
            "At step: 6705 training error: 0.33419293838651176\n",
            "At step: 6706 training error: 0.32599255607352845\n",
            "At step: 6707 training error: 0.32833460079149485\n",
            "At step: 6708 training error: 0.3321448747276047\n",
            "At step: 6709 training error: 0.33832249383914265\n",
            "At step: 6710 training error: 0.3310529921538017\n",
            "At step: 6711 training error: 0.32594114091703186\n",
            "At step: 6712 training error: 0.32878660904191515\n",
            "At step: 6713 training error: 0.3176362916262985\n",
            "At step: 6714 training error: 0.31746761636762255\n",
            "At step: 6715 training error: 0.3142385066286444\n",
            "At step: 6716 training error: 0.3194729625304245\n",
            "At step: 6717 training error: 0.3190334530464865\n",
            "At step: 6718 training error: 0.3070787070055021\n",
            "At step: 6719 training error: 0.3101860550003823\n",
            "At step: 6720 training error: 0.3205424901985319\n",
            "At step: 6721 training error: 0.32716940934913663\n",
            "At step: 6722 training error: 0.32743647764487394\n",
            "At step: 6723 training error: 0.3204323448458247\n",
            "At step: 6724 training error: 0.3214182889863973\n",
            "At step: 6725 training error: 0.3230039005652968\n",
            "At step: 6726 training error: 0.3269023463311868\n",
            "At step: 6727 training error: 0.3347934843887738\n",
            "At step: 6728 training error: 0.3220002543845353\n",
            "At step: 6729 training error: 0.3212102665660015\n",
            "At step: 6730 training error: 0.3199347369755323\n",
            "At step: 6731 training error: 0.3158747929247964\n",
            "At step: 6732 training error: 0.3081481172548553\n",
            "At step: 6733 training error: 0.3177219623487239\n",
            "At step: 6734 training error: 0.3008335890057914\n",
            "At step: 6735 training error: 0.298308014610148\n",
            "At step: 6736 training error: 0.29831639577725416\n",
            "At step: 6737 training error: 0.30451074343914736\n",
            "At step: 6738 training error: 0.310106869952369\n",
            "At step: 6739 training error: 0.31039907264566036\n",
            "At step: 6740 training error: 0.30400492039624083\n",
            "At step: 6741 training error: 0.3083499371940111\n",
            "At step: 6742 training error: 0.3039369103527134\n",
            "At step: 6743 training error: 0.29753926595752306\n",
            "At step: 6744 training error: 0.3021881973758511\n",
            "At step: 6745 training error: 0.3114519275705015\n",
            "At step: 6746 training error: 0.314018302413706\n",
            "At step: 6747 training error: 0.31980726463068165\n",
            "At step: 6748 training error: 0.31686383233855653\n",
            "At step: 6749 training error: 0.3123757760390291\n",
            "At step: 6750 training error: 0.30587385345226425\n",
            "At step: 6751 training error: 0.32165570650436937\n",
            "At step: 6752 training error: 0.31724832137635506\n",
            "At step: 6753 training error: 0.3140514067700591\n",
            "At step: 6754 training error: 0.3132788579082309\n",
            "At step: 6755 training error: 0.3038057089695738\n",
            "At step: 6756 training error: 0.30165201093112265\n",
            "At step: 6757 training error: 0.29950658960061216\n",
            "At step: 6758 training error: 0.3029225519536345\n",
            "At step: 6759 training error: 0.30653188308355095\n",
            "At step: 6760 training error: 0.30086573914392173\n",
            "At step: 6761 training error: 0.3034388337263331\n",
            "At step: 6762 training error: 0.3006071816424423\n",
            "At step: 6763 training error: 0.3051176414223719\n",
            "At step: 6764 training error: 0.3055346737714006\n",
            "At step: 6765 training error: 0.3067383391826949\n",
            "At step: 6766 training error: 0.30943249841391857\n",
            "At step: 6767 training error: 0.3058396040839115\n",
            "At step: 6768 training error: 0.3037825769441214\n",
            "At step: 6769 training error: 0.311858825353839\n",
            "At step: 6770 training error: 0.3063327205146728\n",
            "At step: 6771 training error: 0.3220258282044034\n",
            "At step: 6772 training error: 0.31939061965461213\n",
            "At step: 6773 training error: 0.3150367555476427\n",
            "At step: 6774 training error: 0.3047501941914916\n",
            "At step: 6775 training error: 0.3079264768802939\n",
            "At step: 6776 training error: 0.3098558103500722\n",
            "At step: 6777 training error: 0.30515919893841725\n",
            "At step: 6778 training error: 0.31213117179165467\n",
            "At step: 6779 training error: 0.30632518065925785\n",
            "At step: 6780 training error: 0.3070107429714337\n",
            "At step: 6781 training error: 0.3107714206484747\n",
            "At step: 6782 training error: 0.3102462034744533\n",
            "At step: 6783 training error: 0.31567063084195623\n",
            "At step: 6784 training error: 0.32448446020392957\n",
            "At step: 6785 training error: 0.33115153121408203\n",
            "At step: 6786 training error: 0.32865284961719665\n",
            "At step: 6787 training error: 0.32925938531852783\n",
            "At step: 6788 training error: 0.32498594757380367\n",
            "At step: 6789 training error: 0.3199369174995735\n",
            "At step: 6790 training error: 0.3264110189329825\n",
            "At step: 6791 training error: 0.3270730193482165\n",
            "At step: 6792 training error: 0.32463799448764047\n",
            "At step: 6793 training error: 0.34501538378460306\n",
            "At step: 6794 training error: 0.33782850193320163\n",
            "At step: 6795 training error: 0.3463311584534076\n",
            "At step: 6796 training error: 0.3406705177867827\n",
            "At step: 6797 training error: 0.3463040823326735\n",
            "At step: 6798 training error: 0.3349362821106103\n",
            "At step: 6799 training error: 0.33734776278063405\n",
            "At step: 6800 training error: 0.33123621494090755\n",
            "At step: 6801 training error: 0.34350043740704755\n",
            "At step: 6802 training error: 0.34249127475700064\n",
            "At step: 6803 training error: 0.335126531987358\n",
            "At step: 6804 training error: 0.34325282385629363\n",
            "At step: 6805 training error: 0.33329851516637565\n",
            "At step: 6806 training error: 0.33061241269761044\n",
            "At step: 6807 training error: 0.342025327412451\n",
            "At step: 6808 training error: 0.32905824441061926\n",
            "At step: 6809 training error: 0.32537127412963907\n",
            "At step: 6810 training error: 0.32068865839266447\n",
            "At step: 6811 training error: 0.32245444623702485\n",
            "At step: 6812 training error: 0.3183049004894546\n",
            "At step: 6813 training error: 0.3305805162853868\n",
            "At step: 6814 training error: 0.31950022861846367\n",
            "At step: 6815 training error: 0.3323528330883132\n",
            "At step: 6816 training error: 0.33393374618650323\n",
            "At step: 6817 training error: 0.33377104379245315\n",
            "At step: 6818 training error: 0.328605141755919\n",
            "At step: 6819 training error: 0.3275345060493243\n",
            "At step: 6820 training error: 0.3188477698059576\n",
            "At step: 6821 training error: 0.3183940747127815\n",
            "At step: 6822 training error: 0.30924601151388015\n",
            "At step: 6823 training error: 0.3160754442406494\n",
            "At step: 6824 training error: 0.3154110150692514\n",
            "At step: 6825 training error: 0.3169354652660381\n",
            "At step: 6826 training error: 0.3143199314486779\n",
            "At step: 6827 training error: 0.3149288985740616\n",
            "At step: 6828 training error: 0.3133767604219322\n",
            "At step: 6829 training error: 0.30756694686363095\n",
            "At step: 6830 training error: 0.3097943056579668\n",
            "At step: 6831 training error: 0.2969749506024181\n",
            "At step: 6832 training error: 0.2987596596963808\n",
            "At step: 6833 training error: 0.3034174184020074\n",
            "At step: 6834 training error: 0.3089330796343453\n",
            "At step: 6835 training error: 0.30628706042397\n",
            "At step: 6836 training error: 0.3149257248217474\n",
            "At step: 6837 training error: 0.30669484176317846\n",
            "At step: 6838 training error: 0.31328670759455135\n",
            "At step: 6839 training error: 0.3038338369467668\n",
            "At step: 6840 training error: 0.30844503416429736\n",
            "At step: 6841 training error: 0.29544740939582964\n",
            "At step: 6842 training error: 0.2925934502063052\n",
            "At step: 6843 training error: 0.2871335915359888\n",
            "At step: 6844 training error: 0.2885788722660489\n",
            "At step: 6845 training error: 0.27749266909996034\n",
            "At step: 6846 training error: 0.2717366627146128\n",
            "At step: 6847 training error: 0.27198747340434415\n",
            "At step: 6848 training error: 0.28802219487404224\n",
            "At step: 6849 training error: 0.2949635928121169\n",
            "At step: 6850 training error: 0.3005735249375684\n",
            "At step: 6851 training error: 0.30586019187213537\n",
            "At step: 6852 training error: 0.30458069687482825\n",
            "At step: 6853 training error: 0.3122460424940775\n",
            "At step: 6854 training error: 0.3111055435802429\n",
            "At step: 6855 training error: 0.3083510230350906\n",
            "At step: 6856 training error: 0.310908630883712\n",
            "At step: 6857 training error: 0.3193724687411656\n",
            "At step: 6858 training error: 0.330384622213863\n",
            "At step: 6859 training error: 0.33140899911005184\n",
            "At step: 6860 training error: 0.335536551052743\n",
            "At step: 6861 training error: 0.34181256096432033\n",
            "At step: 6862 training error: 0.34182361448363185\n",
            "At step: 6863 training error: 0.34920114701982463\n",
            "At step: 6864 training error: 0.3400774429092035\n",
            "At step: 6865 training error: 0.33528052922447\n",
            "At step: 6866 training error: 0.331181963532215\n",
            "At step: 6867 training error: 0.32384667985942306\n",
            "At step: 6868 training error: 0.31853729409253734\n",
            "At step: 6869 training error: 0.32731104713555176\n",
            "At step: 6870 training error: 0.3312847677609333\n",
            "At step: 6871 training error: 0.3314053318216772\n",
            "At step: 6872 training error: 0.33865700534371207\n",
            "At step: 6873 training error: 0.3294520669243676\n",
            "At step: 6874 training error: 0.34222032715616846\n",
            "At step: 6875 training error: 0.34282624426307956\n",
            "At step: 6876 training error: 0.3418178022285256\n",
            "At step: 6877 training error: 0.3383330636437607\n",
            "At step: 6878 training error: 0.3402146613614809\n",
            "At step: 6879 training error: 0.33732325918408823\n",
            "At step: 6880 training error: 0.332407714725232\n",
            "At step: 6881 training error: 0.32875951632162365\n",
            "At step: 6882 training error: 0.3329352576600595\n",
            "At step: 6883 training error: 0.3273016857524284\n",
            "At step: 6884 training error: 0.324830144719942\n",
            "At step: 6885 training error: 0.32730986303784676\n",
            "At step: 6886 training error: 0.3207782630149389\n",
            "At step: 6887 training error: 0.32065393546923127\n",
            "At step: 6888 training error: 0.3245088668356273\n",
            "At step: 6889 training error: 0.3313780892938473\n",
            "At step: 6890 training error: 0.33596397721421817\n",
            "At step: 6891 training error: 0.3314950133379249\n",
            "At step: 6892 training error: 0.32421200498832853\n",
            "At step: 6893 training error: 0.3232164337365691\n",
            "At step: 6894 training error: 0.31022738722395954\n",
            "At step: 6895 training error: 0.30522039225775094\n",
            "At step: 6896 training error: 0.30698749108274603\n",
            "At step: 6897 training error: 0.31639622874891543\n",
            "At step: 6898 training error: 0.32135530106979737\n",
            "At step: 6899 training error: 0.3177487736223964\n",
            "At step: 6900 training error: 0.31808414140378216\n",
            "At step: 6901 training error: 0.3133641676728342\n",
            "At step: 6902 training error: 0.30629963338817384\n",
            "At step: 6903 training error: 0.3086241897548417\n",
            "At step: 6904 training error: 0.3036345557888917\n",
            "At step: 6905 training error: 0.3016127781717044\n",
            "At step: 6906 training error: 0.307589319703849\n",
            "At step: 6907 training error: 0.306758785857997\n",
            "At step: 6908 training error: 0.3114007065850253\n",
            "At step: 6909 training error: 0.30830020198128566\n",
            "At step: 6910 training error: 0.3012308160046797\n",
            "At step: 6911 training error: 0.29522698442095996\n",
            "At step: 6912 training error: 0.3050403360951296\n",
            "At step: 6913 training error: 0.3019428963019527\n",
            "At step: 6914 training error: 0.3034064180235064\n",
            "At step: 6915 training error: 0.29113925596952656\n",
            "At step: 6916 training error: 0.30672291658096595\n",
            "At step: 6917 training error: 0.30907994852898185\n",
            "At step: 6918 training error: 0.3199963325026934\n",
            "At step: 6919 training error: 0.3270889144328141\n",
            "At step: 6920 training error: 0.3228513248359153\n",
            "At step: 6921 training error: 0.3401815758572735\n",
            "At step: 6922 training error: 0.3404574129024374\n",
            "At step: 6923 training error: 0.34353658920825586\n",
            "At step: 6924 training error: 0.3339630260787344\n",
            "At step: 6925 training error: 0.33549896577594235\n",
            "At step: 6926 training error: 0.33532249784215673\n",
            "At step: 6927 training error: 0.3348185658262246\n",
            "At step: 6928 training error: 0.3290877608840245\n",
            "At step: 6929 training error: 0.31796514144386406\n",
            "At step: 6930 training error: 0.31899827312440415\n",
            "At step: 6931 training error: 0.3148514587469354\n",
            "At step: 6932 training error: 0.30364412165390664\n",
            "At step: 6933 training error: 0.30222430066379735\n",
            "At step: 6934 training error: 0.2955687641084056\n",
            "At step: 6935 training error: 0.29539336522863774\n",
            "At step: 6936 training error: 0.29239069759691183\n",
            "At step: 6937 training error: 0.30125431311930106\n",
            "At step: 6938 training error: 0.2928148251670206\n",
            "At step: 6939 training error: 0.29542580549758446\n",
            "At step: 6940 training error: 0.2879938403808904\n",
            "At step: 6941 training error: 0.2936429581720103\n",
            "At step: 6942 training error: 0.2924985040975503\n",
            "At step: 6943 training error: 0.2901031498077387\n",
            "At step: 6944 training error: 0.2964990247956183\n",
            "At step: 6945 training error: 0.2958457588815123\n",
            "At step: 6946 training error: 0.29903832006769293\n",
            "At step: 6947 training error: 0.28939883144147527\n",
            "At step: 6948 training error: 0.2921963937447141\n",
            "At step: 6949 training error: 0.3040745657741451\n",
            "At step: 6950 training error: 0.30075652961670146\n",
            "At step: 6951 training error: 0.30780595190927\n",
            "At step: 6952 training error: 0.3014851818323466\n",
            "At step: 6953 training error: 0.3021890263214466\n",
            "At step: 6954 training error: 0.3086795090120048\n",
            "At step: 6955 training error: 0.31290223192170247\n",
            "At step: 6956 training error: 0.3122930520136584\n",
            "At step: 6957 training error: 0.2974264356829442\n",
            "At step: 6958 training error: 0.30957732089660944\n",
            "At step: 6959 training error: 0.30865249664731026\n",
            "At step: 6960 training error: 0.3086502716047789\n",
            "At step: 6961 training error: 0.2993673052375156\n",
            "At step: 6962 training error: 0.3140298978432799\n",
            "At step: 6963 training error: 0.32093160885929317\n",
            "At step: 6964 training error: 0.32175894076639117\n",
            "At step: 6965 training error: 0.3214030420541792\n",
            "At step: 6966 training error: 0.3153879760373418\n",
            "At step: 6967 training error: 0.3126402096555581\n",
            "At step: 6968 training error: 0.31521423408787985\n",
            "At step: 6969 training error: 0.3072122166497205\n",
            "At step: 6970 training error: 0.3020304220211446\n",
            "At step: 6971 training error: 0.2952701282119098\n",
            "At step: 6972 training error: 0.3022827256158692\n",
            "At step: 6973 training error: 0.31085350430094527\n",
            "At step: 6974 training error: 0.3139744734755297\n",
            "At step: 6975 training error: 0.32092470290987174\n",
            "At step: 6976 training error: 0.3248401403092438\n",
            "At step: 6977 training error: 0.3100506526264779\n",
            "At step: 6978 training error: 0.29906960621200146\n",
            "At step: 6979 training error: 0.2942119415555262\n",
            "At step: 6980 training error: 0.2948208801210112\n",
            "At step: 6981 training error: 0.29310337981019835\n",
            "At step: 6982 training error: 0.2815446551269999\n",
            "At step: 6983 training error: 0.28808338467678574\n",
            "At step: 6984 training error: 0.2835934670895685\n",
            "At step: 6985 training error: 0.29285097703604146\n",
            "At step: 6986 training error: 0.3068978450298281\n",
            "At step: 6987 training error: 0.3082543638973786\n",
            "At step: 6988 training error: 0.30049513392205285\n",
            "At step: 6989 training error: 0.30917562580788066\n",
            "At step: 6990 training error: 0.3084865684168338\n",
            "At step: 6991 training error: 0.3047788017567474\n",
            "At step: 6992 training error: 0.308356226884236\n",
            "At step: 6993 training error: 0.3041052698818072\n",
            "At step: 6994 training error: 0.310201717710644\n",
            "At step: 6995 training error: 0.29917731598405245\n",
            "At step: 6996 training error: 0.30311362750488136\n",
            "At step: 6997 training error: 0.29978528263664317\n",
            "At step: 6998 training error: 0.3037133410558914\n",
            "At step: 6999 training error: 0.30852249142999716\n",
            "At step: 7000 training error: 0.3110857435450067\n",
            "At step: 7001 training error: 0.3060833709126834\n",
            "At step: 7002 training error: 0.294438336564613\n",
            "At step: 7003 training error: 0.2976244338846029\n",
            "At step: 7004 training error: 0.30713339857273037\n",
            "At step: 7005 training error: 0.31200167236696574\n",
            "At step: 7006 training error: 0.31121151298321637\n",
            "At step: 7007 training error: 0.31663295170766753\n",
            "At step: 7008 training error: 0.3141663514113919\n",
            "At step: 7009 training error: 0.30519860970345447\n",
            "At step: 7010 training error: 0.3084041730987284\n",
            "At step: 7011 training error: 0.30425835332156614\n",
            "At step: 7012 training error: 0.3036923307187672\n",
            "At step: 7013 training error: 0.3042671350311976\n",
            "At step: 7014 training error: 0.2964131911370784\n",
            "At step: 7015 training error: 0.30517587208920394\n",
            "At step: 7016 training error: 0.3034489887831447\n",
            "At step: 7017 training error: 0.2988217627948326\n",
            "At step: 7018 training error: 0.3137710339838722\n",
            "At step: 7019 training error: 0.30471750441979306\n",
            "At step: 7020 training error: 0.3088625438347469\n",
            "At step: 7021 training error: 0.3091916853114777\n",
            "At step: 7022 training error: 0.307654411381845\n",
            "At step: 7023 training error: 0.2970960156207392\n",
            "At step: 7024 training error: 0.30284612000871464\n",
            "At step: 7025 training error: 0.3022370781302828\n",
            "At step: 7026 training error: 0.2930865033104099\n",
            "At step: 7027 training error: 0.309267439371974\n",
            "At step: 7028 training error: 0.3056742835083391\n",
            "At step: 7029 training error: 0.30403701956937784\n",
            "At step: 7030 training error: 0.30605279387830403\n",
            "At step: 7031 training error: 0.31754101946858676\n",
            "At step: 7032 training error: 0.31379463812507175\n",
            "At step: 7033 training error: 0.30494296616827093\n",
            "At step: 7034 training error: 0.30106106830381824\n",
            "At step: 7035 training error: 0.29813741626212686\n",
            "At step: 7036 training error: 0.3001003076681913\n",
            "At step: 7037 training error: 0.30084128145272737\n",
            "At step: 7038 training error: 0.29854189712240425\n",
            "At step: 7039 training error: 0.30669747855210205\n",
            "At step: 7040 training error: 0.31465435855629187\n",
            "At step: 7041 training error: 0.30806161112935493\n",
            "At step: 7042 training error: 0.30968194849392\n",
            "At step: 7043 training error: 0.30154158285127314\n",
            "At step: 7044 training error: 0.30162193102805746\n",
            "At step: 7045 training error: 0.29151541026653066\n",
            "At step: 7046 training error: 0.29306860663326767\n",
            "At step: 7047 training error: 0.2978237164499321\n",
            "At step: 7048 training error: 0.3047291853010049\n",
            "At step: 7049 training error: 0.2963426035632127\n",
            "At step: 7050 training error: 0.30928131753754573\n",
            "At step: 7051 training error: 0.30783424740216303\n",
            "At step: 7052 training error: 0.3052240030457096\n",
            "At step: 7053 training error: 0.2992658954423304\n",
            "At step: 7054 training error: 0.3065751569678707\n",
            "At step: 7055 training error: 0.3122462718560084\n",
            "At step: 7056 training error: 0.3166882256749477\n",
            "At step: 7057 training error: 0.307769570255199\n",
            "At step: 7058 training error: 0.31215430755891105\n",
            "At step: 7059 training error: 0.3081323155740636\n",
            "At step: 7060 training error: 0.3135516674725917\n",
            "At step: 7061 training error: 0.3110079995001632\n",
            "At step: 7062 training error: 0.3137475444619942\n",
            "At step: 7063 training error: 0.3056479046643664\n",
            "At step: 7064 training error: 0.30426452943060933\n",
            "At step: 7065 training error: 0.29998591280820786\n",
            "At step: 7066 training error: 0.301770064643887\n",
            "At step: 7067 training error: 0.29952417128907693\n",
            "At step: 7068 training error: 0.2939018326386192\n",
            "At step: 7069 training error: 0.2901991088459304\n",
            "At step: 7070 training error: 0.28691092674517177\n",
            "At step: 7071 training error: 0.2818079342804927\n",
            "At step: 7072 training error: 0.28966993697884996\n",
            "At step: 7073 training error: 0.30091745941034487\n",
            "At step: 7074 training error: 0.29953343310396946\n",
            "At step: 7075 training error: 0.30106122085317005\n",
            "At step: 7076 training error: 0.2905983717664127\n",
            "At step: 7077 training error: 0.2967697066395507\n",
            "At step: 7078 training error: 0.31231930970627914\n",
            "At step: 7079 training error: 0.30574674265857765\n",
            "At step: 7080 training error: 0.31078817486936106\n",
            "At step: 7081 training error: 0.3054328675051388\n",
            "At step: 7082 training error: 0.29295077327248853\n",
            "At step: 7083 training error: 0.2961791088592712\n",
            "At step: 7084 training error: 0.2960483735830397\n",
            "At step: 7085 training error: 0.2968910820607663\n",
            "At step: 7086 training error: 0.3019621978860919\n",
            "At step: 7087 training error: 0.30081275448717487\n",
            "At step: 7088 training error: 0.30145146050793575\n",
            "At step: 7089 training error: 0.2976923802037433\n",
            "At step: 7090 training error: 0.3050118681689512\n",
            "At step: 7091 training error: 0.3099520498202692\n",
            "At step: 7092 training error: 0.3085753696150479\n",
            "At step: 7093 training error: 0.30643050711846054\n",
            "At step: 7094 training error: 0.3026544772265807\n",
            "At step: 7095 training error: 0.31353387388670273\n",
            "At step: 7096 training error: 0.3210217263245392\n",
            "At step: 7097 training error: 0.3252443547764747\n",
            "At step: 7098 training error: 0.33212483496637274\n",
            "At step: 7099 training error: 0.3100939669947181\n",
            "At step: 7100 training error: 0.33055653461251455\n",
            "At step: 7101 training error: 0.31955143564491634\n",
            "At step: 7102 training error: 0.31044142330592484\n",
            "At step: 7103 training error: 0.3182376903611618\n",
            "At step: 7104 training error: 0.328818293368076\n",
            "At step: 7105 training error: 0.32583089825361006\n",
            "At step: 7106 training error: 0.31882771311255187\n",
            "At step: 7107 training error: 0.3191010983641948\n",
            "At step: 7108 training error: 0.31130594727719346\n",
            "At step: 7109 training error: 0.3096787526489229\n",
            "At step: 7110 training error: 0.30868648188585573\n",
            "At step: 7111 training error: 0.305520487903576\n",
            "At step: 7112 training error: 0.309850403695726\n",
            "At step: 7113 training error: 0.3163472319498341\n",
            "At step: 7114 training error: 0.3075378737894087\n",
            "At step: 7115 training error: 0.30873188473326263\n",
            "At step: 7116 training error: 0.3061591139151157\n",
            "At step: 7117 training error: 0.31490881861193276\n",
            "At step: 7118 training error: 0.3206720376783823\n",
            "At step: 7119 training error: 0.3148863183213191\n",
            "At step: 7120 training error: 0.3160499536529564\n",
            "At step: 7121 training error: 0.31539786177445517\n",
            "At step: 7122 training error: 0.30123530753138583\n",
            "At step: 7123 training error: 0.306961029532647\n",
            "At step: 7124 training error: 0.3170516481947035\n",
            "At step: 7125 training error: 0.3103920152697841\n",
            "At step: 7126 training error: 0.3042322792559558\n",
            "At step: 7127 training error: 0.30091013730378385\n",
            "At step: 7128 training error: 0.3083312885259716\n",
            "At step: 7129 training error: 0.30174088898618817\n",
            "At step: 7130 training error: 0.2979117945636921\n",
            "At step: 7131 training error: 0.30460437783352895\n",
            "At step: 7132 training error: 0.29807404192266646\n",
            "At step: 7133 training error: 0.3029938697736622\n",
            "At step: 7134 training error: 0.2973329493631079\n",
            "At step: 7135 training error: 0.3010451334265948\n",
            "At step: 7136 training error: 0.3065044191499757\n",
            "At step: 7137 training error: 0.30511280749046576\n",
            "At step: 7138 training error: 0.2902722587343186\n",
            "At step: 7139 training error: 0.2924933332981152\n",
            "At step: 7140 training error: 0.28623913532235057\n",
            "At step: 7141 training error: 0.2946098278384058\n",
            "At step: 7142 training error: 0.2848471003721063\n",
            "At step: 7143 training error: 0.2866564938017935\n",
            "At step: 7144 training error: 0.27782624488187946\n",
            "At step: 7145 training error: 0.2830822895704308\n",
            "At step: 7146 training error: 0.2822975586361761\n",
            "At step: 7147 training error: 0.28348920715495235\n",
            "At step: 7148 training error: 0.28262872041863973\n",
            "At step: 7149 training error: 0.293484420602891\n",
            "At step: 7150 training error: 0.29933198788850185\n",
            "At step: 7151 training error: 0.30661567607675716\n",
            "At step: 7152 training error: 0.3174953421234147\n",
            "At step: 7153 training error: 0.3204506698048208\n",
            "At step: 7154 training error: 0.31305367800032846\n",
            "At step: 7155 training error: 0.30841067522877647\n",
            "At step: 7156 training error: 0.3107899287692091\n",
            "At step: 7157 training error: 0.3047675288575615\n",
            "At step: 7158 training error: 0.3085698204769582\n",
            "At step: 7159 training error: 0.3082342308970389\n",
            "At step: 7160 training error: 0.31398639311921966\n",
            "At step: 7161 training error: 0.311781798752827\n",
            "At step: 7162 training error: 0.3286980399362633\n",
            "At step: 7163 training error: 0.3129982741136902\n",
            "At step: 7164 training error: 0.3173001353056742\n",
            "At step: 7165 training error: 0.31174019536383885\n",
            "At step: 7166 training error: 0.3119692751667511\n",
            "At step: 7167 training error: 0.32223018884426724\n",
            "At step: 7168 training error: 0.3253712210539908\n",
            "At step: 7169 training error: 0.3356565531958653\n",
            "At step: 7170 training error: 0.33016385186950686\n",
            "At step: 7171 training error: 0.344155273409755\n",
            "At step: 7172 training error: 0.3514838927332066\n",
            "At step: 7173 training error: 0.3436677469563086\n",
            "At step: 7174 training error: 0.33848532190598646\n",
            "At step: 7175 training error: 0.3381527535679935\n",
            "At step: 7176 training error: 0.33181330649303376\n",
            "At step: 7177 training error: 0.333660974308337\n",
            "At step: 7178 training error: 0.3337623445555434\n",
            "At step: 7179 training error: 0.3348297431502262\n",
            "At step: 7180 training error: 0.3355551778827723\n",
            "At step: 7181 training error: 0.3209331001503405\n",
            "At step: 7182 training error: 0.3174596692618426\n",
            "At step: 7183 training error: 0.31280294514904056\n",
            "At step: 7184 training error: 0.3158792794742485\n",
            "At step: 7185 training error: 0.32026030200302336\n",
            "At step: 7186 training error: 0.3230358814069936\n",
            "At step: 7187 training error: 0.33536835820802735\n",
            "At step: 7188 training error: 0.33051374855614457\n",
            "At step: 7189 training error: 0.3276610557365322\n",
            "At step: 7190 training error: 0.32928482277867605\n",
            "At step: 7191 training error: 0.3251974301590581\n",
            "At step: 7192 training error: 0.31976716607034733\n",
            "At step: 7193 training error: 0.3203098432366808\n",
            "At step: 7194 training error: 0.3134924664435182\n",
            "At step: 7195 training error: 0.32514089671081287\n",
            "At step: 7196 training error: 0.3320639544115168\n",
            "At step: 7197 training error: 0.3267462986633758\n",
            "At step: 7198 training error: 0.3268452673359423\n",
            "At step: 7199 training error: 0.321086222727469\n",
            "At step: 7200 training error: 0.3196920856451452\n",
            "At step: 7201 training error: 0.31316847039339696\n",
            "At step: 7202 training error: 0.31662331869401356\n",
            "At step: 7203 training error: 0.31642635787459933\n",
            "At step: 7204 training error: 0.3095105395279697\n",
            "At step: 7205 training error: 0.30719018857838015\n",
            "At step: 7206 training error: 0.3019820858795538\n",
            "At step: 7207 training error: 0.29341049004263786\n",
            "At step: 7208 training error: 0.30740775152914634\n",
            "At step: 7209 training error: 0.3068524133358429\n",
            "At step: 7210 training error: 0.31084101107462636\n",
            "At step: 7211 training error: 0.3254043480311411\n",
            "At step: 7212 training error: 0.3318086702942752\n",
            "At step: 7213 training error: 0.32642519427189787\n",
            "At step: 7214 training error: 0.3377161476623588\n",
            "At step: 7215 training error: 0.3492410977762153\n",
            "At step: 7216 training error: 0.3357348145125882\n",
            "At step: 7217 training error: 0.3435839983611838\n",
            "At step: 7218 training error: 0.3367316203427513\n",
            "At step: 7219 training error: 0.3375063926763686\n",
            "At step: 7220 training error: 0.344918112828252\n",
            "At step: 7221 training error: 0.3428445579107261\n",
            "At step: 7222 training error: 0.33840062241018704\n",
            "At step: 7223 training error: 0.33495158283247956\n",
            "At step: 7224 training error: 0.3262535145373688\n",
            "At step: 7225 training error: 0.3181327303046265\n",
            "At step: 7226 training error: 0.32732049525239093\n",
            "At step: 7227 training error: 0.3280968979790916\n",
            "At step: 7228 training error: 0.32736485884574473\n",
            "At step: 7229 training error: 0.31594568887800545\n",
            "At step: 7230 training error: 0.31666662170104054\n",
            "At step: 7231 training error: 0.3130206492869087\n",
            "At step: 7232 training error: 0.30813088058416754\n",
            "At step: 7233 training error: 0.30789383371804413\n",
            "At step: 7234 training error: 0.3150203610847847\n",
            "At step: 7235 training error: 0.3225336283288292\n",
            "At step: 7236 training error: 0.31657814046345173\n",
            "At step: 7237 training error: 0.31879020095155197\n",
            "At step: 7238 training error: 0.3131556744105342\n",
            "At step: 7239 training error: 0.31181055963199017\n",
            "At step: 7240 training error: 0.3105123578011495\n",
            "At step: 7241 training error: 0.3105466288265733\n",
            "At step: 7242 training error: 0.30565457389906325\n",
            "At step: 7243 training error: 0.3106128958512596\n",
            "At step: 7244 training error: 0.3170808377584519\n",
            "At step: 7245 training error: 0.3080924646632611\n",
            "At step: 7246 training error: 0.3174684567633308\n",
            "At step: 7247 training error: 0.32074596097297836\n",
            "At step: 7248 training error: 0.3370076837784452\n",
            "At step: 7249 training error: 0.3309082044911427\n",
            "At step: 7250 training error: 0.3381388164069609\n",
            "At step: 7251 training error: 0.33540840268170813\n",
            "At step: 7252 training error: 0.32203637912203126\n",
            "At step: 7253 training error: 0.33064833309653896\n",
            "At step: 7254 training error: 0.3315691264253304\n",
            "At step: 7255 training error: 0.3406266139580115\n",
            "At step: 7256 training error: 0.3469618096532162\n",
            "At step: 7257 training error: 0.34354173021106277\n",
            "At step: 7258 training error: 0.34803692961677035\n",
            "At step: 7259 training error: 0.34560066606038686\n",
            "At step: 7260 training error: 0.33464479550355863\n",
            "At step: 7261 training error: 0.3338459057508684\n",
            "At step: 7262 training error: 0.331238203770214\n",
            "At step: 7263 training error: 0.33081574544424414\n",
            "At step: 7264 training error: 0.31840739965817977\n",
            "At step: 7265 training error: 0.31517419691129606\n",
            "At step: 7266 training error: 0.32409409233857167\n",
            "At step: 7267 training error: 0.3263416673912433\n",
            "At step: 7268 training error: 0.3118359459705804\n",
            "At step: 7269 training error: 0.3099744968242143\n",
            "At step: 7270 training error: 0.30770656473377345\n",
            "At step: 7271 training error: 0.317133978846786\n",
            "At step: 7272 training error: 0.31855959020765146\n",
            "At step: 7273 training error: 0.33092879364188216\n",
            "At step: 7274 training error: 0.3199688255572599\n",
            "At step: 7275 training error: 0.32727570212207036\n",
            "At step: 7276 training error: 0.3226328326247136\n",
            "At step: 7277 training error: 0.31401853010035063\n",
            "At step: 7278 training error: 0.31601443096750803\n",
            "At step: 7279 training error: 0.3146502318162647\n",
            "At step: 7280 training error: 0.3201437089137331\n",
            "At step: 7281 training error: 0.31047892494091944\n",
            "At step: 7282 training error: 0.3041217711293564\n",
            "At step: 7283 training error: 0.3033480102607748\n",
            "At step: 7284 training error: 0.31671813757440287\n",
            "At step: 7285 training error: 0.31811289791728775\n",
            "At step: 7286 training error: 0.31258718849219913\n",
            "At step: 7287 training error: 0.3078503097397531\n",
            "At step: 7288 training error: 0.3005963365759681\n",
            "At step: 7289 training error: 0.2997883958848518\n",
            "At step: 7290 training error: 0.306089548248809\n",
            "At step: 7291 training error: 0.30531321174585696\n",
            "At step: 7292 training error: 0.30275153431391993\n",
            "At step: 7293 training error: 0.3258587322960791\n",
            "At step: 7294 training error: 0.32494320431158336\n",
            "At step: 7295 training error: 0.3235587667540164\n",
            "At step: 7296 training error: 0.3229887358043165\n",
            "At step: 7297 training error: 0.3167614622842455\n",
            "At step: 7298 training error: 0.31403695369672074\n",
            "At step: 7299 training error: 0.3084874022920502\n",
            "At step: 7300 training error: 0.3096905917013828\n",
            "At step: 7301 training error: 0.3067790854180028\n",
            "At step: 7302 training error: 0.3081803090332231\n",
            "At step: 7303 training error: 0.2934652320026901\n",
            "At step: 7304 training error: 0.29292591852735944\n",
            "At step: 7305 training error: 0.3029326544860368\n",
            "At step: 7306 training error: 0.30566305062340093\n",
            "At step: 7307 training error: 0.3135006571538803\n",
            "At step: 7308 training error: 0.3001291709911399\n",
            "At step: 7309 training error: 0.29191392771610114\n",
            "At step: 7310 training error: 0.2878019321818122\n",
            "At step: 7311 training error: 0.28656316357533335\n",
            "At step: 7312 training error: 0.2888759287929971\n",
            "At step: 7313 training error: 0.284318328778201\n",
            "At step: 7314 training error: 0.2890045610696374\n",
            "At step: 7315 training error: 0.28459113203190856\n",
            "At step: 7316 training error: 0.27303899173883855\n",
            "At step: 7317 training error: 0.28431483013266745\n",
            "At step: 7318 training error: 0.2881292490227887\n",
            "At step: 7319 training error: 0.2907274357036511\n",
            "At step: 7320 training error: 0.28964772524213506\n",
            "At step: 7321 training error: 0.2913235749799664\n",
            "At step: 7322 training error: 0.2966577126075602\n",
            "At step: 7323 training error: 0.29881247954749063\n",
            "At step: 7324 training error: 0.3014977317602104\n",
            "At step: 7325 training error: 0.3003795241972821\n",
            "At step: 7326 training error: 0.3162077148607426\n",
            "At step: 7327 training error: 0.3197503127199556\n",
            "At step: 7328 training error: 0.32836744039729165\n",
            "At step: 7329 training error: 0.33098409791605443\n",
            "At step: 7330 training error: 0.3251276112386919\n",
            "At step: 7331 training error: 0.3188259970475863\n",
            "At step: 7332 training error: 0.31346548289035475\n",
            "At step: 7333 training error: 0.3219540128180442\n",
            "At step: 7334 training error: 0.3212721852608973\n",
            "At step: 7335 training error: 0.319466640487029\n",
            "At step: 7336 training error: 0.30753073652337526\n",
            "At step: 7337 training error: 0.3081828107334569\n",
            "At step: 7338 training error: 0.3073496375342843\n",
            "At step: 7339 training error: 0.307441873514892\n",
            "At step: 7340 training error: 0.2965204001008225\n",
            "At step: 7341 training error: 0.3011701546319557\n",
            "At step: 7342 training error: 0.31708021214134546\n",
            "At step: 7343 training error: 0.3116024492340931\n",
            "At step: 7344 training error: 0.3221491028029361\n",
            "At step: 7345 training error: 0.3212198428732229\n",
            "At step: 7346 training error: 0.31650743923051045\n",
            "At step: 7347 training error: 0.3147892620959582\n",
            "At step: 7348 training error: 0.30479049520501134\n",
            "At step: 7349 training error: 0.31516331798496555\n",
            "At step: 7350 training error: 0.3122408987554315\n",
            "At step: 7351 training error: 0.3024876635749942\n",
            "At step: 7352 training error: 0.3017549079722346\n",
            "At step: 7353 training error: 0.30742600369464024\n",
            "At step: 7354 training error: 0.30550209589252353\n",
            "At step: 7355 training error: 0.31842421076437677\n",
            "At step: 7356 training error: 0.325195216073332\n",
            "At step: 7357 training error: 0.32538499150306405\n",
            "At step: 7358 training error: 0.3249297129761972\n",
            "At step: 7359 training error: 0.3299051685101809\n",
            "At step: 7360 training error: 0.3403916568282994\n",
            "At step: 7361 training error: 0.3361073307643871\n",
            "At step: 7362 training error: 0.3325106228638233\n",
            "At step: 7363 training error: 0.33694009132720554\n",
            "At step: 7364 training error: 0.3343502792460875\n",
            "At step: 7365 training error: 0.32819171896843685\n",
            "At step: 7366 training error: 0.329254853176162\n",
            "At step: 7367 training error: 0.3380605507145313\n",
            "At step: 7368 training error: 0.3286825563086683\n",
            "At step: 7369 training error: 0.3325684023148898\n",
            "At step: 7370 training error: 0.34231222262841576\n",
            "At step: 7371 training error: 0.3318517874711615\n",
            "At step: 7372 training error: 0.3202988916380617\n",
            "At step: 7373 training error: 0.33942071979819577\n",
            "At step: 7374 training error: 0.3282838750334342\n",
            "At step: 7375 training error: 0.3184268156900177\n",
            "At step: 7376 training error: 0.325355450209574\n",
            "At step: 7377 training error: 0.3254600352980359\n",
            "At step: 7378 training error: 0.31288805568005695\n",
            "At step: 7379 training error: 0.30451137275250634\n",
            "At step: 7380 training error: 0.31417562235354934\n",
            "At step: 7381 training error: 0.30709054196416113\n",
            "At step: 7382 training error: 0.3035563898539107\n",
            "At step: 7383 training error: 0.3016918407585606\n",
            "At step: 7384 training error: 0.30797900320484406\n",
            "At step: 7385 training error: 0.31153628066107225\n",
            "At step: 7386 training error: 0.3085838803768593\n",
            "At step: 7387 training error: 0.31536746214611094\n",
            "At step: 7388 training error: 0.328688344300294\n",
            "At step: 7389 training error: 0.3186158303714124\n",
            "At step: 7390 training error: 0.3236995863914445\n",
            "At step: 7391 training error: 0.3196415473388565\n",
            "At step: 7392 training error: 0.31115067077605074\n",
            "At step: 7393 training error: 0.31823637155429824\n",
            "At step: 7394 training error: 0.32511495374768706\n",
            "At step: 7395 training error: 0.31425691569616826\n",
            "At step: 7396 training error: 0.3141708544132366\n",
            "At step: 7397 training error: 0.31579851333763\n",
            "At step: 7398 training error: 0.3167426162587381\n",
            "At step: 7399 training error: 0.3101735552559852\n",
            "At step: 7400 training error: 0.3005802550543329\n",
            "At step: 7401 training error: 0.3053646033655778\n",
            "At step: 7402 training error: 0.3171046834048681\n",
            "At step: 7403 training error: 0.32529569816241904\n",
            "At step: 7404 training error: 0.32267626593889775\n",
            "At step: 7405 training error: 0.30926837855191225\n",
            "At step: 7406 training error: 0.3054504493673767\n",
            "At step: 7407 training error: 0.30066711775952987\n",
            "At step: 7408 training error: 0.3072119691879598\n",
            "At step: 7409 training error: 0.3085520611170979\n",
            "At step: 7410 training error: 0.31603323952053075\n",
            "At step: 7411 training error: 0.31019923731390725\n",
            "At step: 7412 training error: 0.3089856667282406\n",
            "At step: 7413 training error: 0.3025501968701075\n",
            "At step: 7414 training error: 0.29989480280127256\n",
            "At step: 7415 training error: 0.30232181691585147\n",
            "At step: 7416 training error: 0.2974080842153264\n",
            "At step: 7417 training error: 0.30146605966135964\n",
            "At step: 7418 training error: 0.30533791348930567\n",
            "At step: 7419 training error: 0.30652697589512495\n",
            "At step: 7420 training error: 0.30443992916238916\n",
            "At step: 7421 training error: 0.30887809042554404\n",
            "At step: 7422 training error: 0.31028124615892605\n",
            "At step: 7423 training error: 0.3085332030459049\n",
            "At step: 7424 training error: 0.31457720370098474\n",
            "At step: 7425 training error: 0.31496568831636224\n",
            "At step: 7426 training error: 0.311029723767289\n",
            "At step: 7427 training error: 0.30627124564093966\n",
            "At step: 7428 training error: 0.3095420363993123\n",
            "At step: 7429 training error: 0.303199772183056\n",
            "At step: 7430 training error: 0.31338589048940935\n",
            "At step: 7431 training error: 0.3187235371956485\n",
            "At step: 7432 training error: 0.3324032763458848\n",
            "At step: 7433 training error: 0.33012311977543946\n",
            "At step: 7434 training error: 0.31602240203529075\n",
            "At step: 7435 training error: 0.32638861536789776\n",
            "At step: 7436 training error: 0.31911498434616736\n",
            "At step: 7437 training error: 0.32090974365469704\n",
            "At step: 7438 training error: 0.32785545959993034\n",
            "At step: 7439 training error: 0.3267260313980594\n",
            "At step: 7440 training error: 0.3195006694212147\n",
            "At step: 7441 training error: 0.31088685793202536\n",
            "At step: 7442 training error: 0.3186670356129779\n",
            "At step: 7443 training error: 0.3082417537178773\n",
            "At step: 7444 training error: 0.3211228473425967\n",
            "At step: 7445 training error: 0.3356948290662769\n",
            "At step: 7446 training error: 0.33634628961617025\n",
            "At step: 7447 training error: 0.32957779217694705\n",
            "At step: 7448 training error: 0.3242075897077785\n",
            "At step: 7449 training error: 0.3242711364117987\n",
            "At step: 7450 training error: 0.3274265143055843\n",
            "At step: 7451 training error: 0.3166721212779784\n",
            "At step: 7452 training error: 0.315669987705583\n",
            "At step: 7453 training error: 0.3161106724255848\n",
            "At step: 7454 training error: 0.3185894467503032\n",
            "At step: 7455 training error: 0.31738555857230866\n",
            "At step: 7456 training error: 0.29723287823341693\n",
            "At step: 7457 training error: 0.2986216025086174\n",
            "At step: 7458 training error: 0.2973863622503088\n",
            "At step: 7459 training error: 0.30645266472121513\n",
            "At step: 7460 training error: 0.3067720249702039\n",
            "At step: 7461 training error: 0.32179887576928234\n",
            "At step: 7462 training error: 0.3220596320765168\n",
            "At step: 7463 training error: 0.311574998342587\n",
            "At step: 7464 training error: 0.3156259320575459\n",
            "At step: 7465 training error: 0.31417693109731704\n",
            "At step: 7466 training error: 0.30977219878440243\n",
            "At step: 7467 training error: 0.30555292846656934\n",
            "At step: 7468 training error: 0.3037486252920856\n",
            "At step: 7469 training error: 0.31135818255914777\n",
            "At step: 7470 training error: 0.30846164572874596\n",
            "At step: 7471 training error: 0.3199871094527538\n",
            "At step: 7472 training error: 0.33452312782853694\n",
            "At step: 7473 training error: 0.3296063854322901\n",
            "At step: 7474 training error: 0.3312268320580822\n",
            "At step: 7475 training error: 0.3213092505313777\n",
            "At step: 7476 training error: 0.3169399110620705\n",
            "At step: 7477 training error: 0.31338461780504934\n",
            "At step: 7478 training error: 0.30927320399017694\n",
            "At step: 7479 training error: 0.3112533796423356\n",
            "At step: 7480 training error: 0.31550396594824515\n",
            "At step: 7481 training error: 0.32820685472916994\n",
            "At step: 7482 training error: 0.32367632741621677\n",
            "At step: 7483 training error: 0.3181358535763725\n",
            "At step: 7484 training error: 0.30506251997118694\n",
            "At step: 7485 training error: 0.30399191288550576\n",
            "At step: 7486 training error: 0.29451521131629416\n",
            "At step: 7487 training error: 0.29534617501500415\n",
            "At step: 7488 training error: 0.2924382694667676\n",
            "At step: 7489 training error: 0.2851655128997918\n",
            "At step: 7490 training error: 0.28134472589934445\n",
            "At step: 7491 training error: 0.2738460515132628\n",
            "At step: 7492 training error: 0.26934690171061704\n",
            "At step: 7493 training error: 0.2712990130643198\n",
            "At step: 7494 training error: 0.27409672825222786\n",
            "At step: 7495 training error: 0.2691918854668949\n",
            "At step: 7496 training error: 0.2789162497565252\n",
            "At step: 7497 training error: 0.2806754995759982\n",
            "At step: 7498 training error: 0.28342396375205103\n",
            "At step: 7499 training error: 0.2940128436706217\n",
            "At step: 7500 training error: 0.3090600603477612\n",
            "At step: 7501 training error: 0.3118486503737979\n",
            "At step: 7502 training error: 0.3055858695941405\n",
            "At step: 7503 training error: 0.31076542439367316\n",
            "At step: 7504 training error: 0.3176331838318573\n",
            "At step: 7505 training error: 0.3357453218145735\n",
            "At step: 7506 training error: 0.3383037967998964\n",
            "At step: 7507 training error: 0.3423221285511719\n",
            "At step: 7508 training error: 0.3521178925979598\n",
            "At step: 7509 training error: 0.34840024004524045\n",
            "At step: 7510 training error: 0.34673687608590303\n",
            "At step: 7511 training error: 0.33930458396741187\n",
            "At step: 7512 training error: 0.3363444482905784\n",
            "At step: 7513 training error: 0.3307220544019862\n",
            "At step: 7514 training error: 0.3320836505432262\n",
            "At step: 7515 training error: 0.3241844185449423\n",
            "At step: 7516 training error: 0.320856829528355\n",
            "At step: 7517 training error: 0.3246987785926131\n",
            "At step: 7518 training error: 0.3334122313981987\n",
            "At step: 7519 training error: 0.3357849826671245\n",
            "At step: 7520 training error: 0.3278827954785544\n",
            "At step: 7521 training error: 0.3260198577644791\n",
            "At step: 7522 training error: 0.32305120150888134\n",
            "At step: 7523 training error: 0.31789889412698896\n",
            "At step: 7524 training error: 0.3357796611417849\n",
            "At step: 7525 training error: 0.3360863909237439\n",
            "At step: 7526 training error: 0.33069746801483213\n",
            "At step: 7527 training error: 0.3190201171479661\n",
            "At step: 7528 training error: 0.3106535935371887\n",
            "At step: 7529 training error: 0.3061250717598105\n",
            "At step: 7530 training error: 0.31162292947748393\n",
            "At step: 7531 training error: 0.3034854796689258\n",
            "At step: 7532 training error: 0.2943609903858041\n",
            "At step: 7533 training error: 0.2898686222468282\n",
            "At step: 7534 training error: 0.2900617504960856\n",
            "At step: 7535 training error: 0.29137364143319444\n",
            "At step: 7536 training error: 0.2987457528266305\n",
            "At step: 7537 training error: 0.29501087911918766\n",
            "At step: 7538 training error: 0.29400348586035197\n",
            "At step: 7539 training error: 0.29366034231280636\n",
            "At step: 7540 training error: 0.29138840245473047\n",
            "At step: 7541 training error: 0.294707647089641\n",
            "At step: 7542 training error: 0.285805535677069\n",
            "At step: 7543 training error: 0.2933799307693194\n",
            "At step: 7544 training error: 0.2875382527089997\n",
            "At step: 7545 training error: 0.2988253847425404\n",
            "At step: 7546 training error: 0.30999880965887505\n",
            "At step: 7547 training error: 0.3238626774322668\n",
            "At step: 7548 training error: 0.33754723599441555\n",
            "At step: 7549 training error: 0.33407488609707353\n",
            "At step: 7550 training error: 0.32533517209364715\n",
            "At step: 7551 training error: 0.3203739801210207\n",
            "At step: 7552 training error: 0.3169169641387477\n",
            "At step: 7553 training error: 0.3138152434844213\n",
            "At step: 7554 training error: 0.3102274266774963\n",
            "At step: 7555 training error: 0.3059535938809239\n",
            "At step: 7556 training error: 0.30329819062604146\n",
            "At step: 7557 training error: 0.3277896105167687\n",
            "At step: 7558 training error: 0.3253800301707895\n",
            "At step: 7559 training error: 0.32400791981401916\n",
            "At step: 7560 training error: 0.32014526399206794\n",
            "At step: 7561 training error: 0.31057745118168323\n",
            "At step: 7562 training error: 0.3041262573175051\n",
            "At step: 7563 training error: 0.3000609524546688\n",
            "At step: 7564 training error: 0.29861715773707165\n",
            "At step: 7565 training error: 0.28753728158407105\n",
            "At step: 7566 training error: 0.286127551936423\n",
            "At step: 7567 training error: 0.2836966657983557\n",
            "At step: 7568 training error: 0.28296818634571985\n",
            "At step: 7569 training error: 0.2994892421334753\n",
            "At step: 7570 training error: 0.2955086394052875\n",
            "At step: 7571 training error: 0.29191509870888144\n",
            "At step: 7572 training error: 0.28561499661930173\n",
            "At step: 7573 training error: 0.3004838133353364\n",
            "At step: 7574 training error: 0.28976061521747365\n",
            "At step: 7575 training error: 0.2841355499847726\n",
            "At step: 7576 training error: 0.30372891759514137\n",
            "At step: 7577 training error: 0.2941077477468927\n",
            "At step: 7578 training error: 0.29225916582303274\n",
            "At step: 7579 training error: 0.2868368712945786\n",
            "At step: 7580 training error: 0.2809950093068623\n",
            "At step: 7581 training error: 0.2852204617798309\n",
            "At step: 7582 training error: 0.28290036026839516\n",
            "At step: 7583 training error: 0.2807005285266256\n",
            "At step: 7584 training error: 0.28381857022744145\n",
            "At step: 7585 training error: 0.28117318708434946\n",
            "At step: 7586 training error: 0.2912051331723001\n",
            "At step: 7587 training error: 0.3071253110730144\n",
            "At step: 7588 training error: 0.2983335774126672\n",
            "At step: 7589 training error: 0.292659861753191\n",
            "At step: 7590 training error: 0.30251349530294325\n",
            "At step: 7591 training error: 0.30358478865083316\n",
            "At step: 7592 training error: 0.2983698527621783\n",
            "At step: 7593 training error: 0.29292078579277203\n",
            "At step: 7594 training error: 0.28559135415500153\n",
            "At step: 7595 training error: 0.2748320449900965\n",
            "At step: 7596 training error: 0.27733977965733386\n",
            "At step: 7597 training error: 0.2710718574872438\n",
            "At step: 7598 training error: 0.27414763228845684\n",
            "At step: 7599 training error: 0.26763985647465893\n",
            "At step: 7600 training error: 0.2691635023992738\n",
            "At step: 7601 training error: 0.2625897219957666\n",
            "At step: 7602 training error: 0.25805853161994574\n",
            "At step: 7603 training error: 0.26949213404750977\n",
            "At step: 7604 training error: 0.2720674466864735\n",
            "At step: 7605 training error: 0.2735988815648721\n",
            "At step: 7606 training error: 0.2751509981189855\n",
            "At step: 7607 training error: 0.28009055698725044\n",
            "At step: 7608 training error: 0.28863212148227446\n",
            "At step: 7609 training error: 0.292366049800271\n",
            "At step: 7610 training error: 0.2925869851486333\n",
            "At step: 7611 training error: 0.2888438751264579\n",
            "At step: 7612 training error: 0.29515890421929775\n",
            "At step: 7613 training error: 0.29602002788299414\n",
            "At step: 7614 training error: 0.30146774539385857\n",
            "At step: 7615 training error: 0.29579383896365286\n",
            "At step: 7616 training error: 0.2971924644158112\n",
            "At step: 7617 training error: 0.31093047618938235\n",
            "At step: 7618 training error: 0.30845794480917366\n",
            "At step: 7619 training error: 0.3165613022984857\n",
            "At step: 7620 training error: 0.32237064923399084\n",
            "At step: 7621 training error: 0.32534085466879803\n",
            "At step: 7622 training error: 0.3261240027889554\n",
            "At step: 7623 training error: 0.3256354382385641\n",
            "At step: 7624 training error: 0.3267529187003447\n",
            "At step: 7625 training error: 0.3176274931086467\n",
            "At step: 7626 training error: 0.3131212946727262\n",
            "At step: 7627 training error: 0.31183886279180195\n",
            "At step: 7628 training error: 0.3171546650924887\n",
            "At step: 7629 training error: 0.31720388038058434\n",
            "At step: 7630 training error: 0.3130048162595194\n",
            "At step: 7631 training error: 0.31127262760605523\n",
            "At step: 7632 training error: 0.31421556874953727\n",
            "At step: 7633 training error: 0.3252367880408902\n",
            "At step: 7634 training error: 0.327013557893776\n",
            "At step: 7635 training error: 0.3331338040547916\n",
            "At step: 7636 training error: 0.33283154941741494\n",
            "At step: 7637 training error: 0.33487193857527375\n",
            "At step: 7638 training error: 0.3255863736182658\n",
            "At step: 7639 training error: 0.32389888669667893\n",
            "At step: 7640 training error: 0.3261653971471742\n",
            "At step: 7641 training error: 0.33242633005829425\n",
            "At step: 7642 training error: 0.33472037721231485\n",
            "At step: 7643 training error: 0.3366844420480942\n",
            "At step: 7644 training error: 0.33035385090653213\n",
            "At step: 7645 training error: 0.3339802003363052\n",
            "At step: 7646 training error: 0.32007273283249216\n",
            "At step: 7647 training error: 0.3248269327549391\n",
            "At step: 7648 training error: 0.3168115610296712\n",
            "At step: 7649 training error: 0.3191454335460914\n",
            "At step: 7650 training error: 0.3182244581344524\n",
            "At step: 7651 training error: 0.3143121320976081\n",
            "At step: 7652 training error: 0.3122516906029074\n",
            "At step: 7653 training error: 0.31273745115752205\n",
            "At step: 7654 training error: 0.3253320099452401\n",
            "At step: 7655 training error: 0.3193317125518095\n",
            "At step: 7656 training error: 0.3100470485864316\n",
            "At step: 7657 training error: 0.3087979969991467\n",
            "At step: 7658 training error: 0.31822112884750214\n",
            "At step: 7659 training error: 0.30665637309732435\n",
            "At step: 7660 training error: 0.301636619405622\n",
            "At step: 7661 training error: 0.29473125630260405\n",
            "At step: 7662 training error: 0.29642872239090434\n",
            "At step: 7663 training error: 0.2930558611543711\n",
            "At step: 7664 training error: 0.29602849394357916\n",
            "At step: 7665 training error: 0.29871140994849354\n",
            "At step: 7666 training error: 0.297826689830786\n",
            "At step: 7667 training error: 0.2953229766354246\n",
            "At step: 7668 training error: 0.3075295891943991\n",
            "At step: 7669 training error: 0.3130883603089895\n",
            "At step: 7670 training error: 0.31859858907757255\n",
            "At step: 7671 training error: 0.3303651247364995\n",
            "At step: 7672 training error: 0.32217215314553904\n",
            "At step: 7673 training error: 0.3211383013850858\n",
            "At step: 7674 training error: 0.31520694950009404\n",
            "At step: 7675 training error: 0.31403053737127773\n",
            "At step: 7676 training error: 0.3121018144392899\n",
            "At step: 7677 training error: 0.30930474685988585\n",
            "At step: 7678 training error: 0.3076940897598527\n",
            "At step: 7679 training error: 0.29640664970517255\n",
            "At step: 7680 training error: 0.2964565583307138\n",
            "At step: 7681 training error: 0.2995880256624091\n",
            "At step: 7682 training error: 0.2957417589272482\n",
            "At step: 7683 training error: 0.29601189757338514\n",
            "At step: 7684 training error: 0.28648425665355426\n",
            "At step: 7685 training error: 0.2834217370415447\n",
            "At step: 7686 training error: 0.27884705734722237\n",
            "At step: 7687 training error: 0.29478897539410154\n",
            "At step: 7688 training error: 0.2968283325017137\n",
            "At step: 7689 training error: 0.30150201596844073\n",
            "At step: 7690 training error: 0.2934258572323275\n",
            "At step: 7691 training error: 0.2809294910746123\n",
            "At step: 7692 training error: 0.2905151009095297\n",
            "At step: 7693 training error: 0.29707512544703585\n",
            "At step: 7694 training error: 0.2885807820816214\n",
            "At step: 7695 training error: 0.2844714559887535\n",
            "At step: 7696 training error: 0.294509591850655\n",
            "At step: 7697 training error: 0.29290854459178284\n",
            "At step: 7698 training error: 0.2859304801705052\n",
            "At step: 7699 training error: 0.2870259084979165\n",
            "At step: 7700 training error: 0.28616041691511596\n",
            "At step: 7701 training error: 0.28760723870622235\n",
            "At step: 7702 training error: 0.29522827434041987\n",
            "At step: 7703 training error: 0.2929071040392355\n",
            "At step: 7704 training error: 0.2903489594577026\n",
            "At step: 7705 training error: 0.2876558852947916\n",
            "At step: 7706 training error: 0.2879629852735459\n",
            "At step: 7707 training error: 0.2971097120254482\n",
            "At step: 7708 training error: 0.29069975522880326\n",
            "At step: 7709 training error: 0.2917529804810696\n",
            "At step: 7710 training error: 0.2921291876738662\n",
            "At step: 7711 training error: 0.2936240904760531\n",
            "At step: 7712 training error: 0.29700671143650387\n",
            "At step: 7713 training error: 0.2973356184669365\n",
            "At step: 7714 training error: 0.2935551393508719\n",
            "At step: 7715 training error: 0.30017857306006906\n",
            "At step: 7716 training error: 0.30393105549044097\n",
            "At step: 7717 training error: 0.316390383707746\n",
            "At step: 7718 training error: 0.31165979926121135\n",
            "At step: 7719 training error: 0.30486595924439897\n",
            "At step: 7720 training error: 0.29399606970934017\n",
            "At step: 7721 training error: 0.29343769316788837\n",
            "At step: 7722 training error: 0.28592169305685206\n",
            "At step: 7723 training error: 0.286846369500715\n",
            "At step: 7724 training error: 0.2996177707475301\n",
            "At step: 7725 training error: 0.29536018882190446\n",
            "At step: 7726 training error: 0.2979414606638628\n",
            "At step: 7727 training error: 0.28820798250599183\n",
            "At step: 7728 training error: 0.29470740608073287\n",
            "At step: 7729 training error: 0.29095412444487273\n",
            "At step: 7730 training error: 0.29970957669299864\n",
            "At step: 7731 training error: 0.30152790551631686\n",
            "At step: 7732 training error: 0.2988611109527419\n",
            "At step: 7733 training error: 0.3049010204884234\n",
            "At step: 7734 training error: 0.3091674984974813\n",
            "At step: 7735 training error: 0.314787023797656\n",
            "At step: 7736 training error: 0.31425356067263005\n",
            "At step: 7737 training error: 0.3096781501760062\n",
            "At step: 7738 training error: 0.3076259936958083\n",
            "At step: 7739 training error: 0.2992926238093526\n",
            "At step: 7740 training error: 0.2870134485507654\n",
            "At step: 7741 training error: 0.2876467636579695\n",
            "At step: 7742 training error: 0.27614948084426666\n",
            "At step: 7743 training error: 0.2800714715583705\n",
            "At step: 7744 training error: 0.2805332252058866\n",
            "At step: 7745 training error: 0.289815929808764\n",
            "At step: 7746 training error: 0.29135828218137216\n",
            "At step: 7747 training error: 0.28734955669430684\n",
            "At step: 7748 training error: 0.2883830377799152\n",
            "At step: 7749 training error: 0.2807123549307579\n",
            "At step: 7750 training error: 0.28239862031936036\n",
            "At step: 7751 training error: 0.28102940917885066\n",
            "At step: 7752 training error: 0.295547265618512\n",
            "At step: 7753 training error: 0.2985466741510887\n",
            "At step: 7754 training error: 0.3044084925929216\n",
            "At step: 7755 training error: 0.301775652597172\n",
            "At step: 7756 training error: 0.30589919169561125\n",
            "At step: 7757 training error: 0.31043367251326387\n",
            "At step: 7758 training error: 0.300752195866255\n",
            "At step: 7759 training error: 0.303992478517628\n",
            "At step: 7760 training error: 0.3076534542601447\n",
            "At step: 7761 training error: 0.3016319548248294\n",
            "At step: 7762 training error: 0.30246395586384206\n",
            "At step: 7763 training error: 0.30644116918484365\n",
            "At step: 7764 training error: 0.29696546894891596\n",
            "At step: 7765 training error: 0.29577275070878417\n",
            "At step: 7766 training error: 0.2989178226735366\n",
            "At step: 7767 training error: 0.3106644891151938\n",
            "At step: 7768 training error: 0.3078003979744749\n",
            "At step: 7769 training error: 0.29871349081105947\n",
            "At step: 7770 training error: 0.2921635396401873\n",
            "At step: 7771 training error: 0.29974988143121356\n",
            "At step: 7772 training error: 0.295611762505892\n",
            "At step: 7773 training error: 0.29353625211962076\n",
            "At step: 7774 training error: 0.2883148594047877\n",
            "At step: 7775 training error: 0.2862042812421536\n",
            "At step: 7776 training error: 0.28463735668761936\n",
            "At step: 7777 training error: 0.28187517964480563\n",
            "At step: 7778 training error: 0.29089687576487955\n",
            "At step: 7779 training error: 0.28773008634144953\n",
            "At step: 7780 training error: 0.3045899593857039\n",
            "At step: 7781 training error: 0.3206867784338334\n",
            "At step: 7782 training error: 0.3225674501739816\n",
            "At step: 7783 training error: 0.3260170041401108\n",
            "At step: 7784 training error: 0.3288474213056177\n",
            "At step: 7785 training error: 0.32069722118054056\n",
            "At step: 7786 training error: 0.3203437623922762\n",
            "At step: 7787 training error: 0.3236135745890599\n",
            "At step: 7788 training error: 0.3097009379123875\n",
            "At step: 7789 training error: 0.30361723121177225\n",
            "At step: 7790 training error: 0.29777899424618326\n",
            "At step: 7791 training error: 0.30001076068580224\n",
            "At step: 7792 training error: 0.30558605657076515\n",
            "At step: 7793 training error: 0.31502749435645877\n",
            "At step: 7794 training error: 0.3142992577756338\n",
            "At step: 7795 training error: 0.3131860096498733\n",
            "At step: 7796 training error: 0.30661264286989404\n",
            "At step: 7797 training error: 0.3067506318678702\n",
            "At step: 7798 training error: 0.2991300980442536\n",
            "At step: 7799 training error: 0.2993740648113729\n",
            "At step: 7800 training error: 0.29877985412986746\n",
            "At step: 7801 training error: 0.31704806373223315\n",
            "At step: 7802 training error: 0.3137540439269702\n",
            "At step: 7803 training error: 0.32000897315550836\n",
            "At step: 7804 training error: 0.31878383812026856\n",
            "At step: 7805 training error: 0.32050738211629637\n",
            "At step: 7806 training error: 0.3166890110113843\n",
            "At step: 7807 training error: 0.3087378214390766\n",
            "At step: 7808 training error: 0.3019514686169243\n",
            "At step: 7809 training error: 0.3047574735310694\n",
            "At step: 7810 training error: 0.30472124100798303\n",
            "At step: 7811 training error: 0.3123640562017902\n",
            "At step: 7812 training error: 0.3025362949125894\n",
            "At step: 7813 training error: 0.305262612074208\n",
            "At step: 7814 training error: 0.30948798705550284\n",
            "At step: 7815 training error: 0.3075427184600526\n",
            "At step: 7816 training error: 0.30500298114965646\n",
            "At step: 7817 training error: 0.3088190065969165\n",
            "At step: 7818 training error: 0.3162569243643598\n",
            "At step: 7819 training error: 0.3170067345603623\n",
            "At step: 7820 training error: 0.32318295751199366\n",
            "At step: 7821 training error: 0.3255044933891555\n",
            "At step: 7822 training error: 0.32453739334030257\n",
            "At step: 7823 training error: 0.32378995572400626\n",
            "At step: 7824 training error: 0.3142336113192215\n",
            "At step: 7825 training error: 0.3165089423259156\n",
            "At step: 7826 training error: 0.3233121183538995\n",
            "At step: 7827 training error: 0.31981255082606125\n",
            "At step: 7828 training error: 0.3280008802559644\n",
            "At step: 7829 training error: 0.3285725663206528\n",
            "At step: 7830 training error: 0.33284548218749477\n",
            "At step: 7831 training error: 0.33264182419798843\n",
            "At step: 7832 training error: 0.339893215860546\n",
            "At step: 7833 training error: 0.34489230200277515\n",
            "At step: 7834 training error: 0.3404813490053803\n",
            "At step: 7835 training error: 0.34190975415216446\n",
            "At step: 7836 training error: 0.33447566828286723\n",
            "At step: 7837 training error: 0.3389101603498263\n",
            "At step: 7838 training error: 0.3325754399996573\n",
            "At step: 7839 training error: 0.3243821426706276\n",
            "At step: 7840 training error: 0.3191987841439186\n",
            "At step: 7841 training error: 0.31924423931705065\n",
            "At step: 7842 training error: 0.3293180934196628\n",
            "At step: 7843 training error: 0.3216973733039917\n",
            "At step: 7844 training error: 0.32782101810891345\n",
            "At step: 7845 training error: 0.31564663006465843\n",
            "At step: 7846 training error: 0.3093775003275051\n",
            "At step: 7847 training error: 0.3051955714239779\n",
            "At step: 7848 training error: 0.3084632517952875\n",
            "At step: 7849 training error: 0.3132512776416223\n",
            "At step: 7850 training error: 0.30594670953011827\n",
            "At step: 7851 training error: 0.30301090348545084\n",
            "At step: 7852 training error: 0.3051102599644437\n",
            "At step: 7853 training error: 0.3117574420618491\n",
            "At step: 7854 training error: 0.31671256672921577\n",
            "At step: 7855 training error: 0.3108794916279145\n",
            "At step: 7856 training error: 0.3022811953781723\n",
            "At step: 7857 training error: 0.3006027398501505\n",
            "At step: 7858 training error: 0.30805732473335135\n",
            "At step: 7859 training error: 0.3031560774024416\n",
            "At step: 7860 training error: 0.31234994000948685\n",
            "At step: 7861 training error: 0.31108786124805277\n",
            "At step: 7862 training error: 0.30123648250743906\n",
            "At step: 7863 training error: 0.302272630877062\n",
            "At step: 7864 training error: 0.3024685464863295\n",
            "At step: 7865 training error: 0.30141305864722046\n",
            "At step: 7866 training error: 0.2987100739263741\n",
            "At step: 7867 training error: 0.3012032359383344\n",
            "At step: 7868 training error: 0.3078401287483008\n",
            "At step: 7869 training error: 0.31200361998094645\n",
            "At step: 7870 training error: 0.3173837281675735\n",
            "At step: 7871 training error: 0.31349915412842594\n",
            "At step: 7872 training error: 0.314860389071051\n",
            "At step: 7873 training error: 0.3227157587789452\n",
            "At step: 7874 training error: 0.3149298387181155\n",
            "At step: 7875 training error: 0.3152182119919983\n",
            "At step: 7876 training error: 0.3111710395415848\n",
            "At step: 7877 training error: 0.3056957646726805\n",
            "At step: 7878 training error: 0.3110922277848545\n",
            "At step: 7879 training error: 0.300778981843839\n",
            "At step: 7880 training error: 0.3010024911165084\n",
            "At step: 7881 training error: 0.3149537202909352\n",
            "At step: 7882 training error: 0.3180515423733608\n",
            "At step: 7883 training error: 0.32829745240153374\n",
            "At step: 7884 training error: 0.332622032931896\n",
            "At step: 7885 training error: 0.32116825981406316\n",
            "At step: 7886 training error: 0.31488154242593586\n",
            "At step: 7887 training error: 0.3081017232787125\n",
            "At step: 7888 training error: 0.3169327955198418\n",
            "At step: 7889 training error: 0.3129408359600942\n",
            "At step: 7890 training error: 0.3141438966564796\n",
            "At step: 7891 training error: 0.31848198461975696\n",
            "At step: 7892 training error: 0.3374350350121604\n",
            "At step: 7893 training error: 0.3436953438757165\n",
            "At step: 7894 training error: 0.32881733926526974\n",
            "At step: 7895 training error: 0.32562417283043177\n",
            "At step: 7896 training error: 0.32033150192438786\n",
            "At step: 7897 training error: 0.3173881611859133\n",
            "At step: 7898 training error: 0.31720902529723255\n",
            "At step: 7899 training error: 0.31556475850424887\n",
            "At step: 7900 training error: 0.3132162323350197\n",
            "At step: 7901 training error: 0.30235331200788224\n",
            "At step: 7902 training error: 0.29574180414643686\n",
            "At step: 7903 training error: 0.29399990690727346\n",
            "At step: 7904 training error: 0.2923359916636583\n",
            "At step: 7905 training error: 0.2963333707834866\n",
            "At step: 7906 training error: 0.29789857989030105\n",
            "At step: 7907 training error: 0.2919754751882689\n",
            "At step: 7908 training error: 0.3048667727441065\n",
            "At step: 7909 training error: 0.3080189312791091\n",
            "At step: 7910 training error: 0.3109292694224805\n",
            "At step: 7911 training error: 0.3108246535306732\n",
            "At step: 7912 training error: 0.31726761669744447\n",
            "At step: 7913 training error: 0.32035662658178843\n",
            "At step: 7914 training error: 0.30356178573152254\n",
            "At step: 7915 training error: 0.3063385344006849\n",
            "At step: 7916 training error: 0.29825689006160194\n",
            "At step: 7917 training error: 0.29375574034425267\n",
            "At step: 7918 training error: 0.3108760171532628\n",
            "At step: 7919 training error: 0.3085615505852851\n",
            "At step: 7920 training error: 0.3081140192745898\n",
            "At step: 7921 training error: 0.3019240828326434\n",
            "At step: 7922 training error: 0.30107571051574245\n",
            "At step: 7923 training error: 0.30212495006882434\n",
            "At step: 7924 training error: 0.30322500390098783\n",
            "At step: 7925 training error: 0.2951008974345172\n",
            "At step: 7926 training error: 0.2966825755555854\n",
            "At step: 7927 training error: 0.30787351982348643\n",
            "At step: 7928 training error: 0.3098257289436374\n",
            "At step: 7929 training error: 0.31441323865830684\n",
            "At step: 7930 training error: 0.3226646847063258\n",
            "At step: 7931 training error: 0.3214237602547415\n",
            "At step: 7932 training error: 0.3131883888227436\n",
            "At step: 7933 training error: 0.3165800009608693\n",
            "At step: 7934 training error: 0.31889147017365\n",
            "At step: 7935 training error: 0.33086681271445806\n",
            "At step: 7936 training error: 0.3274156984157233\n",
            "At step: 7937 training error: 0.3143319803422591\n",
            "At step: 7938 training error: 0.3135301233783098\n",
            "At step: 7939 training error: 0.3130378091109221\n",
            "At step: 7940 training error: 0.3146247386274117\n",
            "At step: 7941 training error: 0.3118466135639336\n",
            "At step: 7942 training error: 0.31617245296792873\n",
            "At step: 7943 training error: 0.3162412916473052\n",
            "At step: 7944 training error: 0.314473660125648\n",
            "At step: 7945 training error: 0.31529901704199026\n",
            "At step: 7946 training error: 0.3247642674756796\n",
            "At step: 7947 training error: 0.33613454089368033\n",
            "At step: 7948 training error: 0.3416244716623722\n",
            "At step: 7949 training error: 0.3342271839840942\n",
            "At step: 7950 training error: 0.327908852189572\n",
            "At step: 7951 training error: 0.3184977448304787\n",
            "At step: 7952 training error: 0.31801645363938863\n",
            "At step: 7953 training error: 0.3124668586691046\n",
            "At step: 7954 training error: 0.3255027069898392\n",
            "At step: 7955 training error: 0.31364132151708596\n",
            "At step: 7956 training error: 0.3100184232191094\n",
            "At step: 7957 training error: 0.3074001980512672\n",
            "At step: 7958 training error: 0.3127453647091091\n",
            "At step: 7959 training error: 0.30443303960087054\n",
            "At step: 7960 training error: 0.3059497738596555\n",
            "At step: 7961 training error: 0.2947466378565712\n",
            "At step: 7962 training error: 0.2927920629148691\n",
            "At step: 7963 training error: 0.28751439988505384\n",
            "At step: 7964 training error: 0.2960482908897937\n",
            "At step: 7965 training error: 0.3078183039619875\n",
            "At step: 7966 training error: 0.32032433010949335\n",
            "At step: 7967 training error: 0.3216521666565673\n",
            "At step: 7968 training error: 0.32056243895384995\n",
            "At step: 7969 training error: 0.3208060717760648\n",
            "At step: 7970 training error: 0.31558418354473117\n",
            "At step: 7971 training error: 0.30921803129658293\n",
            "At step: 7972 training error: 0.3128466383225905\n",
            "At step: 7973 training error: 0.30435168606656504\n",
            "At step: 7974 training error: 0.3125473984348116\n",
            "At step: 7975 training error: 0.2981650153728077\n",
            "At step: 7976 training error: 0.2949629979604157\n",
            "At step: 7977 training error: 0.2920187593393057\n",
            "At step: 7978 training error: 0.2976980067505158\n",
            "At step: 7979 training error: 0.31003734868229277\n",
            "At step: 7980 training error: 0.31720478337682556\n",
            "At step: 7981 training error: 0.3179583590011846\n",
            "At step: 7982 training error: 0.3240473495674915\n",
            "At step: 7983 training error: 0.3295351696408545\n",
            "At step: 7984 training error: 0.3267299057740167\n",
            "At step: 7985 training error: 0.32037191303109674\n",
            "At step: 7986 training error: 0.3095649339132346\n",
            "At step: 7987 training error: 0.3188411036590314\n",
            "At step: 7988 training error: 0.3195927121264403\n",
            "At step: 7989 training error: 0.3204016317645527\n",
            "At step: 7990 training error: 0.31436676309072686\n",
            "At step: 7991 training error: 0.3123969916514845\n",
            "At step: 7992 training error: 0.3118874330911358\n",
            "At step: 7993 training error: 0.3127282923867989\n",
            "At step: 7994 training error: 0.31045102238512556\n",
            "At step: 7995 training error: 0.31295791323550093\n",
            "At step: 7996 training error: 0.32199832113685584\n",
            "At step: 7997 training error: 0.32048858336382124\n",
            "At step: 7998 training error: 0.3038989292712257\n",
            "At step: 7999 training error: 0.2988928952991936\n",
            "At step: 8000 training error: 0.29822101037704085\n",
            "At step: 8001 training error: 0.30156285541974753\n",
            "At step: 8002 training error: 0.30793635625214055\n",
            "At step: 8003 training error: 0.3169167380550433\n",
            "At step: 8004 training error: 0.32242175419849406\n",
            "At step: 8005 training error: 0.310975923381991\n",
            "At step: 8006 training error: 0.31730798163981416\n",
            "At step: 8007 training error: 0.3140932156197911\n",
            "At step: 8008 training error: 0.31221334040966603\n",
            "At step: 8009 training error: 0.3079161825860437\n",
            "At step: 8010 training error: 0.3092565718113959\n",
            "At step: 8011 training error: 0.3101242277540597\n",
            "At step: 8012 training error: 0.3187000236956933\n",
            "At step: 8013 training error: 0.3208309225006692\n",
            "At step: 8014 training error: 0.315976036446838\n",
            "At step: 8015 training error: 0.324084645913685\n",
            "At step: 8016 training error: 0.3200595307313257\n",
            "At step: 8017 training error: 0.3166437282440305\n",
            "At step: 8018 training error: 0.3050868466027182\n",
            "At step: 8019 training error: 0.3068272880984861\n",
            "At step: 8020 training error: 0.29502267985962766\n",
            "At step: 8021 training error: 0.2994853065367437\n",
            "At step: 8022 training error: 0.29733983861665814\n",
            "At step: 8023 training error: 0.29890786749521514\n",
            "At step: 8024 training error: 0.29012624327456554\n",
            "At step: 8025 training error: 0.27624032240040336\n",
            "At step: 8026 training error: 0.27816738025962123\n",
            "At step: 8027 training error: 0.2704115506482659\n",
            "At step: 8028 training error: 0.281929310446584\n",
            "At step: 8029 training error: 0.28434673324622745\n",
            "At step: 8030 training error: 0.28968412153542117\n",
            "At step: 8031 training error: 0.3020430040157714\n",
            "At step: 8032 training error: 0.2979356863289643\n",
            "At step: 8033 training error: 0.2957739054938239\n",
            "At step: 8034 training error: 0.29788576014475954\n",
            "At step: 8035 training error: 0.30325778271454196\n",
            "At step: 8036 training error: 0.3032302841424313\n",
            "At step: 8037 training error: 0.3074440587805073\n",
            "At step: 8038 training error: 0.31696797980805763\n",
            "At step: 8039 training error: 0.32514377292772195\n",
            "At step: 8040 training error: 0.31763934542609196\n",
            "At step: 8041 training error: 0.30935438593723763\n",
            "At step: 8042 training error: 0.3121807161286959\n",
            "At step: 8043 training error: 0.3254999099158666\n",
            "At step: 8044 training error: 0.3155170347001936\n",
            "At step: 8045 training error: 0.3094388063895268\n",
            "At step: 8046 training error: 0.3230151006342089\n",
            "At step: 8047 training error: 0.32397535084251505\n",
            "At step: 8048 training error: 0.32530244900231786\n",
            "At step: 8049 training error: 0.3269027072208956\n",
            "At step: 8050 training error: 0.31740201550459385\n",
            "At step: 8051 training error: 0.3291563416402079\n",
            "At step: 8052 training error: 0.3276305301232005\n",
            "At step: 8053 training error: 0.3270608577700382\n",
            "At step: 8054 training error: 0.32215867342999066\n",
            "At step: 8055 training error: 0.33038234378811454\n",
            "At step: 8056 training error: 0.3256595974907006\n",
            "At step: 8057 training error: 0.32855893532728053\n",
            "At step: 8058 training error: 0.3244597379501145\n",
            "At step: 8059 training error: 0.3089369852179417\n",
            "At step: 8060 training error: 0.30444464849892633\n",
            "At step: 8061 training error: 0.29801062969800735\n",
            "At step: 8062 training error: 0.2979365991443521\n",
            "At step: 8063 training error: 0.3070239244522477\n",
            "At step: 8064 training error: 0.3015232174743516\n",
            "At step: 8065 training error: 0.2957004383044835\n",
            "At step: 8066 training error: 0.2960566692580079\n",
            "At step: 8067 training error: 0.29868148470228567\n",
            "At step: 8068 training error: 0.30556857622104416\n",
            "At step: 8069 training error: 0.29583602621518645\n",
            "At step: 8070 training error: 0.3009165171681901\n",
            "At step: 8071 training error: 0.3042874598807057\n",
            "At step: 8072 training error: 0.3101226013919372\n",
            "At step: 8073 training error: 0.3379671965839665\n",
            "At step: 8074 training error: 0.3309691741335487\n",
            "At step: 8075 training error: 0.3276529245286043\n",
            "At step: 8076 training error: 0.33434108601976026\n",
            "At step: 8077 training error: 0.3340240336560888\n",
            "At step: 8078 training error: 0.34007760761250433\n",
            "At step: 8079 training error: 0.3305736312276023\n",
            "At step: 8080 training error: 0.3205056489209283\n",
            "At step: 8081 training error: 0.3116687141410457\n",
            "At step: 8082 training error: 0.30993312421366837\n",
            "At step: 8083 training error: 0.30699282772174974\n",
            "At step: 8084 training error: 0.3124332276757717\n",
            "At step: 8085 training error: 0.31267136497145237\n",
            "At step: 8086 training error: 0.311736394063897\n",
            "At step: 8087 training error: 0.3088840110264789\n",
            "At step: 8088 training error: 0.29923285508614217\n",
            "At step: 8089 training error: 0.2906551328277871\n",
            "At step: 8090 training error: 0.29756392607974325\n",
            "At step: 8091 training error: 0.3074617305189771\n",
            "At step: 8092 training error: 0.2891926909146436\n",
            "At step: 8093 training error: 0.28702731938682813\n",
            "At step: 8094 training error: 0.28356630209717937\n",
            "At step: 8095 training error: 0.27308239332237305\n",
            "At step: 8096 training error: 0.28291875318511034\n",
            "At step: 8097 training error: 0.2722206650988645\n",
            "At step: 8098 training error: 0.2771956959560545\n",
            "At step: 8099 training error: 0.28310845655492106\n",
            "At step: 8100 training error: 0.2890782713348941\n",
            "At step: 8101 training error: 0.28389336080943556\n",
            "At step: 8102 training error: 0.295217028524024\n",
            "At step: 8103 training error: 0.2916443655295211\n",
            "At step: 8104 training error: 0.29188164414602086\n",
            "At step: 8105 training error: 0.28463065858236436\n",
            "At step: 8106 training error: 0.2752527171047592\n",
            "At step: 8107 training error: 0.26946191902968825\n",
            "At step: 8108 training error: 0.27249896143254915\n",
            "At step: 8109 training error: 0.27815133281913224\n",
            "At step: 8110 training error: 0.27453235971193224\n",
            "At step: 8111 training error: 0.27000059801406495\n",
            "At step: 8112 training error: 0.2861072243324596\n",
            "At step: 8113 training error: 0.2825481614867506\n",
            "At step: 8114 training error: 0.28427319955675817\n",
            "At step: 8115 training error: 0.2780255928597218\n",
            "At step: 8116 training error: 0.28338172850813714\n",
            "At step: 8117 training error: 0.2841488209947859\n",
            "At step: 8118 training error: 0.28798663018984416\n",
            "At step: 8119 training error: 0.2882157414998331\n",
            "At step: 8120 training error: 0.2811573920092333\n",
            "At step: 8121 training error: 0.27599502906866974\n",
            "At step: 8122 training error: 0.26507009754727223\n",
            "At step: 8123 training error: 0.2744923660828928\n",
            "At step: 8124 training error: 0.28514736775940464\n",
            "At step: 8125 training error: 0.2883749765544188\n",
            "At step: 8126 training error: 0.29065127649694344\n",
            "At step: 8127 training error: 0.29648495625913585\n",
            "At step: 8128 training error: 0.2948863925602083\n",
            "At step: 8129 training error: 0.29053889175253816\n",
            "At step: 8130 training error: 0.30124818281870946\n",
            "At step: 8131 training error: 0.3015995466462242\n",
            "At step: 8132 training error: 0.29356979828173757\n",
            "At step: 8133 training error: 0.29936967860534697\n",
            "At step: 8134 training error: 0.3029957847781987\n",
            "At step: 8135 training error: 0.3035519790060497\n",
            "At step: 8136 training error: 0.3043494580628085\n",
            "At step: 8137 training error: 0.3078581559551474\n",
            "At step: 8138 training error: 0.28630742461378555\n",
            "At step: 8139 training error: 0.2898612815661983\n",
            "At step: 8140 training error: 0.2814544319881809\n",
            "At step: 8141 training error: 0.2954882837804983\n",
            "At step: 8142 training error: 0.2944542286537293\n",
            "At step: 8143 training error: 0.29728281309922994\n",
            "At step: 8144 training error: 0.29340248137774083\n",
            "At step: 8145 training error: 0.29183863025450796\n",
            "At step: 8146 training error: 0.28565634836452575\n",
            "At step: 8147 training error: 0.2892355872963343\n",
            "At step: 8148 training error: 0.2848019947737823\n",
            "At step: 8149 training error: 0.2875248026494849\n",
            "At step: 8150 training error: 0.28378004164331033\n",
            "At step: 8151 training error: 0.2905174443667755\n",
            "At step: 8152 training error: 0.2912505924174286\n",
            "At step: 8153 training error: 0.29072595751792063\n",
            "At step: 8154 training error: 0.2899713415977401\n",
            "At step: 8155 training error: 0.2800596956606252\n",
            "At step: 8156 training error: 0.2848737683309382\n",
            "At step: 8157 training error: 0.28281899598055765\n",
            "At step: 8158 training error: 0.2949969789299732\n",
            "At step: 8159 training error: 0.3083084503176977\n",
            "At step: 8160 training error: 0.3130391895374691\n",
            "At step: 8161 training error: 0.32692568731098803\n",
            "At step: 8162 training error: 0.32023541881808804\n",
            "At step: 8163 training error: 0.300097874997086\n",
            "At step: 8164 training error: 0.30391283760243215\n",
            "At step: 8165 training error: 0.3040580815805343\n",
            "At step: 8166 training error: 0.3056373538702039\n",
            "At step: 8167 training error: 0.3219324957678734\n",
            "At step: 8168 training error: 0.31348034471618635\n",
            "At step: 8169 training error: 0.3182871661630371\n",
            "At step: 8170 training error: 0.3304578822983882\n",
            "At step: 8171 training error: 0.32644535961073184\n",
            "At step: 8172 training error: 0.3229502081873506\n",
            "At step: 8173 training error: 0.32182545008947744\n",
            "At step: 8174 training error: 0.3253094160740337\n",
            "At step: 8175 training error: 0.3246326523846154\n",
            "At step: 8176 training error: 0.31848111087465714\n",
            "At step: 8177 training error: 0.3272361758277011\n",
            "At step: 8178 training error: 0.327359020381761\n",
            "At step: 8179 training error: 0.3225844764676046\n",
            "At step: 8180 training error: 0.3221743719631154\n",
            "At step: 8181 training error: 0.3262585177305506\n",
            "At step: 8182 training error: 0.3196723382720383\n",
            "At step: 8183 training error: 0.3053591567876806\n",
            "At step: 8184 training error: 0.2992479455608962\n",
            "At step: 8185 training error: 0.3038051739184192\n",
            "At step: 8186 training error: 0.309096564773913\n",
            "At step: 8187 training error: 0.3088386819221887\n",
            "At step: 8188 training error: 0.30755697884851074\n",
            "At step: 8189 training error: 0.311025106928883\n",
            "At step: 8190 training error: 0.3038758624510222\n",
            "At step: 8191 training error: 0.301962302854031\n",
            "At step: 8192 training error: 0.2996395774870265\n",
            "At step: 8193 training error: 0.3021825588183916\n",
            "At step: 8194 training error: 0.3185020207507342\n",
            "At step: 8195 training error: 0.3030364851987047\n",
            "At step: 8196 training error: 0.3118244637247937\n",
            "At step: 8197 training error: 0.32110655664826737\n",
            "At step: 8198 training error: 0.324614322363669\n",
            "At step: 8199 training error: 0.3279881625984376\n",
            "At step: 8200 training error: 0.3335036810217108\n",
            "At step: 8201 training error: 0.32334699772669595\n",
            "At step: 8202 training error: 0.3207263046149075\n",
            "At step: 8203 training error: 0.33181033105701047\n",
            "At step: 8204 training error: 0.32329898270217866\n",
            "At step: 8205 training error: 0.32759289457777246\n",
            "At step: 8206 training error: 0.31832907075916095\n",
            "At step: 8207 training error: 0.3257217590772462\n",
            "At step: 8208 training error: 0.32119382963197757\n",
            "At step: 8209 training error: 0.31700844949625956\n",
            "At step: 8210 training error: 0.31567202947758644\n",
            "At step: 8211 training error: 0.30225660126979453\n",
            "At step: 8212 training error: 0.30034990844254106\n",
            "At step: 8213 training error: 0.3037237715840662\n",
            "At step: 8214 training error: 0.30504482799268956\n",
            "At step: 8215 training error: 0.3075899150291292\n",
            "At step: 8216 training error: 0.3006339323454736\n",
            "At step: 8217 training error: 0.29183157797178183\n",
            "At step: 8218 training error: 0.27904435124850746\n",
            "At step: 8219 training error: 0.2688495305453592\n",
            "At step: 8220 training error: 0.2699111327352584\n",
            "At step: 8221 training error: 0.27090198354472816\n",
            "At step: 8222 training error: 0.27097116999948356\n",
            "At step: 8223 training error: 0.2717123756026902\n",
            "At step: 8224 training error: 0.2702871870205166\n",
            "At step: 8225 training error: 0.2774462507659339\n",
            "At step: 8226 training error: 0.27053556889451164\n",
            "At step: 8227 training error: 0.2834330713448843\n",
            "At step: 8228 training error: 0.2829616955720513\n",
            "At step: 8229 training error: 0.28691214145239274\n",
            "At step: 8230 training error: 0.2983744955789904\n",
            "At step: 8231 training error: 0.299608836597366\n",
            "At step: 8232 training error: 0.29752661924106943\n",
            "At step: 8233 training error: 0.29066244247081713\n",
            "At step: 8234 training error: 0.2913605750755374\n",
            "At step: 8235 training error: 0.3059755840039895\n",
            "At step: 8236 training error: 0.31394599594723127\n",
            "At step: 8237 training error: 0.3178402146592066\n",
            "At step: 8238 training error: 0.3162495716677039\n",
            "At step: 8239 training error: 0.32076993310516333\n",
            "At step: 8240 training error: 0.3202640858227112\n",
            "At step: 8241 training error: 0.3163007652459309\n",
            "At step: 8242 training error: 0.3059194487202949\n",
            "At step: 8243 training error: 0.3065725845982178\n",
            "At step: 8244 training error: 0.3008617335555406\n",
            "At step: 8245 training error: 0.3186041884440624\n",
            "At step: 8246 training error: 0.30727706090022705\n",
            "At step: 8247 training error: 0.31085460327079806\n",
            "At step: 8248 training error: 0.30926247340816704\n",
            "At step: 8249 training error: 0.3135512275403722\n",
            "At step: 8250 training error: 0.31701955184833797\n",
            "At step: 8251 training error: 0.31641578997563974\n",
            "At step: 8252 training error: 0.3199671019519446\n",
            "At step: 8253 training error: 0.3081637568490879\n",
            "At step: 8254 training error: 0.30360065494431204\n",
            "At step: 8255 training error: 0.30500896446844616\n",
            "At step: 8256 training error: 0.30110054196435615\n",
            "At step: 8257 training error: 0.30161736177229864\n",
            "At step: 8258 training error: 0.3028218278959335\n",
            "At step: 8259 training error: 0.2997554141069152\n",
            "At step: 8260 training error: 0.30472397320600614\n",
            "At step: 8261 training error: 0.29955522021160735\n",
            "At step: 8262 training error: 0.29376589852477497\n",
            "At step: 8263 training error: 0.2890085934675319\n",
            "At step: 8264 training error: 0.2976828758891759\n",
            "At step: 8265 training error: 0.29698014388783367\n",
            "At step: 8266 training error: 0.2961059255405696\n",
            "At step: 8267 training error: 0.29603842302460304\n",
            "At step: 8268 training error: 0.29904096456596435\n",
            "At step: 8269 training error: 0.2985044178445897\n",
            "At step: 8270 training error: 0.29260949411123255\n",
            "At step: 8271 training error: 0.2813589585501962\n",
            "At step: 8272 training error: 0.27809870769591616\n",
            "At step: 8273 training error: 0.2724356191827369\n",
            "At step: 8274 training error: 0.2866117956545533\n",
            "At step: 8275 training error: 0.2867378252240807\n",
            "At step: 8276 training error: 0.2859671911329453\n",
            "At step: 8277 training error: 0.2904336854030619\n",
            "At step: 8278 training error: 0.291572066844882\n",
            "At step: 8279 training error: 0.29904531691439223\n",
            "At step: 8280 training error: 0.29521864047215174\n",
            "At step: 8281 training error: 0.2908824102075769\n",
            "At step: 8282 training error: 0.2944542116121968\n",
            "At step: 8283 training error: 0.29691471562133953\n",
            "At step: 8284 training error: 0.29526271142893834\n",
            "At step: 8285 training error: 0.28413870958842147\n",
            "At step: 8286 training error: 0.28106528484932425\n",
            "At step: 8287 training error: 0.27524831354003476\n",
            "At step: 8288 training error: 0.2786442040468365\n",
            "At step: 8289 training error: 0.2713323201195698\n",
            "At step: 8290 training error: 0.27837437651855007\n",
            "At step: 8291 training error: 0.28232001565653814\n",
            "At step: 8292 training error: 0.2797709823873136\n",
            "At step: 8293 training error: 0.2818083209523032\n",
            "At step: 8294 training error: 0.28861135833747703\n",
            "At step: 8295 training error: 0.307920745834233\n",
            "At step: 8296 training error: 0.3006125841089823\n",
            "At step: 8297 training error: 0.3069743987713649\n",
            "At step: 8298 training error: 0.3070401296029538\n",
            "At step: 8299 training error: 0.29774510941194543\n",
            "At step: 8300 training error: 0.2982106814641826\n",
            "At step: 8301 training error: 0.29850143348415437\n",
            "At step: 8302 training error: 0.3013251090062989\n",
            "At step: 8303 training error: 0.3055857262363158\n",
            "At step: 8304 training error: 0.3030786603086615\n",
            "At step: 8305 training error: 0.29514725607434195\n",
            "At step: 8306 training error: 0.2857568025973488\n",
            "At step: 8307 training error: 0.29139268328845014\n",
            "At step: 8308 training error: 0.28441234321087616\n",
            "At step: 8309 training error: 0.29036767611918435\n",
            "At step: 8310 training error: 0.29795058844445854\n",
            "At step: 8311 training error: 0.3011672919431168\n",
            "At step: 8312 training error: 0.30313994528793303\n",
            "At step: 8313 training error: 0.29678016304351296\n",
            "At step: 8314 training error: 0.304456002342503\n",
            "At step: 8315 training error: 0.29847931591956867\n",
            "At step: 8316 training error: 0.28958002585742065\n",
            "At step: 8317 training error: 0.2859362613102271\n",
            "At step: 8318 training error: 0.2830329488840107\n",
            "At step: 8319 training error: 0.29387978561617967\n",
            "At step: 8320 training error: 0.2954149623550981\n",
            "At step: 8321 training error: 0.2965519337230614\n",
            "At step: 8322 training error: 0.2948411284733812\n",
            "At step: 8323 training error: 0.2955875837351406\n",
            "At step: 8324 training error: 0.30066534282165547\n",
            "At step: 8325 training error: 0.3030946113390484\n",
            "At step: 8326 training error: 0.30498943391588196\n",
            "At step: 8327 training error: 0.30388047414998576\n",
            "At step: 8328 training error: 0.29716892531532874\n",
            "At step: 8329 training error: 0.2938364814908362\n",
            "At step: 8330 training error: 0.2845933069535067\n",
            "At step: 8331 training error: 0.28988074472327013\n",
            "At step: 8332 training error: 0.28927670166714803\n",
            "At step: 8333 training error: 0.30149976764836406\n",
            "At step: 8334 training error: 0.29676942143684876\n",
            "At step: 8335 training error: 0.29212346162939967\n",
            "At step: 8336 training error: 0.29112119137677717\n",
            "At step: 8337 training error: 0.2917249806758188\n",
            "At step: 8338 training error: 0.28974176573007904\n",
            "At step: 8339 training error: 0.2846027001256225\n",
            "At step: 8340 training error: 0.2729437846006162\n",
            "At step: 8341 training error: 0.2626482571422202\n",
            "At step: 8342 training error: 0.2712638466647781\n",
            "At step: 8343 training error: 0.2782060833521043\n",
            "At step: 8344 training error: 0.27676747656553025\n",
            "At step: 8345 training error: 0.2847936439861509\n",
            "At step: 8346 training error: 0.28257757076438383\n",
            "At step: 8347 training error: 0.2907490619608294\n",
            "At step: 8348 training error: 0.2922661518265549\n",
            "At step: 8349 training error: 0.30696353996063874\n",
            "At step: 8350 training error: 0.30896368207893404\n",
            "At step: 8351 training error: 0.2968014145130515\n",
            "At step: 8352 training error: 0.30320681038113667\n",
            "At step: 8353 training error: 0.30181069231662533\n",
            "At step: 8354 training error: 0.2935532352016567\n",
            "At step: 8355 training error: 0.29158569049871536\n",
            "At step: 8356 training error: 0.2907037150216835\n",
            "At step: 8357 training error: 0.30238987670259987\n",
            "At step: 8358 training error: 0.29969849498770657\n",
            "At step: 8359 training error: 0.2971897459475202\n",
            "At step: 8360 training error: 0.29274689691096456\n",
            "At step: 8361 training error: 0.29798517451247347\n",
            "At step: 8362 training error: 0.29751615936534587\n",
            "At step: 8363 training error: 0.28602456586837877\n",
            "At step: 8364 training error: 0.2845300139326731\n",
            "At step: 8365 training error: 0.2777029171575273\n",
            "At step: 8366 training error: 0.27880177809081114\n",
            "At step: 8367 training error: 0.27846262444641695\n",
            "At step: 8368 training error: 0.2752711782919591\n",
            "At step: 8369 training error: 0.2846272627143878\n",
            "At step: 8370 training error: 0.2855410685183995\n",
            "At step: 8371 training error: 0.28786006222711086\n",
            "At step: 8372 training error: 0.30046101620502064\n",
            "At step: 8373 training error: 0.3078397276753389\n",
            "At step: 8374 training error: 0.3052179013649081\n",
            "At step: 8375 training error: 0.3186002639229148\n",
            "At step: 8376 training error: 0.32756152476162403\n",
            "At step: 8377 training error: 0.32161246044548153\n",
            "At step: 8378 training error: 0.3138226730159451\n",
            "At step: 8379 training error: 0.3048059020703899\n",
            "At step: 8380 training error: 0.311297959595645\n",
            "At step: 8381 training error: 0.29924644762641617\n",
            "At step: 8382 training error: 0.294641079662561\n",
            "At step: 8383 training error: 0.2840297944811383\n",
            "At step: 8384 training error: 0.2918878151062016\n",
            "At step: 8385 training error: 0.289697746208358\n",
            "At step: 8386 training error: 0.29438828604152706\n",
            "At step: 8387 training error: 0.30021651500440094\n",
            "At step: 8388 training error: 0.30183263686965206\n",
            "At step: 8389 training error: 0.2985242554787413\n",
            "At step: 8390 training error: 0.293320973225042\n",
            "At step: 8391 training error: 0.3007017101290318\n",
            "At step: 8392 training error: 0.3000137872656369\n",
            "At step: 8393 training error: 0.29498141327263694\n",
            "At step: 8394 training error: 0.2954922373341841\n",
            "At step: 8395 training error: 0.2990843014387571\n",
            "At step: 8396 training error: 0.3091247975955754\n",
            "At step: 8397 training error: 0.3129811789385703\n",
            "At step: 8398 training error: 0.29666082182159126\n",
            "At step: 8399 training error: 0.2892212074232868\n",
            "At step: 8400 training error: 0.2789805133212647\n",
            "At step: 8401 training error: 0.2764379143924691\n",
            "At step: 8402 training error: 0.28519933377003737\n",
            "At step: 8403 training error: 0.29415669435247377\n",
            "At step: 8404 training error: 0.29824749167197306\n",
            "At step: 8405 training error: 0.2931913947203204\n",
            "At step: 8406 training error: 0.2923736712373348\n",
            "At step: 8407 training error: 0.28445604839939925\n",
            "At step: 8408 training error: 0.28457165539823936\n",
            "At step: 8409 training error: 0.27930845705856944\n",
            "At step: 8410 training error: 0.28519314267391316\n",
            "At step: 8411 training error: 0.2991075070168087\n",
            "At step: 8412 training error: 0.2970488572383994\n",
            "At step: 8413 training error: 0.3026467351869722\n",
            "At step: 8414 training error: 0.3011731663242007\n",
            "At step: 8415 training error: 0.3116791520973726\n",
            "At step: 8416 training error: 0.31400909077579336\n",
            "At step: 8417 training error: 0.3066239160857323\n",
            "At step: 8418 training error: 0.30041447942733807\n",
            "At step: 8419 training error: 0.2983242862068631\n",
            "At step: 8420 training error: 0.31324677504928045\n",
            "At step: 8421 training error: 0.3192766934598204\n",
            "At step: 8422 training error: 0.3214087407316179\n",
            "At step: 8423 training error: 0.31892626711641187\n",
            "At step: 8424 training error: 0.31789622911254306\n",
            "At step: 8425 training error: 0.31898934384657146\n",
            "At step: 8426 training error: 0.3111679473013891\n",
            "At step: 8427 training error: 0.3098858677789261\n",
            "At step: 8428 training error: 0.3125367668498626\n",
            "At step: 8429 training error: 0.3170954822948096\n",
            "At step: 8430 training error: 0.30746321104351887\n",
            "At step: 8431 training error: 0.3141802314964182\n",
            "At step: 8432 training error: 0.3165923740171051\n",
            "At step: 8433 training error: 0.31445573716191333\n",
            "At step: 8434 training error: 0.3146759652501868\n",
            "At step: 8435 training error: 0.30729715645587957\n",
            "At step: 8436 training error: 0.30730782915497507\n",
            "At step: 8437 training error: 0.3076034995379103\n",
            "At step: 8438 training error: 0.30438132531634987\n",
            "At step: 8439 training error: 0.3068780291459442\n",
            "At step: 8440 training error: 0.3038843826206772\n",
            "At step: 8441 training error: 0.30123264567865116\n",
            "At step: 8442 training error: 0.2896725942336475\n",
            "At step: 8443 training error: 0.29826293330246073\n",
            "At step: 8444 training error: 0.30847145363428796\n",
            "At step: 8445 training error: 0.30472271591471134\n",
            "At step: 8446 training error: 0.2987536368525379\n",
            "At step: 8447 training error: 0.31151078012925515\n",
            "At step: 8448 training error: 0.3053906152013133\n",
            "At step: 8449 training error: 0.3068000032290758\n",
            "At step: 8450 training error: 0.29566368773948504\n",
            "At step: 8451 training error: 0.3010980364945562\n",
            "At step: 8452 training error: 0.3020544228670186\n",
            "At step: 8453 training error: 0.3139511171847384\n",
            "At step: 8454 training error: 0.3102072148711743\n",
            "At step: 8455 training error: 0.30690184686354527\n",
            "At step: 8456 training error: 0.3081076485464161\n",
            "At step: 8457 training error: 0.3049419222751087\n",
            "At step: 8458 training error: 0.3098858318451107\n",
            "At step: 8459 training error: 0.31606854976238197\n",
            "At step: 8460 training error: 0.3192891715778762\n",
            "At step: 8461 training error: 0.32586811679824795\n",
            "At step: 8462 training error: 0.3255461208318403\n",
            "At step: 8463 training error: 0.3211848801573954\n",
            "At step: 8464 training error: 0.31866600803656253\n",
            "At step: 8465 training error: 0.3075204312459119\n",
            "At step: 8466 training error: 0.3111677667149744\n",
            "At step: 8467 training error: 0.3061057023097873\n",
            "At step: 8468 training error: 0.29991183527891446\n",
            "At step: 8469 training error: 0.302825529970201\n",
            "At step: 8470 training error: 0.2955125561743542\n",
            "At step: 8471 training error: 0.29666681945810053\n",
            "At step: 8472 training error: 0.29339779708055763\n",
            "At step: 8473 training error: 0.30002116965147646\n",
            "At step: 8474 training error: 0.2834776673382214\n",
            "At step: 8475 training error: 0.2863289204770281\n",
            "At step: 8476 training error: 0.2767960202700675\n",
            "At step: 8477 training error: 0.27824319833397987\n",
            "At step: 8478 training error: 0.2801588896927951\n",
            "At step: 8479 training error: 0.2856248950057288\n",
            "At step: 8480 training error: 0.2811514612900475\n",
            "At step: 8481 training error: 0.2820153462120803\n",
            "At step: 8482 training error: 0.27812053962340094\n",
            "At step: 8483 training error: 0.269450642309225\n",
            "At step: 8484 training error: 0.27815413325642646\n",
            "At step: 8485 training error: 0.29173497889934114\n",
            "At step: 8486 training error: 0.2886523857724458\n",
            "At step: 8487 training error: 0.2942746270491564\n",
            "At step: 8488 training error: 0.2929377588362975\n",
            "At step: 8489 training error: 0.3038607526211192\n",
            "At step: 8490 training error: 0.29341867696406154\n",
            "At step: 8491 training error: 0.29462172881211335\n",
            "At step: 8492 training error: 0.30093020177263313\n",
            "At step: 8493 training error: 0.3089337866595935\n",
            "At step: 8494 training error: 0.30101202437858177\n",
            "At step: 8495 training error: 0.29560900198915235\n",
            "At step: 8496 training error: 0.2994808350765929\n",
            "At step: 8497 training error: 0.31100214944009075\n",
            "At step: 8498 training error: 0.31163918604810137\n",
            "At step: 8499 training error: 0.3126507502741248\n",
            "At step: 8500 training error: 0.31492397549565343\n",
            "At step: 8501 training error: 0.30473362461913867\n",
            "At step: 8502 training error: 0.2972017364765334\n",
            "At step: 8503 training error: 0.3091059293746643\n",
            "At step: 8504 training error: 0.31295185451949237\n",
            "At step: 8505 training error: 0.3067349894574554\n",
            "At step: 8506 training error: 0.3015124620483475\n",
            "At step: 8507 training error: 0.30168805784244596\n",
            "At step: 8508 training error: 0.2930705486131965\n",
            "At step: 8509 training error: 0.2860700878040175\n",
            "At step: 8510 training error: 0.285945842648767\n",
            "At step: 8511 training error: 0.3019251588197819\n",
            "At step: 8512 training error: 0.29167784653296963\n",
            "At step: 8513 training error: 0.2866296270894463\n",
            "At step: 8514 training error: 0.281320532131123\n",
            "At step: 8515 training error: 0.2914800555651483\n",
            "At step: 8516 training error: 0.2882390927499334\n",
            "At step: 8517 training error: 0.2773152049753319\n",
            "At step: 8518 training error: 0.27671119067305094\n",
            "At step: 8519 training error: 0.2780520764704705\n",
            "At step: 8520 training error: 0.2670459136976305\n",
            "At step: 8521 training error: 0.2861519778765653\n",
            "At step: 8522 training error: 0.2866852452322026\n",
            "At step: 8523 training error: 0.2889731498716022\n",
            "At step: 8524 training error: 0.27857408637508746\n",
            "At step: 8525 training error: 0.2839881755401469\n",
            "At step: 8526 training error: 0.2890529237801484\n",
            "At step: 8527 training error: 0.2774728096258927\n",
            "At step: 8528 training error: 0.29799914413927137\n",
            "At step: 8529 training error: 0.29098413815115\n",
            "At step: 8530 training error: 0.30182088778264526\n",
            "At step: 8531 training error: 0.2980544868363239\n",
            "At step: 8532 training error: 0.3043647135421045\n",
            "At step: 8533 training error: 0.3102086621301796\n",
            "At step: 8534 training error: 0.3084449400703786\n",
            "At step: 8535 training error: 0.3080184879318434\n",
            "At step: 8536 training error: 0.3141785185219158\n",
            "At step: 8537 training error: 0.3095531709847556\n",
            "At step: 8538 training error: 0.3118917569798767\n",
            "At step: 8539 training error: 0.3128438781453981\n",
            "At step: 8540 training error: 0.2998952082388601\n",
            "At step: 8541 training error: 0.2968881425326259\n",
            "At step: 8542 training error: 0.2978266336039041\n",
            "At step: 8543 training error: 0.3085145811651991\n",
            "At step: 8544 training error: 0.3113757099015003\n",
            "At step: 8545 training error: 0.31459880989716804\n",
            "At step: 8546 training error: 0.3101140087770193\n",
            "At step: 8547 training error: 0.3139868321637784\n",
            "At step: 8548 training error: 0.3213185154075376\n",
            "At step: 8549 training error: 0.3119976015262564\n",
            "At step: 8550 training error: 0.31669294070836235\n",
            "At step: 8551 training error: 0.320213946213463\n",
            "At step: 8552 training error: 0.33519848009585657\n",
            "At step: 8553 training error: 0.3350406125168656\n",
            "At step: 8554 training error: 0.3241616815282669\n",
            "At step: 8555 training error: 0.3157998983767119\n",
            "At step: 8556 training error: 0.3326717074485781\n",
            "At step: 8557 training error: 0.33166012349705865\n",
            "At step: 8558 training error: 0.32555326470171425\n",
            "At step: 8559 training error: 0.32356129249583354\n",
            "At step: 8560 training error: 0.32349430530292383\n",
            "At step: 8561 training error: 0.32602452077766303\n",
            "At step: 8562 training error: 0.3363782566429529\n",
            "At step: 8563 training error: 0.32892089210671555\n",
            "At step: 8564 training error: 0.32729471826589984\n",
            "At step: 8565 training error: 0.32497487234226613\n",
            "At step: 8566 training error: 0.317999040049389\n",
            "At step: 8567 training error: 0.31037477627111665\n",
            "At step: 8568 training error: 0.3026502211692079\n",
            "At step: 8569 training error: 0.30026832744675974\n",
            "At step: 8570 training error: 0.2972318621027041\n",
            "At step: 8571 training error: 0.30313876822085417\n",
            "At step: 8572 training error: 0.3080094359827807\n",
            "At step: 8573 training error: 0.31418527304635663\n",
            "At step: 8574 training error: 0.3065642043149434\n",
            "At step: 8575 training error: 0.30671034140075676\n",
            "At step: 8576 training error: 0.3058912937092745\n",
            "At step: 8577 training error: 0.29921078232615367\n",
            "At step: 8578 training error: 0.3074378186695797\n",
            "At step: 8579 training error: 0.30927562512900636\n",
            "At step: 8580 training error: 0.3119593507831575\n",
            "At step: 8581 training error: 0.3102267552334285\n",
            "At step: 8582 training error: 0.2994418002369336\n",
            "At step: 8583 training error: 0.2932937116446556\n",
            "At step: 8584 training error: 0.29656426134589403\n",
            "At step: 8585 training error: 0.2944296538624176\n",
            "At step: 8586 training error: 0.27859827510095636\n",
            "At step: 8587 training error: 0.269073405640097\n",
            "At step: 8588 training error: 0.28009618589401636\n",
            "At step: 8589 training error: 0.28259013262151605\n",
            "At step: 8590 training error: 0.28625449771782197\n",
            "At step: 8591 training error: 0.27354372239088254\n",
            "At step: 8592 training error: 0.2800564166278649\n",
            "At step: 8593 training error: 0.27490395184041216\n",
            "At step: 8594 training error: 0.28474833081175355\n",
            "At step: 8595 training error: 0.29471411145668636\n",
            "At step: 8596 training error: 0.29071544764769985\n",
            "At step: 8597 training error: 0.29270917868262275\n",
            "At step: 8598 training error: 0.29103511785186736\n",
            "At step: 8599 training error: 0.30134928078254575\n",
            "At step: 8600 training error: 0.3078080289819522\n",
            "At step: 8601 training error: 0.30668776876664544\n",
            "At step: 8602 training error: 0.29709719711322985\n",
            "At step: 8603 training error: 0.298009995253046\n",
            "At step: 8604 training error: 0.2883726892389486\n",
            "At step: 8605 training error: 0.2732436662592514\n",
            "At step: 8606 training error: 0.26982715131474555\n",
            "At step: 8607 training error: 0.2768959424648078\n",
            "At step: 8608 training error: 0.27847685191567606\n",
            "At step: 8609 training error: 0.2815788320054606\n",
            "At step: 8610 training error: 0.2728575971003993\n",
            "At step: 8611 training error: 0.27040134396799365\n",
            "At step: 8612 training error: 0.2852865456884569\n",
            "At step: 8613 training error: 0.28326842940158775\n",
            "At step: 8614 training error: 0.27895452745814003\n",
            "At step: 8615 training error: 0.28258131034508344\n",
            "At step: 8616 training error: 0.2770516941105859\n",
            "At step: 8617 training error: 0.27719458252750884\n",
            "At step: 8618 training error: 0.27852126382889814\n",
            "At step: 8619 training error: 0.2817275631144256\n",
            "At step: 8620 training error: 0.28831641713649864\n",
            "At step: 8621 training error: 0.2948597179947612\n",
            "At step: 8622 training error: 0.2889507717767211\n",
            "At step: 8623 training error: 0.288638919802506\n",
            "At step: 8624 training error: 0.2889173015729145\n",
            "At step: 8625 training error: 0.29728616020792076\n",
            "At step: 8626 training error: 0.30862733844097945\n",
            "At step: 8627 training error: 0.31251871759635674\n",
            "At step: 8628 training error: 0.3154095734025283\n",
            "At step: 8629 training error: 0.30163296497466996\n",
            "At step: 8630 training error: 0.2961689580513987\n",
            "At step: 8631 training error: 0.29143315609795717\n",
            "At step: 8632 training error: 0.28927641377769236\n",
            "At step: 8633 training error: 0.2902086322368085\n",
            "At step: 8634 training error: 0.29410649386251964\n",
            "At step: 8635 training error: 0.298617009556238\n",
            "At step: 8636 training error: 0.3033766994074208\n",
            "At step: 8637 training error: 0.31040621720484807\n",
            "At step: 8638 training error: 0.2952188778268985\n",
            "At step: 8639 training error: 0.3117200319246519\n",
            "At step: 8640 training error: 0.31572422847122816\n",
            "At step: 8641 training error: 0.3140800973527359\n",
            "At step: 8642 training error: 0.31609012007153303\n",
            "At step: 8643 training error: 0.325694518423608\n",
            "At step: 8644 training error: 0.3271250001350577\n",
            "At step: 8645 training error: 0.33921922526930726\n",
            "At step: 8646 training error: 0.3347081308567004\n",
            "At step: 8647 training error: 0.3314163331230918\n",
            "At step: 8648 training error: 0.3208918816760193\n",
            "At step: 8649 training error: 0.3192836143691051\n",
            "At step: 8650 training error: 0.3212964352738832\n",
            "At step: 8651 training error: 0.3171690310368217\n",
            "At step: 8652 training error: 0.32949082479388586\n",
            "At step: 8653 training error: 0.3173335850164206\n",
            "At step: 8654 training error: 0.30501802137360834\n",
            "At step: 8655 training error: 0.2978300263512396\n",
            "At step: 8656 training error: 0.2943588426616166\n",
            "At step: 8657 training error: 0.2900705221867059\n",
            "At step: 8658 training error: 0.28560740364907605\n",
            "At step: 8659 training error: 0.2929480843758636\n",
            "At step: 8660 training error: 0.2864882463859575\n",
            "At step: 8661 training error: 0.28529509812138876\n",
            "At step: 8662 training error: 0.29299099208329304\n",
            "At step: 8663 training error: 0.28814978717853246\n",
            "At step: 8664 training error: 0.28123138721792684\n",
            "At step: 8665 training error: 0.27637782071465683\n",
            "At step: 8666 training error: 0.2815987104732942\n",
            "At step: 8667 training error: 0.28256133183221305\n",
            "At step: 8668 training error: 0.2844237058683048\n",
            "At step: 8669 training error: 0.28453196952258125\n",
            "At step: 8670 training error: 0.276720749512048\n",
            "At step: 8671 training error: 0.28020520217797495\n",
            "At step: 8672 training error: 0.2935770481690912\n",
            "At step: 8673 training error: 0.3025164385431122\n",
            "At step: 8674 training error: 0.29970090805689287\n",
            "At step: 8675 training error: 0.29398319251815047\n",
            "At step: 8676 training error: 0.30817844320154186\n",
            "At step: 8677 training error: 0.30979261638912264\n",
            "At step: 8678 training error: 0.31309419652730835\n",
            "At step: 8679 training error: 0.3139139783832518\n",
            "At step: 8680 training error: 0.3091457415097338\n",
            "At step: 8681 training error: 0.3038842547308959\n",
            "At step: 8682 training error: 0.3077341611017327\n",
            "At step: 8683 training error: 0.2968275572206308\n",
            "At step: 8684 training error: 0.2987754468410407\n",
            "At step: 8685 training error: 0.2944269360900861\n",
            "At step: 8686 training error: 0.30170151891730423\n",
            "At step: 8687 training error: 0.308838984047307\n",
            "At step: 8688 training error: 0.3140811107683915\n",
            "At step: 8689 training error: 0.32566960901226727\n",
            "At step: 8690 training error: 0.34219841636595594\n",
            "At step: 8691 training error: 0.3472816323077016\n",
            "At step: 8692 training error: 0.33455038219572736\n",
            "At step: 8693 training error: 0.32557872476686606\n",
            "At step: 8694 training error: 0.32337209800877686\n",
            "At step: 8695 training error: 0.3291374856289331\n",
            "At step: 8696 training error: 0.3305880192771028\n",
            "At step: 8697 training error: 0.32497398893350515\n",
            "At step: 8698 training error: 0.31525804711540567\n",
            "At step: 8699 training error: 0.31883200460984357\n",
            "At step: 8700 training error: 0.30990200510815796\n",
            "At step: 8701 training error: 0.3219111239616745\n",
            "At step: 8702 training error: 0.3158098087740357\n",
            "At step: 8703 training error: 0.31061400470367717\n",
            "At step: 8704 training error: 0.31926066910578726\n",
            "At step: 8705 training error: 0.31864985471423707\n",
            "At step: 8706 training error: 0.3223224700814171\n",
            "At step: 8707 training error: 0.3302942766706406\n",
            "At step: 8708 training error: 0.3307749703943712\n",
            "At step: 8709 training error: 0.33199558875108887\n",
            "At step: 8710 training error: 0.32921029021684417\n",
            "At step: 8711 training error: 0.32682928850916515\n",
            "At step: 8712 training error: 0.31612924642604695\n",
            "At step: 8713 training error: 0.3237541896432446\n",
            "At step: 8714 training error: 0.3323302086900255\n",
            "At step: 8715 training error: 0.33558996917315553\n",
            "At step: 8716 training error: 0.3275126125005887\n",
            "At step: 8717 training error: 0.3242266811741193\n",
            "At step: 8718 training error: 0.32916748976352334\n",
            "At step: 8719 training error: 0.3240029479000334\n",
            "At step: 8720 training error: 0.31949177499357306\n",
            "At step: 8721 training error: 0.3159589397856982\n",
            "At step: 8722 training error: 0.3174319271886731\n",
            "At step: 8723 training error: 0.3272544614999906\n",
            "At step: 8724 training error: 0.3157678490337119\n",
            "At step: 8725 training error: 0.3028494496998527\n",
            "At step: 8726 training error: 0.30885023228123765\n",
            "At step: 8727 training error: 0.29640301431509464\n",
            "At step: 8728 training error: 0.28150750690448084\n",
            "At step: 8729 training error: 0.3082097815222844\n",
            "At step: 8730 training error: 0.3110376134735907\n",
            "At step: 8731 training error: 0.3101467062187593\n",
            "At step: 8732 training error: 0.30235017719422874\n",
            "At step: 8733 training error: 0.29736360862190614\n",
            "At step: 8734 training error: 0.2929433787387778\n",
            "At step: 8735 training error: 0.286372173347491\n",
            "At step: 8736 training error: 0.285326751324687\n",
            "At step: 8737 training error: 0.28572894571495716\n",
            "At step: 8738 training error: 0.28731792415899027\n",
            "At step: 8739 training error: 0.29128095366690204\n",
            "At step: 8740 training error: 0.2909782752551484\n",
            "At step: 8741 training error: 0.3015314943342244\n",
            "At step: 8742 training error: 0.3110132460924461\n",
            "At step: 8743 training error: 0.312930223148805\n",
            "At step: 8744 training error: 0.31627024923408764\n",
            "At step: 8745 training error: 0.31770848933766493\n",
            "At step: 8746 training error: 0.31406774066134424\n",
            "At step: 8747 training error: 0.3140543440657154\n",
            "At step: 8748 training error: 0.30401474743239393\n",
            "At step: 8749 training error: 0.2964621006259284\n",
            "At step: 8750 training error: 0.2929580690116741\n",
            "At step: 8751 training error: 0.30290681286525883\n",
            "At step: 8752 training error: 0.29803077284071244\n",
            "At step: 8753 training error: 0.311919704524922\n",
            "At step: 8754 training error: 0.31555336881931717\n",
            "At step: 8755 training error: 0.30897905036412754\n",
            "At step: 8756 training error: 0.3148318507443397\n",
            "At step: 8757 training error: 0.31029634729530486\n",
            "At step: 8758 training error: 0.3039835384262037\n",
            "At step: 8759 training error: 0.3003045448490994\n",
            "At step: 8760 training error: 0.30347749127826174\n",
            "At step: 8761 training error: 0.2976428319278439\n",
            "At step: 8762 training error: 0.2952810933660186\n",
            "At step: 8763 training error: 0.29837932642454024\n",
            "At step: 8764 training error: 0.30174974034115387\n",
            "At step: 8765 training error: 0.30551882509412887\n",
            "At step: 8766 training error: 0.30920077564460896\n",
            "At step: 8767 training error: 0.3078318972335807\n",
            "At step: 8768 training error: 0.3077453239652212\n",
            "At step: 8769 training error: 0.3113415342875399\n",
            "At step: 8770 training error: 0.30877674573408487\n",
            "At step: 8771 training error: 0.30182367819230194\n",
            "At step: 8772 training error: 0.2978047096373526\n",
            "At step: 8773 training error: 0.2867973932978119\n",
            "At step: 8774 training error: 0.2886095003816521\n",
            "At step: 8775 training error: 0.28850053861257685\n",
            "At step: 8776 training error: 0.28644845894607535\n",
            "At step: 8777 training error: 0.29673683364653985\n",
            "At step: 8778 training error: 0.29386087103702\n",
            "At step: 8779 training error: 0.30397009640892114\n",
            "At step: 8780 training error: 0.3112041269716054\n",
            "At step: 8781 training error: 0.3112324725105379\n",
            "At step: 8782 training error: 0.3149485501481725\n",
            "At step: 8783 training error: 0.31233637373745715\n",
            "At step: 8784 training error: 0.30667011797287835\n",
            "At step: 8785 training error: 0.31330119124311867\n",
            "At step: 8786 training error: 0.31214217144728196\n",
            "At step: 8787 training error: 0.3110706285095997\n",
            "At step: 8788 training error: 0.3176726251352026\n",
            "At step: 8789 training error: 0.31358102080638495\n",
            "At step: 8790 training error: 0.3033309952944815\n",
            "At step: 8791 training error: 0.2897594928250687\n",
            "At step: 8792 training error: 0.30415313170646463\n",
            "At step: 8793 training error: 0.3203684137584184\n",
            "At step: 8794 training error: 0.32724087342050384\n",
            "At step: 8795 training error: 0.3256253653041465\n",
            "At step: 8796 training error: 0.32316365720954177\n",
            "At step: 8797 training error: 0.32144556456488316\n",
            "At step: 8798 training error: 0.3125105884288413\n",
            "At step: 8799 training error: 0.32214092037408504\n",
            "At step: 8800 training error: 0.3237981014304693\n",
            "At step: 8801 training error: 0.3272141316013273\n",
            "At step: 8802 training error: 0.3170491169172681\n",
            "At step: 8803 training error: 0.31004507556231903\n",
            "At step: 8804 training error: 0.309139666820413\n",
            "At step: 8805 training error: 0.31208819826121936\n",
            "At step: 8806 training error: 0.30890321838459467\n",
            "At step: 8807 training error: 0.303591341078567\n",
            "At step: 8808 training error: 0.29974090089108624\n",
            "At step: 8809 training error: 0.30515219446033126\n",
            "At step: 8810 training error: 0.31500993049993997\n",
            "At step: 8811 training error: 0.3191961489154954\n",
            "At step: 8812 training error: 0.3182720100682658\n",
            "At step: 8813 training error: 0.30648890879730045\n",
            "At step: 8814 training error: 0.3011382336803887\n",
            "At step: 8815 training error: 0.3050711569092796\n",
            "At step: 8816 training error: 0.31064636958739755\n",
            "At step: 8817 training error: 0.3130505088974564\n",
            "At step: 8818 training error: 0.3038024062633059\n",
            "At step: 8819 training error: 0.3020570690051301\n",
            "At step: 8820 training error: 0.3023829212311469\n",
            "At step: 8821 training error: 0.2969602069090399\n",
            "At step: 8822 training error: 0.2896237336283798\n",
            "At step: 8823 training error: 0.29457018608439234\n",
            "At step: 8824 training error: 0.2922806312602443\n",
            "At step: 8825 training error: 0.30226646547191294\n",
            "At step: 8826 training error: 0.29708658133894444\n",
            "At step: 8827 training error: 0.29764464110668376\n",
            "At step: 8828 training error: 0.3073894991032966\n",
            "At step: 8829 training error: 0.3105394968063107\n",
            "At step: 8830 training error: 0.30569940556156455\n",
            "At step: 8831 training error: 0.31068428094922085\n",
            "At step: 8832 training error: 0.3144721296216219\n",
            "At step: 8833 training error: 0.3211235425748188\n",
            "At step: 8834 training error: 0.3156888499685381\n",
            "At step: 8835 training error: 0.31972130106446367\n",
            "At step: 8836 training error: 0.318080400630472\n",
            "At step: 8837 training error: 0.3071382657928896\n",
            "At step: 8838 training error: 0.30155632331312765\n",
            "At step: 8839 training error: 0.3093911022120539\n",
            "At step: 8840 training error: 0.3147142961570079\n",
            "At step: 8841 training error: 0.3162384149992321\n",
            "At step: 8842 training error: 0.319579343863613\n",
            "At step: 8843 training error: 0.30893411221394923\n",
            "At step: 8844 training error: 0.30681469114433113\n",
            "At step: 8845 training error: 0.30701946189142215\n",
            "At step: 8846 training error: 0.31083299502700684\n",
            "At step: 8847 training error: 0.3178954249670818\n",
            "At step: 8848 training error: 0.31800574870120263\n",
            "At step: 8849 training error: 0.30473890671966775\n",
            "At step: 8850 training error: 0.2954370270946436\n",
            "At step: 8851 training error: 0.2962309825992452\n",
            "At step: 8852 training error: 0.2924997155702833\n",
            "At step: 8853 training error: 0.29042770496232984\n",
            "At step: 8854 training error: 0.2769778887530661\n",
            "At step: 8855 training error: 0.28039986318722626\n",
            "At step: 8856 training error: 0.2761905168456892\n",
            "At step: 8857 training error: 0.27439611058160035\n",
            "At step: 8858 training error: 0.2787282087030524\n",
            "At step: 8859 training error: 0.2689283570617886\n",
            "At step: 8860 training error: 0.2851978479949792\n",
            "At step: 8861 training error: 0.2905050827601869\n",
            "At step: 8862 training error: 0.2968173327120752\n",
            "At step: 8863 training error: 0.3024441532300227\n",
            "At step: 8864 training error: 0.28327730200152057\n",
            "At step: 8865 training error: 0.28211281204830957\n",
            "At step: 8866 training error: 0.2786416524024054\n",
            "At step: 8867 training error: 0.2906048492310138\n",
            "At step: 8868 training error: 0.3032573799392449\n",
            "At step: 8869 training error: 0.30695858558876804\n",
            "At step: 8870 training error: 0.3146210350569323\n",
            "At step: 8871 training error: 0.2977771217798994\n",
            "At step: 8872 training error: 0.31007410991864487\n",
            "At step: 8873 training error: 0.30611953807809067\n",
            "At step: 8874 training error: 0.3092725151274687\n",
            "At step: 8875 training error: 0.3094677955384241\n",
            "At step: 8876 training error: 0.3041117164139356\n",
            "At step: 8877 training error: 0.3079818442915971\n",
            "At step: 8878 training error: 0.2985431852967464\n",
            "At step: 8879 training error: 0.29920674817340387\n",
            "At step: 8880 training error: 0.2936948048904086\n",
            "At step: 8881 training error: 0.30564548613177306\n",
            "At step: 8882 training error: 0.3067490842486299\n",
            "At step: 8883 training error: 0.3196755651000227\n",
            "At step: 8884 training error: 0.3151782036030378\n",
            "At step: 8885 training error: 0.3019667276104661\n",
            "At step: 8886 training error: 0.30552168760347115\n",
            "At step: 8887 training error: 0.29920448903346963\n",
            "At step: 8888 training error: 0.30745255630778023\n",
            "At step: 8889 training error: 0.3163462283432121\n",
            "At step: 8890 training error: 0.3221360835740284\n",
            "At step: 8891 training error: 0.3332478276578421\n",
            "At step: 8892 training error: 0.32575441126108906\n",
            "At step: 8893 training error: 0.3178342844549674\n",
            "At step: 8894 training error: 0.31311045785933267\n",
            "At step: 8895 training error: 0.3169024673283304\n",
            "At step: 8896 training error: 0.3142091428825568\n",
            "At step: 8897 training error: 0.3094943575834847\n",
            "At step: 8898 training error: 0.3080060360149547\n",
            "At step: 8899 training error: 0.3095649018812894\n",
            "At step: 8900 training error: 0.318600092052797\n",
            "At step: 8901 training error: 0.320840142345755\n",
            "At step: 8902 training error: 0.3094904375488528\n",
            "At step: 8903 training error: 0.30403070724855863\n",
            "At step: 8904 training error: 0.3129401023083787\n",
            "At step: 8905 training error: 0.3218598103606861\n",
            "At step: 8906 training error: 0.3118472176726472\n",
            "At step: 8907 training error: 0.30874692754278826\n",
            "At step: 8908 training error: 0.3111450632027305\n",
            "At step: 8909 training error: 0.31064832961883626\n",
            "At step: 8910 training error: 0.31095570093935404\n",
            "At step: 8911 training error: 0.3154547334469316\n",
            "At step: 8912 training error: 0.31818736549379106\n",
            "At step: 8913 training error: 0.30880216376133046\n",
            "At step: 8914 training error: 0.30001950991393395\n",
            "At step: 8915 training error: 0.2955369453758495\n",
            "At step: 8916 training error: 0.30163658905861473\n",
            "At step: 8917 training error: 0.3011583505005727\n",
            "At step: 8918 training error: 0.29539777980868803\n",
            "At step: 8919 training error: 0.2986005039974433\n",
            "At step: 8920 training error: 0.29794079590817735\n",
            "At step: 8921 training error: 0.292828710675108\n",
            "At step: 8922 training error: 0.3013724442170974\n",
            "At step: 8923 training error: 0.29143402785333233\n",
            "At step: 8924 training error: 0.29412901992985496\n",
            "At step: 8925 training error: 0.3006790548235298\n",
            "At step: 8926 training error: 0.2902297433540966\n",
            "At step: 8927 training error: 0.28757075859039877\n",
            "At step: 8928 training error: 0.2935702347891561\n",
            "At step: 8929 training error: 0.2910895800063824\n",
            "At step: 8930 training error: 0.2928520891183423\n",
            "At step: 8931 training error: 0.2925724267172037\n",
            "At step: 8932 training error: 0.288969853234291\n",
            "At step: 8933 training error: 0.2908221711771965\n",
            "At step: 8934 training error: 0.29096049568792476\n",
            "At step: 8935 training error: 0.29462323929988277\n",
            "At step: 8936 training error: 0.30236217852067954\n",
            "At step: 8937 training error: 0.3047070675950767\n",
            "At step: 8938 training error: 0.2982314761578442\n",
            "At step: 8939 training error: 0.2975203772088997\n",
            "At step: 8940 training error: 0.2980257434730777\n",
            "At step: 8941 training error: 0.29801979963446545\n",
            "At step: 8942 training error: 0.2894356494257806\n",
            "At step: 8943 training error: 0.3012986057854329\n",
            "At step: 8944 training error: 0.2933495007026734\n",
            "At step: 8945 training error: 0.28597008591274686\n",
            "At step: 8946 training error: 0.2829825265588575\n",
            "At step: 8947 training error: 0.2773191708809982\n",
            "At step: 8948 training error: 0.27143396031770495\n",
            "At step: 8949 training error: 0.2811348411695688\n",
            "At step: 8950 training error: 0.2743995281412252\n",
            "At step: 8951 training error: 0.2781883583022356\n",
            "At step: 8952 training error: 0.27091081311551646\n",
            "At step: 8953 training error: 0.2861832123695817\n",
            "At step: 8954 training error: 0.2806843258358045\n",
            "At step: 8955 training error: 0.27508354828900516\n",
            "At step: 8956 training error: 0.28334943011206826\n",
            "At step: 8957 training error: 0.28571066268695333\n",
            "At step: 8958 training error: 0.28824553652202634\n",
            "At step: 8959 training error: 0.27892573346400035\n",
            "At step: 8960 training error: 0.29599295342597615\n",
            "At step: 8961 training error: 0.28588633766198146\n",
            "At step: 8962 training error: 0.2832840003758784\n",
            "At step: 8963 training error: 0.2925529898763943\n",
            "At step: 8964 training error: 0.29189551035437794\n",
            "At step: 8965 training error: 0.29084418870690754\n",
            "At step: 8966 training error: 0.29600963605408337\n",
            "At step: 8967 training error: 0.2911621965076435\n",
            "At step: 8968 training error: 0.29407773150334854\n",
            "At step: 8969 training error: 0.29399176074892946\n",
            "At step: 8970 training error: 0.29028229145663786\n",
            "At step: 8971 training error: 0.29255191802532\n",
            "At step: 8972 training error: 0.2868958753374398\n",
            "At step: 8973 training error: 0.2772049989349082\n",
            "At step: 8974 training error: 0.26228408790856905\n",
            "At step: 8975 training error: 0.262568903879916\n",
            "At step: 8976 training error: 0.2582968146170891\n",
            "At step: 8977 training error: 0.2614061893718758\n",
            "At step: 8978 training error: 0.26060908470430766\n",
            "At step: 8979 training error: 0.26894871108461404\n",
            "At step: 8980 training error: 0.2623321959639305\n",
            "At step: 8981 training error: 0.2765631939296016\n",
            "At step: 8982 training error: 0.27981144639842886\n",
            "At step: 8983 training error: 0.280152110672848\n",
            "At step: 8984 training error: 0.28763963097359707\n",
            "At step: 8985 training error: 0.2790645722499321\n",
            "At step: 8986 training error: 0.2911849095124349\n",
            "At step: 8987 training error: 0.2860228072368357\n",
            "At step: 8988 training error: 0.28105262436851686\n",
            "At step: 8989 training error: 0.2892481304623911\n",
            "At step: 8990 training error: 0.2733602493982693\n",
            "At step: 8991 training error: 0.27854708853457144\n",
            "At step: 8992 training error: 0.2747147820991458\n",
            "At step: 8993 training error: 0.2859683592984438\n",
            "At step: 8994 training error: 0.2868434947051613\n",
            "At step: 8995 training error: 0.2738749260246909\n",
            "At step: 8996 training error: 0.2685547062281026\n",
            "At step: 8997 training error: 0.261318683225888\n",
            "At step: 8998 training error: 0.2652231895476067\n",
            "At step: 8999 training error: 0.2640593995074787\n",
            "At step: 9000 training error: 0.2711558485470609\n",
            "At step: 9001 training error: 0.26799747683009495\n",
            "At step: 9002 training error: 0.28127019380456586\n",
            "At step: 9003 training error: 0.28993800385196644\n",
            "At step: 9004 training error: 0.29680041870730967\n",
            "At step: 9005 training error: 0.29384501973344446\n",
            "At step: 9006 training error: 0.3068851851569137\n",
            "At step: 9007 training error: 0.31666799756863157\n",
            "At step: 9008 training error: 0.3088086954633841\n",
            "At step: 9009 training error: 0.3033115794984383\n",
            "At step: 9010 training error: 0.3076836484207359\n",
            "At step: 9011 training error: 0.303932661953421\n",
            "At step: 9012 training error: 0.3020375265522548\n",
            "At step: 9013 training error: 0.31404790691328377\n",
            "At step: 9014 training error: 0.324448300104773\n",
            "At step: 9015 training error: 0.30845678199944615\n",
            "At step: 9016 training error: 0.3095253241097348\n",
            "At step: 9017 training error: 0.3025331657719806\n",
            "At step: 9018 training error: 0.30669319383671784\n",
            "At step: 9019 training error: 0.3125397389365581\n",
            "At step: 9020 training error: 0.3099561160290912\n",
            "At step: 9021 training error: 0.3056035771111132\n",
            "At step: 9022 training error: 0.2980430154322886\n",
            "At step: 9023 training error: 0.30261949786937054\n",
            "At step: 9024 training error: 0.30165478368561083\n",
            "At step: 9025 training error: 0.30841235005749856\n",
            "At step: 9026 training error: 0.3028684869436642\n",
            "At step: 9027 training error: 0.3078474985396382\n",
            "At step: 9028 training error: 0.29908583394583765\n",
            "At step: 9029 training error: 0.2931361626020682\n",
            "At step: 9030 training error: 0.29107765283136156\n",
            "At step: 9031 training error: 0.29674597293523985\n",
            "At step: 9032 training error: 0.2934778692275301\n",
            "At step: 9033 training error: 0.29208027143168563\n",
            "At step: 9034 training error: 0.2887683715048944\n",
            "At step: 9035 training error: 0.29820250964772255\n",
            "At step: 9036 training error: 0.29017399001843913\n",
            "At step: 9037 training error: 0.30552500696255336\n",
            "At step: 9038 training error: 0.3076998739112234\n",
            "At step: 9039 training error: 0.3104383093956111\n",
            "At step: 9040 training error: 0.3109735489435675\n",
            "At step: 9041 training error: 0.3179017952464133\n",
            "At step: 9042 training error: 0.318823854013069\n",
            "At step: 9043 training error: 0.3105732079045151\n",
            "At step: 9044 training error: 0.311573845218445\n",
            "At step: 9045 training error: 0.30473360170927555\n",
            "At step: 9046 training error: 0.2944158165183215\n",
            "At step: 9047 training error: 0.29952927998003437\n",
            "At step: 9048 training error: 0.2979042355300702\n",
            "At step: 9049 training error: 0.2930929371446031\n",
            "At step: 9050 training error: 0.28737907170096366\n",
            "At step: 9051 training error: 0.29926558409907666\n",
            "At step: 9052 training error: 0.3012782246130457\n",
            "At step: 9053 training error: 0.30841421562484067\n",
            "At step: 9054 training error: 0.3092239000601486\n",
            "At step: 9055 training error: 0.2957150610869443\n",
            "At step: 9056 training error: 0.2975656028040465\n",
            "At step: 9057 training error: 0.2969508079994464\n",
            "At step: 9058 training error: 0.3088718207892672\n",
            "At step: 9059 training error: 0.3077959060844783\n",
            "At step: 9060 training error: 0.30754715188622106\n",
            "At step: 9061 training error: 0.31697545344141514\n",
            "At step: 9062 training error: 0.3110878700470176\n",
            "At step: 9063 training error: 0.30139828651612893\n",
            "At step: 9064 training error: 0.32489316199385926\n",
            "At step: 9065 training error: 0.3056104787220283\n",
            "At step: 9066 training error: 0.3103177993466599\n",
            "At step: 9067 training error: 0.31057527852457645\n",
            "At step: 9068 training error: 0.31254204705484495\n",
            "At step: 9069 training error: 0.3000027977616251\n",
            "At step: 9070 training error: 0.30013850498603306\n",
            "At step: 9071 training error: 0.29490654500966174\n",
            "At step: 9072 training error: 0.292586583728102\n",
            "At step: 9073 training error: 0.28145916253987613\n",
            "At step: 9074 training error: 0.2721087666696907\n",
            "At step: 9075 training error: 0.2769270403115775\n",
            "At step: 9076 training error: 0.2683747152010124\n",
            "At step: 9077 training error: 0.27408220289548024\n",
            "At step: 9078 training error: 0.2752472163390306\n",
            "At step: 9079 training error: 0.27940428924124844\n",
            "At step: 9080 training error: 0.2817749140668117\n",
            "At step: 9081 training error: 0.2808059420872298\n",
            "At step: 9082 training error: 0.2714122426720475\n",
            "At step: 9083 training error: 0.279953065787957\n",
            "At step: 9084 training error: 0.2814329956291477\n",
            "At step: 9085 training error: 0.2679297585336725\n",
            "At step: 9086 training error: 0.26870319501489787\n",
            "At step: 9087 training error: 0.2770351836626327\n",
            "At step: 9088 training error: 0.2710749051351494\n",
            "At step: 9089 training error: 0.2726312433080606\n",
            "At step: 9090 training error: 0.26667147832510074\n",
            "At step: 9091 training error: 0.2748127718290936\n",
            "At step: 9092 training error: 0.27696216834346227\n",
            "At step: 9093 training error: 0.2956395852765406\n",
            "At step: 9094 training error: 0.29029119672932785\n",
            "At step: 9095 training error: 0.291992859798572\n",
            "At step: 9096 training error: 0.28915713336682586\n",
            "At step: 9097 training error: 0.29289764584500894\n",
            "At step: 9098 training error: 0.2971513774329933\n",
            "At step: 9099 training error: 0.30731884424465156\n",
            "At step: 9100 training error: 0.3138441614097187\n",
            "At step: 9101 training error: 0.31317121997249403\n",
            "At step: 9102 training error: 0.3128161734361258\n",
            "At step: 9103 training error: 0.3305170296865131\n",
            "At step: 9104 training error: 0.3327091996455093\n",
            "At step: 9105 training error: 0.3485634314951462\n",
            "At step: 9106 training error: 0.34001014593760825\n",
            "At step: 9107 training error: 0.33784694740563553\n",
            "At step: 9108 training error: 0.3388306632145823\n",
            "At step: 9109 training error: 0.33522764844524044\n",
            "At step: 9110 training error: 0.33287313452560946\n",
            "At step: 9111 training error: 0.3310305288263918\n",
            "At step: 9112 training error: 0.33061596889362876\n",
            "At step: 9113 training error: 0.3282128042481492\n",
            "At step: 9114 training error: 0.34333283656249663\n",
            "At step: 9115 training error: 0.3256387623457354\n",
            "At step: 9116 training error: 0.32032657023713523\n",
            "At step: 9117 training error: 0.3304134145019573\n",
            "At step: 9118 training error: 0.327177040084576\n",
            "At step: 9119 training error: 0.3250087033721405\n",
            "At step: 9120 training error: 0.32757221315757395\n",
            "At step: 9121 training error: 0.3274771424521467\n",
            "At step: 9122 training error: 0.32794805686129636\n",
            "At step: 9123 training error: 0.3344553684348419\n",
            "At step: 9124 training error: 0.32797038249083654\n",
            "At step: 9125 training error: 0.334112208436647\n",
            "At step: 9126 training error: 0.32759551160805594\n",
            "At step: 9127 training error: 0.32279148570324334\n",
            "At step: 9128 training error: 0.32711157239680383\n",
            "At step: 9129 training error: 0.34523060200113653\n",
            "At step: 9130 training error: 0.3370983262069118\n",
            "At step: 9131 training error: 0.3394653262508395\n",
            "At step: 9132 training error: 0.33122101646289476\n",
            "At step: 9133 training error: 0.3361191822236578\n",
            "At step: 9134 training error: 0.3333612386218342\n",
            "At step: 9135 training error: 0.3277902775813859\n",
            "At step: 9136 training error: 0.32200332351591404\n",
            "At step: 9137 training error: 0.3163259117642086\n",
            "At step: 9138 training error: 0.3085128263846851\n",
            "At step: 9139 training error: 0.306667944444213\n",
            "At step: 9140 training error: 0.30623688116155046\n",
            "At step: 9141 training error: 0.32110612544365214\n",
            "At step: 9142 training error: 0.31389849175962925\n",
            "At step: 9143 training error: 0.3084311101587683\n",
            "At step: 9144 training error: 0.3038335533234658\n",
            "At step: 9145 training error: 0.3009407788896069\n",
            "At step: 9146 training error: 0.29326094530056607\n",
            "At step: 9147 training error: 0.28729782182604796\n",
            "At step: 9148 training error: 0.30570082529156456\n",
            "At step: 9149 training error: 0.3147427377196559\n",
            "At step: 9150 training error: 0.307430761392604\n",
            "At step: 9151 training error: 0.31772889468037563\n",
            "At step: 9152 training error: 0.3143841202248665\n",
            "At step: 9153 training error: 0.3196511455076478\n",
            "At step: 9154 training error: 0.3207422733052865\n",
            "At step: 9155 training error: 0.3172338887773974\n",
            "At step: 9156 training error: 0.31172099838111056\n",
            "At step: 9157 training error: 0.3200183064900937\n",
            "At step: 9158 training error: 0.3179038364543341\n",
            "At step: 9159 training error: 0.3192760223829166\n",
            "At step: 9160 training error: 0.31274969949735537\n",
            "At step: 9161 training error: 0.3058885100441985\n",
            "At step: 9162 training error: 0.3070555096160657\n",
            "At step: 9163 training error: 0.3104987365107432\n",
            "At step: 9164 training error: 0.3102005120973504\n",
            "At step: 9165 training error: 0.3105211442726975\n",
            "At step: 9166 training error: 0.30046522540623966\n",
            "At step: 9167 training error: 0.2992209262301524\n",
            "At step: 9168 training error: 0.3002754007446083\n",
            "At step: 9169 training error: 0.30283111712427874\n",
            "At step: 9170 training error: 0.31592533374980486\n",
            "At step: 9171 training error: 0.3172158601960093\n",
            "At step: 9172 training error: 0.3248371341971223\n",
            "At step: 9173 training error: 0.32518046663177197\n",
            "At step: 9174 training error: 0.3104508302817486\n",
            "At step: 9175 training error: 0.30029519072399496\n",
            "At step: 9176 training error: 0.2997534653180703\n",
            "At step: 9177 training error: 0.30847902660803483\n",
            "At step: 9178 training error: 0.3078387962746567\n",
            "At step: 9179 training error: 0.31379215825151896\n",
            "At step: 9180 training error: 0.32192500526580925\n",
            "At step: 9181 training error: 0.3329679806100364\n",
            "At step: 9182 training error: 0.32753232613174\n",
            "At step: 9183 training error: 0.3314006834926966\n",
            "At step: 9184 training error: 0.32316849498327854\n",
            "At step: 9185 training error: 0.3189936756906968\n",
            "At step: 9186 training error: 0.32676657760941014\n",
            "At step: 9187 training error: 0.31995340531172906\n",
            "At step: 9188 training error: 0.30578899515559443\n",
            "At step: 9189 training error: 0.31404481584264154\n",
            "At step: 9190 training error: 0.31179022097572723\n",
            "At step: 9191 training error: 0.3125642124498412\n",
            "At step: 9192 training error: 0.308318225874445\n",
            "At step: 9193 training error: 0.31140947022323767\n",
            "At step: 9194 training error: 0.3074903779693304\n",
            "At step: 9195 training error: 0.2996019134366097\n",
            "At step: 9196 training error: 0.2973382979972155\n",
            "At step: 9197 training error: 0.2934392822655172\n",
            "At step: 9198 training error: 0.28526626329446353\n",
            "At step: 9199 training error: 0.2843574667880956\n",
            "At step: 9200 training error: 0.29328767008342316\n",
            "At step: 9201 training error: 0.2879180391687532\n",
            "At step: 9202 training error: 0.2941651842609098\n",
            "At step: 9203 training error: 0.2859326481155379\n",
            "At step: 9204 training error: 0.2890176165272883\n",
            "At step: 9205 training error: 0.28588972713832145\n",
            "At step: 9206 training error: 0.300495633948247\n",
            "At step: 9207 training error: 0.30086497330450274\n",
            "At step: 9208 training error: 0.2906778326264059\n",
            "At step: 9209 training error: 0.28488124562647454\n",
            "At step: 9210 training error: 0.2894667824065303\n",
            "At step: 9211 training error: 0.2939071665860501\n",
            "At step: 9212 training error: 0.2877205355407645\n",
            "At step: 9213 training error: 0.3004944164426319\n",
            "At step: 9214 training error: 0.30479552344615835\n",
            "At step: 9215 training error: 0.3045427178796519\n",
            "At step: 9216 training error: 0.31086347143641996\n",
            "At step: 9217 training error: 0.303632054010893\n",
            "At step: 9218 training error: 0.2999788414245741\n",
            "At step: 9219 training error: 0.2969898171549021\n",
            "At step: 9220 training error: 0.29707578913091043\n",
            "At step: 9221 training error: 0.2941316813708887\n",
            "At step: 9222 training error: 0.29749710506555804\n",
            "At step: 9223 training error: 0.29427089639902976\n",
            "At step: 9224 training error: 0.29956245026573697\n",
            "At step: 9225 training error: 0.29765641757246303\n",
            "At step: 9226 training error: 0.2917390429081779\n",
            "At step: 9227 training error: 0.28953303477342346\n",
            "At step: 9228 training error: 0.2847587857073019\n",
            "At step: 9229 training error: 0.2935364193966166\n",
            "At step: 9230 training error: 0.29929178628495623\n",
            "At step: 9231 training error: 0.30710199091739143\n",
            "At step: 9232 training error: 0.31011222938680494\n",
            "At step: 9233 training error: 0.3058602196379513\n",
            "At step: 9234 training error: 0.3118502319457172\n",
            "At step: 9235 training error: 0.31064720289578984\n",
            "At step: 9236 training error: 0.31005794445719936\n",
            "At step: 9237 training error: 0.2955364507510637\n",
            "At step: 9238 training error: 0.2981177455337942\n",
            "At step: 9239 training error: 0.29481000085554776\n",
            "At step: 9240 training error: 0.29136427733502857\n",
            "At step: 9241 training error: 0.29426500252883075\n",
            "At step: 9242 training error: 0.30311482313486654\n",
            "At step: 9243 training error: 0.29920126862899404\n",
            "At step: 9244 training error: 0.2980325284066632\n",
            "At step: 9245 training error: 0.308341704208751\n",
            "At step: 9246 training error: 0.3096538047008975\n",
            "At step: 9247 training error: 0.30756740061098065\n",
            "At step: 9248 training error: 0.31049544158540354\n",
            "At step: 9249 training error: 0.3007615109999085\n",
            "At step: 9250 training error: 0.29813868663095466\n",
            "At step: 9251 training error: 0.29489875670169696\n",
            "At step: 9252 training error: 0.3091915531347073\n",
            "At step: 9253 training error: 0.30886247274660433\n",
            "At step: 9254 training error: 0.2978546828388395\n",
            "At step: 9255 training error: 0.30160570402964887\n",
            "At step: 9256 training error: 0.29953943476283423\n",
            "At step: 9257 training error: 0.3012874052937715\n",
            "At step: 9258 training error: 0.2954187467899692\n",
            "At step: 9259 training error: 0.3041338550339342\n",
            "At step: 9260 training error: 0.3056369214082527\n",
            "At step: 9261 training error: 0.3056202419554346\n",
            "At step: 9262 training error: 0.30511540513191965\n",
            "At step: 9263 training error: 0.3082554258149764\n",
            "At step: 9264 training error: 0.2993208219285299\n",
            "At step: 9265 training error: 0.30137953665750433\n",
            "At step: 9266 training error: 0.3002001367580036\n",
            "At step: 9267 training error: 0.2989689204369427\n",
            "At step: 9268 training error: 0.3110040131433311\n",
            "At step: 9269 training error: 0.30755897729544557\n",
            "At step: 9270 training error: 0.3071653293199957\n",
            "At step: 9271 training error: 0.31215396742077456\n",
            "At step: 9272 training error: 0.30416245856997604\n",
            "At step: 9273 training error: 0.3008221663837203\n",
            "At step: 9274 training error: 0.3068274414903984\n",
            "At step: 9275 training error: 0.30007149614046985\n",
            "At step: 9276 training error: 0.3010756230746544\n",
            "At step: 9277 training error: 0.2905991681666191\n",
            "At step: 9278 training error: 0.31025104850643703\n",
            "At step: 9279 training error: 0.3181018519690065\n",
            "At step: 9280 training error: 0.3167731933318405\n",
            "At step: 9281 training error: 0.30912058356331396\n",
            "At step: 9282 training error: 0.3016878399551534\n",
            "At step: 9283 training error: 0.30365910522848266\n",
            "At step: 9284 training error: 0.3104291670126982\n",
            "At step: 9285 training error: 0.3156047000135599\n",
            "At step: 9286 training error: 0.3115140424624723\n",
            "At step: 9287 training error: 0.30679254694796726\n",
            "At step: 9288 training error: 0.3055293832786956\n",
            "At step: 9289 training error: 0.298337156573605\n",
            "At step: 9290 training error: 0.29955972652842466\n",
            "At step: 9291 training error: 0.30263114093047816\n",
            "At step: 9292 training error: 0.2980075239998707\n",
            "At step: 9293 training error: 0.2904671047108943\n",
            "At step: 9294 training error: 0.28753788897809407\n",
            "At step: 9295 training error: 0.29478260589986305\n",
            "At step: 9296 training error: 0.2882389320810244\n",
            "At step: 9297 training error: 0.2910865613218772\n",
            "At step: 9298 training error: 0.30204576865313093\n",
            "At step: 9299 training error: 0.2951174887792855\n",
            "At step: 9300 training error: 0.29139319113768775\n",
            "At step: 9301 training error: 0.3009187221409366\n",
            "At step: 9302 training error: 0.31613093320094265\n",
            "At step: 9303 training error: 0.3077954058937992\n",
            "At step: 9304 training error: 0.3174795511541338\n",
            "At step: 9305 training error: 0.32248618279727037\n",
            "At step: 9306 training error: 0.31802974836805864\n",
            "At step: 9307 training error: 0.3206202319783744\n",
            "At step: 9308 training error: 0.3168460519345594\n",
            "At step: 9309 training error: 0.32156970512804006\n",
            "At step: 9310 training error: 0.31302751404962487\n",
            "At step: 9311 training error: 0.3081500256576696\n",
            "At step: 9312 training error: 0.3170245709664389\n",
            "At step: 9313 training error: 0.3135959221244977\n",
            "At step: 9314 training error: 0.31923757136936226\n",
            "At step: 9315 training error: 0.3082603636363586\n",
            "At step: 9316 training error: 0.30360523764412223\n",
            "At step: 9317 training error: 0.29251800380728443\n",
            "At step: 9318 training error: 0.29318401683386835\n",
            "At step: 9319 training error: 0.30241287290109864\n",
            "At step: 9320 training error: 0.3011172863659719\n",
            "At step: 9321 training error: 0.2957084577603389\n",
            "At step: 9322 training error: 0.287944999984044\n",
            "At step: 9323 training error: 0.2819335395890493\n",
            "At step: 9324 training error: 0.2816257397053198\n",
            "At step: 9325 training error: 0.2835520465795939\n",
            "At step: 9326 training error: 0.28585549672521415\n",
            "At step: 9327 training error: 0.285110047295111\n",
            "At step: 9328 training error: 0.2824491711928835\n",
            "At step: 9329 training error: 0.28341622509321274\n",
            "At step: 9330 training error: 0.28480296153467344\n",
            "At step: 9331 training error: 0.2922349769305804\n",
            "At step: 9332 training error: 0.2923873369342738\n",
            "At step: 9333 training error: 0.2928585779180679\n",
            "At step: 9334 training error: 0.29751775927508234\n",
            "At step: 9335 training error: 0.3016478331855679\n",
            "At step: 9336 training error: 0.31297987031417507\n",
            "At step: 9337 training error: 0.3217730549166766\n",
            "At step: 9338 training error: 0.3122738973204627\n",
            "At step: 9339 training error: 0.3057387635022185\n",
            "At step: 9340 training error: 0.30868195483997807\n",
            "At step: 9341 training error: 0.3133331863338924\n",
            "At step: 9342 training error: 0.3063349500601505\n",
            "At step: 9343 training error: 0.3070468563348397\n",
            "At step: 9344 training error: 0.3085307665712178\n",
            "At step: 9345 training error: 0.3123609085830659\n",
            "At step: 9346 training error: 0.3163788229247297\n",
            "At step: 9347 training error: 0.3116802292180243\n",
            "At step: 9348 training error: 0.3076361165423226\n",
            "At step: 9349 training error: 0.3119890252141791\n",
            "At step: 9350 training error: 0.30976957890097295\n",
            "At step: 9351 training error: 0.2991072766793645\n",
            "At step: 9352 training error: 0.30004944325607724\n",
            "At step: 9353 training error: 0.3081527666545514\n",
            "At step: 9354 training error: 0.3030721001583822\n",
            "At step: 9355 training error: 0.2947944747410418\n",
            "At step: 9356 training error: 0.28452501250614526\n",
            "At step: 9357 training error: 0.27953236368449486\n",
            "At step: 9358 training error: 0.2772046306879297\n",
            "At step: 9359 training error: 0.27686383368953127\n",
            "At step: 9360 training error: 0.2831199759878901\n",
            "At step: 9361 training error: 0.2740978048984626\n",
            "At step: 9362 training error: 0.2859794917187344\n",
            "At step: 9363 training error: 0.28771830431308926\n",
            "At step: 9364 training error: 0.2892714301782591\n",
            "At step: 9365 training error: 0.2934502229502715\n",
            "At step: 9366 training error: 0.2956064123089512\n",
            "At step: 9367 training error: 0.3040657230948704\n",
            "At step: 9368 training error: 0.30747527239530653\n",
            "At step: 9369 training error: 0.2986507175281809\n",
            "At step: 9370 training error: 0.2874046332366401\n",
            "At step: 9371 training error: 0.28850169628654604\n",
            "At step: 9372 training error: 0.29256574218297887\n",
            "At step: 9373 training error: 0.29180513684938\n",
            "At step: 9374 training error: 0.28861452968533685\n",
            "At step: 9375 training error: 0.290772915047533\n",
            "At step: 9376 training error: 0.29941844063410245\n",
            "At step: 9377 training error: 0.30296853338877927\n",
            "At step: 9378 training error: 0.29334312671727086\n",
            "At step: 9379 training error: 0.28957470936024443\n",
            "At step: 9380 training error: 0.2934105465334004\n",
            "At step: 9381 training error: 0.3017212186001519\n",
            "At step: 9382 training error: 0.29754774124404865\n",
            "At step: 9383 training error: 0.295741225076991\n",
            "At step: 9384 training error: 0.289599299185409\n",
            "At step: 9385 training error: 0.28237126826867104\n",
            "At step: 9386 training error: 0.28633747336898296\n",
            "At step: 9387 training error: 0.29399156116929337\n",
            "At step: 9388 training error: 0.2935015832558609\n",
            "At step: 9389 training error: 0.2864462689036225\n",
            "At step: 9390 training error: 0.2839122224976611\n",
            "At step: 9391 training error: 0.27571447716592373\n",
            "At step: 9392 training error: 0.27537681137702885\n",
            "At step: 9393 training error: 0.2766499640685202\n",
            "At step: 9394 training error: 0.27710231767778515\n",
            "At step: 9395 training error: 0.2873129647665812\n",
            "At step: 9396 training error: 0.2896021766646468\n",
            "At step: 9397 training error: 0.2927094797024209\n",
            "At step: 9398 training error: 0.3065099071574911\n",
            "At step: 9399 training error: 0.3032275353752629\n",
            "At step: 9400 training error: 0.2928980116965422\n",
            "At step: 9401 training error: 0.2981171446467687\n",
            "At step: 9402 training error: 0.30125620327895286\n",
            "At step: 9403 training error: 0.31494558692773056\n",
            "At step: 9404 training error: 0.3242301400050073\n",
            "At step: 9405 training error: 0.32929565704056296\n",
            "At step: 9406 training error: 0.31803057855712497\n",
            "At step: 9407 training error: 0.3093812864643464\n",
            "At step: 9408 training error: 0.30840183448484587\n",
            "At step: 9409 training error: 0.2959592276766461\n",
            "At step: 9410 training error: 0.2971115001991708\n",
            "At step: 9411 training error: 0.3189331360243248\n",
            "At step: 9412 training error: 0.32080110353943697\n",
            "At step: 9413 training error: 0.31460572890135113\n",
            "At step: 9414 training error: 0.30804254948115223\n",
            "At step: 9415 training error: 0.3019758800017567\n",
            "At step: 9416 training error: 0.29947128273455637\n",
            "At step: 9417 training error: 0.2908592337190921\n",
            "At step: 9418 training error: 0.2949893361661296\n",
            "At step: 9419 training error: 0.29746169379373655\n",
            "At step: 9420 training error: 0.28670241219288906\n",
            "At step: 9421 training error: 0.2971156164515388\n",
            "At step: 9422 training error: 0.3005708184109921\n",
            "At step: 9423 training error: 0.29776152720736\n",
            "At step: 9424 training error: 0.29940399562009634\n",
            "At step: 9425 training error: 0.2918008947622354\n",
            "At step: 9426 training error: 0.27865788848648193\n",
            "At step: 9427 training error: 0.2803407386998693\n",
            "At step: 9428 training error: 0.27953485385583743\n",
            "At step: 9429 training error: 0.27973159894858396\n",
            "At step: 9430 training error: 0.28476674585832307\n",
            "At step: 9431 training error: 0.28416487382667527\n",
            "At step: 9432 training error: 0.29135386344114844\n",
            "At step: 9433 training error: 0.29901783473247256\n",
            "At step: 9434 training error: 0.299219886934166\n",
            "At step: 9435 training error: 0.2965599556299354\n",
            "At step: 9436 training error: 0.307962099038912\n",
            "At step: 9437 training error: 0.30976965780130655\n",
            "At step: 9438 training error: 0.3049936365747556\n",
            "At step: 9439 training error: 0.30334277015494043\n",
            "At step: 9440 training error: 0.315289810953465\n",
            "At step: 9441 training error: 0.3173008978943304\n",
            "At step: 9442 training error: 0.3184766370853809\n",
            "At step: 9443 training error: 0.3064759132066902\n",
            "At step: 9444 training error: 0.3074042170550763\n",
            "At step: 9445 training error: 0.3046016702356792\n",
            "At step: 9446 training error: 0.3018027982797096\n",
            "At step: 9447 training error: 0.3007051390315287\n",
            "At step: 9448 training error: 0.2955767656565993\n",
            "At step: 9449 training error: 0.29673513307240623\n",
            "At step: 9450 training error: 0.2914356239045625\n",
            "At step: 9451 training error: 0.2887109749189727\n",
            "At step: 9452 training error: 0.29891436899099744\n",
            "At step: 9453 training error: 0.2945328455535038\n",
            "At step: 9454 training error: 0.2976221185447652\n",
            "At step: 9455 training error: 0.3025641389612039\n",
            "At step: 9456 training error: 0.29912238322428586\n",
            "At step: 9457 training error: 0.31606633801345685\n",
            "At step: 9458 training error: 0.3090155898609861\n",
            "At step: 9459 training error: 0.30979727820840397\n",
            "At step: 9460 training error: 0.2997429316280368\n",
            "At step: 9461 training error: 0.2915056084448385\n",
            "At step: 9462 training error: 0.28910340311380056\n",
            "At step: 9463 training error: 0.2926511222809328\n",
            "At step: 9464 training error: 0.2844871804017399\n",
            "At step: 9465 training error: 0.2854725853672201\n",
            "At step: 9466 training error: 0.2906516007556115\n",
            "At step: 9467 training error: 0.3058590704164799\n",
            "At step: 9468 training error: 0.3056676594649881\n",
            "At step: 9469 training error: 0.292583139947061\n",
            "At step: 9470 training error: 0.28519456815792366\n",
            "At step: 9471 training error: 0.2945861169720029\n",
            "At step: 9472 training error: 0.29356818843495847\n",
            "At step: 9473 training error: 0.30061476905504697\n",
            "At step: 9474 training error: 0.30273086315624675\n",
            "At step: 9475 training error: 0.30508120936892014\n",
            "At step: 9476 training error: 0.30793932985206435\n",
            "At step: 9477 training error: 0.30691668757626084\n",
            "At step: 9478 training error: 0.3056371980549251\n",
            "At step: 9479 training error: 0.3006108418321806\n",
            "At step: 9480 training error: 0.3007304105817322\n",
            "At step: 9481 training error: 0.307285028334177\n",
            "At step: 9482 training error: 0.2961362917393144\n",
            "At step: 9483 training error: 0.2947264311759947\n",
            "At step: 9484 training error: 0.28029057092843523\n",
            "At step: 9485 training error: 0.2814274474949813\n",
            "At step: 9486 training error: 0.27334306640329986\n",
            "At step: 9487 training error: 0.2787989039405293\n",
            "At step: 9488 training error: 0.28105215171711334\n",
            "At step: 9489 training error: 0.2766369666742726\n",
            "At step: 9490 training error: 0.2781647205162191\n",
            "At step: 9491 training error: 0.2747932444018902\n",
            "At step: 9492 training error: 0.28520539268840966\n",
            "At step: 9493 training error: 0.2874631638208094\n",
            "At step: 9494 training error: 0.2807981916406205\n",
            "At step: 9495 training error: 0.27776655747474577\n",
            "At step: 9496 training error: 0.2828155280320989\n",
            "At step: 9497 training error: 0.2778373286914053\n",
            "At step: 9498 training error: 0.2843936340751362\n",
            "At step: 9499 training error: 0.2771984813295658\n",
            "At step: 9500 training error: 0.27230026192690787\n",
            "At step: 9501 training error: 0.2735459411290386\n",
            "At step: 9502 training error: 0.26255493567034044\n",
            "At step: 9503 training error: 0.27048177658559375\n",
            "At step: 9504 training error: 0.25979623522829\n",
            "At step: 9505 training error: 0.2712239691235225\n",
            "At step: 9506 training error: 0.2762889278313846\n",
            "At step: 9507 training error: 0.2776236212732989\n",
            "At step: 9508 training error: 0.2828583244158653\n",
            "At step: 9509 training error: 0.2852041283791125\n",
            "At step: 9510 training error: 0.29870385226884394\n",
            "At step: 9511 training error: 0.30251954633433836\n",
            "At step: 9512 training error: 0.3177278412816434\n",
            "At step: 9513 training error: 0.31790992289041126\n",
            "At step: 9514 training error: 0.32436005132213774\n",
            "At step: 9515 training error: 0.3224869555420614\n",
            "At step: 9516 training error: 0.3160404998131613\n",
            "At step: 9517 training error: 0.31520756306405895\n",
            "At step: 9518 training error: 0.31511079148746524\n",
            "At step: 9519 training error: 0.3215226349645843\n",
            "At step: 9520 training error: 0.3082859446968779\n",
            "At step: 9521 training error: 0.30774831207122993\n",
            "At step: 9522 training error: 0.3126674566580625\n",
            "At step: 9523 training error: 0.31697058484667473\n",
            "At step: 9524 training error: 0.30972901291750077\n",
            "At step: 9525 training error: 0.30140838965872774\n",
            "At step: 9526 training error: 0.29666749597634573\n",
            "At step: 9527 training error: 0.2970471805513746\n",
            "At step: 9528 training error: 0.29788568777642904\n",
            "At step: 9529 training error: 0.2956733747278302\n",
            "At step: 9530 training error: 0.29581398426307165\n",
            "At step: 9531 training error: 0.29570630474532233\n",
            "At step: 9532 training error: 0.30356519358859163\n",
            "At step: 9533 training error: 0.3024151119489312\n",
            "At step: 9534 training error: 0.2897989199885606\n",
            "At step: 9535 training error: 0.2857735911236562\n",
            "At step: 9536 training error: 0.27227072334125907\n",
            "At step: 9537 training error: 0.2833798638391259\n",
            "At step: 9538 training error: 0.2828804292899667\n",
            "At step: 9539 training error: 0.28757009302703224\n",
            "At step: 9540 training error: 0.2889093506110484\n",
            "At step: 9541 training error: 0.2986606445464738\n",
            "At step: 9542 training error: 0.29105961382115836\n",
            "At step: 9543 training error: 0.28841672203432445\n",
            "At step: 9544 training error: 0.28470483923347706\n",
            "At step: 9545 training error: 0.2943332912183865\n",
            "At step: 9546 training error: 0.30327961020864136\n",
            "At step: 9547 training error: 0.29370322506882335\n",
            "At step: 9548 training error: 0.300124629075405\n",
            "At step: 9549 training error: 0.2995800641065592\n",
            "At step: 9550 training error: 0.3022149584465669\n",
            "At step: 9551 training error: 0.310744478344429\n",
            "At step: 9552 training error: 0.31195765355825944\n",
            "At step: 9553 training error: 0.3148264518756735\n",
            "At step: 9554 training error: 0.3199131046980919\n",
            "At step: 9555 training error: 0.31920505726235193\n",
            "At step: 9556 training error: 0.3174997161738996\n",
            "At step: 9557 training error: 0.32041793338907254\n",
            "At step: 9558 training error: 0.322039211142079\n",
            "At step: 9559 training error: 0.3218577876128499\n",
            "At step: 9560 training error: 0.31760770776108915\n",
            "At step: 9561 training error: 0.30554633985600355\n",
            "At step: 9562 training error: 0.29757549702491837\n",
            "At step: 9563 training error: 0.30251111490116117\n",
            "At step: 9564 training error: 0.3065001311179766\n",
            "At step: 9565 training error: 0.3021302970438341\n",
            "At step: 9566 training error: 0.29201145777476106\n",
            "At step: 9567 training error: 0.2941551376387456\n",
            "At step: 9568 training error: 0.298982976348529\n",
            "At step: 9569 training error: 0.31279109613092476\n",
            "At step: 9570 training error: 0.30830118997221695\n",
            "At step: 9571 training error: 0.3096882247954766\n",
            "At step: 9572 training error: 0.30263456744401174\n",
            "At step: 9573 training error: 0.31684444136277656\n",
            "At step: 9574 training error: 0.3213067516990894\n",
            "At step: 9575 training error: 0.31419066417921704\n",
            "At step: 9576 training error: 0.30687259694345065\n",
            "At step: 9577 training error: 0.3127421616755838\n",
            "At step: 9578 training error: 0.3082368597525655\n",
            "At step: 9579 training error: 0.30171868359522286\n",
            "At step: 9580 training error: 0.2994157157172123\n",
            "At step: 9581 training error: 0.29227338772079603\n",
            "At step: 9582 training error: 0.3109926523117783\n",
            "At step: 9583 training error: 0.31266432022893703\n",
            "At step: 9584 training error: 0.31560060330110085\n",
            "At step: 9585 training error: 0.323280200259235\n",
            "At step: 9586 training error: 0.3240939537240826\n",
            "At step: 9587 training error: 0.33572129615641\n",
            "At step: 9588 training error: 0.328287427278211\n",
            "At step: 9589 training error: 0.32831686517013836\n",
            "At step: 9590 training error: 0.32372437077039656\n",
            "At step: 9591 training error: 0.31800061803435653\n",
            "At step: 9592 training error: 0.3233976980715698\n",
            "At step: 9593 training error: 0.31464976349805546\n",
            "At step: 9594 training error: 0.31794641732221707\n",
            "At step: 9595 training error: 0.3152934390480363\n",
            "At step: 9596 training error: 0.30777662769185754\n",
            "At step: 9597 training error: 0.30207272688291\n",
            "At step: 9598 training error: 0.30286062891190463\n",
            "At step: 9599 training error: 0.30787115156014044\n",
            "At step: 9600 training error: 0.2934036625915779\n",
            "At step: 9601 training error: 0.28565650278391624\n",
            "At step: 9602 training error: 0.2898215392216326\n",
            "At step: 9603 training error: 0.2947226318844286\n",
            "At step: 9604 training error: 0.29077116378332424\n",
            "At step: 9605 training error: 0.2874025807874068\n",
            "At step: 9606 training error: 0.2986788512839398\n",
            "At step: 9607 training error: 0.29671468680583307\n",
            "At step: 9608 training error: 0.298080570480957\n",
            "At step: 9609 training error: 0.30203320968869607\n",
            "At step: 9610 training error: 0.3132722779197228\n",
            "At step: 9611 training error: 0.306011642522543\n",
            "At step: 9612 training error: 0.3132282829750421\n",
            "At step: 9613 training error: 0.3104130394549018\n",
            "At step: 9614 training error: 0.3046271183198463\n",
            "At step: 9615 training error: 0.2925669940309203\n",
            "At step: 9616 training error: 0.29235585162711475\n",
            "At step: 9617 training error: 0.3029134405549749\n",
            "At step: 9618 training error: 0.29501364984881623\n",
            "At step: 9619 training error: 0.2945558370704213\n",
            "At step: 9620 training error: 0.3000382735379874\n",
            "At step: 9621 training error: 0.3010853365306331\n",
            "At step: 9622 training error: 0.2949622708945801\n",
            "At step: 9623 training error: 0.28992131191298715\n",
            "At step: 9624 training error: 0.2963146872477367\n",
            "At step: 9625 training error: 0.29682806352305807\n",
            "At step: 9626 training error: 0.2902782760636712\n",
            "At step: 9627 training error: 0.28730099105107576\n",
            "At step: 9628 training error: 0.2800047599675479\n",
            "At step: 9629 training error: 0.27405979658265056\n",
            "At step: 9630 training error: 0.2711794357089253\n",
            "At step: 9631 training error: 0.2719221596646911\n",
            "At step: 9632 training error: 0.27784067684886476\n",
            "At step: 9633 training error: 0.28517942477134395\n",
            "At step: 9634 training error: 0.2773865896375148\n",
            "At step: 9635 training error: 0.28454965126635473\n",
            "At step: 9636 training error: 0.2804758064141271\n",
            "At step: 9637 training error: 0.26892501379732664\n",
            "At step: 9638 training error: 0.27839989636451923\n",
            "At step: 9639 training error: 0.27350344934056137\n",
            "At step: 9640 training error: 0.27249133824197613\n",
            "At step: 9641 training error: 0.27197008176172016\n",
            "At step: 9642 training error: 0.2714933763282817\n",
            "At step: 9643 training error: 0.26895595761516883\n",
            "At step: 9644 training error: 0.2605675879490302\n",
            "At step: 9645 training error: 0.26562290682949896\n",
            "At step: 9646 training error: 0.2701275610403116\n",
            "At step: 9647 training error: 0.2664880836309523\n",
            "At step: 9648 training error: 0.26545063942530356\n",
            "At step: 9649 training error: 0.26135390450396173\n",
            "At step: 9650 training error: 0.269870590768751\n",
            "At step: 9651 training error: 0.2629419065225378\n",
            "At step: 9652 training error: 0.2635099989009585\n",
            "At step: 9653 training error: 0.26600909555165847\n",
            "At step: 9654 training error: 0.2631727280212341\n",
            "At step: 9655 training error: 0.2641572709767396\n",
            "At step: 9656 training error: 0.26018912225422375\n",
            "At step: 9657 training error: 0.2636966555883425\n",
            "At step: 9658 training error: 0.26637510412209625\n",
            "At step: 9659 training error: 0.27362071381060316\n",
            "At step: 9660 training error: 0.2713525485561645\n",
            "At step: 9661 training error: 0.2673046039188204\n",
            "At step: 9662 training error: 0.27382371292931684\n",
            "At step: 9663 training error: 0.27264826907455286\n",
            "At step: 9664 training error: 0.2758543474611304\n",
            "At step: 9665 training error: 0.29077132302757885\n",
            "At step: 9666 training error: 0.2963139064970945\n",
            "At step: 9667 training error: 0.2938603886550847\n",
            "At step: 9668 training error: 0.3001744899306343\n",
            "At step: 9669 training error: 0.29777037334110457\n",
            "At step: 9670 training error: 0.29410503725579407\n",
            "At step: 9671 training error: 0.30137965304199527\n",
            "At step: 9672 training error: 0.28492546985628653\n",
            "At step: 9673 training error: 0.2861587166871662\n",
            "At step: 9674 training error: 0.28999490367960334\n",
            "At step: 9675 training error: 0.282291075086408\n",
            "At step: 9676 training error: 0.2817500115844772\n",
            "At step: 9677 training error: 0.27846341800625024\n",
            "At step: 9678 training error: 0.26135500528958244\n",
            "At step: 9679 training error: 0.2638019047574535\n",
            "At step: 9680 training error: 0.2604395372422752\n",
            "At step: 9681 training error: 0.26343241933230843\n",
            "At step: 9682 training error: 0.26150649238464646\n",
            "At step: 9683 training error: 0.27500810272648807\n",
            "At step: 9684 training error: 0.2691982471971756\n",
            "At step: 9685 training error: 0.28274840830455306\n",
            "At step: 9686 training error: 0.27157811348001165\n",
            "At step: 9687 training error: 0.2708201936199325\n",
            "At step: 9688 training error: 0.267534403980781\n",
            "At step: 9689 training error: 0.26389914528219854\n",
            "At step: 9690 training error: 0.2732373508294548\n",
            "At step: 9691 training error: 0.26956505647922857\n",
            "At step: 9692 training error: 0.2754798199226807\n",
            "At step: 9693 training error: 0.27799236335917427\n",
            "At step: 9694 training error: 0.27194855102878046\n",
            "At step: 9695 training error: 0.2755626890323136\n",
            "At step: 9696 training error: 0.27072573423689034\n",
            "At step: 9697 training error: 0.27744426207018136\n",
            "At step: 9698 training error: 0.2909830321449352\n",
            "At step: 9699 training error: 0.28670805620342416\n",
            "At step: 9700 training error: 0.28679915850236865\n",
            "At step: 9701 training error: 0.2788956560879243\n",
            "At step: 9702 training error: 0.2830354467577812\n",
            "At step: 9703 training error: 0.2966278600277316\n",
            "At step: 9704 training error: 0.28904043689534864\n",
            "At step: 9705 training error: 0.2884952328081894\n",
            "At step: 9706 training error: 0.2868548394702167\n",
            "At step: 9707 training error: 0.28837042358320086\n",
            "At step: 9708 training error: 0.29244166895582613\n",
            "At step: 9709 training error: 0.2914484889528481\n",
            "At step: 9710 training error: 0.2902208131870626\n",
            "At step: 9711 training error: 0.2949439942245778\n",
            "At step: 9712 training error: 0.2923316314018975\n",
            "At step: 9713 training error: 0.29017303684857726\n",
            "At step: 9714 training error: 0.29110315500171463\n",
            "At step: 9715 training error: 0.28861026596102923\n",
            "At step: 9716 training error: 0.28663187964415654\n",
            "At step: 9717 training error: 0.2941864700260078\n",
            "At step: 9718 training error: 0.2890372414407487\n",
            "At step: 9719 training error: 0.29703486157991715\n",
            "At step: 9720 training error: 0.29171474672751785\n",
            "At step: 9721 training error: 0.2914953017776114\n",
            "At step: 9722 training error: 0.3012509690326701\n",
            "At step: 9723 training error: 0.2919802433539096\n",
            "At step: 9724 training error: 0.28390078098624516\n",
            "At step: 9725 training error: 0.27869142819738385\n",
            "At step: 9726 training error: 0.2813710730955282\n",
            "At step: 9727 training error: 0.2807847610665498\n",
            "At step: 9728 training error: 0.27003500963834964\n",
            "At step: 9729 training error: 0.27393227646994195\n",
            "At step: 9730 training error: 0.2700931982224048\n",
            "At step: 9731 training error: 0.27957603485742993\n",
            "At step: 9732 training error: 0.27019789522299864\n",
            "At step: 9733 training error: 0.2670284017273597\n",
            "At step: 9734 training error: 0.2661277685741261\n",
            "At step: 9735 training error: 0.27606708719301\n",
            "At step: 9736 training error: 0.27846278045673606\n",
            "At step: 9737 training error: 0.26964679579593265\n",
            "At step: 9738 training error: 0.2636455801256768\n",
            "At step: 9739 training error: 0.2710856953173098\n",
            "At step: 9740 training error: 0.27206115667287634\n",
            "At step: 9741 training error: 0.2705167758803918\n",
            "At step: 9742 training error: 0.2682062730045313\n",
            "At step: 9743 training error: 0.2718002335675504\n",
            "At step: 9744 training error: 0.27346203741046765\n",
            "At step: 9745 training error: 0.2860295839811667\n",
            "At step: 9746 training error: 0.28922155082344864\n",
            "At step: 9747 training error: 0.2828849960572952\n",
            "At step: 9748 training error: 0.2838138645012774\n",
            "At step: 9749 training error: 0.2826536393457278\n",
            "At step: 9750 training error: 0.2766050095153969\n",
            "At step: 9751 training error: 0.29148518247840055\n",
            "At step: 9752 training error: 0.3006424171345986\n",
            "At step: 9753 training error: 0.3073906385131601\n",
            "At step: 9754 training error: 0.3016279048327255\n",
            "At step: 9755 training error: 0.3042446345966637\n",
            "At step: 9756 training error: 0.3063681444962461\n",
            "At step: 9757 training error: 0.3131828596780631\n",
            "At step: 9758 training error: 0.31111850199444796\n",
            "At step: 9759 training error: 0.30921525666438415\n",
            "At step: 9760 training error: 0.30903378216526756\n",
            "At step: 9761 training error: 0.3108964934600562\n",
            "At step: 9762 training error: 0.3064975963493678\n",
            "At step: 9763 training error: 0.3088581284473668\n",
            "At step: 9764 training error: 0.30098257958514263\n",
            "At step: 9765 training error: 0.29910433088245003\n",
            "At step: 9766 training error: 0.29522880709110483\n",
            "At step: 9767 training error: 0.29470978671113024\n",
            "At step: 9768 training error: 0.3103790307587645\n",
            "At step: 9769 training error: 0.30742518860605184\n",
            "At step: 9770 training error: 0.2926360385096737\n",
            "At step: 9771 training error: 0.301182339222997\n",
            "At step: 9772 training error: 0.3005432462780045\n",
            "At step: 9773 training error: 0.3010028323997995\n",
            "At step: 9774 training error: 0.3053152985157354\n",
            "At step: 9775 training error: 0.32092167765835733\n",
            "At step: 9776 training error: 0.31991559039231005\n",
            "At step: 9777 training error: 0.31369894834233647\n",
            "At step: 9778 training error: 0.32281928843266977\n",
            "At step: 9779 training error: 0.32369068200866447\n",
            "At step: 9780 training error: 0.32850726525181523\n",
            "At step: 9781 training error: 0.334447723777548\n",
            "At step: 9782 training error: 0.3364134228986517\n",
            "At step: 9783 training error: 0.32840985382818344\n",
            "At step: 9784 training error: 0.3360763184807776\n",
            "At step: 9785 training error: 0.33298703048267453\n",
            "At step: 9786 training error: 0.32904997563526656\n",
            "At step: 9787 training error: 0.3225127505927364\n",
            "At step: 9788 training error: 0.3141889349392271\n",
            "At step: 9789 training error: 0.3123624521900949\n",
            "At step: 9790 training error: 0.3010031558750339\n",
            "At step: 9791 training error: 0.30442181610102836\n",
            "At step: 9792 training error: 0.2997873500020368\n",
            "At step: 9793 training error: 0.2921779415102043\n",
            "At step: 9794 training error: 0.2898670755310035\n",
            "At step: 9795 training error: 0.2837535486484806\n",
            "At step: 9796 training error: 0.275312930764815\n",
            "At step: 9797 training error: 0.2751432253763193\n",
            "At step: 9798 training error: 0.2769606944227424\n",
            "At step: 9799 training error: 0.2770341691154285\n",
            "At step: 9800 training error: 0.2891924658104214\n",
            "At step: 9801 training error: 0.29378031832374585\n",
            "At step: 9802 training error: 0.30599580790663744\n",
            "At step: 9803 training error: 0.29683324779698483\n",
            "At step: 9804 training error: 0.29567179776935265\n",
            "At step: 9805 training error: 0.2927279996393535\n",
            "At step: 9806 training error: 0.2948685758303648\n",
            "At step: 9807 training error: 0.2973601093847896\n",
            "At step: 9808 training error: 0.2965042405834772\n",
            "At step: 9809 training error: 0.2894136251035519\n",
            "At step: 9810 training error: 0.2874244885248444\n",
            "At step: 9811 training error: 0.28307637019604404\n",
            "At step: 9812 training error: 0.27313633181746944\n",
            "At step: 9813 training error: 0.27507105598289466\n",
            "At step: 9814 training error: 0.2690163681549842\n",
            "At step: 9815 training error: 0.2697533143725229\n",
            "At step: 9816 training error: 0.2669226587989563\n",
            "At step: 9817 training error: 0.2704802915294085\n",
            "At step: 9818 training error: 0.2753150610114348\n",
            "At step: 9819 training error: 0.27646886973255363\n",
            "At step: 9820 training error: 0.27462000407125875\n",
            "At step: 9821 training error: 0.2694213321595088\n",
            "At step: 9822 training error: 0.272619292715161\n",
            "At step: 9823 training error: 0.28236118459163345\n",
            "At step: 9824 training error: 0.293198550691643\n",
            "At step: 9825 training error: 0.29251564680697945\n",
            "At step: 9826 training error: 0.2864386318199143\n",
            "At step: 9827 training error: 0.2846283095287821\n",
            "At step: 9828 training error: 0.2798657557495986\n",
            "At step: 9829 training error: 0.2836101440619283\n",
            "At step: 9830 training error: 0.28067911795343076\n",
            "At step: 9831 training error: 0.26825601329751375\n",
            "At step: 9832 training error: 0.2682194962911686\n",
            "At step: 9833 training error: 0.2658513693606863\n",
            "At step: 9834 training error: 0.2693966907148382\n",
            "At step: 9835 training error: 0.2750069731097155\n",
            "At step: 9836 training error: 0.28215847515394304\n",
            "At step: 9837 training error: 0.2827345022259393\n",
            "At step: 9838 training error: 0.28964950644894594\n",
            "At step: 9839 training error: 0.3099553187752747\n",
            "At step: 9840 training error: 0.30140980090931635\n",
            "At step: 9841 training error: 0.2976427465581018\n",
            "At step: 9842 training error: 0.289399263943961\n",
            "At step: 9843 training error: 0.28883820205924554\n",
            "At step: 9844 training error: 0.289626893091698\n",
            "At step: 9845 training error: 0.2965716944800242\n",
            "At step: 9846 training error: 0.3023891634357267\n",
            "At step: 9847 training error: 0.3073008223527358\n",
            "At step: 9848 training error: 0.3051836656331836\n",
            "At step: 9849 training error: 0.30751972442524056\n",
            "At step: 9850 training error: 0.3014569766866108\n",
            "At step: 9851 training error: 0.29743983382478084\n",
            "At step: 9852 training error: 0.3108824709694854\n",
            "At step: 9853 training error: 0.3061076364500135\n",
            "At step: 9854 training error: 0.31938693181850264\n",
            "At step: 9855 training error: 0.3149603579905568\n",
            "At step: 9856 training error: 0.3108916109611263\n",
            "At step: 9857 training error: 0.31273389765229637\n",
            "At step: 9858 training error: 0.3105659247773717\n",
            "At step: 9859 training error: 0.3049507271168588\n",
            "At step: 9860 training error: 0.29984354868264\n",
            "At step: 9861 training error: 0.29393164150682644\n",
            "At step: 9862 training error: 0.2947381597419542\n",
            "At step: 9863 training error: 0.31082350544379095\n",
            "At step: 9864 training error: 0.31588999126448297\n",
            "At step: 9865 training error: 0.32170723748157726\n",
            "At step: 9866 training error: 0.32858089691214976\n",
            "At step: 9867 training error: 0.31591180989591483\n",
            "At step: 9868 training error: 0.32726454076402045\n",
            "At step: 9869 training error: 0.3230065657425598\n",
            "At step: 9870 training error: 0.3193198633971732\n",
            "At step: 9871 training error: 0.30826127491637717\n",
            "At step: 9872 training error: 0.3051616819026007\n",
            "At step: 9873 training error: 0.29565067668529155\n",
            "At step: 9874 training error: 0.28931885654355627\n",
            "At step: 9875 training error: 0.28597219712120797\n",
            "At step: 9876 training error: 0.3047730862489509\n",
            "At step: 9877 training error: 0.3009101808059373\n",
            "At step: 9878 training error: 0.2939773153527823\n",
            "At step: 9879 training error: 0.30125094240133854\n",
            "At step: 9880 training error: 0.3092534784554783\n",
            "At step: 9881 training error: 0.322031521686693\n",
            "At step: 9882 training error: 0.32555493450658474\n",
            "At step: 9883 training error: 0.3185608736779698\n",
            "At step: 9884 training error: 0.3177402183403718\n",
            "At step: 9885 training error: 0.312308441546303\n",
            "At step: 9886 training error: 0.3125002776387168\n",
            "At step: 9887 training error: 0.3133037606374904\n",
            "At step: 9888 training error: 0.3199850156873284\n",
            "At step: 9889 training error: 0.3143489452373061\n",
            "At step: 9890 training error: 0.31638807710102496\n",
            "At step: 9891 training error: 0.32349937211938107\n",
            "At step: 9892 training error: 0.32851087656680583\n",
            "At step: 9893 training error: 0.31816592219973117\n",
            "At step: 9894 training error: 0.3165320506421732\n",
            "At step: 9895 training error: 0.3095474869342282\n",
            "At step: 9896 training error: 0.3073306612707795\n",
            "At step: 9897 training error: 0.3078702960452598\n",
            "At step: 9898 training error: 0.30116973944714814\n",
            "At step: 9899 training error: 0.30401856852606957\n",
            "At step: 9900 training error: 0.2979257044954902\n",
            "At step: 9901 training error: 0.29417730170263534\n",
            "At step: 9902 training error: 0.28804643623501613\n",
            "At step: 9903 training error: 0.28639071312622943\n",
            "At step: 9904 training error: 0.2810039386926396\n",
            "At step: 9905 training error: 0.2815468461356116\n",
            "At step: 9906 training error: 0.27734375628377567\n",
            "At step: 9907 training error: 0.28284502679805057\n",
            "At step: 9908 training error: 0.2768320794070268\n",
            "At step: 9909 training error: 0.2882702211040701\n",
            "At step: 9910 training error: 0.2941039167747211\n",
            "At step: 9911 training error: 0.2954956425402833\n",
            "At step: 9912 training error: 0.2858990025457664\n",
            "At step: 9913 training error: 0.2870138431493864\n",
            "At step: 9914 training error: 0.2845722689075754\n",
            "At step: 9915 training error: 0.28056582714419404\n",
            "At step: 9916 training error: 0.2773118365757139\n",
            "At step: 9917 training error: 0.28639150546999914\n",
            "At step: 9918 training error: 0.28400050892250517\n",
            "At step: 9919 training error: 0.29868511810519355\n",
            "At step: 9920 training error: 0.3048211706277527\n",
            "At step: 9921 training error: 0.31094758855221516\n",
            "At step: 9922 training error: 0.30385372798155935\n",
            "At step: 9923 training error: 0.3029991211208328\n",
            "At step: 9924 training error: 0.30152931789164233\n",
            "At step: 9925 training error: 0.2963880468679007\n",
            "At step: 9926 training error: 0.3102247547542587\n",
            "At step: 9927 training error: 0.2991134738009446\n",
            "At step: 9928 training error: 0.2942214458412853\n",
            "At step: 9929 training error: 0.30520326260109587\n",
            "At step: 9930 training error: 0.29025614886274137\n",
            "At step: 9931 training error: 0.2969815337250164\n",
            "At step: 9932 training error: 0.30603544011940964\n",
            "At step: 9933 training error: 0.3116888452191725\n",
            "At step: 9934 training error: 0.31311303685776853\n",
            "At step: 9935 training error: 0.30596431198824664\n",
            "At step: 9936 training error: 0.30398327198753183\n",
            "At step: 9937 training error: 0.29543524940997756\n",
            "At step: 9938 training error: 0.2910746020643515\n",
            "At step: 9939 training error: 0.2922551327976885\n",
            "At step: 9940 training error: 0.2814013153867713\n",
            "At step: 9941 training error: 0.28300650210580175\n",
            "At step: 9942 training error: 0.2795153100501749\n",
            "At step: 9943 training error: 0.28039025498846964\n",
            "At step: 9944 training error: 0.27923100021713443\n",
            "At step: 9945 training error: 0.28087955569072054\n",
            "At step: 9946 training error: 0.281967365213178\n",
            "At step: 9947 training error: 0.28316418561634477\n",
            "At step: 9948 training error: 0.28893526951870674\n",
            "At step: 9949 training error: 0.29171138750520176\n",
            "At step: 9950 training error: 0.297377046071038\n",
            "At step: 9951 training error: 0.29606318501283\n",
            "At step: 9952 training error: 0.2955628449483224\n",
            "At step: 9953 training error: 0.291998594494413\n",
            "At step: 9954 training error: 0.2931237418161865\n",
            "At step: 9955 training error: 0.3023879942337754\n",
            "At step: 9956 training error: 0.3036729494637812\n",
            "At step: 9957 training error: 0.30457587005826087\n",
            "At step: 9958 training error: 0.31804934722656847\n",
            "At step: 9959 training error: 0.308659125195749\n",
            "At step: 9960 training error: 0.3055049368241987\n",
            "At step: 9961 training error: 0.3049222731001929\n",
            "At step: 9962 training error: 0.3003394640796126\n",
            "At step: 9963 training error: 0.30159092655041914\n",
            "At step: 9964 training error: 0.3050519394759244\n",
            "At step: 9965 training error: 0.30637185497000374\n",
            "At step: 9966 training error: 0.31455575275323633\n",
            "At step: 9967 training error: 0.30827010284106465\n",
            "At step: 9968 training error: 0.31603030296543966\n",
            "At step: 9969 training error: 0.3267940838953998\n",
            "At step: 9970 training error: 0.3142443867286313\n",
            "At step: 9971 training error: 0.30861637408807424\n",
            "At step: 9972 training error: 0.3090506484543998\n",
            "At step: 9973 training error: 0.3012443031539147\n",
            "At step: 9974 training error: 0.2960408683327987\n",
            "At step: 9975 training error: 0.30046816829631556\n",
            "At step: 9976 training error: 0.30196488592866766\n",
            "At step: 9977 training error: 0.30197358847752975\n",
            "At step: 9978 training error: 0.29774839091330535\n",
            "At step: 9979 training error: 0.29553761624110275\n",
            "At step: 9980 training error: 0.3061323304161069\n",
            "At step: 9981 training error: 0.31954885910825914\n",
            "At step: 9982 training error: 0.31305694199647977\n",
            "At step: 9983 training error: 0.3054421544404703\n",
            "At step: 9984 training error: 0.2970519753772839\n",
            "At step: 9985 training error: 0.2950516445964026\n",
            "At step: 9986 training error: 0.2872410088597218\n",
            "At step: 9987 training error: 0.28581237809693416\n",
            "At step: 9988 training error: 0.2821561570433375\n",
            "At step: 9989 training error: 0.2838155623756399\n",
            "At step: 9990 training error: 0.2960361188666585\n",
            "At step: 9991 training error: 0.29637994686591257\n",
            "At step: 9992 training error: 0.3089479322233559\n",
            "At step: 9993 training error: 0.3112068095617203\n",
            "At step: 9994 training error: 0.3169122286615191\n",
            "At step: 9995 training error: 0.31441526068140063\n",
            "At step: 9996 training error: 0.3103576488427497\n",
            "At step: 9997 training error: 0.3188445842903672\n",
            "At step: 9998 training error: 0.3161843390799036\n",
            "At step: 9999 training error: 0.3184614065386573\n",
            "At Epoch 2, validation error: 0.03505454898786638, validation accuracy 0.8115\n",
            "At step: 0 training error: 0.3474229662451659\n",
            "At step: 1 training error: 0.3460745162288116\n",
            "At step: 2 training error: 0.3373289128677577\n",
            "At step: 3 training error: 0.33315906329949396\n",
            "At step: 4 training error: 0.3250809951312439\n",
            "At step: 5 training error: 0.319256820056825\n",
            "At step: 6 training error: 0.31051931249557524\n",
            "At step: 7 training error: 0.30672911638246375\n",
            "At step: 8 training error: 0.2898632108763011\n",
            "At step: 9 training error: 0.2934273873438572\n",
            "At step: 10 training error: 0.2865888562831022\n",
            "At step: 11 training error: 0.2903757545010468\n",
            "At step: 12 training error: 0.2939249009064762\n",
            "At step: 13 training error: 0.29132462167842815\n",
            "At step: 14 training error: 0.2834165400563054\n",
            "At step: 15 training error: 0.29248579816017795\n",
            "At step: 16 training error: 0.3039819667103846\n",
            "At step: 17 training error: 0.3105583358782768\n",
            "At step: 18 training error: 0.303805219669296\n",
            "At step: 19 training error: 0.3129295352624673\n",
            "At step: 20 training error: 0.315398516571325\n",
            "At step: 21 training error: 0.3085525572257355\n",
            "At step: 22 training error: 0.30614152490041036\n",
            "At step: 23 training error: 0.2997104704226939\n",
            "At step: 24 training error: 0.3097007922705079\n",
            "At step: 25 training error: 0.30904853090810164\n",
            "At step: 26 training error: 0.30874250782824897\n",
            "At step: 27 training error: 0.3105616371921405\n",
            "At step: 28 training error: 0.30491814237692716\n",
            "At step: 29 training error: 0.3086783872872289\n",
            "At step: 30 training error: 0.2983333570309998\n",
            "At step: 31 training error: 0.30546761197018013\n",
            "At step: 32 training error: 0.3045340299073054\n",
            "At step: 33 training error: 0.29840320193472447\n",
            "At step: 34 training error: 0.28654792750067265\n",
            "At step: 35 training error: 0.2867316747508693\n",
            "At step: 36 training error: 0.2850726783703125\n",
            "At step: 37 training error: 0.2825371901612403\n",
            "At step: 38 training error: 0.2951850568440586\n",
            "At step: 39 training error: 0.2956964523598644\n",
            "At step: 40 training error: 0.29540936968677184\n",
            "At step: 41 training error: 0.289919705440616\n",
            "At step: 42 training error: 0.2907473081698202\n",
            "At step: 43 training error: 0.28936325507466565\n",
            "At step: 44 training error: 0.28846896093156776\n",
            "At step: 45 training error: 0.29558949388224287\n",
            "At step: 46 training error: 0.2938809938468318\n",
            "At step: 47 training error: 0.30794837271052566\n",
            "At step: 48 training error: 0.3122107335672238\n",
            "At step: 49 training error: 0.31974968345386234\n",
            "At step: 50 training error: 0.3307807442238047\n",
            "At step: 51 training error: 0.33025913090861164\n",
            "At step: 52 training error: 0.3219237664637201\n",
            "At step: 53 training error: 0.31362602453047916\n",
            "At step: 54 training error: 0.3044522791519401\n",
            "At step: 55 training error: 0.29632304350819705\n",
            "At step: 56 training error: 0.30078871431320453\n",
            "At step: 57 training error: 0.3052457053956634\n",
            "At step: 58 training error: 0.3051519410132932\n",
            "At step: 59 training error: 0.30399599142614453\n",
            "At step: 60 training error: 0.3194293930440191\n",
            "At step: 61 training error: 0.3215080936908205\n",
            "At step: 62 training error: 0.31195925243973166\n",
            "At step: 63 training error: 0.30200691342455155\n",
            "At step: 64 training error: 0.28828836811610936\n",
            "At step: 65 training error: 0.29173471155236674\n",
            "At step: 66 training error: 0.29433464098692835\n",
            "At step: 67 training error: 0.28849562994657335\n",
            "At step: 68 training error: 0.28087071516021017\n",
            "At step: 69 training error: 0.27780275394393894\n",
            "At step: 70 training error: 0.2797175342238092\n",
            "At step: 71 training error: 0.27607555393584393\n",
            "At step: 72 training error: 0.2804623346608711\n",
            "At step: 73 training error: 0.2877664172216365\n",
            "At step: 74 training error: 0.28631566290500937\n",
            "At step: 75 training error: 0.2839952069932479\n",
            "At step: 76 training error: 0.2880763344628182\n",
            "At step: 77 training error: 0.28560545847540725\n",
            "At step: 78 training error: 0.28288419094728146\n",
            "At step: 79 training error: 0.2801696553855236\n",
            "At step: 80 training error: 0.28709566578147805\n",
            "At step: 81 training error: 0.28664387790829\n",
            "At step: 82 training error: 0.29739812022021783\n",
            "At step: 83 training error: 0.2990206056188092\n",
            "At step: 84 training error: 0.3023146752912838\n",
            "At step: 85 training error: 0.2912922295226592\n",
            "At step: 86 training error: 0.2969142417589617\n",
            "At step: 87 training error: 0.2908591693476672\n",
            "At step: 88 training error: 0.3085639028512965\n",
            "At step: 89 training error: 0.3221692294904747\n",
            "At step: 90 training error: 0.3142666728209629\n",
            "At step: 91 training error: 0.3160401334030834\n",
            "At step: 92 training error: 0.31684961322593863\n",
            "At step: 93 training error: 0.31650162241370255\n",
            "At step: 94 training error: 0.30957971011012275\n",
            "At step: 95 training error: 0.2987657414860478\n",
            "At step: 96 training error: 0.29603483161863964\n",
            "At step: 97 training error: 0.2857043915469567\n",
            "At step: 98 training error: 0.2988783167779449\n",
            "At step: 99 training error: 0.29620238075817956\n",
            "At step: 100 training error: 0.29555656498759697\n",
            "At step: 101 training error: 0.3020069407416759\n",
            "At step: 102 training error: 0.3059236123798439\n",
            "At step: 103 training error: 0.3038058834768909\n",
            "At step: 104 training error: 0.29675387316643637\n",
            "At step: 105 training error: 0.29509733448966613\n",
            "At step: 106 training error: 0.3120553170724908\n",
            "At step: 107 training error: 0.31354148332716597\n",
            "At step: 108 training error: 0.3097168667031997\n",
            "At step: 109 training error: 0.3205925011744002\n",
            "At step: 110 training error: 0.3103695942464403\n",
            "At step: 111 training error: 0.30573603348503453\n",
            "At step: 112 training error: 0.3015264121663173\n",
            "At step: 113 training error: 0.3034909324447005\n",
            "At step: 114 training error: 0.29883960093838674\n",
            "At step: 115 training error: 0.3071076572554889\n",
            "At step: 116 training error: 0.29651007341543895\n",
            "At step: 117 training error: 0.29620844720498035\n",
            "At step: 118 training error: 0.2946151841310335\n",
            "At step: 119 training error: 0.2907562370263933\n",
            "At step: 120 training error: 0.28703160361354724\n",
            "At step: 121 training error: 0.28710453090041316\n",
            "At step: 122 training error: 0.28969535596372165\n",
            "At step: 123 training error: 0.2980783569386526\n",
            "At step: 124 training error: 0.29731276140689156\n",
            "At step: 125 training error: 0.29652070104470196\n",
            "At step: 126 training error: 0.2975761578142819\n",
            "At step: 127 training error: 0.29658724086514965\n",
            "At step: 128 training error: 0.29582377135261717\n",
            "At step: 129 training error: 0.3064274780169425\n",
            "At step: 130 training error: 0.30106631696930863\n",
            "At step: 131 training error: 0.306792521547265\n",
            "At step: 132 training error: 0.31198149356577615\n",
            "At step: 133 training error: 0.3155125714143897\n",
            "At step: 134 training error: 0.31450068900688327\n",
            "At step: 135 training error: 0.3009754172518909\n",
            "At step: 136 training error: 0.28582715444822326\n",
            "At step: 137 training error: 0.28766168277221615\n",
            "At step: 138 training error: 0.28870376490416033\n",
            "At step: 139 training error: 0.2851139674941243\n",
            "At step: 140 training error: 0.28455616081007973\n",
            "At step: 141 training error: 0.2950871185045354\n",
            "At step: 142 training error: 0.3129032204359826\n",
            "At step: 143 training error: 0.32512595620495655\n",
            "At step: 144 training error: 0.3189287397412064\n",
            "At step: 145 training error: 0.3279640717833956\n",
            "At step: 146 training error: 0.32807134188356096\n",
            "At step: 147 training error: 0.3281236264521225\n",
            "At step: 148 training error: 0.3273566222126815\n",
            "At step: 149 training error: 0.3279123829310948\n",
            "At step: 150 training error: 0.33078882809033866\n",
            "At step: 151 training error: 0.3314322825394128\n",
            "At step: 152 training error: 0.31336155610599314\n",
            "At step: 153 training error: 0.3071928338375308\n",
            "At step: 154 training error: 0.3086323805066894\n",
            "At step: 155 training error: 0.30365182866491025\n",
            "At step: 156 training error: 0.2988339996495017\n",
            "At step: 157 training error: 0.30133793576575174\n",
            "At step: 158 training error: 0.2885017895863363\n",
            "At step: 159 training error: 0.29781178871620245\n",
            "At step: 160 training error: 0.3014507925153279\n",
            "At step: 161 training error: 0.297879146354353\n",
            "At step: 162 training error: 0.2862510211727153\n",
            "At step: 163 training error: 0.2875030260252356\n",
            "At step: 164 training error: 0.29118865354723134\n",
            "At step: 165 training error: 0.28623747011342104\n",
            "At step: 166 training error: 0.28347284085996627\n",
            "At step: 167 training error: 0.2735393613011487\n",
            "At step: 168 training error: 0.2724811740769345\n",
            "At step: 169 training error: 0.2750423273286552\n",
            "At step: 170 training error: 0.27636083327142413\n",
            "At step: 171 training error: 0.27143841114671496\n",
            "At step: 172 training error: 0.2586465016520166\n",
            "At step: 173 training error: 0.27128627842858655\n",
            "At step: 174 training error: 0.2628418743652563\n",
            "At step: 175 training error: 0.2772790362379958\n",
            "At step: 176 training error: 0.2792403779147607\n",
            "At step: 177 training error: 0.29143254139528196\n",
            "At step: 178 training error: 0.3112822544352473\n",
            "At step: 179 training error: 0.3092478869903169\n",
            "At step: 180 training error: 0.3176850670322081\n",
            "At step: 181 training error: 0.31429532382652836\n",
            "At step: 182 training error: 0.3061424670858375\n",
            "At step: 183 training error: 0.3036809051601805\n",
            "At step: 184 training error: 0.2978676997022615\n",
            "At step: 185 training error: 0.3000747132592984\n",
            "At step: 186 training error: 0.29712941558400957\n",
            "At step: 187 training error: 0.30210744835634884\n",
            "At step: 188 training error: 0.298600784257986\n",
            "At step: 189 training error: 0.30332631905853\n",
            "At step: 190 training error: 0.3006189846603815\n",
            "At step: 191 training error: 0.3043807350653644\n",
            "At step: 192 training error: 0.3024050115650239\n",
            "At step: 193 training error: 0.29814770982135447\n",
            "At step: 194 training error: 0.2931591118823584\n",
            "At step: 195 training error: 0.2933623846787025\n",
            "At step: 196 training error: 0.2955603183267526\n",
            "At step: 197 training error: 0.2894081644151699\n",
            "At step: 198 training error: 0.2868422630127095\n",
            "At step: 199 training error: 0.2801375677487195\n",
            "At step: 200 training error: 0.2795005083122205\n",
            "At step: 201 training error: 0.27854032342579627\n",
            "At step: 202 training error: 0.27266679132261934\n",
            "At step: 203 training error: 0.2767301886749566\n",
            "At step: 204 training error: 0.28294271183706315\n",
            "At step: 205 training error: 0.28920862750016413\n",
            "At step: 206 training error: 0.2938763309242441\n",
            "At step: 207 training error: 0.2882929002331724\n",
            "At step: 208 training error: 0.29161739870705833\n",
            "At step: 209 training error: 0.28828774679705166\n",
            "At step: 210 training error: 0.28963880160845556\n",
            "At step: 211 training error: 0.30362109411427385\n",
            "At step: 212 training error: 0.29503212096893316\n",
            "At step: 213 training error: 0.2987517120098648\n",
            "At step: 214 training error: 0.30242094653356966\n",
            "At step: 215 training error: 0.29961384164630195\n",
            "At step: 216 training error: 0.3030041688544136\n",
            "At step: 217 training error: 0.2977359031011398\n",
            "At step: 218 training error: 0.2984881258639625\n",
            "At step: 219 training error: 0.30264260571672325\n",
            "At step: 220 training error: 0.3056443916605936\n",
            "At step: 221 training error: 0.3000734937888831\n",
            "At step: 222 training error: 0.29465993128812534\n",
            "At step: 223 training error: 0.300846435396412\n",
            "At step: 224 training error: 0.30217725847660515\n",
            "At step: 225 training error: 0.29532470686007867\n",
            "At step: 226 training error: 0.30372252831687013\n",
            "At step: 227 training error: 0.2955316058419981\n",
            "At step: 228 training error: 0.3000107693055918\n",
            "At step: 229 training error: 0.28732099500595343\n",
            "At step: 230 training error: 0.2933795593267645\n",
            "At step: 231 training error: 0.2898816715607557\n",
            "At step: 232 training error: 0.29368503739069807\n",
            "At step: 233 training error: 0.28376942017373585\n",
            "At step: 234 training error: 0.2849032654485298\n",
            "At step: 235 training error: 0.28672584745157176\n",
            "At step: 236 training error: 0.27196773044224193\n",
            "At step: 237 training error: 0.28376840027381056\n",
            "At step: 238 training error: 0.2831365662490289\n",
            "At step: 239 training error: 0.2797551022808045\n",
            "At step: 240 training error: 0.28174826522284585\n",
            "At step: 241 training error: 0.29245114379831\n",
            "At step: 242 training error: 0.2991274039428492\n",
            "At step: 243 training error: 0.3031153929916228\n",
            "At step: 244 training error: 0.3084013916965642\n",
            "At step: 245 training error: 0.3131953815322456\n",
            "At step: 246 training error: 0.30512271729726836\n",
            "At step: 247 training error: 0.2987223601333137\n",
            "At step: 248 training error: 0.29066492104089714\n",
            "At step: 249 training error: 0.2932124849548136\n",
            "At step: 250 training error: 0.30059807173227315\n",
            "At step: 251 training error: 0.2931859690750823\n",
            "At step: 252 training error: 0.29215116976020783\n",
            "At step: 253 training error: 0.2823820254764956\n",
            "At step: 254 training error: 0.27254620727812545\n",
            "At step: 255 training error: 0.2906858372320501\n",
            "At step: 256 training error: 0.28807237444452977\n",
            "At step: 257 training error: 0.2802465489089751\n",
            "At step: 258 training error: 0.27246846295971333\n",
            "At step: 259 training error: 0.2730363025723487\n",
            "At step: 260 training error: 0.27108670132822626\n",
            "At step: 261 training error: 0.2840980700638924\n",
            "At step: 262 training error: 0.28162647785958594\n",
            "At step: 263 training error: 0.28021350412707113\n",
            "At step: 264 training error: 0.2864449593068281\n",
            "At step: 265 training error: 0.2844115941803855\n",
            "At step: 266 training error: 0.29008571809895883\n",
            "At step: 267 training error: 0.27582522452101993\n",
            "At step: 268 training error: 0.2751250536518006\n",
            "At step: 269 training error: 0.2876446401666599\n",
            "At step: 270 training error: 0.29541657525903764\n",
            "At step: 271 training error: 0.2851522664061169\n",
            "At step: 272 training error: 0.278522702307972\n",
            "At step: 273 training error: 0.277681387708085\n",
            "At step: 274 training error: 0.281596320130653\n",
            "At step: 275 training error: 0.2825674515185962\n",
            "At step: 276 training error: 0.28691035574077794\n",
            "At step: 277 training error: 0.2779428242725931\n",
            "At step: 278 training error: 0.27900220000239373\n",
            "At step: 279 training error: 0.28012003311292794\n",
            "At step: 280 training error: 0.2749406568271563\n",
            "At step: 281 training error: 0.27319506288381773\n",
            "At step: 282 training error: 0.2778367265746491\n",
            "At step: 283 training error: 0.27597160029070045\n",
            "At step: 284 training error: 0.27259782798737897\n",
            "At step: 285 training error: 0.27111433197340284\n",
            "At step: 286 training error: 0.2690189556932633\n",
            "At step: 287 training error: 0.2634058792780142\n",
            "At step: 288 training error: 0.27323988472399185\n",
            "At step: 289 training error: 0.2760458522355463\n",
            "At step: 290 training error: 0.2757534659028899\n",
            "At step: 291 training error: 0.2787494478014106\n",
            "At step: 292 training error: 0.2833849395438002\n",
            "At step: 293 training error: 0.29114611516128625\n",
            "At step: 294 training error: 0.29696793133240723\n",
            "At step: 295 training error: 0.2863601326321311\n",
            "At step: 296 training error: 0.28312617499315984\n",
            "At step: 297 training error: 0.2761016331107592\n",
            "At step: 298 training error: 0.28066751805016227\n",
            "At step: 299 training error: 0.2877434639176602\n",
            "At step: 300 training error: 0.28172079478905576\n",
            "At step: 301 training error: 0.2798810142638072\n",
            "At step: 302 training error: 0.27742969591045236\n",
            "At step: 303 training error: 0.27234032121063184\n",
            "At step: 304 training error: 0.2758196642976732\n",
            "At step: 305 training error: 0.26900585608412936\n",
            "At step: 306 training error: 0.26974409212880085\n",
            "At step: 307 training error: 0.2643794539510167\n",
            "At step: 308 training error: 0.2685954923922873\n",
            "At step: 309 training error: 0.28568387771708353\n",
            "At step: 310 training error: 0.2876809333842539\n",
            "At step: 311 training error: 0.2838055160385212\n",
            "At step: 312 training error: 0.2883024182519599\n",
            "At step: 313 training error: 0.2924922315828159\n",
            "At step: 314 training error: 0.2933468555453743\n",
            "At step: 315 training error: 0.30308571366972903\n",
            "At step: 316 training error: 0.30842923928721105\n",
            "At step: 317 training error: 0.292259151781793\n",
            "At step: 318 training error: 0.29238492289622375\n",
            "At step: 319 training error: 0.3029013749526883\n",
            "At step: 320 training error: 0.3019288261685211\n",
            "At step: 321 training error: 0.3010598657437625\n",
            "At step: 322 training error: 0.3013071356179525\n",
            "At step: 323 training error: 0.3059428867898411\n",
            "At step: 324 training error: 0.31127255054604375\n",
            "At step: 325 training error: 0.3062836189600469\n",
            "At step: 326 training error: 0.3027348978460158\n",
            "At step: 327 training error: 0.31195989310695244\n",
            "At step: 328 training error: 0.29951111455796764\n",
            "At step: 329 training error: 0.29760401966046224\n",
            "At step: 330 training error: 0.3001163156859127\n",
            "At step: 331 training error: 0.2978317486102434\n",
            "At step: 332 training error: 0.2937541834082987\n",
            "At step: 333 training error: 0.2955301091618089\n",
            "At step: 334 training error: 0.28311296681810233\n",
            "At step: 335 training error: 0.27563867432738876\n",
            "At step: 336 training error: 0.2737523319903236\n",
            "At step: 337 training error: 0.2706452136009703\n",
            "At step: 338 training error: 0.27252692487716146\n",
            "At step: 339 training error: 0.27376337765284275\n",
            "At step: 340 training error: 0.2663350790368547\n",
            "At step: 341 training error: 0.27397769550326523\n",
            "At step: 342 training error: 0.2840245918633857\n",
            "At step: 343 training error: 0.2864910671953638\n",
            "At step: 344 training error: 0.2873944394430979\n",
            "At step: 345 training error: 0.2893345509721627\n",
            "At step: 346 training error: 0.2823857754684573\n",
            "At step: 347 training error: 0.2913425071022216\n",
            "At step: 348 training error: 0.29053810986487044\n",
            "At step: 349 training error: 0.27497871090544035\n",
            "At step: 350 training error: 0.27175797045993016\n",
            "At step: 351 training error: 0.2707727759137121\n",
            "At step: 352 training error: 0.27333926571784156\n",
            "At step: 353 training error: 0.26947693886201135\n",
            "At step: 354 training error: 0.2817329087918542\n",
            "At step: 355 training error: 0.28792392885464135\n",
            "At step: 356 training error: 0.29056393061621233\n",
            "At step: 357 training error: 0.29281683452742135\n",
            "At step: 358 training error: 0.3002807096564794\n",
            "At step: 359 training error: 0.2994647371686034\n",
            "At step: 360 training error: 0.29952741717783327\n",
            "At step: 361 training error: 0.2947434946961184\n",
            "At step: 362 training error: 0.29780926115436224\n",
            "At step: 363 training error: 0.2955030841606076\n",
            "At step: 364 training error: 0.2848265614286768\n",
            "At step: 365 training error: 0.2782862159226947\n",
            "At step: 366 training error: 0.2728130787683286\n",
            "At step: 367 training error: 0.26410599026863085\n",
            "At step: 368 training error: 0.27959770791248684\n",
            "At step: 369 training error: 0.27727899072033674\n",
            "At step: 370 training error: 0.285843813110966\n",
            "At step: 371 training error: 0.2888923787426655\n",
            "At step: 372 training error: 0.28474780834660385\n",
            "At step: 373 training error: 0.2938452631844541\n",
            "At step: 374 training error: 0.2929757549943998\n",
            "At step: 375 training error: 0.294013860846567\n",
            "At step: 376 training error: 0.29470692708203167\n",
            "At step: 377 training error: 0.2880912584902931\n",
            "At step: 378 training error: 0.2935356551881323\n",
            "At step: 379 training error: 0.2904811714825565\n",
            "At step: 380 training error: 0.29600742437956884\n",
            "At step: 381 training error: 0.28738900574917925\n",
            "At step: 382 training error: 0.2800074599323681\n",
            "At step: 383 training error: 0.29225437224233153\n",
            "At step: 384 training error: 0.2970349346175455\n",
            "At step: 385 training error: 0.2990119567985284\n",
            "At step: 386 training error: 0.30613222140564145\n",
            "At step: 387 training error: 0.29261955473733775\n",
            "At step: 388 training error: 0.29517274823982137\n",
            "At step: 389 training error: 0.2899632327058893\n",
            "At step: 390 training error: 0.3016943307998381\n",
            "At step: 391 training error: 0.2871253470851847\n",
            "At step: 392 training error: 0.2830853417344873\n",
            "At step: 393 training error: 0.28350086147956527\n",
            "At step: 394 training error: 0.2728649576494173\n",
            "At step: 395 training error: 0.2813514096546469\n",
            "At step: 396 training error: 0.2930154880373194\n",
            "At step: 397 training error: 0.2770699098180207\n",
            "At step: 398 training error: 0.2773273766775153\n",
            "At step: 399 training error: 0.2719196405850092\n",
            "At step: 400 training error: 0.27139378194508906\n",
            "At step: 401 training error: 0.27701242196682146\n",
            "At step: 402 training error: 0.2875193118093856\n",
            "At step: 403 training error: 0.28517806323469513\n",
            "At step: 404 training error: 0.2941652554984663\n",
            "At step: 405 training error: 0.2861462448884269\n",
            "At step: 406 training error: 0.282411645014498\n",
            "At step: 407 training error: 0.28048907430029835\n",
            "At step: 408 training error: 0.2744307397745222\n",
            "At step: 409 training error: 0.278694155728749\n",
            "At step: 410 training error: 0.28679085506224633\n",
            "At step: 411 training error: 0.3049085212336837\n",
            "At step: 412 training error: 0.3053183983217255\n",
            "At step: 413 training error: 0.3019430398956954\n",
            "At step: 414 training error: 0.28462969823794243\n",
            "At step: 415 training error: 0.2983109511810682\n",
            "At step: 416 training error: 0.2956838599843548\n",
            "At step: 417 training error: 0.3080266021593383\n",
            "At step: 418 training error: 0.3080518844755224\n",
            "At step: 419 training error: 0.30476817233153564\n",
            "At step: 420 training error: 0.3000620556427655\n",
            "At step: 421 training error: 0.29899228334305245\n",
            "At step: 422 training error: 0.2976752951704975\n",
            "At step: 423 training error: 0.29396108924484393\n",
            "At step: 424 training error: 0.28442416483290556\n",
            "At step: 425 training error: 0.2917963710253188\n",
            "At step: 426 training error: 0.2917888260199487\n",
            "At step: 427 training error: 0.29625823636632087\n",
            "At step: 428 training error: 0.29929084467699574\n",
            "At step: 429 training error: 0.30781031667777736\n",
            "At step: 430 training error: 0.30283412849780145\n",
            "At step: 431 training error: 0.29297354714018203\n",
            "At step: 432 training error: 0.3025141619722584\n",
            "At step: 433 training error: 0.3037349262892296\n",
            "At step: 434 training error: 0.3055842255003324\n",
            "At step: 435 training error: 0.30416263736989113\n",
            "At step: 436 training error: 0.29473682434465037\n",
            "At step: 437 training error: 0.2933827078619145\n",
            "At step: 438 training error: 0.29006011457508174\n",
            "At step: 439 training error: 0.28214619172728705\n",
            "At step: 440 training error: 0.2852953667743916\n",
            "At step: 441 training error: 0.29528885181143827\n",
            "At step: 442 training error: 0.3002393895140611\n",
            "At step: 443 training error: 0.29630030940369706\n",
            "At step: 444 training error: 0.29938083644612834\n",
            "At step: 445 training error: 0.30514450076958255\n",
            "At step: 446 training error: 0.29099379319597507\n",
            "At step: 447 training error: 0.2959217936126908\n",
            "At step: 448 training error: 0.2879054421499262\n",
            "At step: 449 training error: 0.27738039408775655\n",
            "At step: 450 training error: 0.289027476860901\n",
            "At step: 451 training error: 0.2797325423328625\n",
            "At step: 452 training error: 0.277498867958959\n",
            "At step: 453 training error: 0.27640127786333585\n",
            "At step: 454 training error: 0.26732748951416463\n",
            "At step: 455 training error: 0.2766614255659637\n",
            "At step: 456 training error: 0.27279393774878163\n",
            "At step: 457 training error: 0.27712877602855474\n",
            "At step: 458 training error: 0.28790319926694496\n",
            "At step: 459 training error: 0.28824367074343327\n",
            "At step: 460 training error: 0.29665172306754345\n",
            "At step: 461 training error: 0.29674188621589104\n",
            "At step: 462 training error: 0.30522621374017184\n",
            "At step: 463 training error: 0.30637463593572406\n",
            "At step: 464 training error: 0.31147330148122654\n",
            "At step: 465 training error: 0.29700627304997135\n",
            "At step: 466 training error: 0.2990603330598952\n",
            "At step: 467 training error: 0.30121358390408143\n",
            "At step: 468 training error: 0.30046977125685065\n",
            "At step: 469 training error: 0.3056270905599212\n",
            "At step: 470 training error: 0.31906175783730006\n",
            "At step: 471 training error: 0.3147615493011274\n",
            "At step: 472 training error: 0.31762341964900725\n",
            "At step: 473 training error: 0.3115164265660348\n",
            "At step: 474 training error: 0.31265854655907604\n",
            "At step: 475 training error: 0.31592509865686913\n",
            "At step: 476 training error: 0.31026666058369295\n",
            "At step: 477 training error: 0.3136928451938703\n",
            "At step: 478 training error: 0.31968863679812326\n",
            "At step: 479 training error: 0.32024430499455336\n",
            "At step: 480 training error: 0.3263028208371648\n",
            "At step: 481 training error: 0.3177897766342902\n",
            "At step: 482 training error: 0.3172857856820161\n",
            "At step: 483 training error: 0.3098157581875114\n",
            "At step: 484 training error: 0.30304449373346776\n",
            "At step: 485 training error: 0.3133549023095309\n",
            "At step: 486 training error: 0.30214710539727163\n",
            "At step: 487 training error: 0.29966175256297356\n",
            "At step: 488 training error: 0.3062060698331996\n",
            "At step: 489 training error: 0.3013827398441617\n",
            "At step: 490 training error: 0.29933160855570473\n",
            "At step: 491 training error: 0.2935567206726085\n",
            "At step: 492 training error: 0.29461683406061834\n",
            "At step: 493 training error: 0.29030819874832203\n",
            "At step: 494 training error: 0.2902265347326392\n",
            "At step: 495 training error: 0.28924547861104133\n",
            "At step: 496 training error: 0.3022526824531721\n",
            "At step: 497 training error: 0.29347067539119\n",
            "At step: 498 training error: 0.2947244027324571\n",
            "At step: 499 training error: 0.30357635334876215\n",
            "At step: 500 training error: 0.30891397422855726\n",
            "At step: 501 training error: 0.3082732767493242\n",
            "At step: 502 training error: 0.309500793618956\n",
            "At step: 503 training error: 0.3235183823657736\n",
            "At step: 504 training error: 0.31737070072000784\n",
            "At step: 505 training error: 0.30892159418641063\n",
            "At step: 506 training error: 0.29872564579718053\n",
            "At step: 507 training error: 0.29259750814140584\n",
            "At step: 508 training error: 0.29697741429201596\n",
            "At step: 509 training error: 0.3000783554459797\n",
            "At step: 510 training error: 0.28965271029793693\n",
            "At step: 511 training error: 0.28763226499291716\n",
            "At step: 512 training error: 0.2870740659311175\n",
            "At step: 513 training error: 0.2783060225583124\n",
            "At step: 514 training error: 0.2836454263434615\n",
            "At step: 515 training error: 0.2898857131642875\n",
            "At step: 516 training error: 0.2810731350319271\n",
            "At step: 517 training error: 0.28854602255232353\n",
            "At step: 518 training error: 0.28861665600020536\n",
            "At step: 519 training error: 0.29801381156348283\n",
            "At step: 520 training error: 0.2865374096604042\n",
            "At step: 521 training error: 0.2836200182788622\n",
            "At step: 522 training error: 0.2798034378950895\n",
            "At step: 523 training error: 0.2944685057051893\n",
            "At step: 524 training error: 0.29009076146150253\n",
            "At step: 525 training error: 0.29448294076335624\n",
            "At step: 526 training error: 0.2940733670989686\n",
            "At step: 527 training error: 0.2880014668547285\n",
            "At step: 528 training error: 0.29078539503664613\n",
            "At step: 529 training error: 0.2864803510288262\n",
            "At step: 530 training error: 0.28994119941845414\n",
            "At step: 531 training error: 0.2968854115736336\n",
            "At step: 532 training error: 0.28562774009804015\n",
            "At step: 533 training error: 0.2935917690820818\n",
            "At step: 534 training error: 0.2881989523719321\n",
            "At step: 535 training error: 0.2936319727123178\n",
            "At step: 536 training error: 0.29352876994523425\n",
            "At step: 537 training error: 0.2948634728505784\n",
            "At step: 538 training error: 0.2911956284971242\n",
            "At step: 539 training error: 0.29475746758337096\n",
            "At step: 540 training error: 0.2893506888534035\n",
            "At step: 541 training error: 0.28612206892926967\n",
            "At step: 542 training error: 0.2905740476685926\n",
            "At step: 543 training error: 0.29822967348219487\n",
            "At step: 544 training error: 0.29545061320355254\n",
            "At step: 545 training error: 0.2943378049744682\n",
            "At step: 546 training error: 0.28911986542890933\n",
            "At step: 547 training error: 0.3074411229179469\n",
            "At step: 548 training error: 0.30177935778954335\n",
            "At step: 549 training error: 0.2997199109156117\n",
            "At step: 550 training error: 0.2848016768694245\n",
            "At step: 551 training error: 0.29381338280476027\n",
            "At step: 552 training error: 0.29283882391689897\n",
            "At step: 553 training error: 0.2875580482411753\n",
            "At step: 554 training error: 0.2833317180794616\n",
            "At step: 555 training error: 0.2771228961442312\n",
            "At step: 556 training error: 0.2726808453408367\n",
            "At step: 557 training error: 0.26331287256084496\n",
            "At step: 558 training error: 0.25739197834769373\n",
            "At step: 559 training error: 0.2615258622463889\n",
            "At step: 560 training error: 0.2677401643472386\n",
            "At step: 561 training error: 0.2644730077822124\n",
            "At step: 562 training error: 0.26950964520151255\n",
            "At step: 563 training error: 0.2665681792158387\n",
            "At step: 564 training error: 0.26550447709566266\n",
            "At step: 565 training error: 0.2525292991491368\n",
            "At step: 566 training error: 0.2534044127810243\n",
            "At step: 567 training error: 0.26352759941923576\n",
            "At step: 568 training error: 0.25546667032400394\n",
            "At step: 569 training error: 0.25095960704149667\n",
            "At step: 570 training error: 0.25108826246736077\n",
            "At step: 571 training error: 0.25269980279207394\n",
            "At step: 572 training error: 0.24699963719012183\n",
            "At step: 573 training error: 0.24638286801024484\n",
            "At step: 574 training error: 0.24853657549951047\n",
            "At step: 575 training error: 0.2597985706859215\n",
            "At step: 576 training error: 0.26359896780710024\n",
            "At step: 577 training error: 0.27146206893511365\n",
            "At step: 578 training error: 0.26915478590078734\n",
            "At step: 579 training error: 0.28266376462802023\n",
            "At step: 580 training error: 0.28877200778824713\n",
            "At step: 581 training error: 0.2887929242433977\n",
            "At step: 582 training error: 0.28692130083684714\n",
            "At step: 583 training error: 0.28925535857543067\n",
            "At step: 584 training error: 0.2839779607951978\n",
            "At step: 585 training error: 0.2843411761686767\n",
            "At step: 586 training error: 0.2805022180743564\n",
            "At step: 587 training error: 0.27063466762550736\n",
            "At step: 588 training error: 0.2661014445761548\n",
            "At step: 589 training error: 0.2663574574757412\n",
            "At step: 590 training error: 0.26732660195594793\n",
            "At step: 591 training error: 0.2665947680238035\n",
            "At step: 592 training error: 0.2799498763422283\n",
            "At step: 593 training error: 0.2794285654358016\n",
            "At step: 594 training error: 0.2775789202383227\n",
            "At step: 595 training error: 0.28065463916457767\n",
            "At step: 596 training error: 0.2874857298057075\n",
            "At step: 597 training error: 0.285099395680558\n",
            "At step: 598 training error: 0.27707672860370947\n",
            "At step: 599 training error: 0.2782008282700355\n",
            "At step: 600 training error: 0.2722844953120115\n",
            "At step: 601 training error: 0.27473528400972513\n",
            "At step: 602 training error: 0.2631196537135697\n",
            "At step: 603 training error: 0.2677289741614238\n",
            "At step: 604 training error: 0.27158137447351904\n",
            "At step: 605 training error: 0.2847912827529751\n",
            "At step: 606 training error: 0.2812610200355266\n",
            "At step: 607 training error: 0.2941045248524643\n",
            "At step: 608 training error: 0.3019162305097682\n",
            "At step: 609 training error: 0.30266366296200387\n",
            "At step: 610 training error: 0.3141629214866002\n",
            "At step: 611 training error: 0.3232862041475909\n",
            "At step: 612 training error: 0.33993504035499034\n",
            "At step: 613 training error: 0.33166511498234474\n",
            "At step: 614 training error: 0.32582278037928875\n",
            "At step: 615 training error: 0.3223869980929728\n",
            "At step: 616 training error: 0.31171871601875367\n",
            "At step: 617 training error: 0.3054705612021906\n",
            "At step: 618 training error: 0.29253260348248783\n",
            "At step: 619 training error: 0.2798640076247131\n",
            "At step: 620 training error: 0.2795602658215539\n",
            "At step: 621 training error: 0.27629105996204134\n",
            "At step: 622 training error: 0.2755544626690585\n",
            "At step: 623 training error: 0.2687181328130725\n",
            "At step: 624 training error: 0.2717385208433892\n",
            "At step: 625 training error: 0.2687794873196141\n",
            "At step: 626 training error: 0.2671262930502807\n",
            "At step: 627 training error: 0.27535520147589404\n",
            "At step: 628 training error: 0.2694699151827693\n",
            "At step: 629 training error: 0.28139222671726416\n",
            "At step: 630 training error: 0.2805899828650411\n",
            "At step: 631 training error: 0.2934156214791917\n",
            "At step: 632 training error: 0.2981395658923531\n",
            "At step: 633 training error: 0.29909032505827443\n",
            "At step: 634 training error: 0.2891249262687969\n",
            "At step: 635 training error: 0.2822210562620465\n",
            "At step: 636 training error: 0.2852935558857267\n",
            "At step: 637 training error: 0.30187631331139053\n",
            "At step: 638 training error: 0.31130222017699244\n",
            "At step: 639 training error: 0.3080505115978362\n",
            "At step: 640 training error: 0.30988675364816554\n",
            "At step: 641 training error: 0.3130706695678684\n",
            "At step: 642 training error: 0.3108374055091271\n",
            "At step: 643 training error: 0.30380161652952176\n",
            "At step: 644 training error: 0.3138991770041298\n",
            "At step: 645 training error: 0.3284023757981853\n",
            "At step: 646 training error: 0.32492783489232\n",
            "At step: 647 training error: 0.31758401902131966\n",
            "At step: 648 training error: 0.31577022061825394\n",
            "At step: 649 training error: 0.3190582524564532\n",
            "At step: 650 training error: 0.3125071128711152\n",
            "At step: 651 training error: 0.3132376313573682\n",
            "At step: 652 training error: 0.3077044141228664\n",
            "At step: 653 training error: 0.2937607113613395\n",
            "At step: 654 training error: 0.29192917407972396\n",
            "At step: 655 training error: 0.2882131278523974\n",
            "At step: 656 training error: 0.29641503732953417\n",
            "At step: 657 training error: 0.29535455786523196\n",
            "At step: 658 training error: 0.2898344696090356\n",
            "At step: 659 training error: 0.28269396939097435\n",
            "At step: 660 training error: 0.2856560021842101\n",
            "At step: 661 training error: 0.28728770801811543\n",
            "At step: 662 training error: 0.2897428390478067\n",
            "At step: 663 training error: 0.28382072433759586\n",
            "At step: 664 training error: 0.28553243727886995\n",
            "At step: 665 training error: 0.2982177443391451\n",
            "At step: 666 training error: 0.2990258974956273\n",
            "At step: 667 training error: 0.2923240501136837\n",
            "At step: 668 training error: 0.2881922951142225\n",
            "At step: 669 training error: 0.2853125711754844\n",
            "At step: 670 training error: 0.28926817644033104\n",
            "At step: 671 training error: 0.28395209559479645\n",
            "At step: 672 training error: 0.2830861248471021\n",
            "At step: 673 training error: 0.2967377283958902\n",
            "At step: 674 training error: 0.3007184965745245\n",
            "At step: 675 training error: 0.298329057205107\n",
            "At step: 676 training error: 0.29475967845769924\n",
            "At step: 677 training error: 0.2942479488659925\n",
            "At step: 678 training error: 0.2976030210185471\n",
            "At step: 679 training error: 0.29702887947759493\n",
            "At step: 680 training error: 0.3030641568321007\n",
            "At step: 681 training error: 0.29647840672898385\n",
            "At step: 682 training error: 0.30063283969723215\n",
            "At step: 683 training error: 0.2926233388969995\n",
            "At step: 684 training error: 0.2923663958956274\n",
            "At step: 685 training error: 0.300738705386216\n",
            "At step: 686 training error: 0.28922612548395177\n",
            "At step: 687 training error: 0.30016024177639133\n",
            "At step: 688 training error: 0.3026541632411241\n",
            "At step: 689 training error: 0.2926048726547655\n",
            "At step: 690 training error: 0.2886134546389957\n",
            "At step: 691 training error: 0.2821394515252592\n",
            "At step: 692 training error: 0.28590953607889674\n",
            "At step: 693 training error: 0.27683391698080667\n",
            "At step: 694 training error: 0.27934966466864825\n",
            "At step: 695 training error: 0.2919991760098083\n",
            "At step: 696 training error: 0.3025886633683112\n",
            "At step: 697 training error: 0.3060022896326186\n",
            "At step: 698 training error: 0.3003537346388817\n",
            "At step: 699 training error: 0.2971669043527457\n",
            "At step: 700 training error: 0.2968046535944274\n",
            "At step: 701 training error: 0.29559765056448845\n",
            "At step: 702 training error: 0.29357835647044933\n",
            "At step: 703 training error: 0.29481512377547375\n",
            "At step: 704 training error: 0.29831113583246827\n",
            "At step: 705 training error: 0.2976933917216655\n",
            "At step: 706 training error: 0.2890065976154256\n",
            "At step: 707 training error: 0.2932624560575104\n",
            "At step: 708 training error: 0.28841885795219524\n",
            "At step: 709 training error: 0.29838231898541456\n",
            "At step: 710 training error: 0.30144184523981477\n",
            "At step: 711 training error: 0.2983659125888736\n",
            "At step: 712 training error: 0.29667147363387797\n",
            "At step: 713 training error: 0.29401505858497545\n",
            "At step: 714 training error: 0.29781930737382306\n",
            "At step: 715 training error: 0.28809779441890504\n",
            "At step: 716 training error: 0.28844952628750775\n",
            "At step: 717 training error: 0.29903302451762975\n",
            "At step: 718 training error: 0.302196496057103\n",
            "At step: 719 training error: 0.31164721557516883\n",
            "At step: 720 training error: 0.29764188903100774\n",
            "At step: 721 training error: 0.29216393154427606\n",
            "At step: 722 training error: 0.29857977514668116\n",
            "At step: 723 training error: 0.2959859718461687\n",
            "At step: 724 training error: 0.2984669502807188\n",
            "At step: 725 training error: 0.2947765268750143\n",
            "At step: 726 training error: 0.30019107624851515\n",
            "At step: 727 training error: 0.2917518109913223\n",
            "At step: 728 training error: 0.29852961653986937\n",
            "At step: 729 training error: 0.29861913280863894\n",
            "At step: 730 training error: 0.29315631353827504\n",
            "At step: 731 training error: 0.29500703994508803\n",
            "At step: 732 training error: 0.29341945454713525\n",
            "At step: 733 training error: 0.300855851469048\n",
            "At step: 734 training error: 0.31035452303599376\n",
            "At step: 735 training error: 0.3024370202900466\n",
            "At step: 736 training error: 0.29242124087773064\n",
            "At step: 737 training error: 0.2830642341592355\n",
            "At step: 738 training error: 0.28428252628588424\n",
            "At step: 739 training error: 0.3029448692453214\n",
            "At step: 740 training error: 0.30041464049399164\n",
            "At step: 741 training error: 0.2942123654577623\n",
            "At step: 742 training error: 0.29898789283270955\n",
            "At step: 743 training error: 0.30195965384822143\n",
            "At step: 744 training error: 0.296240444386221\n",
            "At step: 745 training error: 0.29664333553777494\n",
            "At step: 746 training error: 0.282828959229931\n",
            "At step: 747 training error: 0.2816787412407271\n",
            "At step: 748 training error: 0.291975419036533\n",
            "At step: 749 training error: 0.3061806399939\n",
            "At step: 750 training error: 0.30357554547956367\n",
            "At step: 751 training error: 0.2979804179033981\n",
            "At step: 752 training error: 0.2959476344329955\n",
            "At step: 753 training error: 0.28943187215941013\n",
            "At step: 754 training error: 0.2964501801276454\n",
            "At step: 755 training error: 0.28943582658761735\n",
            "At step: 756 training error: 0.27872280874236155\n",
            "At step: 757 training error: 0.28000869218255797\n",
            "At step: 758 training error: 0.2793309176374934\n",
            "At step: 759 training error: 0.2677683750087585\n",
            "At step: 760 training error: 0.26837109554747074\n",
            "At step: 761 training error: 0.2671382423987946\n",
            "At step: 762 training error: 0.2656884757093479\n",
            "At step: 763 training error: 0.273438232037411\n",
            "At step: 764 training error: 0.2875700802036193\n",
            "At step: 765 training error: 0.2851297099461423\n",
            "At step: 766 training error: 0.2862296852288734\n",
            "At step: 767 training error: 0.27793588479778586\n",
            "At step: 768 training error: 0.26956011537179175\n",
            "At step: 769 training error: 0.27446512100461923\n",
            "At step: 770 training error: 0.2931001155176365\n",
            "At step: 771 training error: 0.29595623938803733\n",
            "At step: 772 training error: 0.2996245238432492\n",
            "At step: 773 training error: 0.29980634549738977\n",
            "At step: 774 training error: 0.29645289370031813\n",
            "At step: 775 training error: 0.2886541787048545\n",
            "At step: 776 training error: 0.2957697522350485\n",
            "At step: 777 training error: 0.29284675334096627\n",
            "At step: 778 training error: 0.28808373832691103\n",
            "At step: 779 training error: 0.2832833960192502\n",
            "At step: 780 training error: 0.29202555460125235\n",
            "At step: 781 training error: 0.2800176981233875\n",
            "At step: 782 training error: 0.27829342958679665\n",
            "At step: 783 training error: 0.26832001840198466\n",
            "At step: 784 training error: 0.26327736976236193\n",
            "At step: 785 training error: 0.27769651195662065\n",
            "At step: 786 training error: 0.28743375312744596\n",
            "At step: 787 training error: 0.2807927341064479\n",
            "At step: 788 training error: 0.2775966269159473\n",
            "At step: 789 training error: 0.2813973034701466\n",
            "At step: 790 training error: 0.29352993472398126\n",
            "At step: 791 training error: 0.287823049042642\n",
            "At step: 792 training error: 0.29111643305742047\n",
            "At step: 793 training error: 0.3067270410597508\n",
            "At step: 794 training error: 0.30907985703623103\n",
            "At step: 795 training error: 0.30741667530814654\n",
            "At step: 796 training error: 0.31187820035473207\n",
            "At step: 797 training error: 0.3144858937668767\n",
            "At step: 798 training error: 0.319742304362045\n",
            "At step: 799 training error: 0.3108958360237578\n",
            "At step: 800 training error: 0.3168135132038145\n",
            "At step: 801 training error: 0.3113976141611135\n",
            "At step: 802 training error: 0.3034779752318213\n",
            "At step: 803 training error: 0.3086630015868564\n",
            "At step: 804 training error: 0.3072308283333232\n",
            "At step: 805 training error: 0.3086991284751133\n",
            "At step: 806 training error: 0.3052959744544468\n",
            "At step: 807 training error: 0.30115640820292483\n",
            "At step: 808 training error: 0.29198061192973385\n",
            "At step: 809 training error: 0.2900915772932786\n",
            "At step: 810 training error: 0.29630351002431726\n",
            "At step: 811 training error: 0.30791935960433886\n",
            "At step: 812 training error: 0.29508160807375083\n",
            "At step: 813 training error: 0.2970820211015313\n",
            "At step: 814 training error: 0.3033672495097817\n",
            "At step: 815 training error: 0.3122199400867111\n",
            "At step: 816 training error: 0.30217865199041133\n",
            "At step: 817 training error: 0.29484933207845465\n",
            "At step: 818 training error: 0.2903155259155033\n",
            "At step: 819 training error: 0.29434465418746175\n",
            "At step: 820 training error: 0.293964626839512\n",
            "At step: 821 training error: 0.29218377711502885\n",
            "At step: 822 training error: 0.2972335279884734\n",
            "At step: 823 training error: 0.2913143669248924\n",
            "At step: 824 training error: 0.2850188572789901\n",
            "At step: 825 training error: 0.27014261278809043\n",
            "At step: 826 training error: 0.2677063452720254\n",
            "At step: 827 training error: 0.26461952162781643\n",
            "At step: 828 training error: 0.269465706151826\n",
            "At step: 829 training error: 0.27119813261760795\n",
            "At step: 830 training error: 0.27949580177664585\n",
            "At step: 831 training error: 0.27478911748900564\n",
            "At step: 832 training error: 0.26921571037449205\n",
            "At step: 833 training error: 0.2754197354677155\n",
            "At step: 834 training error: 0.26896712778185616\n",
            "At step: 835 training error: 0.28242329159527624\n",
            "At step: 836 training error: 0.2897530234433256\n",
            "At step: 837 training error: 0.2908249338975218\n",
            "At step: 838 training error: 0.29169107373179587\n",
            "At step: 839 training error: 0.3025429805768124\n",
            "At step: 840 training error: 0.30645544033472477\n",
            "At step: 841 training error: 0.3038288920299938\n",
            "At step: 842 training error: 0.2950340933564618\n",
            "At step: 843 training error: 0.2903488785183075\n",
            "At step: 844 training error: 0.2900313278640926\n",
            "At step: 845 training error: 0.28935143490525406\n",
            "At step: 846 training error: 0.28227832236605843\n",
            "At step: 847 training error: 0.28027615916095433\n",
            "At step: 848 training error: 0.28414509331868854\n",
            "At step: 849 training error: 0.28596233840882224\n",
            "At step: 850 training error: 0.27804926884728615\n",
            "At step: 851 training error: 0.2831998054598177\n",
            "At step: 852 training error: 0.2899427911097868\n",
            "At step: 853 training error: 0.2858996072704638\n",
            "At step: 854 training error: 0.299097198409211\n",
            "At step: 855 training error: 0.29292931928936766\n",
            "At step: 856 training error: 0.2957421367520856\n",
            "At step: 857 training error: 0.2936016857181468\n",
            "At step: 858 training error: 0.28193655437279974\n",
            "At step: 859 training error: 0.2760367912941032\n",
            "At step: 860 training error: 0.2770936636670146\n",
            "At step: 861 training error: 0.27099335294787474\n",
            "At step: 862 training error: 0.2866432251044466\n",
            "At step: 863 training error: 0.2898713029191509\n",
            "At step: 864 training error: 0.2920900058289783\n",
            "At step: 865 training error: 0.28551498083696203\n",
            "At step: 866 training error: 0.27885121266005836\n",
            "At step: 867 training error: 0.2802185182149997\n",
            "At step: 868 training error: 0.285276920700201\n",
            "At step: 869 training error: 0.2969557646008085\n",
            "At step: 870 training error: 0.28872628792193067\n",
            "At step: 871 training error: 0.2849712212924656\n",
            "At step: 872 training error: 0.28102800532323174\n",
            "At step: 873 training error: 0.27560856978811354\n",
            "At step: 874 training error: 0.2736580074859477\n",
            "At step: 875 training error: 0.27777890123538157\n",
            "At step: 876 training error: 0.264443450800909\n",
            "At step: 877 training error: 0.27264218543349816\n",
            "At step: 878 training error: 0.2717210100165827\n",
            "At step: 879 training error: 0.2735322542663036\n",
            "At step: 880 training error: 0.2708087022563199\n",
            "At step: 881 training error: 0.275592324732599\n",
            "At step: 882 training error: 0.2896659486113361\n",
            "At step: 883 training error: 0.30389265397525556\n",
            "At step: 884 training error: 0.30827457788452656\n",
            "At step: 885 training error: 0.3044705649434908\n",
            "At step: 886 training error: 0.3042881350085667\n",
            "At step: 887 training error: 0.3096965764782566\n",
            "At step: 888 training error: 0.3059172062814144\n",
            "At step: 889 training error: 0.2981346746620521\n",
            "At step: 890 training error: 0.2960763622890583\n",
            "At step: 891 training error: 0.2888011698255245\n",
            "At step: 892 training error: 0.2972191986742112\n",
            "At step: 893 training error: 0.300508533737121\n",
            "At step: 894 training error: 0.29531432056728624\n",
            "At step: 895 training error: 0.3004855218150472\n",
            "At step: 896 training error: 0.29926218591847675\n",
            "At step: 897 training error: 0.30544641844550924\n",
            "At step: 898 training error: 0.30113931743856537\n",
            "At step: 899 training error: 0.3094260644541565\n",
            "At step: 900 training error: 0.310154633612672\n",
            "At step: 901 training error: 0.30833835757520917\n",
            "At step: 902 training error: 0.2989599736666329\n",
            "At step: 903 training error: 0.3022960305148947\n",
            "At step: 904 training error: 0.3023782169240685\n",
            "At step: 905 training error: 0.3143592144522373\n",
            "At step: 906 training error: 0.3198026785611476\n",
            "At step: 907 training error: 0.3185452165889742\n",
            "At step: 908 training error: 0.3147398557266476\n",
            "At step: 909 training error: 0.3031186595305813\n",
            "At step: 910 training error: 0.2926838763515443\n",
            "At step: 911 training error: 0.29601845458948156\n",
            "At step: 912 training error: 0.29725153689222084\n",
            "At step: 913 training error: 0.2867183557886298\n",
            "At step: 914 training error: 0.2819144579797869\n",
            "At step: 915 training error: 0.287435885577626\n",
            "At step: 916 training error: 0.2797798930683824\n",
            "At step: 917 training error: 0.2867002306923504\n",
            "At step: 918 training error: 0.2952860679845586\n",
            "At step: 919 training error: 0.2957686074831825\n",
            "At step: 920 training error: 0.2924721223170661\n",
            "At step: 921 training error: 0.28577192589168093\n",
            "At step: 922 training error: 0.298794706776077\n",
            "At step: 923 training error: 0.30423074802492295\n",
            "At step: 924 training error: 0.3024082970604873\n",
            "At step: 925 training error: 0.31373497820739493\n",
            "At step: 926 training error: 0.320566168944058\n",
            "At step: 927 training error: 0.311346805062639\n",
            "At step: 928 training error: 0.3015030304212192\n",
            "At step: 929 training error: 0.3178233848279356\n",
            "At step: 930 training error: 0.3041871770102287\n",
            "At step: 931 training error: 0.29579120729344766\n",
            "At step: 932 training error: 0.29404438255092463\n",
            "At step: 933 training error: 0.2902752991180318\n",
            "At step: 934 training error: 0.3047339967663547\n",
            "At step: 935 training error: 0.2974397966996356\n",
            "At step: 936 training error: 0.2929972698574566\n",
            "At step: 937 training error: 0.29638993132621205\n",
            "At step: 938 training error: 0.2922081892592508\n",
            "At step: 939 training error: 0.29630884091801307\n",
            "At step: 940 training error: 0.2928692624102872\n",
            "At step: 941 training error: 0.29176884784513774\n",
            "At step: 942 training error: 0.2935103517677817\n",
            "At step: 943 training error: 0.29411730746102344\n",
            "At step: 944 training error: 0.2879086047534689\n",
            "At step: 945 training error: 0.29795016895556725\n",
            "At step: 946 training error: 0.29404612892118753\n",
            "At step: 947 training error: 0.29562294573270925\n",
            "At step: 948 training error: 0.2975884831991864\n",
            "At step: 949 training error: 0.2966263214177522\n",
            "At step: 950 training error: 0.29266324291408413\n",
            "At step: 951 training error: 0.29036936176792055\n",
            "At step: 952 training error: 0.2874920388711739\n",
            "At step: 953 training error: 0.29636975365366364\n",
            "At step: 954 training error: 0.3007822472050088\n",
            "At step: 955 training error: 0.2957208399741324\n",
            "At step: 956 training error: 0.30963313132613257\n",
            "At step: 957 training error: 0.3100889803821814\n",
            "At step: 958 training error: 0.3078239684584116\n",
            "At step: 959 training error: 0.3166928610899643\n",
            "At step: 960 training error: 0.3190043963405664\n",
            "At step: 961 training error: 0.3174002525189224\n",
            "At step: 962 training error: 0.3214555696229989\n",
            "At step: 963 training error: 0.3120360652101958\n",
            "At step: 964 training error: 0.3175934824882639\n",
            "At step: 965 training error: 0.3169846194690525\n",
            "At step: 966 training error: 0.31656793214053175\n",
            "At step: 967 training error: 0.3103179645918096\n",
            "At step: 968 training error: 0.315341638545113\n",
            "At step: 969 training error: 0.3120933233199431\n",
            "At step: 970 training error: 0.3009251457296766\n",
            "At step: 971 training error: 0.2997706748442999\n",
            "At step: 972 training error: 0.28626878592324656\n",
            "At step: 973 training error: 0.2849979721649178\n",
            "At step: 974 training error: 0.2766755151055998\n",
            "At step: 975 training error: 0.28848202451079985\n",
            "At step: 976 training error: 0.28960832871772296\n",
            "At step: 977 training error: 0.27909878657835213\n",
            "At step: 978 training error: 0.279989214663195\n",
            "At step: 979 training error: 0.28833744625021324\n",
            "At step: 980 training error: 0.2937554568695556\n",
            "At step: 981 training error: 0.2873216080640899\n",
            "At step: 982 training error: 0.28445248547959656\n",
            "At step: 983 training error: 0.2839616694033894\n",
            "At step: 984 training error: 0.2883794353371022\n",
            "At step: 985 training error: 0.29976005983964366\n",
            "At step: 986 training error: 0.3071409582429391\n",
            "At step: 987 training error: 0.3044123963399912\n",
            "At step: 988 training error: 0.308042949140945\n",
            "At step: 989 training error: 0.2943724247476586\n",
            "At step: 990 training error: 0.28441995689827626\n",
            "At step: 991 training error: 0.2809372084772996\n",
            "At step: 992 training error: 0.2835759910596022\n",
            "At step: 993 training error: 0.2773887605554794\n",
            "At step: 994 training error: 0.28239083928525066\n",
            "At step: 995 training error: 0.2813317167817547\n",
            "At step: 996 training error: 0.2852882731999339\n",
            "At step: 997 training error: 0.28037231285926634\n",
            "At step: 998 training error: 0.2899045077315914\n",
            "At step: 999 training error: 0.2905114573071779\n",
            "At step: 1000 training error: 0.29375875664538015\n",
            "At step: 1001 training error: 0.2817615109233914\n",
            "At step: 1002 training error: 0.2860169815787402\n",
            "At step: 1003 training error: 0.29660382393040036\n",
            "At step: 1004 training error: 0.30549830268628325\n",
            "At step: 1005 training error: 0.2959300847204367\n",
            "At step: 1006 training error: 0.2986825597926808\n",
            "At step: 1007 training error: 0.29523971248855707\n",
            "At step: 1008 training error: 0.29312646981320756\n",
            "At step: 1009 training error: 0.2902281799016229\n",
            "At step: 1010 training error: 0.2863069318145218\n",
            "At step: 1011 training error: 0.28257308843389245\n",
            "At step: 1012 training error: 0.271049440919297\n",
            "At step: 1013 training error: 0.26800004050287235\n",
            "At step: 1014 training error: 0.272243421906601\n",
            "At step: 1015 training error: 0.2884435475730832\n",
            "At step: 1016 training error: 0.28030396552741704\n",
            "At step: 1017 training error: 0.2818187407996765\n",
            "At step: 1018 training error: 0.2677380997431833\n",
            "At step: 1019 training error: 0.27851148312236795\n",
            "At step: 1020 training error: 0.28705623139031444\n",
            "At step: 1021 training error: 0.29360662912463975\n",
            "At step: 1022 training error: 0.3028623475255948\n",
            "At step: 1023 training error: 0.299980821823481\n",
            "At step: 1024 training error: 0.3080733101123156\n",
            "At step: 1025 training error: 0.3064885878853394\n",
            "At step: 1026 training error: 0.2979867014493975\n",
            "At step: 1027 training error: 0.3029961124252142\n",
            "At step: 1028 training error: 0.3046786709161093\n",
            "At step: 1029 training error: 0.3056248868794194\n",
            "At step: 1030 training error: 0.3011087651814482\n",
            "At step: 1031 training error: 0.31034633878231477\n",
            "At step: 1032 training error: 0.315713930954268\n",
            "At step: 1033 training error: 0.3180494249775402\n",
            "At step: 1034 training error: 0.3228335521667527\n",
            "At step: 1035 training error: 0.31180686216788916\n",
            "At step: 1036 training error: 0.30545523126865637\n",
            "At step: 1037 training error: 0.3067640543710689\n",
            "At step: 1038 training error: 0.3073785605843243\n",
            "At step: 1039 training error: 0.29933068796226536\n",
            "At step: 1040 training error: 0.29059247595564647\n",
            "At step: 1041 training error: 0.2822725208429783\n",
            "At step: 1042 training error: 0.27109554180926965\n",
            "At step: 1043 training error: 0.26332121826504296\n",
            "At step: 1044 training error: 0.268331890160001\n",
            "At step: 1045 training error: 0.26187272807293294\n",
            "At step: 1046 training error: 0.2611255421250253\n",
            "At step: 1047 training error: 0.26377875638613524\n",
            "At step: 1048 training error: 0.261969775220776\n",
            "At step: 1049 training error: 0.2705191377300816\n",
            "At step: 1050 training error: 0.2836808278464474\n",
            "At step: 1051 training error: 0.27762617564845277\n",
            "At step: 1052 training error: 0.2746511262814636\n",
            "At step: 1053 training error: 0.27442840184156353\n",
            "At step: 1054 training error: 0.27411220937929814\n",
            "At step: 1055 training error: 0.2613270245079398\n",
            "At step: 1056 training error: 0.28041541516042817\n",
            "At step: 1057 training error: 0.27897862477319374\n",
            "At step: 1058 training error: 0.2853152633371574\n",
            "At step: 1059 training error: 0.28458736756353953\n",
            "At step: 1060 training error: 0.2890444457276753\n",
            "At step: 1061 training error: 0.2869786717615988\n",
            "At step: 1062 training error: 0.2921233147364043\n",
            "At step: 1063 training error: 0.302167661890444\n",
            "At step: 1064 training error: 0.31433202873066\n",
            "At step: 1065 training error: 0.3139887257390681\n",
            "At step: 1066 training error: 0.3058028662026173\n",
            "At step: 1067 training error: 0.2987376463336073\n",
            "At step: 1068 training error: 0.2988336186179183\n",
            "At step: 1069 training error: 0.31077447706167244\n",
            "At step: 1070 training error: 0.3093965145948256\n",
            "At step: 1071 training error: 0.30178697042353825\n",
            "At step: 1072 training error: 0.30000557730545757\n",
            "At step: 1073 training error: 0.2966299755971315\n",
            "At step: 1074 training error: 0.28916234803158014\n",
            "At step: 1075 training error: 0.29326595074931944\n",
            "At step: 1076 training error: 0.28610013471456935\n",
            "At step: 1077 training error: 0.28606052698719336\n",
            "At step: 1078 training error: 0.28472526501396517\n",
            "At step: 1079 training error: 0.2904308783676692\n",
            "At step: 1080 training error: 0.2926437339952534\n",
            "At step: 1081 training error: 0.2980718589467828\n",
            "At step: 1082 training error: 0.2828162238275886\n",
            "At step: 1083 training error: 0.2718749339692404\n",
            "At step: 1084 training error: 0.27153965357393683\n",
            "At step: 1085 training error: 0.281702198786423\n",
            "At step: 1086 training error: 0.2809547018865164\n",
            "At step: 1087 training error: 0.30432468055133194\n",
            "At step: 1088 training error: 0.290701760004934\n",
            "At step: 1089 training error: 0.279710783113099\n",
            "At step: 1090 training error: 0.2770548554664511\n",
            "At step: 1091 training error: 0.2883216996055016\n",
            "At step: 1092 training error: 0.2878080538933944\n",
            "At step: 1093 training error: 0.2837158591137726\n",
            "At step: 1094 training error: 0.2866098398631756\n",
            "At step: 1095 training error: 0.2801436230200776\n",
            "At step: 1096 training error: 0.26963526236152263\n",
            "At step: 1097 training error: 0.2769501639791546\n",
            "At step: 1098 training error: 0.2817710464404654\n",
            "At step: 1099 training error: 0.28401446446404804\n",
            "At step: 1100 training error: 0.2940030058180389\n",
            "At step: 1101 training error: 0.2975258037061154\n",
            "At step: 1102 training error: 0.2929755130012059\n",
            "At step: 1103 training error: 0.2900347744046745\n",
            "At step: 1104 training error: 0.2765632141499826\n",
            "At step: 1105 training error: 0.2738825221481205\n",
            "At step: 1106 training error: 0.2779537251634294\n",
            "At step: 1107 training error: 0.2820795566302553\n",
            "At step: 1108 training error: 0.2834884536712086\n",
            "At step: 1109 training error: 0.2857797810519232\n",
            "At step: 1110 training error: 0.2957327171950428\n",
            "At step: 1111 training error: 0.3083362556245493\n",
            "At step: 1112 training error: 0.2991821870302413\n",
            "At step: 1113 training error: 0.2986324052306278\n",
            "At step: 1114 training error: 0.2978071965823838\n",
            "At step: 1115 training error: 0.29775484132602975\n",
            "At step: 1116 training error: 0.3002405313486556\n",
            "At step: 1117 training error: 0.29898932490658797\n",
            "At step: 1118 training error: 0.2939551583114568\n",
            "At step: 1119 training error: 0.29739375725805045\n",
            "At step: 1120 training error: 0.3043819165249204\n",
            "At step: 1121 training error: 0.2994427151138367\n",
            "At step: 1122 training error: 0.2980890751680155\n",
            "At step: 1123 training error: 0.3022906759193847\n",
            "At step: 1124 training error: 0.2945962726538704\n",
            "At step: 1125 training error: 0.3036479410840386\n",
            "At step: 1126 training error: 0.29332931160788034\n",
            "At step: 1127 training error: 0.29516625665091434\n",
            "At step: 1128 training error: 0.2944024800636431\n",
            "At step: 1129 training error: 0.2890554396379098\n",
            "At step: 1130 training error: 0.2936968425193063\n",
            "At step: 1131 training error: 0.28645524826033536\n",
            "At step: 1132 training error: 0.28257449373385\n",
            "At step: 1133 training error: 0.2810632837210343\n",
            "At step: 1134 training error: 0.2952794620053452\n",
            "At step: 1135 training error: 0.2997739108259593\n",
            "At step: 1136 training error: 0.2987437187364315\n",
            "At step: 1137 training error: 0.30552193963852975\n",
            "At step: 1138 training error: 0.30470490317307186\n",
            "At step: 1139 training error: 0.3106853840542474\n",
            "At step: 1140 training error: 0.3139641454506452\n",
            "At step: 1141 training error: 0.30804741093028537\n",
            "At step: 1142 training error: 0.30571914448828025\n",
            "At step: 1143 training error: 0.30777622435835794\n",
            "At step: 1144 training error: 0.30130340912197945\n",
            "At step: 1145 training error: 0.2968795060115886\n",
            "At step: 1146 training error: 0.3000271902917644\n",
            "At step: 1147 training error: 0.298687773385281\n",
            "At step: 1148 training error: 0.29639089219520076\n",
            "At step: 1149 training error: 0.2915992733951941\n",
            "At step: 1150 training error: 0.28732691608087996\n",
            "At step: 1151 training error: 0.28599487585577904\n",
            "At step: 1152 training error: 0.2931112709287061\n",
            "At step: 1153 training error: 0.3081102181689882\n",
            "At step: 1154 training error: 0.30622870673754815\n",
            "At step: 1155 training error: 0.29429961199219157\n",
            "At step: 1156 training error: 0.28949834009978054\n",
            "At step: 1157 training error: 0.2918445118089448\n",
            "At step: 1158 training error: 0.2889762481539873\n",
            "At step: 1159 training error: 0.2900194989362105\n",
            "At step: 1160 training error: 0.2930989673146587\n",
            "At step: 1161 training error: 0.2952854071628001\n",
            "At step: 1162 training error: 0.296813153245199\n",
            "At step: 1163 training error: 0.3001851282585503\n",
            "At step: 1164 training error: 0.3059088476590902\n",
            "At step: 1165 training error: 0.30079655294693775\n",
            "At step: 1166 training error: 0.30158973908553915\n",
            "At step: 1167 training error: 0.3037559788780605\n",
            "At step: 1168 training error: 0.30206432539702316\n",
            "At step: 1169 training error: 0.2865536626988996\n",
            "At step: 1170 training error: 0.30329834936940564\n",
            "At step: 1171 training error: 0.29836915477174064\n",
            "At step: 1172 training error: 0.2895733045756175\n",
            "At step: 1173 training error: 0.2873038424786186\n",
            "At step: 1174 training error: 0.2977492673255352\n",
            "At step: 1175 training error: 0.2950995972532331\n",
            "At step: 1176 training error: 0.2973306011932596\n",
            "At step: 1177 training error: 0.30361620722538635\n",
            "At step: 1178 training error: 0.30675509306851084\n",
            "At step: 1179 training error: 0.3194915992927224\n",
            "At step: 1180 training error: 0.3197250548027105\n",
            "At step: 1181 training error: 0.31815588758587077\n",
            "At step: 1182 training error: 0.3110944521735989\n",
            "At step: 1183 training error: 0.3053096003679831\n",
            "At step: 1184 training error: 0.3096697797445671\n",
            "At step: 1185 training error: 0.30906303360712967\n",
            "At step: 1186 training error: 0.30673922219253297\n",
            "At step: 1187 training error: 0.29104398408459264\n",
            "At step: 1188 training error: 0.2926906903737809\n",
            "At step: 1189 training error: 0.2899690156040931\n",
            "At step: 1190 training error: 0.2926725184936886\n",
            "At step: 1191 training error: 0.28081596164530176\n",
            "At step: 1192 training error: 0.2698490184022061\n",
            "At step: 1193 training error: 0.27324443736318443\n",
            "At step: 1194 training error: 0.2762280965189298\n",
            "At step: 1195 training error: 0.2901678279015168\n",
            "At step: 1196 training error: 0.28794262363706435\n",
            "At step: 1197 training error: 0.2793438103976165\n",
            "At step: 1198 training error: 0.27431272487893626\n",
            "At step: 1199 training error: 0.2744981627182858\n",
            "At step: 1200 training error: 0.27318039052352094\n",
            "At step: 1201 training error: 0.28246663897526647\n",
            "At step: 1202 training error: 0.2944512369303388\n",
            "At step: 1203 training error: 0.2893404915012328\n",
            "At step: 1204 training error: 0.295388547207797\n",
            "At step: 1205 training error: 0.29563158386461263\n",
            "At step: 1206 training error: 0.29177812586907104\n",
            "At step: 1207 training error: 0.2948691773975619\n",
            "At step: 1208 training error: 0.2959344113096526\n",
            "At step: 1209 training error: 0.3013723770146227\n",
            "At step: 1210 training error: 0.2960477359856693\n",
            "At step: 1211 training error: 0.2942670403778457\n",
            "At step: 1212 training error: 0.2955387637966219\n",
            "At step: 1213 training error: 0.2946810660959572\n",
            "At step: 1214 training error: 0.2950590053298511\n",
            "At step: 1215 training error: 0.29625815976686587\n",
            "At step: 1216 training error: 0.2955948703694805\n",
            "At step: 1217 training error: 0.2939122756502891\n",
            "At step: 1218 training error: 0.30439189877860034\n",
            "At step: 1219 training error: 0.3074132756754378\n",
            "At step: 1220 training error: 0.3027435815724906\n",
            "At step: 1221 training error: 0.30507135239721733\n",
            "At step: 1222 training error: 0.31148805603948104\n",
            "At step: 1223 training error: 0.31496536021830995\n",
            "At step: 1224 training error: 0.30261548860475207\n",
            "At step: 1225 training error: 0.30403276315541056\n",
            "At step: 1226 training error: 0.3010155584478375\n",
            "At step: 1227 training error: 0.31001728200046735\n",
            "At step: 1228 training error: 0.29517499425998683\n",
            "At step: 1229 training error: 0.29303879339998035\n",
            "At step: 1230 training error: 0.2949006588896202\n",
            "At step: 1231 training error: 0.28921238958426865\n",
            "At step: 1232 training error: 0.2895634420424148\n",
            "At step: 1233 training error: 0.282709579188198\n",
            "At step: 1234 training error: 0.27428933722683907\n",
            "At step: 1235 training error: 0.2860087412229207\n",
            "At step: 1236 training error: 0.29216910828330384\n",
            "At step: 1237 training error: 0.30038562408536895\n",
            "At step: 1238 training error: 0.3026118130105666\n",
            "At step: 1239 training error: 0.2932599386734276\n",
            "At step: 1240 training error: 0.3021493653725931\n",
            "At step: 1241 training error: 0.30158816338929645\n",
            "At step: 1242 training error: 0.2896404262965057\n",
            "At step: 1243 training error: 0.27582129788055754\n",
            "At step: 1244 training error: 0.2657806374363809\n",
            "At step: 1245 training error: 0.26099342789699964\n",
            "At step: 1246 training error: 0.2626050550098943\n",
            "At step: 1247 training error: 0.27266701967520907\n",
            "At step: 1248 training error: 0.27225821424799235\n",
            "At step: 1249 training error: 0.27576077917277164\n",
            "At step: 1250 training error: 0.2845180869404008\n",
            "At step: 1251 training error: 0.28969438012392196\n",
            "At step: 1252 training error: 0.29105172951483194\n",
            "At step: 1253 training error: 0.2890284064859802\n",
            "At step: 1254 training error: 0.2867672104770981\n",
            "At step: 1255 training error: 0.29287293754987576\n",
            "At step: 1256 training error: 0.2912773525768608\n",
            "At step: 1257 training error: 0.2917666451850508\n",
            "At step: 1258 training error: 0.2858285884602499\n",
            "At step: 1259 training error: 0.29057437074309483\n",
            "At step: 1260 training error: 0.28267160685421583\n",
            "At step: 1261 training error: 0.2765015280482357\n",
            "At step: 1262 training error: 0.28292260282945214\n",
            "At step: 1263 training error: 0.2834155205315075\n",
            "At step: 1264 training error: 0.2887317792674179\n",
            "At step: 1265 training error: 0.2856606441716092\n",
            "At step: 1266 training error: 0.28796869899117106\n",
            "At step: 1267 training error: 0.2852243585209109\n",
            "At step: 1268 training error: 0.278403664803052\n",
            "At step: 1269 training error: 0.2746865133835934\n",
            "At step: 1270 training error: 0.2706447707402468\n",
            "At step: 1271 training error: 0.2858692932820727\n",
            "At step: 1272 training error: 0.27684766339324796\n",
            "At step: 1273 training error: 0.2750413991520115\n",
            "At step: 1274 training error: 0.2841127055008436\n",
            "At step: 1275 training error: 0.2845505301390298\n",
            "At step: 1276 training error: 0.29240816518769774\n",
            "At step: 1277 training error: 0.2826376427351943\n",
            "At step: 1278 training error: 0.27813630753827767\n",
            "At step: 1279 training error: 0.2753449874374614\n",
            "At step: 1280 training error: 0.27259887933968524\n",
            "At step: 1281 training error: 0.2795315077504047\n",
            "At step: 1282 training error: 0.27454319809182204\n",
            "At step: 1283 training error: 0.27266941186157057\n",
            "At step: 1284 training error: 0.2805315179798783\n",
            "At step: 1285 training error: 0.27997068099060124\n",
            "At step: 1286 training error: 0.2910063103295267\n",
            "At step: 1287 training error: 0.29040507350349276\n",
            "At step: 1288 training error: 0.2858342171216588\n",
            "At step: 1289 training error: 0.28248438963771094\n",
            "At step: 1290 training error: 0.274089698788633\n",
            "At step: 1291 training error: 0.2796302884252102\n",
            "At step: 1292 training error: 0.2758140789442319\n",
            "At step: 1293 training error: 0.2764863709212627\n",
            "At step: 1294 training error: 0.2814461242379759\n",
            "At step: 1295 training error: 0.276883290049888\n",
            "At step: 1296 training error: 0.27264862434086434\n",
            "At step: 1297 training error: 0.2748668816775522\n",
            "At step: 1298 training error: 0.2769699750646372\n",
            "At step: 1299 training error: 0.26760535923880613\n",
            "At step: 1300 training error: 0.2697663729198149\n",
            "At step: 1301 training error: 0.2723702274928651\n",
            "At step: 1302 training error: 0.2770358602743759\n",
            "At step: 1303 training error: 0.29528892726544703\n",
            "At step: 1304 training error: 0.29318460511175537\n",
            "At step: 1305 training error: 0.2869725950437759\n",
            "At step: 1306 training error: 0.2931292264850991\n",
            "At step: 1307 training error: 0.2966489047965391\n",
            "At step: 1308 training error: 0.29918182278890876\n",
            "At step: 1309 training error: 0.30144453511479763\n",
            "At step: 1310 training error: 0.29875748824064685\n",
            "At step: 1311 training error: 0.2989970229179669\n",
            "At step: 1312 training error: 0.29303461132387437\n",
            "At step: 1313 training error: 0.290562438070317\n",
            "At step: 1314 training error: 0.2918224276147301\n",
            "At step: 1315 training error: 0.28425772530424764\n",
            "At step: 1316 training error: 0.29298862139463383\n",
            "At step: 1317 training error: 0.30345895948658885\n",
            "At step: 1318 training error: 0.2988280612509083\n",
            "At step: 1319 training error: 0.29110769552322396\n",
            "At step: 1320 training error: 0.2813336405156813\n",
            "At step: 1321 training error: 0.282914149992564\n",
            "At step: 1322 training error: 0.28066544241006014\n",
            "At step: 1323 training error: 0.2827244671833485\n",
            "At step: 1324 training error: 0.28175385721198426\n",
            "At step: 1325 training error: 0.2794229980047182\n",
            "At step: 1326 training error: 0.281937597102484\n",
            "At step: 1327 training error: 0.29198268037978137\n",
            "At step: 1328 training error: 0.2914234934340053\n",
            "At step: 1329 training error: 0.29280800984821376\n",
            "At step: 1330 training error: 0.28775952686943074\n",
            "At step: 1331 training error: 0.2845268134353611\n",
            "At step: 1332 training error: 0.28177774448190634\n",
            "At step: 1333 training error: 0.28128965410500667\n",
            "At step: 1334 training error: 0.27496201126246617\n",
            "At step: 1335 training error: 0.27217187000124987\n",
            "At step: 1336 training error: 0.2684161655798752\n",
            "At step: 1337 training error: 0.2730143933952377\n",
            "At step: 1338 training error: 0.2848173772460733\n",
            "At step: 1339 training error: 0.2864896073784744\n",
            "At step: 1340 training error: 0.2814826109193413\n",
            "At step: 1341 training error: 0.27568910203618263\n",
            "At step: 1342 training error: 0.2801461601260417\n",
            "At step: 1343 training error: 0.2805759783323583\n",
            "At step: 1344 training error: 0.2872491987629235\n",
            "At step: 1345 training error: 0.2828508463279273\n",
            "At step: 1346 training error: 0.2929925182019385\n",
            "At step: 1347 training error: 0.2986017454809796\n",
            "At step: 1348 training error: 0.287537911553405\n",
            "At step: 1349 training error: 0.28480083017949864\n",
            "At step: 1350 training error: 0.28160220746791514\n",
            "At step: 1351 training error: 0.2842401332519689\n",
            "At step: 1352 training error: 0.2876763869447582\n",
            "At step: 1353 training error: 0.2814065829144668\n",
            "At step: 1354 training error: 0.2861173851078917\n",
            "At step: 1355 training error: 0.285506727316749\n",
            "At step: 1356 training error: 0.2839032072449316\n",
            "At step: 1357 training error: 0.29341959610236906\n",
            "At step: 1358 training error: 0.29485720112297625\n",
            "At step: 1359 training error: 0.3020191412178176\n",
            "At step: 1360 training error: 0.3090000246311415\n",
            "At step: 1361 training error: 0.3025409953106725\n",
            "At step: 1362 training error: 0.30083204992834683\n",
            "At step: 1363 training error: 0.3107440543524134\n",
            "At step: 1364 training error: 0.309486370840895\n",
            "At step: 1365 training error: 0.30518227685685767\n",
            "At step: 1366 training error: 0.3006822306277431\n",
            "At step: 1367 training error: 0.3143542687038908\n",
            "At step: 1368 training error: 0.30402217010162746\n",
            "At step: 1369 training error: 0.31410487167884793\n",
            "At step: 1370 training error: 0.30770925548034367\n",
            "At step: 1371 training error: 0.31083087650486857\n",
            "At step: 1372 training error: 0.3109545270587908\n",
            "At step: 1373 training error: 0.3076171435377375\n",
            "At step: 1374 training error: 0.3079986974549593\n",
            "At step: 1375 training error: 0.3010134382597818\n",
            "At step: 1376 training error: 0.29634832482621853\n",
            "At step: 1377 training error: 0.2844566434893299\n",
            "At step: 1378 training error: 0.27860119675769607\n",
            "At step: 1379 training error: 0.29108112255084473\n",
            "At step: 1380 training error: 0.2931470002570954\n",
            "At step: 1381 training error: 0.29186136827458203\n",
            "At step: 1382 training error: 0.29502560705273007\n",
            "At step: 1383 training error: 0.3003010417822883\n",
            "At step: 1384 training error: 0.2910796858582716\n",
            "At step: 1385 training error: 0.2929349269834557\n",
            "At step: 1386 training error: 0.3014462622617103\n",
            "At step: 1387 training error: 0.3027882431407523\n",
            "At step: 1388 training error: 0.2835363655650493\n",
            "At step: 1389 training error: 0.28744500485923524\n",
            "At step: 1390 training error: 0.2856617765997875\n",
            "At step: 1391 training error: 0.2789465915874282\n",
            "At step: 1392 training error: 0.28556827937001006\n",
            "At step: 1393 training error: 0.288441503662717\n",
            "At step: 1394 training error: 0.28647994942601773\n",
            "At step: 1395 training error: 0.28360758037390177\n",
            "At step: 1396 training error: 0.28632360754678887\n",
            "At step: 1397 training error: 0.2857574159283748\n",
            "At step: 1398 training error: 0.27835216167633137\n",
            "At step: 1399 training error: 0.27962322359742187\n",
            "At step: 1400 training error: 0.28776979974468425\n",
            "At step: 1401 training error: 0.2840949410792171\n",
            "At step: 1402 training error: 0.28531790870243245\n",
            "At step: 1403 training error: 0.28629935722334904\n",
            "At step: 1404 training error: 0.28864905978318983\n",
            "At step: 1405 training error: 0.2880813627058747\n",
            "At step: 1406 training error: 0.28884005261453005\n",
            "At step: 1407 training error: 0.2891358759464911\n",
            "At step: 1408 training error: 0.2840745140138723\n",
            "At step: 1409 training error: 0.27750308393551637\n",
            "At step: 1410 training error: 0.2922340124981834\n",
            "At step: 1411 training error: 0.28999399245982743\n",
            "At step: 1412 training error: 0.29300112726031957\n",
            "At step: 1413 training error: 0.28877691862366206\n",
            "At step: 1414 training error: 0.29100352872289315\n",
            "At step: 1415 training error: 0.30551820079505443\n",
            "At step: 1416 training error: 0.3053875510509585\n",
            "At step: 1417 training error: 0.3025913270330899\n",
            "At step: 1418 training error: 0.30276758154802885\n",
            "At step: 1419 training error: 0.294972246114762\n",
            "At step: 1420 training error: 0.3003454329363981\n",
            "At step: 1421 training error: 0.292795334234708\n",
            "At step: 1422 training error: 0.2934888258756024\n",
            "At step: 1423 training error: 0.2954312131369312\n",
            "At step: 1424 training error: 0.28796683148224933\n",
            "At step: 1425 training error: 0.29043129931464756\n",
            "At step: 1426 training error: 0.29503221030539145\n",
            "At step: 1427 training error: 0.3060566606041787\n",
            "At step: 1428 training error: 0.30941506723145357\n",
            "At step: 1429 training error: 0.3148698518965619\n",
            "At step: 1430 training error: 0.31740751390488275\n",
            "At step: 1431 training error: 0.31155532375236394\n",
            "At step: 1432 training error: 0.31450404296839596\n",
            "At step: 1433 training error: 0.30808343803741867\n",
            "At step: 1434 training error: 0.3038323598786652\n",
            "At step: 1435 training error: 0.3098387132161939\n",
            "At step: 1436 training error: 0.3074176203831626\n",
            "At step: 1437 training error: 0.3004212392972361\n",
            "At step: 1438 training error: 0.30250238095491916\n",
            "At step: 1439 training error: 0.293638360727926\n",
            "At step: 1440 training error: 0.2893042392482623\n",
            "At step: 1441 training error: 0.29722313537505174\n",
            "At step: 1442 training error: 0.29399334803071286\n",
            "At step: 1443 training error: 0.28274012998666365\n",
            "At step: 1444 training error: 0.28049999501965345\n",
            "At step: 1445 training error: 0.2848833450478776\n",
            "At step: 1446 training error: 0.28493707220747827\n",
            "At step: 1447 training error: 0.29240306634386937\n",
            "At step: 1448 training error: 0.28837668619355494\n",
            "At step: 1449 training error: 0.30048539178418593\n",
            "At step: 1450 training error: 0.2923520146198515\n",
            "At step: 1451 training error: 0.3108693802729208\n",
            "At step: 1452 training error: 0.3091705516196227\n",
            "At step: 1453 training error: 0.3073038145697166\n",
            "At step: 1454 training error: 0.3052879645919037\n",
            "At step: 1455 training error: 0.2975627452329121\n",
            "At step: 1456 training error: 0.2989430606457106\n",
            "At step: 1457 training error: 0.29293198102057044\n",
            "At step: 1458 training error: 0.29643063136990616\n",
            "At step: 1459 training error: 0.2902399937982741\n",
            "At step: 1460 training error: 0.2925544654389549\n",
            "At step: 1461 training error: 0.2804440883162564\n",
            "At step: 1462 training error: 0.2739616845378621\n",
            "At step: 1463 training error: 0.2723235520947409\n",
            "At step: 1464 training error: 0.27416247516730113\n",
            "At step: 1465 training error: 0.2797395720689652\n",
            "At step: 1466 training error: 0.2815568743234146\n",
            "At step: 1467 training error: 0.2809598945165892\n",
            "At step: 1468 training error: 0.2876085490132454\n",
            "At step: 1469 training error: 0.2891784320103716\n",
            "At step: 1470 training error: 0.2889722452459096\n",
            "At step: 1471 training error: 0.2859383253649038\n",
            "At step: 1472 training error: 0.28915073149627685\n",
            "At step: 1473 training error: 0.29280001875732087\n",
            "At step: 1474 training error: 0.28598544068956\n",
            "At step: 1475 training error: 0.2887043646908423\n",
            "At step: 1476 training error: 0.2926782042944619\n",
            "At step: 1477 training error: 0.2936651969430434\n",
            "At step: 1478 training error: 0.2879482083799791\n",
            "At step: 1479 training error: 0.28747072352427927\n",
            "At step: 1480 training error: 0.2850898580056552\n",
            "At step: 1481 training error: 0.29645334872446405\n",
            "At step: 1482 training error: 0.28611164733269945\n",
            "At step: 1483 training error: 0.28588092455068853\n",
            "At step: 1484 training error: 0.28625180577285514\n",
            "At step: 1485 training error: 0.2868935428665717\n",
            "At step: 1486 training error: 0.28047617692648086\n",
            "At step: 1487 training error: 0.2775070031155366\n",
            "At step: 1488 training error: 0.2729074828440524\n",
            "At step: 1489 training error: 0.2635006760809561\n",
            "At step: 1490 training error: 0.2612669995500576\n",
            "At step: 1491 training error: 0.2581089470862084\n",
            "At step: 1492 training error: 0.26855702008707644\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "error",
          "ename": "KeyboardInterrupt",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-7-efc4583d1b1a>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      7\u001b[0m \u001b[0;31m#\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      8\u001b[0m \u001b[0mnet\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mNetwork\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m28\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0;36m28\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;36m30\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;36m20\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;36m10\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 9\u001b[0;31m \u001b[0mnet\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msgd\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtrain_X\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtrain_y\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mval_X\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mval_y\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m10\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m10000\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m32\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m0.01\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     10\u001b[0m \u001b[0mnet\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msgd\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtrain_X\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtrain_y\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mval_X\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mval_y\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m10\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m10000\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m32\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m0.03\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     11\u001b[0m \u001b[0mnet\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msgd\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtrain_X\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtrain_y\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mval_X\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mval_y\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m10\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m10000\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m32\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m0.001\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m<ipython-input-6-e25d02340d40>\u001b[0m in \u001b[0;36msgd\u001b[0;34m(self, X, y, val_X, val_y, epochs, steps, batch_size, eta)\u001b[0m\n\u001b[1;32m     88\u001b[0m                 \u001b[0mbatch_X\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mX\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mbatch_mask\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     89\u001b[0m                 \u001b[0mbatch_y\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0my\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mbatch_mask\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 90\u001b[0;31m                 \u001b[0merr\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_step\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mbatch_X\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbatch_y\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbatch_size\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0meta\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     91\u001b[0m                 \u001b[0;32mif\u001b[0m \u001b[0mstep\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     92\u001b[0m                     \u001b[0merr_tot\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0merr\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m<ipython-input-6-e25d02340d40>\u001b[0m in \u001b[0;36m_step\u001b[0;34m(self, X, y, batch_size, eta)\u001b[0m\n\u001b[1;32m     67\u001b[0m         \u001b[0;32mfor\u001b[0m \u001b[0mi\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mrange\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m2\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mz_list\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m+\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     68\u001b[0m             \u001b[0md_list\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m-\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmatmul\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0md_list\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m-\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m+\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mw_list\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m-\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m+\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mT\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0msigmoid_prime\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mz_list\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m-\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 69\u001b[0;31m             \u001b[0mnew_w_list\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m-\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mw_list\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m-\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m-\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0meta\u001b[0m \u001b[0;34m/\u001b[0m \u001b[0mbatch_size\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m*\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmatmul\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0ma_list\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m-\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m-\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mT\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0md_list\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m-\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     70\u001b[0m             \u001b[0mnew_b_list\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m-\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mb_list\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m-\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m-\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0meta\u001b[0m \u001b[0;34m/\u001b[0m \u001b[0mbatch_size\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m*\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msum\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0md_list\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m-\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0maxis\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     71\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mw_list\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnew_w_list\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "TeyuzyE9LRra",
        "colab_type": "text"
      },
      "source": [
        "Môžeme si sieť aj otestovať!"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "iGOxv9_eKyk7",
        "colab_type": "code",
        "outputId": "110405cc-b7f5-4fdd-e21d-22cd5aeedb7c",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        }
      },
      "source": [
        "R = net.fwd(X[60000:60010,:])\n",
        "\n",
        "for i in range(10):\n",
        "  plt.imshow(np.reshape(X[60000 + i,:],(28,28)), cmap = 'gray')\n",
        "  plt.show()\n",
        "  print(R[i])\n",
        "  print(np.argmax(R[i,:]))"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "image/png": "iVBORw0KGgoAAAANSUhEUgAAAP8AAAD8CAYAAAC4nHJkAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz\nAAALEgAACxIB0t1+/AAAADl0RVh0U29mdHdhcmUAbWF0cGxvdGxpYiB2ZXJzaW9uIDMuMC4zLCBo\ndHRwOi8vbWF0cGxvdGxpYi5vcmcvnQurowAADO5JREFUeJzt3V2IXfW5x/Hf76QpiOlFYjUMNpqe\nogerSKKjCMYS9VhyYiEWg9SLkkLJ9CJKCyVU7EVzWaQv1JvAlIbGkmMrpNUoYmNjMQ1qcSJqEmNi\nElIzMW9lhCaCtNGnF7Nsp3H2f+/st7XH5/uBYfZez3p52Mxv1lp77bX/jggByOe/6m4AQD0IP5AU\n4QeSIvxAUoQfSIrwA0kRfiApwg8kRfiBpD7Vz43Z5uOEQI9FhFuZr6M9v+1ltvfZPmD7gU7WBaC/\n3O5n+23PkrRf0h2SxiW9LOneiHijsAx7fqDH+rHnv1HSgYg4FBF/l/RrSSs6WB+APuok/JdKOjLl\n+Xg17T/YHrE9Znusg20B6LKev+EXEaOSRiUO+4FB0sme/6ikBVOef66aBmAG6CT8L0u6wvbnbX9a\n0tckbelOWwB6re3D/og4a/s+Sb+XNEvShojY07XOAPRU25f62toY5/xAz/XlQz4AZi7CDyRF+IGk\nCD+QFOEHkiL8QFKEH0iK8ANJEX4gKcIPJEX4gaQIP5AU4QeSIvxAUoQfSIrwA0kRfiApwg8kRfiB\npAg/kBThB5Ii/EBShB9IivADSRF+ICnCDyRF+IGkCD+QFOEHkmp7iG5Jsn1Y0mlJH0g6GxHD3WgK\nQO91FP7KrRHx1y6sB0AfcdgPJNVp+EPSVts7bY90oyEA/dHpYf+SiDhq+xJJz9p+MyK2T52h+qfA\nPwZgwDgiurMie52kMxHxo8I83dkYgIYiwq3M1/Zhv+0LbX/mo8eSvixpd7vrA9BfnRz2z5f0O9sf\nref/I+KZrnQFoOe6dtjf0sY47Ad6rueH/QBmNsIPJEX4gaQIP5AU4QeSIvxAUt24qy+FlStXNqyt\nXr26uOw777xTrL///vvF+qZNm4r148ePN6wdOHCguCzyYs8PJEX4gaQIP5AU4QeSIvxAUoQfSIrw\nA0lxS2+LDh061LC2cOHC/jUyjdOnTzes7dmzp4+dDJbx8fGGtYceeqi47NjYWLfb6Rtu6QVQRPiB\npAg/kBThB5Ii/EBShB9IivADSXE/f4tK9+xfe+21xWX37t1brF911VXF+nXXXVesL126tGHtpptu\nKi575MiRYn3BggXFeifOnj1brJ86dapYHxoaanvbb7/9drE+k6/zt4o9P5AU4QeSIvxAUoQfSIrw\nA0kRfiApwg8k1fR+ftsbJH1F0smIuKaaNk/SbyQtlHRY0j0R8W7Tjc3g+/kH2dy5cxvWFi1aVFx2\n586dxfoNN9zQVk+taDZewf79+4v1Zp+fmDdvXsPamjVrisuuX7++WB9k3byf/5eSlp0z7QFJ2yLi\nCknbqucAZpCm4Y+I7ZImzpm8QtLG6vFGSXd1uS8APdbuOf/8iDhWPT4uaX6X+gHQJx1/tj8ionQu\nb3tE0kin2wHQXe3u+U/YHpKk6vfJRjNGxGhEDEfEcJvbAtAD7YZ/i6RV1eNVkp7oTjsA+qVp+G0/\nKulFSf9je9z2NyX9UNIdtt+S9L/VcwAzCN/bj4F19913F+uPPfZYsb579+6GtVtvvbW47MTEuRe4\nZg6+tx9AEeEHkiL8QFKEH0iK8ANJEX4gKS71oTaXXHJJsb5r166Oll+5cmXD2ubNm4vLzmRc6gNQ\nRPiBpAg/kBThB5Ii/EBShB9IivADSTFEN2rT7OuzL7744mL93XfL3xa/b9++8+4pE/b8QFKEH0iK\n8ANJEX4gKcIPJEX4gaQIP5AU9/Ojp26++eaGteeee6647OzZs4v1pUuXFuvbt28v1j+puJ8fQBHh\nB5Ii/EBShB9IivADSRF+ICnCDyTV9H5+2xskfUXSyYi4ppq2TtJqSaeq2R6MiKd71SRmruXLlzes\nNbuOv23btmL9xRdfbKsnTGplz/9LScummf7TiFhU/RB8YIZpGv6I2C5pog+9AOijTs7577P9uu0N\ntud2rSMAfdFu+NdL+oKkRZKOSfpxoxltj9gesz3W5rYA9EBb4Y+IExHxQUR8KOnnkm4szDsaEcMR\nMdxukwC6r63w2x6a8vSrknZ3px0A/dLKpb5HJS2V9Fnb45J+IGmp7UWSQtJhSd/qYY8AeoD7+dGR\nCy64oFjfsWNHw9rVV19dXPa2224r1l944YViPSvu5wdQRPiBpAg/kBThB5Ii/EBShB9IiiG60ZG1\na9cW64sXL25Ye+aZZ4rLcimvt9jzA0kRfiApwg8kRfiBpAg/kBThB5Ii/EBS3NKLojvvvLNYf/zx\nx4v19957r2Ft2bLpvhT631566aViHdPjll4ARYQfSIrwA0kRfiApwg8kRfiBpAg/kBT38yd30UUX\nFesPP/xwsT5r1qxi/emnGw/gzHX8erHnB5Ii/EBShB9IivADSRF+ICnCDyRF+IGkmt7Pb3uBpEck\nzZcUkkYj4me250n6jaSFkg5Luici3m2yLu7n77Nm1+GbXWu//vrri/WDBw8W66V79psti/Z0837+\ns5K+GxFflHSTpDW2vyjpAUnbIuIKSduq5wBmiKbhj4hjEfFK9fi0pL2SLpW0QtLGaraNku7qVZMA\nuu+8zvltL5S0WNKfJc2PiGNV6bgmTwsAzBAtf7bf9hxJmyV9JyL+Zv/7tCIiotH5vO0RSSOdNgqg\nu1ra89uercngb4qI31aTT9gequpDkk5Ot2xEjEbEcEQMd6NhAN3RNPye3MX/QtLeiPjJlNIWSauq\nx6skPdH99gD0SiuX+pZI+pOkXZI+rCY/qMnz/sckXSbpL5q81DfRZF1c6uuzK6+8slh/8803O1r/\nihUrivUnn3yyo/Xj/LV6qa/pOX9E7JDUaGW3n09TAAYHn/ADkiL8QFKEH0iK8ANJEX4gKcIPJMVX\nd38CXH755Q1rW7du7Wjda9euLdafeuqpjtaP+rDnB5Ii/EBShB9IivADSRF+ICnCDyRF+IGkuM7/\nCTAy0vhb0i677LKO1v38888X682+DwKDiz0/kBThB5Ii/EBShB9IivADSRF+ICnCDyTFdf4ZYMmS\nJcX6/fff36dO8EnCnh9IivADSRF+ICnCDyRF+IGkCD+QFOEHkmp6nd/2AkmPSJovKSSNRsTPbK+T\ntFrSqWrWByPi6V41mtktt9xSrM+ZM6ftdR88eLBYP3PmTNvrxmBr5UM+ZyV9NyJesf0ZSTttP1vV\nfhoRP+pdewB6pWn4I+KYpGPV49O290q6tNeNAeit8zrnt71Q0mJJf64m3Wf7ddsbbM9tsMyI7THb\nYx11CqCrWg6/7TmSNkv6TkT8TdJ6SV+QtEiTRwY/nm65iBiNiOGIGO5CvwC6pKXw256tyeBviojf\nSlJEnIiIDyLiQ0k/l3Rj79oE0G1Nw2/bkn4haW9E/GTK9KEps31V0u7utwegV1p5t/9mSV+XtMv2\nq9W0ByXda3uRJi//HZb0rZ50iI689tprxfrtt99erE9MTHSzHQyQVt7t3yHJ05S4pg/MYHzCD0iK\n8ANJEX4gKcIPJEX4gaQIP5CU+znEsm3GcwZ6LCKmuzT/Mez5gaQIP5AU4QeSIvxAUoQfSIrwA0kR\nfiCpfg/R/VdJf5ny/LPVtEE0qL0Nal8SvbWrm71d3uqMff2Qz8c2bo8N6nf7DWpvg9qXRG/tqqs3\nDvuBpAg/kFTd4R+tefslg9rboPYl0Vu7aumt1nN+APWpe88PoCa1hN/2Mtv7bB+w/UAdPTRi+7Dt\nXbZfrXuIsWoYtJO2d0+ZNs/2s7bfqn5PO0xaTb2ts320eu1etb28pt4W2P6j7Tds77H97Wp6ra9d\noa9aXre+H/bbniVpv6Q7JI1LelnSvRHxRl8bacD2YUnDEVH7NWHbX5J0RtIjEXFNNe0hSRMR8cPq\nH+fciPjegPS2TtKZukdurgaUGZo6srSkuyR9QzW+doW+7lENr1sde/4bJR2IiEMR8XdJv5a0ooY+\nBl5EbJd07qgZKyRtrB5v1OQfT9816G0gRMSxiHilenxa0kcjS9f62hX6qkUd4b9U0pEpz8c1WEN+\nh6SttnfaHqm7mWnMr4ZNl6TjkubX2cw0mo7c3E/njCw9MK9dOyNedxtv+H3ckoi4TtL/SVpTHd4O\npJg8ZxukyzUtjdzcL9OMLP0vdb527Y543W11hP+opAVTnn+umjYQIuJo9fukpN9p8EYfPvHRIKnV\n75M19/MvgzRy83QjS2sAXrtBGvG6jvC/LOkK25+3/WlJX5O0pYY+Psb2hdUbMbJ9oaQva/BGH94i\naVX1eJWkJ2rs5T8MysjNjUaWVs2v3cCNeB0Rff+RtFyT7/gflPT9Onpo0Nd/S3qt+tlTd2+SHtXk\nYeA/NPneyDclXSRpm6S3JP1B0rwB6u1XknZJel2TQRuqqbclmjykf13Sq9XP8rpfu0JftbxufMIP\nSIo3/ICkCD+QFOEHkiL8QFKEH0iK8ANJEX4gKcIPJPVP82g/p9/JjhUAAAAASUVORK5CYII=\n",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {
            "tags": []
          }
        },
        {
          "output_type": "stream",
          "text": [
            "[0.12523084 0.00301107 0.00462281 0.00622856 0.01245105 0.03782456\n",
            " 0.00170998 0.77672491 0.00525389 0.0393361 ]\n",
            "7\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "display_data",
          "data": {
            "image/png": "iVBORw0KGgoAAAANSUhEUgAAAP8AAAD8CAYAAAC4nHJkAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz\nAAALEgAACxIB0t1+/AAAADl0RVh0U29mdHdhcmUAbWF0cGxvdGxpYiB2ZXJzaW9uIDMuMC4zLCBo\ndHRwOi8vbWF0cGxvdGxpYi5vcmcvnQurowAADXZJREFUeJzt3X+IHPUZx/HPU5uAaFGT0uMwttGo\nhSj+CKcUCaVFjVZiYkA0wT9SWnr9o0LF+ItUUChiKf1B/wpEDCba2jRcjFFL0zZUTSEJOSVGo1ET\nuWjCJdcQ0QSRmuTpHzvXXvXmu5uZ2Z29PO8XHLc7z+7Mw3Kfm5md3e/X3F0A4vlS3Q0AqAfhB4Ii\n/EBQhB8IivADQRF+ICjCDwRF+IGgCD8Q1Jc7uTEz4+OEQJu5u7XyuFJ7fjO70czeNrPdZvZAmXUB\n6Cwr+tl+MztN0juSrpe0T9I2SYvc/c3Ec9jzA23WiT3/1ZJ2u/t77v5vSX+UNL/E+gB0UJnwnyvp\ngzH392XL/o+Z9ZvZoJkNltgWgIq1/Q0/d18uabnEYT/QTcrs+fdLOm/M/WnZMgATQJnwb5N0kZmd\nb2aTJS2UtL6atgC0W+HDfnc/ZmZ3Stog6TRJK9x9Z2WdAWirwpf6Cm2Mc36g7TryIR8AExfhB4Ii\n/EBQhB8IivADQRF+ICjCDwRF+IGgCD8QFOEHgiL8QFCEHwiK8ANBdXTobhRzzz33JOunn356bu2y\nyy5LPvfWW28t1NOoZcuWJeubN2/OrT355JOlto1y2PMDQRF+ICjCDwRF+IGgCD8QFOEHgiL8QFCM\n3tsFVq9enayXvRZfpz179uTWrrvuuuRz33///arbCYHRewEkEX4gKMIPBEX4gaAIPxAU4QeCIvxA\nUKW+z29mQ5KOSDou6Zi791XR1Kmmzuv4u3btStY3bNiQrF9wwQXJ+s0335ysz5gxI7d2xx13JJ/7\n6KOPJusop4rBPL7r7ocqWA+ADuKwHwiqbPhd0l/N7BUz66+iIQCdUfawf7a77zezr0n6m5ntcveX\nxz4g+6fAPwagy5Ta87v7/uz3iKRnJF09zmOWu3sfbwYC3aVw+M3sDDP7yuhtSXMkvVFVYwDaq8xh\nf4+kZ8xsdD1/cPe/VNIVgLYrHH53f0/S5RX2MmH19aXPaBYsWFBq/Tt37kzW582bl1s7dCh9Ffbo\n0aPJ+uTJk5P1LVu2JOuXX57/JzJ16tTkc9FeXOoDgiL8QFCEHwiK8ANBEX4gKMIPBMUU3RXo7e1N\n1rPPQuRqdinvhhtuSNaHh4eT9TKWLFmSrM+cObPwul944YXCz0V57PmBoAg/EBThB4Ii/EBQhB8I\nivADQRF+ICiu81fgueeeS9YvvPDCZP3IkSPJ+uHDh0+6p6osXLgwWZ80aVKHOkHV2PMDQRF+ICjC\nDwRF+IGgCD8QFOEHgiL8QFBc5++AvXv31t1CrnvvvTdZv/jii0utf+vWrYVqaD/2/EBQhB8IivAD\nQRF+ICjCDwRF+IGgCD8QlLl7+gFmKyTNlTTi7pdmy6ZIWi1puqQhSbe5+4dNN2aW3hgqN3fu3GR9\nzZo1yXqzKbpHRkaS9dR4AC+99FLyuSjG3dMTRWRa2fM/IenGzy17QNJGd79I0sbsPoAJpGn43f1l\nSZ8fSma+pJXZ7ZWSbqm4LwBtVvScv8fdR+eIOiCpp6J+AHRI6c/2u7unzuXNrF9Sf9ntAKhW0T3/\nQTPrlaTsd+67Pu6+3N373L2v4LYAtEHR8K+XtDi7vVjSs9W0A6BTmobfzJ6WtFnSN81sn5n9UNIv\nJF1vZu9Kui67D2ACaXrO7+6LckrXVtwL2qCvL3221ew6fjOrV69O1rmW3734hB8QFOEHgiL8QFCE\nHwiK8ANBEX4gKIbuPgWsW7cutzZnzpxS6161alWy/uCDD5ZaP+rDnh8IivADQRF+ICjCDwRF+IGg\nCD8QFOEHgmo6dHelG2Po7kJ6e3uT9ddeey23NnXq1ORzDx06lKxfc801yfqePXuSdXRelUN3AzgF\nEX4gKMIPBEX4gaAIPxAU4QeCIvxAUHyffwIYGBhI1ptdy0956qmnknWu45+62PMDQRF+ICjCDwRF\n+IGgCD8QFOEHgiL8QFBNr/Ob2QpJcyWNuPul2bKHJf1I0r+yhy119z+3q8lT3bx585L1WbNmFV73\niy++mKw/9NBDhdeNia2VPf8Tkm4cZ/lv3f2K7IfgAxNM0/C7+8uSDnegFwAdVOac/04z22FmK8zs\nnMo6AtARRcO/TNIMSVdIGpb067wHmlm/mQ2a2WDBbQFog0Lhd/eD7n7c3U9IekzS1YnHLnf3Pnfv\nK9okgOoVCr+ZjR1OdoGkN6ppB0CntHKp72lJ35H0VTPbJ+khSd8xsyskuaQhST9uY48A2qBp+N19\n0TiLH29DL6esZt+3X7p0abI+adKkwtvevn17sn706NHC68bExif8gKAIPxAU4QeCIvxAUIQfCIrw\nA0ExdHcHLFmyJFm/6qqrSq1/3bp1uTW+sos87PmBoAg/EBThB4Ii/EBQhB8IivADQRF+IChz985t\nzKxzG+sin376abJe5iu7kjRt2rTc2vDwcKl1Y+Jxd2vlcez5gaAIPxAU4QeCIvxAUIQfCIrwA0ER\nfiAovs9/CpgyZUpu7bPPPutgJ1/00Ucf5daa9dbs8w9nnXVWoZ4k6eyzz07W77777sLrbsXx48dz\na/fff3/yuZ988kklPbDnB4Ii/EBQhB8IivADQRF+ICjCDwRF+IGgml7nN7PzJK2S1CPJJS1399+Z\n2RRJqyVNlzQk6TZ3/7B9rSLPjh076m4h15o1a3JrzcYa6OnpSdZvv/32Qj11uwMHDiTrjzzySCXb\naWXPf0zSEnefKelbkn5iZjMlPSBpo7tfJGljdh/ABNE0/O4+7O6vZrePSHpL0rmS5ktamT1spaRb\n2tUkgOqd1Dm/mU2XdKWkrZJ63H30uO2AGqcFACaIlj/bb2ZnShqQdJe7f2z2v2HC3N3zxuczs35J\n/WUbBVCtlvb8ZjZJjeD/3t3XZosPmllvVu+VNDLec919ubv3uXtfFQ0DqEbT8FtjF/+4pLfc/Tdj\nSuslLc5uL5b0bPXtAWiXpkN3m9lsSZskvS7pRLZ4qRrn/X+S9HVJe9W41He4ybpCDt29du3aZH3+\n/Pkd6iSWY8eO5dZOnDiRW2vF+vXrk/XBwcHC6960aVOyvmXLlmS91aG7m57zu/s/JeWt7NpWNgKg\n+/AJPyAowg8ERfiBoAg/EBThB4Ii/EBQTNHdBe67775kvewU3imXXHJJst7Or82uWLEiWR8aGiq1\n/oGBgdzarl27Sq27mzFFN4Akwg8ERfiBoAg/EBThB4Ii/EBQhB8Iiuv8wCmG6/wAkgg/EBThB4Ii\n/EBQhB8IivADQRF+ICjCDwRF+IGgCD8QFOEHgiL8QFCEHwiK8ANBEX4gqKbhN7PzzOwfZvamme00\ns59myx82s/1mtj37uan97QKoStPBPMysV1Kvu79qZl+R9IqkWyTdJumou/+q5Y0xmAfQdq0O5vHl\nFlY0LGk4u33EzN6SdG659gDU7aTO+c1suqQrJW3NFt1pZjvMbIWZnZPznH4zGzSzwVKdAqhUy2P4\nmdmZkl6S9Ii7rzWzHkmHJLmkn6txavCDJuvgsB9os1YP+1sKv5lNkvS8pA3u/ptx6tMlPe/ulzZZ\nD+EH2qyyATzNzCQ9LumtscHP3ggctUDSGyfbJID6tPJu/2xJmyS9LulEtnippEWSrlDjsH9I0o+z\nNwdT62LPD7RZpYf9VSH8QPsxbj+AJMIPBEX4gaAIPxAU4QeCIvxAUIQfCIrwA0ERfiAowg8ERfiB\noAg/EBThB4Ii/EBQTQfwrNghSXvH3P9qtqwbdWtv3dqXRG9FVdnbN1p9YEe/z/+FjZsNuntfbQ0k\ndGtv3dqXRG9F1dUbh/1AUIQfCKru8C+vefsp3dpbt/Yl0VtRtfRW6zk/gPrUvecHUJNawm9mN5rZ\n22a228weqKOHPGY2ZGavZzMP1zrFWDYN2oiZvTFm2RQz+5uZvZv9HneatJp664qZmxMzS9f62nXb\njNcdP+w3s9MkvSPpekn7JG2TtMjd3+xoIznMbEhSn7vXfk3YzL4t6aikVaOzIZnZLyUddvdfZP84\nz3H3+7ukt4d1kjM3t6m3vJmlv68aX7sqZ7yuQh17/qsl7Xb399z935L+KGl+DX10PXd/WdLhzy2e\nL2lldnulGn88HZfTW1dw92F3fzW7fUTS6MzStb52ib5qUUf4z5X0wZj7+9RdU367pL+a2Stm1l93\nM+PoGTMz0gFJPXU2M46mMzd30udmlu6a167IjNdV4w2/L5rt7rMkfU/ST7LD267kjXO2brpcs0zS\nDDWmcRuW9Os6m8lmlh6QdJe7fzy2VudrN05ftbxudYR/v6Tzxtyfli3rCu6+P/s9IukZNU5TusnB\n0UlSs98jNffzX+5+0N2Pu/sJSY+pxtcum1l6QNLv3X1ttrj21268vup63eoI/zZJF5nZ+WY2WdJC\nSetr6OMLzOyM7I0YmdkZkuao+2YfXi9pcXZ7saRna+zl/3TLzM15M0ur5teu62a8dveO/0i6SY13\n/PdI+lkdPeT0dYGk17KfnXX3JulpNQ4DP1PjvZEfSpoqaaOkdyX9XdKULurtSTVmc96hRtB6a+pt\nthqH9Dskbc9+bqr7tUv0Vcvrxif8gKB4ww8IivADQRF+ICjCDwRF+IGgCD8QFOEHgiL8QFD/Abw9\nWv8QfFP9AAAAAElFTkSuQmCC\n",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {
            "tags": []
          }
        },
        {
          "output_type": "stream",
          "text": [
            "[1.20001553e-01 1.96503987e-02 4.58400595e-01 1.57629744e-01\n",
            " 4.41331624e-04 3.10716063e-02 3.76261724e-02 6.81080659e-04\n",
            " 3.38357294e-01 7.09279057e-04]\n",
            "2\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "display_data",
          "data": {
            "image/png": "iVBORw0KGgoAAAANSUhEUgAAAP8AAAD8CAYAAAC4nHJkAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\n/wNRj+er2ohshAAAAABJRU5ErkJggg==\n",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {
            "tags": []
          }
        },
        {
          "output_type": "stream",
          "text": [
            "[0.00122257 0.86629252 0.03101753 0.01315321 0.04036226 0.00153139\n",
            " 0.01156872 0.01348759 0.01669565 0.00615378]\n",
            "1\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "display_data",
          "data": {
            "image/png": "iVBORw0KGgoAAAANSUhEUgAAAP8AAAD8CAYAAAC4nHJkAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\nIvxAUP8FAfaK+yOWZZUAAAAASUVORK5CYII=\n",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {
            "tags": []
          }
        },
        {
          "output_type": "stream",
          "text": [
            "[8.53642695e-01 1.73429039e-04 4.34650021e-02 1.41514665e-02\n",
            " 1.10947576e-02 7.95487282e-02 5.01644949e-02 1.54682001e-02\n",
            " 1.04895016e-02 7.79730643e-03]\n",
            "0\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "display_data",
          "data": {
            "image/png": "iVBORw0KGgoAAAANSUhEUgAAAP8AAAD8CAYAAAC4nHJkAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\nni26LDgAAAAASUVORK5CYII=\n",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {
            "tags": []
          }
        },
        {
          "output_type": "stream",
          "text": [
            "[0.00545605 0.0006034  0.00276516 0.01004959 0.4887804  0.01840578\n",
            " 0.05849188 0.00603938 0.0060543  0.28962314]\n",
            "4\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "display_data",
          "data": {
            "image/png": "iVBORw0KGgoAAAANSUhEUgAAAP8AAAD8CAYAAAC4nHJkAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\n/FJRhl8qyvBLRf0f7V4JFFPw3M8AAAAASUVORK5CYII=\n",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {
            "tags": []
          }
        },
        {
          "output_type": "stream",
          "text": [
            "[6.50422587e-04 8.75325848e-01 1.18020688e-02 1.00696660e-02\n",
            " 2.16820404e-02 1.52270246e-03 2.02840305e-02 3.69091311e-03\n",
            " 1.71153156e-02 8.09528338e-03]\n",
            "1\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "display_data",
          "data": {
            "image/png": "iVBORw0KGgoAAAANSUhEUgAAAP8AAAD8CAYAAAC4nHJkAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\nBEX4gaAIPxDUfwEJEYHZ+iI4owAAAABJRU5ErkJggg==\n",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {
            "tags": []
          }
        },
        {
          "output_type": "stream",
          "text": [
            "[0.00320795 0.0018251  0.00421562 0.00997912 0.44808536 0.02493531\n",
            " 0.0724309  0.05923979 0.0054142  0.22613235]\n",
            "4\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "display_data",
          "data": {
            "image/png": "iVBORw0KGgoAAAANSUhEUgAAAP8AAAD8CAYAAAC4nHJkAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\nkc59O3KwAAAAAElFTkSuQmCC\n",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {
            "tags": []
          }
        },
        {
          "output_type": "stream",
          "text": [
            "[0.0041872  0.00440536 0.00153395 0.00484204 0.18990073 0.06306452\n",
            " 0.01050015 0.02571359 0.01209636 0.13732852]\n",
            "4\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "display_data",
          "data": {
            "image/png": "iVBORw0KGgoAAAANSUhEUgAAAP8AAAD8CAYAAAC4nHJkAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\nmYaFlMuCxPsAAAAASUVORK5CYII=\n",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {
            "tags": []
          }
        },
        {
          "output_type": "stream",
          "text": [
            "[0.12265284 0.00225114 0.03634636 0.00428626 0.18239828 0.01213656\n",
            " 0.06687244 0.00284248 0.01534639 0.02162131]\n",
            "4\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "display_data",
          "data": {
            "image/png": "iVBORw0KGgoAAAANSUhEUgAAAP8AAAD8CAYAAAC4nHJkAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\ngaAIPxAU4QeC+j9mg5DCHVPKAgAAAABJRU5ErkJggg==\n",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {
            "tags": []
          }
        },
        {
          "output_type": "stream",
          "text": [
            "[0.00593848 0.00924074 0.00549288 0.00483596 0.01191088 0.00864117\n",
            " 0.04421318 0.39564688 0.01625643 0.09187523]\n",
            "7\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Ej6vAvd8Ulj5",
        "colab_type": "code",
        "outputId": "fc143ac3-c94a-4bd7-cae6-aa716b928635",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "!pwd\n"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "/content\n"
          ],
          "name": "stdout"
        }
      ]
    }
  ]
}