{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "cv07-en.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "toc_visible": true,
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/kocurvik/edu/blob/master/PNSPV/notebooky/keras_2020/cv07-en.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "NlINbptx_CDZ"
      },
      "source": [
        "# 7th lab - Fine-tuning and visualization\n",
        "\n",
        "Today we will go through the fine-tuning method from last lab. Fine-tuning is a very common form of transfer learning. Try to implemnt this in Google Cloud. In the second part of this lab we will try to visualize which parts of the input image are important for classification.\n",
        "\n",
        "## 1st Exercise\n",
        "Do this exercise on the cloud. You can prepare the code on your computer or in the Google Colab. However you should run the code in the cloud.\n",
        "\n",
        "This task deals with fine-tuning a neural network which was already pretrained on some dataset. The pretrained models are available at: [keras applications](https://keras.io/applications/). We will fine-tune these models ont the cats vs. dogs dataset, which you can find here:\n",
        "\n",
        "```\n",
        "https://www.floydhub.com/swaroopgrs/datasets/dogscats/1\n",
        "```\n",
        "or\n",
        "```\n",
        "https://files.fast.ai/data/examples/dogscats.tgz\n",
        "```\n",
        "\n",
        "To use that dataset use the ImageDataGenerator and its method flow_from_directory.\n",
        "\n",
        "When loading the pretrained model we have three options. We either keep all of the layers trainable, we freeze almost all of them or we freeze just some of them. You can freeze the layers in a for cycle.\n",
        "\n",
        "```python\n",
        "xception = keras.applications.xception.Xception(include_top = False)\n",
        "for layer in xception.layers:\n",
        "    layer.trainable = False\n",
        "```\n",
        "\n",
        "Use the model without top (include_top = False). You will then need to add some dense layers at the end of the model.\n",
        "\n",
        "You can add the loaded model as a \"layer\" into the a new Sequential model and then add a Global Pooling layer and few Dense layers. Test the training for all of the three options.\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "8RZwi9aiAJ1-"
      },
      "source": [
        "## Visualizing important parts of the image input\n",
        "\n",
        "Now we will try to check which parts of the input image are important for classification. We will do this by taking an image and looking at the resulting class. Afterwards we will add a black square on various parts of the image to see which placements of the square lead to the greatest change in the network output."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "J_BBXq6y-ow7"
      },
      "source": [
        "import keras\n",
        "import cv2\n",
        "import numpy as np\n",
        "from keras.applications.imagenet_utils import preprocess_input, decode_predictions\n",
        "import matplotlib.pyplot as plt"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "mrZBoP3rGV2F"
      },
      "source": [
        "We will use a pretrained model as well."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Tp6kx6zyGUuk"
      },
      "source": [
        "resnet = keras.applications.resnet.ResNet50()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "7LVOYMyYOPmP"
      },
      "source": [
        "Let us load some testing images and change their sizes."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "xRnmRsRiL0jX"
      },
      "source": [
        "test_imgs = []\n",
        "!wget https://pixnio.com/free-images/2017/06/08/2017-06-08-13-53-59-900x576.jpg\n",
        "test_imgs.append(cv2.resize(cv2.imread('2017-06-08-13-53-59-900x576.jpg'),(224,224)))\n",
        "!wget https://storage.needpix.com/rsynced_images/diver-1881751_1280.jpg\n",
        "test_imgs.append(cv2.resize(cv2.imread('diver-1881751_1280.jpg'),(224,224)))\n",
        "!wget https://cdn.pixabay.com/photo/2017/09/22/23/24/white-stork-2777489_960_720.jpg\n",
        "test_imgs.append(cv2.resize(cv2.imread('white-stork-2777489_960_720.jpg'),(224,224)))\n",
        "!wget https://upload.wikimedia.org/wikipedia/commons/thumb/8/84/Croatia_police_van_%2804%29.JPG/800px-Croatia_police_van_%2804%29.JPG\n",
        "test_imgs.append(cv2.resize(cv2.imread('800px-Croatia_police_van_(04).JPG'),(224,224)))\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "neOXUgLROUgA"
      },
      "source": [
        "Before using the network we have to first preprocess the images in order for them to be in the same format as the training images for the network.**It is important to check whether the input image is in RGB or BGR as in OpenCV**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "le7hrl_LHo77"
      },
      "source": [
        "pred = resnet.predict(preprocess_input(test_imgs[0])[None, :, :, :])\n",
        "print(np.argmax(pred[0]))\n",
        "print(decode_predictions(pred)[0])"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "R-fMH8vx3_8C"
      },
      "source": [
        "Implement this function so that it returns a heatmap of size $rectangle\\_num \\times rectangle\\_num$. The elements of the array will represent how much the predicted output changes if we add a black $rectangle\\_size \\times rectangle\\_size$ square to that position in the image. \n",
        "\n",
        "When implementing this function it is beneficial to use the fact that the method model.predict can take multiple images as an input if they are stacked together in the same fashion we did when generating batches."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "HeXbPdTROj5W"
      },
      "source": [
        "def generate_heatmap(img, model, rectangle_num, rectangle_size):\n",
        "  heatmap = np.zeros([rectangle_num, rectangle_num])\n",
        "  return heatmap"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "oV8K0GLT4xt8"
      },
      "source": [
        "This code should show the resulting heatmaps for the test images."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "FL_OxjL0PqYN"
      },
      "source": [
        "for test_img in test_imgs:\n",
        "  hmap = generate_heatmap(test_img, resnet, 20, 9)\n",
        "  plt.imshow(hmap,cmap='gray')\n",
        "  plt.show()\n",
        "  plt.imshow(test_img[:,:,::-1])\n",
        "  plt.show()"
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}