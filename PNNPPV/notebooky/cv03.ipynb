{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "cv03.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "toc_visible": true,
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/kocurvik/edu/blob/master/PNNPPV/notebooky/cv03.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "iIVREN6GLQI1",
        "colab_type": "text"
      },
      "source": [
        "# 3. cvičenie - trénovanie sietí\n",
        "\n",
        "V tomto notebooku si vyskúšame trénovanie v kerase. Prejdeme si základ delenia dát na trénovacie, validačné a testovacie. Skontrolujeme účinky over a underfittingu. Otestujeme rôzne aktivačné funkcie a cenové funkcie. Otestujeme možnosti regularizácie.\n",
        "\n",
        "Behom cvičenia budeme používať framework keras. Jeho dokumentáciu nájdete na [keras.io](https://keras.io/)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "9Gi6M79scklj",
        "colab_type": "text"
      },
      "source": [
        "## Plne prepojená sieť v kerase\n",
        "\n",
        "V tomto aj v ďalších cvičeniach budeme používať keras. Keras pôvodne vznikol ako nadstavba tensorflow a theana aby poskytol jednoduché API pre deep learning. Dnes je keras dokonca súčasťou distribúcie tensorflowu. My si ho však budeme importovať samostatne."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "U9sp3P_wZsM0",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "import keras\n",
        "from keras.datasets import mnist"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "S4_RRqTNaN0S",
        "colab_type": "text"
      },
      "source": [
        "Načítame dáta. "
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "69afZV8RbHpR",
        "colab_type": "code",
        "outputId": "1278ede7-2219-48d2-f404-53602ac60e2e",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 320
        }
      },
      "source": [
        "(x, y), (x_test, y_test) = mnist.load_data()\n",
        "x = np.reshape(x,(-1,784)).astype(np.float32) / 255\n",
        "x_test = np.reshape(x_test,(-1,784)).astype(np.float32) / 255\n",
        "y = keras.utils.to_categorical(y)\n",
        "y_test = keras.utils.to_categorical(y_test)\n",
        "\n",
        "plt.imshow(np.reshape(x[0,:],(28,28)), cmap='gray')\n",
        "plt.show()\n",
        "print(y[0])"
      ],
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Downloading data from https://s3.amazonaws.com/img-datasets/mnist.npz\n",
            "11493376/11490434 [==============================] - 1s 0us/step\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "display_data",
          "data": {
            "image/png": "iVBORw0KGgoAAAANSUhEUgAAAP8AAAD8CAYAAAC4nHJkAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\n",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {
            "tags": []
          }
        },
        {
          "output_type": "stream",
          "text": [
            "[0. 0. 0. 0. 0. 1. 0. 0. 0. 0.]\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "udwpZyG-dlff",
        "colab_type": "text"
      },
      "source": [
        "### Konštrukcia modelu\n",
        "\n",
        "Keras má triedu Sequential, ktorá predstavuje model neurónovej siete, kde každá vrstva posúva svoje výstupy do práve jednej nasledujúcej. To modelu tak vieme jednoznačne pridávať ďalšie vrstvy. Teraz si spravíme model ako z minulého cvičenia."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "aY8yguc9W_CM",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "from keras.models import Sequential\n",
        "from keras.layers import Dense"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "92bprjyTeKuV",
        "colab_type": "code",
        "outputId": "83f43959-d27a-4ca7-f107-065ae66c1fc0",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 71
        }
      },
      "source": [
        "model = Sequential()\n",
        "model.add(Dense(30, activation='sigmoid', input_shape=(784,)))\n",
        "model.add(Dense(20, activation='sigmoid'))\n",
        "model.add(Dense(10, activation='softmax'))"
      ],
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py:66: The name tf.get_default_graph is deprecated. Please use tf.compat.v1.get_default_graph instead.\n",
            "\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "8nR1mHhXfQdF",
        "colab_type": "text"
      },
      "source": [
        "Modelu musíme pridať cenovú funkciu a vybrať optimalizačný algoritmus. Tento krok za nazýva tzv. kompilácia. Po kompilácii si môžeme model pozrieť pomocou metódy summary.\n",
        "\n",
        "*Pozn.:* Summary môžeme zavolať až keď je model kompletný. Teda vieme aké v ňom budú veľkosti vrstiev. Ak prvej vrstve nepridáme parameter input_shape, tak summary môžeme zavolať až po trénovaní (to už sieť bude vedieť aký je vstup)."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "siJkGdtLffBd",
        "colab_type": "code",
        "outputId": "875b817a-337b-47be-cf10-e50787fe387c",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 326
        }
      },
      "source": [
        "loss = keras.losses.categorical_crossentropy\n",
        "model.compile(loss=loss,\n",
        "              optimizer='sgd',\n",
        "              metrics=['accuracy'])\n",
        "print(model.summary())"
      ],
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/keras/optimizers.py:793: The name tf.train.Optimizer is deprecated. Please use tf.compat.v1.train.Optimizer instead.\n",
            "\n",
            "Model: \"sequential_1\"\n",
            "_________________________________________________________________\n",
            "Layer (type)                 Output Shape              Param #   \n",
            "=================================================================\n",
            "dense_1 (Dense)              (None, 30)                23550     \n",
            "_________________________________________________________________\n",
            "dense_2 (Dense)              (None, 20)                620       \n",
            "_________________________________________________________________\n",
            "dense_3 (Dense)              (None, 10)                210       \n",
            "=================================================================\n",
            "Total params: 24,380\n",
            "Trainable params: 24,380\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n",
            "None\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "a_q9uHbKemE9",
        "colab_type": "text"
      },
      "source": [
        "Model trénujeme volaním metódy fit ktorej poskytneme trénovacie dáta. Tentokrát si tréning spustíme len na chvílu. Neriešime ani validačné dáta."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "t2iulP5oe3lA",
        "colab_type": "code",
        "outputId": "e8327d60-d61c-496b-b96e-37603de44675",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 275
        }
      },
      "source": [
        "model.fit(x, y, batch_size=32, epochs=5)"
      ],
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/tensorflow_core/python/ops/math_grad.py:1424: where (from tensorflow.python.ops.array_ops) is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "Use tf.where in 2.0, which has the same broadcast rule as np.where\n",
            "Epoch 1/5\n",
            "60000/60000 [==============================] - 13s 208us/step - loss: 2.2649 - acc: 0.2412\n",
            "Epoch 2/5\n",
            "60000/60000 [==============================] - 7s 120us/step - loss: 2.0641 - acc: 0.4835\n",
            "Epoch 3/5\n",
            "60000/60000 [==============================] - 7s 117us/step - loss: 1.6911 - acc: 0.5885\n",
            "Epoch 4/5\n",
            "60000/60000 [==============================] - 7s 116us/step - loss: 1.3123 - acc: 0.6935\n",
            "Epoch 5/5\n",
            "60000/60000 [==============================] - 7s 117us/step - loss: 1.0098 - acc: 0.7700\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<keras.callbacks.History at 0x7fd16667e278>"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 8
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "qP7dlrc3TZbR",
        "colab_type": "text"
      },
      "source": [
        "## Predbežné testovanie modelu\n",
        "\n",
        "Pri trénovaní modelu je nutné overiť si, že má dostatočnú kapacitu pre daný problém. Kapacita modelu je v tomto prípade vyjadrenie toho akú veľkú (resp. ako zložitú) množinu funkcií je možné modelovať. Ak náš model ani teoreticky nedokáže modelovať žiadanú funkciu (napr. klasifikátor), tak nieje vhodné ho použiť. Napr. používať lineárny klasifikátor na dáta o ktorých vieme, že sú lineárne neseparovateľné je príklad nedostatočnej kapacity modelu.\n",
        "\n",
        "Najjednoduchšie ako toto budeme testovať je tak, že vyberieme veľmi malú časť (napr. 1 minibatch) dát na ktorých chceme trénovať a overíme, či sa nám podarí model natrénovať na 100 percent na takejto malej vzorke.\n",
        "\n",
        "Týmto testovaním tiež overíme, že trénovanie funguje a nieje problém s dátami. Tento postup je vhodný prvý krok pri troubleshootingu sietí.\n",
        "\n",
        "*Pozn.:* Pri takomto testovaní je dôležité nemať všetky príklady z rovnakej kategórie, lebo v takom prípade ani netreba uvažovať o kapacite modelu."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "9rtiKiV5cRHC",
        "colab_type": "text"
      },
      "source": [
        "Vyberieme malú vzorku dát a skúsime natrénovať model."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Rq3dGAMwcWBp",
        "colab_type": "code",
        "outputId": "4fe3c871-89c5-4558-e273-07c31751d096",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 374
        }
      },
      "source": [
        "x_mini = x[:32]\n",
        "y_mini = y[:32]\n",
        "\n",
        "model = Sequential()\n",
        "model.add(Dense(30, activation='sigmoid'))\n",
        "model.add(Dense(20, activation='sigmoid'))\n",
        "model.add(Dense(10, activation='softmax'))\n",
        "\n",
        "loss = keras.losses.categorical_crossentropy\n",
        "model.compile(loss=loss,\n",
        "              optimizer='sgd',\n",
        "              metrics=['accuracy'])\n",
        "\n",
        "model.fit(x_mini, y_mini, steps_per_epoch=1000, epochs=10)"
      ],
      "execution_count": 9,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Epoch 1/10\n",
            "1000/1000 [==============================] - 4s 4ms/step - loss: 2.1673 - acc: 0.2220\n",
            "Epoch 2/10\n",
            "1000/1000 [==============================] - 4s 4ms/step - loss: 1.9409 - acc: 0.3965\n",
            "Epoch 3/10\n",
            "1000/1000 [==============================] - 4s 4ms/step - loss: 1.5564 - acc: 0.6616\n",
            "Epoch 4/10\n",
            "1000/1000 [==============================] - 4s 4ms/step - loss: 1.1277 - acc: 0.7500\n",
            "Epoch 5/10\n",
            "1000/1000 [==============================] - 4s 4ms/step - loss: 0.8092 - acc: 0.7754\n",
            "Epoch 6/10\n",
            "1000/1000 [==============================] - 4s 4ms/step - loss: 0.5994 - acc: 0.9025\n",
            "Epoch 7/10\n",
            "1000/1000 [==============================] - 4s 4ms/step - loss: 0.4555 - acc: 0.9367\n",
            "Epoch 8/10\n",
            "1000/1000 [==============================] - 4s 4ms/step - loss: 0.3499 - acc: 1.0000\n",
            "Epoch 9/10\n",
            "1000/1000 [==============================] - 4s 4ms/step - loss: 0.2705 - acc: 1.0000\n",
            "Epoch 10/10\n",
            "1000/1000 [==============================] - 4s 4ms/step - loss: 0.2112 - acc: 1.0000\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<keras.callbacks.History at 0x7fd17cbee630>"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 9
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "mYbfK_V7g4Xk",
        "colab_type": "text"
      },
      "source": [
        "Ako je možné vidieť tak náš model dosahuje 100 percentnú presnosť na našich dátach. To ukazuje, že náš model má aspoň takú kapacitu aby fungoval. Teraz si ukážeme príklad keď to nefunguje. Napríklad vynechaním nelinearity."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "W1RB9ec5hY2s",
        "colab_type": "code",
        "outputId": "e06df60c-378e-47b3-a88b-ed26351f078e",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 374
        }
      },
      "source": [
        "x_mini = x[:32]\n",
        "y_mini = y[:32]\n",
        "\n",
        "model = Sequential()\n",
        "model.add(Dense(30))\n",
        "model.add(Dense(20))\n",
        "model.add(Dense(10))\n",
        "\n",
        "loss = keras.losses.categorical_crossentropy\n",
        "model.compile(loss=loss,\n",
        "              optimizer='sgd',\n",
        "              metrics=['accuracy'])\n",
        "\n",
        "model.fit(x_mini, y_mini, steps_per_epoch=1000, epochs=10)"
      ],
      "execution_count": 10,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Epoch 1/10\n",
            "1000/1000 [==============================] - 4s 4ms/step - loss: 8.0450 - acc: 0.1261\n",
            "Epoch 2/10\n",
            "1000/1000 [==============================] - 4s 4ms/step - loss: 8.0590 - acc: 0.1250\n",
            "Epoch 3/10\n",
            "1000/1000 [==============================] - 4s 4ms/step - loss: 8.0590 - acc: 0.1250\n",
            "Epoch 4/10\n",
            "1000/1000 [==============================] - 4s 4ms/step - loss: 8.0590 - acc: 0.1250\n",
            "Epoch 5/10\n",
            "1000/1000 [==============================] - 4s 4ms/step - loss: 8.0590 - acc: 0.1250\n",
            "Epoch 6/10\n",
            "1000/1000 [==============================] - 4s 4ms/step - loss: 8.0590 - acc: 0.1250\n",
            "Epoch 7/10\n",
            "1000/1000 [==============================] - 4s 4ms/step - loss: 8.0590 - acc: 0.1250\n",
            "Epoch 8/10\n",
            "1000/1000 [==============================] - 4s 4ms/step - loss: 8.0590 - acc: 0.1250\n",
            "Epoch 9/10\n",
            "1000/1000 [==============================] - 4s 4ms/step - loss: 8.0590 - acc: 0.1250\n",
            "Epoch 10/10\n",
            "1000/1000 [==============================] - 4s 4ms/step - loss: 8.0590 - acc: 0.1250\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<keras.callbacks.History at 0x7fd110b40dd8>"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 10
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Mgeqb7qempvY",
        "colab_type": "text"
      },
      "source": [
        "Podobne to bude pre príliš malý model."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "EzbAFTjyk2MT",
        "colab_type": "code",
        "outputId": "9864c1b3-7078-47fb-9339-b8c953b7c451",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 374
        }
      },
      "source": [
        "x_mini = x[:32]\n",
        "y_mini = y[:32]\n",
        "\n",
        "model = Sequential()\n",
        "model.add(Dense(2, activation='sigmoid'))\n",
        "model.add(Dense(10, activation='softmax'))\n",
        "\n",
        "loss = keras.losses.categorical_crossentropy\n",
        "model.compile(loss=loss,\n",
        "              optimizer='sgd',\n",
        "              metrics=['accuracy'])\n",
        "\n",
        "model.fit(x_mini, y_mini, steps_per_epoch=10000, epochs=10)"
      ],
      "execution_count": 11,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Epoch 1/10\n",
            "10000/10000 [==============================] - 36s 4ms/step - loss: 1.4876 - acc: 0.5332\n",
            "Epoch 2/10\n",
            "10000/10000 [==============================] - 36s 4ms/step - loss: 0.9744 - acc: 0.6607\n",
            "Epoch 3/10\n",
            "10000/10000 [==============================] - 36s 4ms/step - loss: 0.8134 - acc: 0.7125\n",
            "Epoch 4/10\n",
            "10000/10000 [==============================] - 36s 4ms/step - loss: 0.7024 - acc: 0.8380\n",
            "Epoch 5/10\n",
            "10000/10000 [==============================] - 35s 4ms/step - loss: 0.6147 - acc: 0.8910\n",
            "Epoch 6/10\n",
            "10000/10000 [==============================] - 36s 4ms/step - loss: 0.5451 - acc: 1.0000\n",
            "Epoch 7/10\n",
            "10000/10000 [==============================] - 35s 4ms/step - loss: 0.4889 - acc: 1.0000\n",
            "Epoch 8/10\n",
            "10000/10000 [==============================] - 36s 4ms/step - loss: 0.4428 - acc: 1.0000\n",
            "Epoch 9/10\n",
            "10000/10000 [==============================] - 35s 4ms/step - loss: 0.4046 - acc: 1.0000\n",
            "Epoch 10/10\n",
            "10000/10000 [==============================] - 36s 4ms/step - loss: 0.3728 - acc: 1.0000\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<keras.callbacks.History at 0x7fd110abe358>"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 11
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "BVberJIGhLjU",
        "colab_type": "text"
      },
      "source": [
        "Takisto ak nastavíme príliš veľký krok SGD."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "qRAb04O7hTT8",
        "colab_type": "code",
        "outputId": "75343d3e-999e-4ad2-c9f8-a2a8b4732315",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 204
        }
      },
      "source": [
        "x_mini = x[:32]\n",
        "y_mini = y[:32]\n",
        "\n",
        "model = Sequential()\n",
        "model.add(Dense(20, activation='sigmoid'))\n",
        "model.add(Dense(10, activation='softmax'))\n",
        "\n",
        "loss = keras.losses.categorical_crossentropy\n",
        "sgd = keras.optimizers.SGD(lr = 100.0) # toto sme označili minule ako eta - defaultne je 0.01\n",
        "model.compile(loss=loss,\n",
        "              optimizer=sgd,\n",
        "              metrics=['accuracy'])\n",
        "\n",
        "model.fit(x_mini, y_mini, steps_per_epoch=10000, epochs=5)\n"
      ],
      "execution_count": 12,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Epoch 1/5\n",
            "10000/10000 [==============================] - 36s 4ms/step - loss: 14.1020 - acc: 0.1250\n",
            "Epoch 2/5\n",
            "10000/10000 [==============================] - 36s 4ms/step - loss: 14.1033 - acc: 0.1250\n",
            "Epoch 3/5\n",
            "10000/10000 [==============================] - 35s 4ms/step - loss: 14.1033 - acc: 0.1250\n",
            "Epoch 4/5\n",
            "10000/10000 [==============================] - 36s 4ms/step - loss: 14.1033 - acc: 0.1250\n",
            "Epoch 5/5\n",
            "10000/10000 [==============================] - 36s 4ms/step - loss: 14.1033 - acc: 0.1250\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<keras.callbacks.History at 0x7fd1109aeac8>"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 12
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Xh_NGCZjnT2x",
        "colab_type": "text"
      },
      "source": [
        "Toto testovanie nám len dokáže overiť či trénovanie môže prebehnúť. Dokážeme totiž natrénovať model aj pre úplne náhodné dáta, keďže príkladov je málo. Ak by sme však trénovali na náhodných dátach pre väčšiu vzorku, tak by to nemalo zmysel."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "YabwlzZ2nYAu",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 374
        },
        "outputId": "aabd6e79-e355-471a-9d3a-48f27a369af1"
      },
      "source": [
        "x_mini = np.random.rand(32,784)\n",
        "y_mini = y[:32]\n",
        "\n",
        "model = Sequential()\n",
        "model.add(Dense(30, activation='sigmoid'))\n",
        "model.add(Dense(20, activation='sigmoid'))\n",
        "model.add(Dense(10, activation='softmax'))\n",
        "\n",
        "loss = keras.losses.categorical_crossentropy\n",
        "model.compile(loss=loss,\n",
        "              optimizer='sgd',\n",
        "              metrics=['accuracy'])\n",
        "\n",
        "model.fit(x_mini, y_mini, steps_per_epoch=1000, epochs=10)"
      ],
      "execution_count": 13,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Epoch 1/10\n",
            "1000/1000 [==============================] - 4s 4ms/step - loss: 2.1725 - acc: 0.1840\n",
            "Epoch 2/10\n",
            "1000/1000 [==============================] - 4s 4ms/step - loss: 2.0154 - acc: 0.3594\n",
            "Epoch 3/10\n",
            "1000/1000 [==============================] - 4s 4ms/step - loss: 1.7049 - acc: 0.5873\n",
            "Epoch 4/10\n",
            "1000/1000 [==============================] - 4s 4ms/step - loss: 1.2593 - acc: 0.6757\n",
            "Epoch 5/10\n",
            "1000/1000 [==============================] - 4s 4ms/step - loss: 0.8763 - acc: 0.7593\n",
            "Epoch 6/10\n",
            "1000/1000 [==============================] - 4s 4ms/step - loss: 0.6036 - acc: 0.9915\n",
            "Epoch 7/10\n",
            "1000/1000 [==============================] - 4s 4ms/step - loss: 0.4161 - acc: 1.0000\n",
            "Epoch 8/10\n",
            "1000/1000 [==============================] - 4s 4ms/step - loss: 0.2898 - acc: 1.0000\n",
            "Epoch 9/10\n",
            "1000/1000 [==============================] - 4s 4ms/step - loss: 0.2072 - acc: 1.0000\n",
            "Epoch 10/10\n",
            "1000/1000 [==============================] - 4s 4ms/step - loss: 0.1538 - acc: 1.0000\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<keras.callbacks.History at 0x7fd110946438>"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 13
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "6gyMtvn-sQq4",
        "colab_type": "text"
      },
      "source": [
        "## train/val/test\n",
        "\n",
        "Pri ďalšej práci s kapacitou modelu budeme potrebovať vymedziť tzv. split našich dát. Tento split robíme preto aby sme vedeli verifikovať, či náš model naozaj dokáže dosahovať dobré výsledky na dátach ktoré neboli použíté na trénovanie. \n",
        "\n",
        "Dáta ktoré model nevidel budeme označovať ako testovacie. Tieto dáta používame len na overenie výsledkov.\n",
        "\n",
        "Ostali nám teda dáta na trénovanie. Problém ale je, že máme dva druhy optimalizácie. Jednou optimalizáciou (napr. SGD) vyberáme samotné parametre modelu. Druhú optimalizáciu robíme ako uživatelia a to tým, že vyberáme optimalizačný algoritmus pre prvý druh optimalizácie. Takisto vyberáme aj parametre tejto optimalizácie a iné veci ako napríklad samotný výber architektúry modelu, inicializačný algoritmus, veľkosť minibatch, dĺžku trénovania atď. Tieto veci častokrát označujeme za tzv. hyperparametre.\n",
        "\n",
        "Aby sme mohli takto vyberať, tak vždy najprv trénujeme (prvý druh optimalizácie)na tzv. trénovacej množine a takto natrénované parametre potom overíme na tzv. validačnej množine. Tieto výsledky nám potom umožnia realizovať druhý druh optimalizácie a porovnávať tak výsledky pre rôzne druhy optimalizácie.\n",
        "\n",
        "Dôvod prečo to nerobíme na testovacej množine je ten, že sa môže stať že výber hyperparametrov je tiež taký, že sme ich vybrali zrovna tak, že sa presne hodí na validačnú množinu.\n",
        "\n",
        "Typicky delíme dáta pomerom 80/10/10, alebo 60/20/20 atď, ale záleží na danej úlohe a množstve dát. Podobne si rozdelíme dataset MNIST.\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "EP9BroCkzb9_",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "x_train = x[:50000]\n",
        "y_train = y[:50000]\n",
        "x_val = x[50000:]\n",
        "y_val = y[50000:]"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "XUbiSu3-zq4H",
        "colab_type": "text"
      },
      "source": [
        "Vyrobíme si trocha špeciálny prípad, kde budeme používať len veľmi málo príkladov z trénovacej množiny, aby sme videli efekt validačných dát."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "_nyCkyF6z2CX",
        "colab_type": "code",
        "outputId": "2f786625-c4c1-49d2-e1a3-592a8f01d039",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        }
      },
      "source": [
        "model1 = Sequential()\n",
        "model1.add(Dense(20, activation='sigmoid'))\n",
        "model1.add(Dense(10, activation='softmax'))\n",
        "\n",
        "loss = keras.losses.categorical_crossentropy\n",
        "model1.compile(loss=loss,\n",
        "              optimizer='sgd',\n",
        "              metrics=['accuracy'])\n",
        "\n",
        "history1 = model1.fit(x_train[:20], y_train[:20], validation_data = (x_val, y_val), steps_per_epoch = 1000, validation_steps = 100, epochs=30)"
      ],
      "execution_count": 15,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Train on 20 samples, validate on 10000 samples\n",
            "Epoch 1/30\n",
            "1000/1000 [==============================] - 5s 5ms/step - loss: 1.4677 - acc: 0.7114 - val_loss: 1.8439 - val_acc: 0.4374\n",
            "Epoch 2/30\n",
            "1000/1000 [==============================] - 4s 4ms/step - loss: 0.5960 - acc: 0.9517 - val_loss: 1.6064 - val_acc: 0.5097\n",
            "Epoch 3/30\n",
            "1000/1000 [==============================] - 4s 4ms/step - loss: 0.3011 - acc: 1.0000 - val_loss: 1.5096 - val_acc: 0.5332\n",
            "Epoch 4/30\n",
            "1000/1000 [==============================] - 4s 4ms/step - loss: 0.1833 - acc: 1.0000 - val_loss: 1.4672 - val_acc: 0.5428\n",
            "Epoch 5/30\n",
            "1000/1000 [==============================] - 4s 4ms/step - loss: 0.1253 - acc: 1.0000 - val_loss: 1.4484 - val_acc: 0.5492\n",
            "Epoch 6/30\n",
            "1000/1000 [==============================] - 4s 4ms/step - loss: 0.0926 - acc: 1.0000 - val_loss: 1.4406 - val_acc: 0.5536\n",
            "Epoch 7/30\n",
            "1000/1000 [==============================] - 4s 4ms/step - loss: 0.0724 - acc: 1.0000 - val_loss: 1.4381 - val_acc: 0.5553\n",
            "Epoch 8/30\n",
            "1000/1000 [==============================] - 4s 4ms/step - loss: 0.0589 - acc: 1.0000 - val_loss: 1.4384 - val_acc: 0.5570\n",
            "Epoch 9/30\n",
            "1000/1000 [==============================] - 4s 4ms/step - loss: 0.0493 - acc: 1.0000 - val_loss: 1.4403 - val_acc: 0.5587\n",
            "Epoch 10/30\n",
            "1000/1000 [==============================] - 4s 4ms/step - loss: 0.0423 - acc: 1.0000 - val_loss: 1.4430 - val_acc: 0.5592\n",
            "Epoch 11/30\n",
            "1000/1000 [==============================] - 4s 4ms/step - loss: 0.0369 - acc: 1.0000 - val_loss: 1.4461 - val_acc: 0.5600\n",
            "Epoch 12/30\n",
            "1000/1000 [==============================] - 4s 4ms/step - loss: 0.0327 - acc: 1.0000 - val_loss: 1.4495 - val_acc: 0.5603\n",
            "Epoch 13/30\n",
            "1000/1000 [==============================] - 4s 4ms/step - loss: 0.0293 - acc: 1.0000 - val_loss: 1.4531 - val_acc: 0.5610\n",
            "Epoch 14/30\n",
            "1000/1000 [==============================] - 4s 4ms/step - loss: 0.0265 - acc: 1.0000 - val_loss: 1.4566 - val_acc: 0.5611\n",
            "Epoch 15/30\n",
            "1000/1000 [==============================] - 4s 4ms/step - loss: 0.0242 - acc: 1.0000 - val_loss: 1.4602 - val_acc: 0.5618\n",
            "Epoch 16/30\n",
            "1000/1000 [==============================] - 4s 4ms/step - loss: 0.0222 - acc: 1.0000 - val_loss: 1.4637 - val_acc: 0.5625\n",
            "Epoch 17/30\n",
            "1000/1000 [==============================] - 4s 4ms/step - loss: 0.0205 - acc: 1.0000 - val_loss: 1.4672 - val_acc: 0.5634\n",
            "Epoch 18/30\n",
            "1000/1000 [==============================] - 4s 4ms/step - loss: 0.0191 - acc: 1.0000 - val_loss: 1.4706 - val_acc: 0.5642\n",
            "Epoch 19/30\n",
            "1000/1000 [==============================] - 4s 4ms/step - loss: 0.0178 - acc: 1.0000 - val_loss: 1.4739 - val_acc: 0.5647\n",
            "Epoch 20/30\n",
            "1000/1000 [==============================] - 4s 4ms/step - loss: 0.0167 - acc: 1.0000 - val_loss: 1.4772 - val_acc: 0.5647\n",
            "Epoch 21/30\n",
            "1000/1000 [==============================] - 4s 4ms/step - loss: 0.0157 - acc: 1.0000 - val_loss: 1.4804 - val_acc: 0.5652\n",
            "Epoch 22/30\n",
            "1000/1000 [==============================] - 4s 4ms/step - loss: 0.0148 - acc: 1.0000 - val_loss: 1.4835 - val_acc: 0.5657\n",
            "Epoch 23/30\n",
            "1000/1000 [==============================] - 4s 4ms/step - loss: 0.0140 - acc: 1.0000 - val_loss: 1.4865 - val_acc: 0.5664\n",
            "Epoch 24/30\n",
            "1000/1000 [==============================] - 4s 4ms/step - loss: 0.0133 - acc: 1.0000 - val_loss: 1.4895 - val_acc: 0.5664\n",
            "Epoch 25/30\n",
            "1000/1000 [==============================] - 4s 4ms/step - loss: 0.0127 - acc: 1.0000 - val_loss: 1.4923 - val_acc: 0.5671\n",
            "Epoch 26/30\n",
            "1000/1000 [==============================] - 4s 4ms/step - loss: 0.0121 - acc: 1.0000 - val_loss: 1.4952 - val_acc: 0.5675\n",
            "Epoch 27/30\n",
            "1000/1000 [==============================] - 4s 4ms/step - loss: 0.0115 - acc: 1.0000 - val_loss: 1.4979 - val_acc: 0.5679\n",
            "Epoch 28/30\n",
            "1000/1000 [==============================] - 4s 4ms/step - loss: 0.0110 - acc: 1.0000 - val_loss: 1.5006 - val_acc: 0.5682\n",
            "Epoch 29/30\n",
            "1000/1000 [==============================] - 4s 4ms/step - loss: 0.0106 - acc: 1.0000 - val_loss: 1.5032 - val_acc: 0.5685\n",
            "Epoch 30/30\n",
            "1000/1000 [==============================] - 4s 4ms/step - loss: 0.0102 - acc: 1.0000 - val_loss: 1.5058 - val_acc: 0.5686\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "RsxydmJQd1zx",
        "colab_type": "code",
        "outputId": "897b1194-ec28-4361-b29d-1f8b05e18efb",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 538
        }
      },
      "source": [
        "print(history1.history.keys())\n",
        "plt.plot(np.arange(30), history1.history['val_loss'])\n",
        "plt.plot(np.arange(30), history1.history['loss'])\n",
        "plt.show()\n",
        "plt.plot(np.arange(30), history1.history['val_acc'])\n",
        "plt.plot(np.arange(30), history1.history['acc'])\n",
        "plt.show()"
      ],
      "execution_count": 16,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "dict_keys(['val_loss', 'val_acc', 'loss', 'acc'])\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "display_data",
          "data": {
            "image/png": "iVBORw0KGgoAAAANSUhEUgAAAX4AAAD8CAYAAABw1c+bAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz\nAAALEgAACxIB0t1+/AAAADl0RVh0U29mdHdhcmUAbWF0cGxvdGxpYiB2ZXJzaW9uIDMuMC4zLCBo\ndHRwOi8vbWF0cGxvdGxpYi5vcmcvnQurowAAIABJREFUeJzt3XuYHXWd5/H391y6O5fuJk2aSzpX\nMBADCEIborCCKBic0eCuowmwoqJxfERn1sd5xtnZUQd3dxx1d5x5Fi/RyagjJLIoGF0RUFEUCKaD\nEUkQCOGWQC4kkHu6+5zz3T+qTnd153T6pPukq0/V5/U89VTVr351zq845FPVv7qZuyMiIumRibsB\nIiIythT8IiIpo+AXEUkZBb+ISMoo+EVEUkbBLyKSMgp+EZGUUfCLiKSMgl9EJGVycTegkqlTp/rs\n2bPjboaISN1Yt27dS+7eXk3dcRn8s2fPpqurK+5miIjUDTN7ttq66uoREUkZBb+ISMoo+EVEUkbB\nLyKSMgp+EZGUUfCLiKSMgl9EJGUSE/yHe4t8477NPPDUS3E3RURkXBuXN3CNRDZjfOPXm5k/rYU3\nnD417uaIiIxbiTniz2czLFkwk189sZPndx+MuzkiIuNWYoIfYOmCGWTMuOW3z8XdFBGRcStRwX9q\n6wTePO8kbl37PN2FYtzNEREZlxIV/ADXLpzFrgM9/PTRbXE3RURkXEpc8F/8qqnMOnEiN69Rd4+I\nSCWJC/5Mxrh6wUx++8xuHt+2L+7miIiMO8MGv5mtMLMdZvboEMv/yszWh8OjZlY0s7Zw2TNm9odw\n2Zg9YP/POmfQkMtw80NVP55aRCQ1qjni/xawaKiF7v5Fdz/P3c8D/gb4lbvvjlR5U7i8c3RNrV7b\npAb+5JxT+cHDWznQXRirrxURqQvDBr+73wfsHq5eaCmwclQtqpFrF85kf3eBH65/Ie6miIiMKzXr\n4zeziQR/GXw/UuzA3Wa2zsyWDbP+MjPrMrOunTt3jro958+cwrxTmvnummdx91F/nohIUtTy5O7b\ngfsHdfNc7O7nA1cCHzWzNw61srsvd/dOd+9sb6/qfcFHZWZcu3AWG1/cy++ef2XUnycikhS1DP4l\nDOrmcfet4XgHcDuwoIbfN6yrXtvBpIYs312jk7wiImU1CX4zawUuAX4YKZtkZs3laeAKoOKVQcfL\n5MYc7zy/gx8/8iIvH+gZy68WERm3qrmccyXwIHCmmW0xs+vN7M/N7M8j1d4J3O3uByJlJwO/MbPf\nA78F/p+7/7SWja/GtQtn0VMocdu6LWP91SIi49Kwj2V296VV1PkWwWWf0bLNwLkjbVitzDulhc5Z\nU7j5oWe5/uI5ZDIWd5NERGKVuDt3K7l24Sye2XWQ+/WSFhGRdAT/leecQtukBp3kFREhJcHfmMvy\nZ53T+dljO9i253DczRERiVUqgh/gmgWzKLmzUi9pEZGUS03wzzxxIm+c286qtc/RWyzF3RwRkdik\nJvghOMm7fW83P39se9xNERGJTaqC/7J5JzGttYnv6iUtIpJiqQr+bMZYumAmv9n0Ek+/dGD4FURE\nEihVwQ/wntfNIJcxbtalnSKSUqkL/pNamrjirJO5tet5ntt1MO7miIiMudQFP8BfvuUMzIwlyx9U\n+ItI6qQy+M84uZmbP3ghB3uLvGf5gzy7S/39IpIeqQx+gLM7Wrnlgws53FtkyfI1PKOTvSKSEqkN\nfoD501q4ORL+utJHRNIg1cEPQfjf8qGF9BRLLFn+oMJfRBIv9cEP8OpTW7jlQxfSW3Te8/UH2bxz\nf9xNEhE5bhT8oXmntLDyQwsplpwly9fwlMJfRBJKwR9x5inNrFy2kJIH4b9ph8JfRJKnmnfurjCz\nHWZW8UXpZnapme0xs/Xh8OnIskVm9riZbTKzT9Wy4cfLGSc3s/JDC3GHpd9Yw6Yd++JukohITVVz\nxP8tYNEwdX7t7ueFw40AZpYFbgKuBOYDS81s/mgaO1bmntzMqmUX4g5Llj/Ems27cPe4myUiCeTu\n9BRK7O8usOdg75h8ZzUvW7/PzGaP4LMXAJvCl65jZquAxcDGEXzWmHvVSc2sWraQa765hiXL13BO\nRyvvv2g2f/qaaTTk1EMmUq8KxRI9xRLdvcG4p1Ciu1Ciu1CkpxDMl8vL092F0pDLyuv3zxfpLXpf\nne6wTu+g9Xojy8ramxtZ+7dvOe7/DYYN/iq93sx+D7wAfNLdNwAdwPOROluAC4f6ADNbBiwDmDlz\nZo2aNTqvOmky937yUn7w8Fb+7f6n+cStv+cf7vwj1144i2sWzmTq5Ma4myhSN4olp7tQ7Avc7t4g\nbLsjwVsO0P7xkfUHL4+GeHdvEKbdvcUjQrm8bqlGf7xnDBpyGRqyGRpyWRpzGRpyGfJZi5RnaG3I\nh9PWVxbUC8aN2f755qZ8bRo3jFoE/8PALHffb2ZvA+4A5h7rh7j7cmA5QGdn57jpV5nYkOPahbO4\nesFMfr3pJf7t/qf5p589wU33buLt507j/RfN5uyO1ribKTIsd+87ei2H6OFI+B7uLQ5YdkQw9xY5\nHI4HhHXvwOCutF53oUShBomby1hfwDbkMjRGAjeYD4K2sbmxb74xDOHGfHZA8Patlx0435jLDigv\nT0e/pyGbIZet37/8Rx387r43Mv0TM/uKmU0FtgIzIlWnh2XHV6kEmdr/IJmMcckZ7VxyRjubduzn\n2w88w23rtvD9h7ewYE4bH7hoDpfPP5lsxmr+3ZI8pZL3he3hMIAP9xbDocThSPCWy7oH1OuvM7hu\nNMQHj0dzqsqMMEizNOX7A7I83ZjLMLkxF0znM311o4EaLR8QzJHlDdnMgM+P1te/r9qwak5ahn38\nP3b3syssOwXY7u5uZguA24BZQBZ4AngzQeCvBa4Ou4GOqrOz07u6uo5hMwgC/0uvggveD2/+u2Nb\nd4T2HOzle13P8e0HnmXrK4dob27kvBkncNa0Fs6e1spZHS2c0tKEmf5nHe/cI0HcW+JQGMLlcXdv\nf0gf6hkqsCPzhRKHe8p1BtUrDOzXPVa5jNGUDwK1KV8O0yCMm8LwPGIcrZ8Ljn4HzA+YDoM9sqwx\nlyWfNf2/PI6Z2Tp376ym7rBH/Ga2ErgUmGpmW4DPAHkAd/8a8C7gI2ZWAA4BSzzYmxTM7AbgLoKd\nwIpqQn/EMhnINcHe4/9HRVnrxDzL3ng6H7hoDvds3M6dj25jwwt7+Nlj2/uOrNomNXDWtBbOmtbK\n2R3BeFbbRDI6chlWoVgKAnRwqEamD0XC9HBPcWA4F44M5EPlo+fIuodGeTTcmMswoSFLUzl881ka\n81machmmTGxgQr6/vBzUQd1o+eDwHrROGMxNufruYpDxoaoj/rE2oiN+gG9eDvkmuO5HtW/UMTjQ\nXeCP2/by6Na9bHhhD49u3cuTO/bRWwz+W09uzDHthCbaJjVEhkbaJuZpm9xI28Sg7MTJDbROCE4M\nxbGjKPcJ912dcNQrGfr7ew9H+n37+o2j/cm9Q3dxRLszRtonnM3YEWE7eL4cohMa+qeb+sI7qDsh\nEtQToutFl+UyOgqWcaGmR/x1pbUDXnwk7lYwqTHHBbPauGBWW19Zd6HIk9v3s+GFPWx8YS/b9h5m\n94EeHt+2j90HenjlUO9RjzhzGSOfLV8xkKUhvHIgH7kioJw/7uDhhPfNe9+ykgdH04WS01ssUSg6\nhZJTKAXTveGyYo0ufwhOrPX39zYN6nponZCvfKQbHgGXj6bLXRYT8oOOlnNZmhr6wzivI2KRo0pW\n8Ld0wOM/DdJtnB2FNeaynN3ROuQVQMWS88rBHnYf6B92Hehh7+HeAdcA9xaDvujewdcGFwf2GZsZ\nRvCfwSLz5WX5rJHLZshnjFzWyGaCnUquPA6nK13d0Dc94KqJ/u6K8gm8pvAqCnVriYwvyQv+wiE4\n9DJMbBu+/jiSzRgnTm7kRN0bICLHWbL+Jm6ZFoz3bIm3HSIi41iygr91ejDe+0K87RARGceSFfwt\nHcF4r474RUSGkqzgn3wSZHI64hcROYpkBX8mC82nwp6xu4lLRKTeJCv4ITjBO4Z374qI1JsEBn+H\ngl9E5CgSGPzTgj7+cfgoChGR8SB5wd86HQqH4eDuuFsiIjIuJS/4dUmniMhRJTj4dUmniEglyQv+\n1jD49dgGEZGKkhf8k9rDm7h0ZY+ISCXJC/5MFpqnqatHRGQIyQt+CLp7dPeuiEhFwwa/ma0wsx1m\n9ugQy68xs0fM7A9m9oCZnRtZ9kxYvt7MRvAuxRHS3bsiIkOq5oj/W8Cioyx/GrjE3c8BPgcsH7T8\nTe5+XrXvgqyJlg7dxCUiMoRhg9/d7wOGvBvK3R9w95fD2TXA9Bq1beRaOqDYDQd3xd0SEZFxp9Z9\n/NcDd0bmHbjbzNaZ2bKjrWhmy8ysy8y6du7cObpW6JJOEZEh1Sz4zexNBMH/15Hii939fOBK4KNm\n9sah1nf35e7e6e6d7e3to2tM301c6ucXERmsJsFvZq8Bvgksdve+/hV33xqOdwC3Awtq8X3D0t27\nIiJDGnXwm9lM4AfAf3b3JyLlk8ysuTwNXAFUvDKo5ia1Qyavrh4RkQpyw1Uws5XApcBUM9sCfAbI\nA7j714BPAycCXzEzgEJ4Bc/JwO1hWQ64xd1/ehy24UiZDLScqiN+EZEKhg1+d186zPIPAh+sUL4Z\nOPfINcZIy3T18YuIVJDMO3chuIlLXT0iIkdIbvC3dsC+F6FUirslIiLjSnKDv2U6FHvg4Etxt0RE\nZFxJcPBPC8bq5xcRGSC5wd93966CX0QkKrnBr5u4REQqSm7wT5wK2Qa9dF1EZJDkBn8mE17Sqa4e\nEZGo5AY/9D+XX0RE+qQg+NXVIyISlfDgnwZ7dROXiEhUsoO/dTqUeuHAKF/sIiKSIMkO/r5LOtXd\nIyJSlvDgL9+9qxO8IiJlyQ7+1vC977qkU0SkT7KDf+KJkG3U83pERCKSHfxm4ZU9Cn4RkbJkBz/o\nJi4RkUGqCn4zW2FmO8ys4svSLfAvZrbJzB4xs/Mjy64zsyfD4bpaNbxqrR3q4xcRiaj2iP9bwKKj\nLL8SmBsOy4CvAphZG8HL2S8EFgCfMbMpI23siLR0wL4XoFQc068VERmvqgp+d78P2H2UKouB73hg\nDXCCmZ0KvBW4x913u/vLwD0cfQdSey3ToFTQTVwiIqFa9fF3AM9H5reEZUOVH8HMlplZl5l17dxZ\nw5DWJZ0iIgOMm5O77r7c3TvdvbO9vb12H6xXMIqIDFCr4N8KzIjMTw/LhiofOy3hEb+CX0QEqF3w\nrwbeG17dsxDY4+4vAncBV5jZlPCk7hVh2diZ2Aa5Jtij5/WIiADkqqlkZiuBS4GpZraF4EqdPIC7\nfw34CfA2YBNwEHh/uGy3mX0OWBt+1I3ufrSTxLXXdxOXruUXEYEqg9/dlw6z3IGPDrFsBbDi2JtW\nQy0d6uoREQmNm5O7x5Xu3hUR6ZOO4G8Ng183cYmIpCT4WzrAi7B/R9wtERGJXXqCH9TPLyJCWoK/\nNQx+XdIpIpKS4O874tcJXhGRdAT/hCmQm6CuHhER0hL8ehOXiEifdAQ/6IUsIiKh9AR/y3T18YuI\nkKrgnwb7XtRNXCKSeukJ/tbwJq592+JuiYhIrNIT/LqkU0QESGXw6yYuEUm39AR/q474RUQgTcHf\ndALkJ+qSThFJvfQEv1n4XH519YhIuqUn+EGvYBQRocrgN7NFZva4mW0ys09VWP5PZrY+HJ4ws1ci\ny4qRZatr2fhj1jpdXT0iknrDvnPXzLLATcDlwBZgrZmtdveN5Tru/l8i9T8GvDbyEYfc/bzaNXkU\nWjpg/zYoFiBb1euGRUQSp5oj/gXAJnff7O49wCpg8VHqLwVW1qJxNdcyDbwUhL+ISEpVE/wdwPOR\n+S1h2RHMbBYwB/hFpLjJzLrMbI2ZXTXUl5jZsrBe186dO6to1gi0Tg/G6ucXkRSr9cndJcBt7h59\nIM4sd+8Erga+bGanV1rR3Ze7e6e7d7a3t9e4WaGWacFYb+ISkRSrJvi3AjMi89PDskqWMKibx923\nhuPNwC8Z2P8/tvTuXRGRqoJ/LTDXzOaYWQNBuB9xdY6ZzQOmAA9GyqaYWWM4PRW4CNg4eN0x09QK\nDZPV1SMiqTbspS3uXjCzG4C7gCywwt03mNmNQJe7l3cCS4BV7u6R1V8NfN3MSgQ7mc9HrwYac+U3\ncamrR0RSrKprGt39J8BPBpV9etD8Zyus9wBwzijaV3stHTriF5FUS9eduxAGv/r4RSS90hf8rR3B\ny1iKvXG3REQkFukL/pZpgOtNXCKSWikM/vJNXOruEZF0Sl/wt+pafhFJt/QFf9/duwp+EUmn9AV/\nUys0NOuSThFJrfQFP4QvZNFNXCKSTukM/tYOdfWISGqlM/h1966IpFh6g3//dug5GHdLRETGXDqD\nf9brAYenfh53S0RExlxKg/9imHgibLgj7paIiIy5dAZ/Ngfz/hSe+Cn0Ho67NSIiYyqdwQ9w1lXQ\ns1/dPSKSOukN/tn/ASZMUXePiKROeoM/mw+6ex6/EwrdcbdGRGTMVBX8ZrbIzB43s01m9qkKy99n\nZjvNbH04fDCy7DozezIcrqtl40dt/lXQsw+e+kXcLRERGTPDvnrRzLLATcDlwBZgrZmtrvDu3O+5\n+w2D1m0DPgN0Ag6sC9d9uSatH63TLoGmE2DjD+HMK+NujYjImKjmiH8BsMndN7t7D7AKWFzl578V\nuMfdd4dhfw+waGRNPQ6yeZj3J/DHn6i7R0RSo5rg7wCej8xvCcsG+09m9oiZ3WZmM45x3fjMvwq6\n98DmX8XdEhGRMVGrk7s/Ama7+2sIjuq/fawfYGbLzKzLzLp27txZo2ZV4bRLobEVNurqHhFJh2qC\nfyswIzI/PSzr4+673L3cV/JN4IJq1418xnJ373T3zvb29mraXhu5Bpj3Nvjjj6HQM3bfKyISk2qC\nfy0w18zmmFkDsARYHa1gZqdGZt8BPBZO3wVcYWZTzGwKcEVYNr7MXwyH98DT98XdEhGR427Yq3rc\nvWBmNxAEdhZY4e4bzOxGoMvdVwMfN7N3AAVgN/C+cN3dZvY5gp0HwI3uvvs4bMfonH5Z8FaujXfA\n3LfE3RoRkePK3D3uNhyhs7PTu7q6xvZLv/8h2HQPfPLJ4GofEZE6Ymbr3L2zmrrpvXN3sLOugkMv\nq7tHRBJPwV92+mXQMDm4mUtEJMEU/GX5CXDGouDqnmIh7taIiBw3Cv6o+Yvh4C549jdxt0RE5LhR\n8EfNvRzyk/SoZhFJNAV/VH4CnHEFPPYjKBXjbo2IyHGh4B9s/lVw8CV49v64WyIiclwo+Aebeznk\nJujqHhFJLAX/YA2Tgu6ejavV3SMiiaTgr2T+YjiwA55bE3dLRERqTsFfydy3Qq5Jj2oWkURS8FfS\nOBle9Zawu6cUd2tERGpKwT+Us94J+7fB8w/F3RIRkZpS8A/ljLdCtlHdPSKSOAr+oTQ2q7tHRBJJ\nwX808xfDvhdgy9rh64qI1AkF/9GcuSjo7rnvi7qmX0QSQ8F/NE2tsOh/Bm/m+vnfx90aEZGaqCr4\nzWyRmT1uZpvM7FMVln/CzDaa2SNm9nMzmxVZVjSz9eGwevC6497rPgid18P9/wzrV8bdGhGRURv2\nZetmlgVuAi4HtgBrzWy1u2+MVPsd0OnuB83sI8AXgPeEyw65+3k1bvfYuvIf4aUn4EcfhxNPhxkL\n4m6RiMiIVXPEvwDY5O6b3b0HWAUsjlZw93vd/WA4uwaYXttmxiybh3d/B1o6YNU1sGdL3C0SERmx\naoK/A3g+Mr8lLBvK9cCdkfkmM+syszVmdtUI2jg+TGyDpaug9xCsXAo9B+JukYjIiNT05K6ZXQt0\nAl+MFM9y907gauDLZnb6EOsuC3cQXTt37qxls2rnpHnwrhWw7Q9wx0d0fb+I1KVqgn8rMCMyPz0s\nG8DM3gL8LfAOd+8ul7v71nC8Gfgl8NpKX+Luy929090729vbq96AMXfGFXD5jcHz+u/7QtytERE5\nZtUE/1pgrpnNMbMGYAkw4OocM3st8HWC0N8RKZ9iZo3h9FTgIiB6Urg+veFjcO7V8Mt/gA23x90a\nEZFjMuxVPe5eMLMbgLuALLDC3TeY2Y1Al7uvJujamQz8XzMDeM7d3wG8Gvi6mZUIdjKfH3Q1UH0y\ng7d/GXZtgts/Am2nwannxt0qEZGqmLvH3YYjdHZ2eldXV9zNGN6+7fCNywCHD90LzSfH3SIRSSkz\nWxeeTx2W7twdjeaTYektcOhl+N410Hs47haJiAxLwT9ap54LV301eJDbDz8aXO4pIjKOKfhr4ayr\n4LL/Bo/eBjddCI/fOfw6IiIxUfDXyhv/Ct77w+BdvSuXwM3vhl1Pxd0qEZEjKPhr6bRL4SP3wxX/\nHZ69H76yEH7+Oeg5ONyaIiJjRsFfa9l8cJ3/x9YF7+399ZfgpgXBDV/j8AoqEUkfBf/x0nwK/Mfl\n8P47obEFbn0v/Ps7YecTcbdMRFJOwX+8zXoDfPg+uPILsPVh+Orr4e6/g4O7426ZiKSUgn8sZHNw\n4YfhY13wmiXwwL/Al+bCd98Fv7s5uA9ARGSM6M7dOGz7AzxyK2y4A/Y8B5k8nH5ZcE7gzCthwglx\nt1BE6syx3Lk77LN65Dg45ZxguPzGoPtn4+3BTuDJuyDbAKe/uX8n0NQSd2tFJGEU/HEyg+kXBMPl\nn4Ot64KnfW64HZ64E7KNcNolMP11MO186Dg/eCGMiMgoKPjHCzOY3hkMl38OtnYFO4An74En7+6v\nN2V2/06g44LgkRENk2JrtojUH/Xx14PDe+CF9fDCw0HX0NaHYW/43l/LQPu8YGdw0jyYMid4TPSU\n2dAwMdZmi8jYUR9/0jS1Bl0+p13SX7Z/R7ADKO8MnrgT1n934HrNp4Y7gTnQFu4Q2ubACbNgwpTg\nrwwRSR0Ff72afBKcuSgYyg7uhpefht3lYXMwv+ke2L994Pq5puAzJp8SPF568inBTWfNpwwsm9gG\nmezYbpuIHFcK/iSZ2BYMHRccuaznALz8TLAzeOU52Lct2Bns2xbcTfz0fUGXUiVNrTChLfgrYWI4\nnjBlYFnTCdDYHFyF1NgcDA3NwT0MIjKu6F9lWjRMgpPPCoah9B4KdwbbYf+2YHxwV3CD2aHdwfjg\n7uCVk4deHnpHEZWf1L8j6NshTA7OP+QnBu3KTwznJ0XKJ0N+QjDkmiqP9ZeIyIhUFfxmtgj4Z4J3\n7n7T3T8/aHkj8B3gAmAX8B53fyZc9jfA9UAR+Li731Wz1ktt5ScEJ4WnzK6ufrEQhP+h3XDoFeje\nC937Bg2Dy/YGO5OeA9B7MHhyae8B8NKxtzeT798R5Jog1xBcApsLh2zDoPLydEPwML1sdLqxQnku\n+I5sHjK5/uWZfIVl4TiTD3ZIA+Z1g7yML8MGv5llgZuAy4EtwFozWz3openXAy+7+6vMbAnwj8B7\nzGw+sAQ4C5gG/MzMznD3Yq03RGKQzcGkE4NhNNyh0B3uDA707wx6DkLhcDD0HobCoaHHhe5gKPaE\n63QH48OvQKEHit39dUq9YVkPjMn/ihbZEeSCHUPfdC64Mis6n8kGg2X75/vqRMsz4XR20LhSeaZ/\nvm86rGc2xLJBw1DlQ9azKupb8N9nqGXlaTjKMhtY1lfXhlhuFabTdaFDNUf8C4BN7r4ZwMxWAYuB\naPAvBj4bTt8G/B8zs7B8lbt3A0+b2abw8x6sTfMlEcwg3xQMjHIncqxKRSj2BjuBvnFP/3ypN/jL\nphSpUypUWBaWl4rBfF+dCvNeDOuW60fHkWkvhtPhfKE7Ul4aWKdcNmC+Unk4PZK/sJIuuiOI7iwq\n7SgG7DCOZR2O/Ixo3YlT4QPH/w1+1QR/B/B8ZH4LcOFQddy9YGZ7CP4FdwBrBq3bMeLWitRa+eg6\n3xR3S8ZeqdS/I4juFErhX0F9ZZGdRXmIruteoZ4Pql8EBpUNqDP4M7x/51SxTjj0faaH77vwgXUZ\n9B198xylbrletNwjbfHKdSuuUy6rUK/SuHFsHtEybk7umtkyYBnAzJkzY26NSApkMgQP6B03MSBj\npJqzTluBGZH56WFZxTpmlgNaCU7yVrMuAO6+3N073b2zvb29utaLiMgxqyb41wJzzWyOmTUQnKxd\nPajOauC6cPpdwC88eBbEamCJmTWa2RxgLvDb2jRdRERGYti/8cI++xuAuwgu51zh7hvM7Eagy91X\nA/8K/Ht48nY3wc6BsN6tBCeCC8BHdUWPiEi89JA2EZEEOJaHtOnOEhGRlFHwi4ikjIJfRCRlFPwi\nIikzLk/umtlO4NkRrj4VeKmGzYlb0rYHkrdNSdseSN42JW174MhtmuXuVd0ENS6DfzTMrKvaM9v1\nIGnbA8nbpqRtDyRvm5K2PTC6bVJXj4hIyij4RURSJonBvzzuBtRY0rYHkrdNSdseSN42JW17YBTb\nlLg+fhERObokHvGLiMhRJCb4zWyRmT1uZpvM7FNxt6cWzOwZM/uDma03s7p8eJGZrTCzHWb2aKSs\nzczuMbMnw/GUONt4LIbYns+a2dbwd1pvZm+Ls43HwsxmmNm9ZrbRzDaY2V+E5fX8Gw21TXX5O5lZ\nk5n91sx+H27P34flc8zsoTDzvhc+Pbm6z0xCV0/4XuAniLwXGFg66L3AdcfMngE63b1urz82szcC\n+4HvuPvZYdkXgN3u/vlwJz3F3f86znZWa4jt+Syw392/FGfbRsLMTgVOdfeHzawZWAdcBbyP+v2N\nhtqmd1OHv1P4GttJ7r7fzPLAb4C/AD4B/MDdV5nZ14Dfu/tXq/nMpBzx970X2N17gPJ7gSVm7n4f\nwaO6oxYD3w6nv03wj7IuDLE9dcvdX3T3h8PpfcBjBK9HreffaKhtqkse2B/O5sPBgcsI3nEOx/gb\nJSX4K70XuG5/6AgH7jazdeGrKZPiZHd/MZzeBpwcZ2Nq5AYzeyTsCqqbbpEoM5sNvBZ4iIT8RoO2\nCer0dzKzrJmtB3YA9wBPAa+4eyGsckyZl5TgT6qL3f184Ergo2E3Q6KEb2qr9/7GrwKnA+cBLwL/\nK97mHDszmwx8H/hLd98bXVZ6rfBsAAABeElEQVSvv1GFbarb38ndi+5+HsHraxcA80bzeUkJ/qrf\n7VtP3H1rON4B3E7wgyfB9rAfttwfuyPm9oyKu28P/2GWgG9QZ79T2G/8feBmd/9BWFzXv1Glbar3\n3wnA3V8B7gVeD5wQvuMcjjHzkhL81bwXuK6Y2aTwxBRmNgm4Anj06GvVjeg7mq8DfhhjW0atHJCh\nd1JHv1N44vBfgcfc/X9HFtXtbzTUNtXr72Rm7WZ2Qjg9geAilscIdgDvCqsd02+UiKt6AMJLs75M\n/3uB/0fMTRoVMzuN4Cgfgncj31KP22RmK4FLCZ4kuB34DHAHcCswk+AprO9297o4YTrE9lxK0H3g\nwDPAhyP94+OamV0M/Br4A1AKi/8rQZ94vf5GQ23TUurwdzKz1xCcvM0SHKzf6u43hhmxCmgDfgdc\n6+7dVX1mUoJfRESqk5SuHhERqZKCX0QkZRT8IiIpo+AXEUkZBb+ISMoo+EVEUkbBLyKSMgp+EZGU\n+f8eTcla26fa9wAAAABJRU5ErkJggg==\n",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {
            "tags": []
          }
        },
        {
          "output_type": "display_data",
          "data": {
            "image/png": "iVBORw0KGgoAAAANSUhEUgAAAXcAAAD8CAYAAACMwORRAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\n4S4iEiCFu4hIgBTuIiIBUriLiATo/wHk5u+GHZb2lAAAAABJRU5ErkJggg==\n",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {
            "tags": []
          }
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "CGkwJ47A0kN9",
        "colab_type": "code",
        "outputId": "097c328d-391c-47c5-f342-f87221e31d6a",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        }
      },
      "source": [
        "model2 = Sequential()\n",
        "model2.add(Dense(30, activation='sigmoid'))\n",
        "model2.add(Dense(20, activation='sigmoid'))\n",
        "model2.add(Dense(10, activation='softmax'))\n",
        "\n",
        "loss = keras.losses.categorical_crossentropy\n",
        "model2.compile(loss=loss,\n",
        "              optimizer='sgd',\n",
        "              metrics=['accuracy'])\n",
        "\n",
        "history2 = model2.fit(x_train, y_train, validation_data = (x_val, y_val), batch_size=32, epochs=50)"
      ],
      "execution_count": 17,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Train on 50000 samples, validate on 10000 samples\n",
            "Epoch 1/50\n",
            "50000/50000 [==============================] - 7s 136us/step - loss: 2.2608 - acc: 0.2387 - val_loss: 2.1953 - val_acc: 0.4226\n",
            "Epoch 2/50\n",
            "50000/50000 [==============================] - 6s 128us/step - loss: 2.0916 - acc: 0.4772 - val_loss: 1.9520 - val_acc: 0.5417\n",
            "Epoch 3/50\n",
            "50000/50000 [==============================] - 7s 130us/step - loss: 1.7821 - acc: 0.5577 - val_loss: 1.5868 - val_acc: 0.6331\n",
            "Epoch 4/50\n",
            "50000/50000 [==============================] - 6s 129us/step - loss: 1.4321 - acc: 0.6373 - val_loss: 1.2565 - val_acc: 0.7023\n",
            "Epoch 5/50\n",
            "50000/50000 [==============================] - 7s 133us/step - loss: 1.1606 - acc: 0.7016 - val_loss: 1.0233 - val_acc: 0.7531\n",
            "Epoch 6/50\n",
            "50000/50000 [==============================] - 7s 130us/step - loss: 0.9713 - acc: 0.7523 - val_loss: 0.8617 - val_acc: 0.7880\n",
            "Epoch 7/50\n",
            "50000/50000 [==============================] - 7s 132us/step - loss: 0.8373 - acc: 0.7882 - val_loss: 0.7462 - val_acc: 0.8220\n",
            "Epoch 8/50\n",
            "50000/50000 [==============================] - 7s 134us/step - loss: 0.7391 - acc: 0.8172 - val_loss: 0.6611 - val_acc: 0.8409\n",
            "Epoch 9/50\n",
            "50000/50000 [==============================] - 7s 133us/step - loss: 0.6643 - acc: 0.8370 - val_loss: 0.5962 - val_acc: 0.8568\n",
            "Epoch 10/50\n",
            "50000/50000 [==============================] - 7s 131us/step - loss: 0.6055 - acc: 0.8522 - val_loss: 0.5446 - val_acc: 0.8692\n",
            "Epoch 11/50\n",
            "50000/50000 [==============================] - 7s 133us/step - loss: 0.5582 - acc: 0.8629 - val_loss: 0.5028 - val_acc: 0.8778\n",
            "Epoch 12/50\n",
            "50000/50000 [==============================] - 7s 132us/step - loss: 0.5197 - acc: 0.8709 - val_loss: 0.4693 - val_acc: 0.8828\n",
            "Epoch 13/50\n",
            "50000/50000 [==============================] - 7s 134us/step - loss: 0.4880 - acc: 0.8759 - val_loss: 0.4412 - val_acc: 0.8891\n",
            "Epoch 14/50\n",
            "50000/50000 [==============================] - 7s 134us/step - loss: 0.4616 - acc: 0.8815 - val_loss: 0.4178 - val_acc: 0.8939\n",
            "Epoch 15/50\n",
            "50000/50000 [==============================] - 7s 132us/step - loss: 0.4392 - acc: 0.8859 - val_loss: 0.3989 - val_acc: 0.8970\n",
            "Epoch 16/50\n",
            "50000/50000 [==============================] - 7s 133us/step - loss: 0.4202 - acc: 0.8902 - val_loss: 0.3817 - val_acc: 0.9003\n",
            "Epoch 17/50\n",
            "50000/50000 [==============================] - 6s 130us/step - loss: 0.4037 - acc: 0.8937 - val_loss: 0.3673 - val_acc: 0.9039\n",
            "Epoch 18/50\n",
            "50000/50000 [==============================] - 7s 134us/step - loss: 0.3893 - acc: 0.8966 - val_loss: 0.3547 - val_acc: 0.9062\n",
            "Epoch 19/50\n",
            "50000/50000 [==============================] - 7s 140us/step - loss: 0.3765 - acc: 0.8993 - val_loss: 0.3434 - val_acc: 0.9089\n",
            "Epoch 20/50\n",
            "50000/50000 [==============================] - 7s 133us/step - loss: 0.3651 - acc: 0.9016 - val_loss: 0.3333 - val_acc: 0.9110\n",
            "Epoch 21/50\n",
            "50000/50000 [==============================] - 7s 132us/step - loss: 0.3547 - acc: 0.9042 - val_loss: 0.3244 - val_acc: 0.9117\n",
            "Epoch 22/50\n",
            "50000/50000 [==============================] - 7s 131us/step - loss: 0.3453 - acc: 0.9061 - val_loss: 0.3164 - val_acc: 0.9132\n",
            "Epoch 23/50\n",
            "50000/50000 [==============================] - 7s 132us/step - loss: 0.3368 - acc: 0.9079 - val_loss: 0.3088 - val_acc: 0.9150\n",
            "Epoch 24/50\n",
            "50000/50000 [==============================] - 7s 132us/step - loss: 0.3288 - acc: 0.9100 - val_loss: 0.3018 - val_acc: 0.9161\n",
            "Epoch 25/50\n",
            "50000/50000 [==============================] - 7s 132us/step - loss: 0.3213 - acc: 0.9124 - val_loss: 0.2956 - val_acc: 0.9184\n",
            "Epoch 26/50\n",
            "50000/50000 [==============================] - 6s 129us/step - loss: 0.3146 - acc: 0.9134 - val_loss: 0.2895 - val_acc: 0.9196\n",
            "Epoch 27/50\n",
            "50000/50000 [==============================] - 7s 131us/step - loss: 0.3082 - acc: 0.9153 - val_loss: 0.2841 - val_acc: 0.9208\n",
            "Epoch 28/50\n",
            "50000/50000 [==============================] - 7s 135us/step - loss: 0.3022 - acc: 0.9169 - val_loss: 0.2789 - val_acc: 0.9225\n",
            "Epoch 29/50\n",
            "50000/50000 [==============================] - 7s 131us/step - loss: 0.2965 - acc: 0.9177 - val_loss: 0.2737 - val_acc: 0.9245\n",
            "Epoch 30/50\n",
            "50000/50000 [==============================] - 7s 132us/step - loss: 0.2910 - acc: 0.9193 - val_loss: 0.2689 - val_acc: 0.9252\n",
            "Epoch 31/50\n",
            "50000/50000 [==============================] - 7s 131us/step - loss: 0.2859 - acc: 0.9205 - val_loss: 0.2650 - val_acc: 0.9260\n",
            "Epoch 32/50\n",
            "50000/50000 [==============================] - 7s 135us/step - loss: 0.2810 - acc: 0.9220 - val_loss: 0.2604 - val_acc: 0.9273\n",
            "Epoch 33/50\n",
            "50000/50000 [==============================] - 7s 132us/step - loss: 0.2762 - acc: 0.9229 - val_loss: 0.2563 - val_acc: 0.9278\n",
            "Epoch 34/50\n",
            "50000/50000 [==============================] - 7s 131us/step - loss: 0.2718 - acc: 0.9247 - val_loss: 0.2526 - val_acc: 0.9293\n",
            "Epoch 35/50\n",
            "50000/50000 [==============================] - 7s 132us/step - loss: 0.2675 - acc: 0.9255 - val_loss: 0.2487 - val_acc: 0.9303\n",
            "Epoch 36/50\n",
            "50000/50000 [==============================] - 7s 133us/step - loss: 0.2633 - acc: 0.9264 - val_loss: 0.2456 - val_acc: 0.9311\n",
            "Epoch 37/50\n",
            "50000/50000 [==============================] - 7s 133us/step - loss: 0.2594 - acc: 0.9275 - val_loss: 0.2422 - val_acc: 0.9325\n",
            "Epoch 38/50\n",
            "50000/50000 [==============================] - 7s 132us/step - loss: 0.2555 - acc: 0.9288 - val_loss: 0.2385 - val_acc: 0.9338\n",
            "Epoch 39/50\n",
            "50000/50000 [==============================] - 7s 131us/step - loss: 0.2519 - acc: 0.9296 - val_loss: 0.2357 - val_acc: 0.9336\n",
            "Epoch 40/50\n",
            "50000/50000 [==============================] - 7s 134us/step - loss: 0.2483 - acc: 0.9310 - val_loss: 0.2325 - val_acc: 0.9350\n",
            "Epoch 41/50\n",
            "50000/50000 [==============================] - 7s 131us/step - loss: 0.2448 - acc: 0.9315 - val_loss: 0.2296 - val_acc: 0.9357\n",
            "Epoch 42/50\n",
            "50000/50000 [==============================] - 7s 131us/step - loss: 0.2415 - acc: 0.9324 - val_loss: 0.2266 - val_acc: 0.9370\n",
            "Epoch 43/50\n",
            "50000/50000 [==============================] - 7s 132us/step - loss: 0.2383 - acc: 0.9335 - val_loss: 0.2240 - val_acc: 0.9378\n",
            "Epoch 44/50\n",
            "50000/50000 [==============================] - 7s 132us/step - loss: 0.2351 - acc: 0.9340 - val_loss: 0.2211 - val_acc: 0.9390\n",
            "Epoch 45/50\n",
            "50000/50000 [==============================] - 6s 129us/step - loss: 0.2320 - acc: 0.9352 - val_loss: 0.2187 - val_acc: 0.9399\n",
            "Epoch 46/50\n",
            "50000/50000 [==============================] - 7s 131us/step - loss: 0.2291 - acc: 0.9358 - val_loss: 0.2166 - val_acc: 0.9397\n",
            "Epoch 47/50\n",
            "50000/50000 [==============================] - 7s 130us/step - loss: 0.2262 - acc: 0.9364 - val_loss: 0.2141 - val_acc: 0.9412\n",
            "Epoch 48/50\n",
            "50000/50000 [==============================] - 7s 132us/step - loss: 0.2233 - acc: 0.9371 - val_loss: 0.2115 - val_acc: 0.9423\n",
            "Epoch 49/50\n",
            "50000/50000 [==============================] - 7s 132us/step - loss: 0.2207 - acc: 0.9376 - val_loss: 0.2094 - val_acc: 0.9424\n",
            "Epoch 50/50\n",
            "50000/50000 [==============================] - 7s 131us/step - loss: 0.2180 - acc: 0.9387 - val_loss: 0.2072 - val_acc: 0.9432\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "RzbY74mhq0wH",
        "colab_type": "code",
        "outputId": "be561be5-e426-4e66-9a6d-530e0e303e2f",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 521
        }
      },
      "source": [
        "plt.plot(np.arange(50), history2.history['val_loss'])\n",
        "plt.plot(np.arange(50), history2.history['loss'])\n",
        "plt.show()\n",
        "plt.plot(np.arange(50), history2.history['val_acc'])\n",
        "plt.plot(np.arange(50), history2.history['acc'])\n",
        "plt.show()"
      ],
      "execution_count": 18,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "image/png": "iVBORw0KGgoAAAANSUhEUgAAAXcAAAD8CAYAAACMwORRAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\ngg==\n",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {
            "tags": []
          }
        },
        {
          "output_type": "display_data",
          "data": {
            "image/png": "iVBORw0KGgoAAAANSUhEUgAAAXcAAAD8CAYAAACMwORRAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\n3EVEipDCXUSkCCncRUSKkMJdRKQI/X84vbTeNsx2HgAAAABJRU5ErkJggg==\n",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {
            "tags": []
          }
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "A-zfic8f35dI",
        "colab_type": "text"
      },
      "source": [
        "Na testovanie potom použijeme metódu eval"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "2_jWIYC38l1f",
        "colab_type": "code",
        "outputId": "9791c6d2-16eb-48cd-8d14-d97bee9aa6d9",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 68
        }
      },
      "source": [
        "loss, accuracy = model2.evaluate(x_test,y_test)\n",
        "print(\"Loss: {}\".format(loss))\n",
        "print(\"Accuracy: {}\".format(accuracy))"
      ],
      "execution_count": 19,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "10000/10000 [==============================] - 1s 52us/step\n",
            "Loss: 0.21701645460128785\n",
            "Accuracy: 0.9394\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ndiLL_zyCU-U",
        "colab_type": "text"
      },
      "source": [
        "## Nastavenie trénovacieho kroku\n",
        "\n",
        "Už sme si ukázali ako zobraziť vývoj trénovania. Teraz si pozrieme ako nastaviť krok aby sa nám podarilo nájsť ideálny startovací bod."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "outputId": "a18a9e74-45d0-43db-ebd4-2d977c26c20d",
        "id": "w62iWhxNG0Zs",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        }
      },
      "source": [
        "lr_list = [0.3, 0.1, 0.03, 0.01, 0.003, 0.001]\n",
        "\n",
        "\n",
        "for lr in lr_list:\n",
        "  model = Sequential()\n",
        "  model.add(Dense(30, activation='sigmoid'))\n",
        "  model.add(Dense(20, activation='sigmoid'))\n",
        "  model.add(Dense(10, activation='softmax'))\n",
        "  sgd = keras.optimizers.SGD(lr)\n",
        "  loss = keras.losses.categorical_crossentropy\n",
        "  model.compile(loss=loss,\n",
        "                optimizer=sgd,\n",
        "                metrics=['accuracy'])\n",
        "  h = model.fit(x_train, y_train, validation_data=(x_val, y_val), batch_size=32, epochs=5)\n",
        "  plt.plot(np.arange(5), h.history['val_loss'])\n",
        "  \n",
        "plt.show()"
      ],
      "execution_count": 20,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Train on 50000 samples, validate on 10000 samples\n",
            "Epoch 1/5\n",
            "50000/50000 [==============================] - 7s 146us/step - loss: 0.7223 - acc: 0.7903 - val_loss: 0.2984 - val_acc: 0.9143\n",
            "Epoch 2/5\n",
            "50000/50000 [==============================] - 7s 134us/step - loss: 0.2714 - acc: 0.9221 - val_loss: 0.2246 - val_acc: 0.9368\n",
            "Epoch 3/5\n",
            "50000/50000 [==============================] - 7s 139us/step - loss: 0.2017 - acc: 0.9407 - val_loss: 0.1937 - val_acc: 0.9430\n",
            "Epoch 4/5\n",
            "50000/50000 [==============================] - 7s 139us/step - loss: 0.1669 - acc: 0.9504 - val_loss: 0.1535 - val_acc: 0.9570\n",
            "Epoch 5/5\n",
            "50000/50000 [==============================] - 7s 131us/step - loss: 0.1437 - acc: 0.9569 - val_loss: 0.1570 - val_acc: 0.9556\n",
            "Train on 50000 samples, validate on 10000 samples\n",
            "Epoch 1/5\n",
            "50000/50000 [==============================] - 7s 141us/step - loss: 1.2208 - acc: 0.6707 - val_loss: 0.5138 - val_acc: 0.8695\n",
            "Epoch 2/5\n",
            "50000/50000 [==============================] - 6s 126us/step - loss: 0.4409 - acc: 0.8792 - val_loss: 0.3419 - val_acc: 0.9085\n",
            "Epoch 3/5\n",
            "50000/50000 [==============================] - 6s 130us/step - loss: 0.3321 - acc: 0.9079 - val_loss: 0.2867 - val_acc: 0.9199\n",
            "Epoch 4/5\n",
            "50000/50000 [==============================] - 6s 129us/step - loss: 0.2769 - acc: 0.9213 - val_loss: 0.2398 - val_acc: 0.9338\n",
            "Epoch 5/5\n",
            "50000/50000 [==============================] - 6s 128us/step - loss: 0.2409 - acc: 0.9313 - val_loss: 0.2158 - val_acc: 0.9380\n",
            "Train on 50000 samples, validate on 10000 samples\n",
            "Epoch 1/5\n",
            "50000/50000 [==============================] - 7s 141us/step - loss: 1.9690 - acc: 0.4432 - val_loss: 1.4430 - val_acc: 0.6546\n",
            "Epoch 2/5\n",
            "50000/50000 [==============================] - 6s 129us/step - loss: 1.1028 - acc: 0.7280 - val_loss: 0.8269 - val_acc: 0.8051\n",
            "Epoch 3/5\n",
            "50000/50000 [==============================] - 7s 134us/step - loss: 0.7357 - acc: 0.8130 - val_loss: 0.6011 - val_acc: 0.8550\n",
            "Epoch 4/5\n",
            "50000/50000 [==============================] - 7s 133us/step - loss: 0.5681 - acc: 0.8558 - val_loss: 0.4775 - val_acc: 0.8820\n",
            "Epoch 5/5\n",
            "50000/50000 [==============================] - 7s 138us/step - loss: 0.4683 - acc: 0.8794 - val_loss: 0.4048 - val_acc: 0.8939\n",
            "Train on 50000 samples, validate on 10000 samples\n",
            "Epoch 1/5\n",
            "50000/50000 [==============================] - 8s 150us/step - loss: 2.2538 - acc: 0.2558 - val_loss: 2.1612 - val_acc: 0.4152\n",
            "Epoch 2/5\n",
            "50000/50000 [==============================] - 7s 133us/step - loss: 2.0281 - acc: 0.4454 - val_loss: 1.8473 - val_acc: 0.5321\n",
            "Epoch 3/5\n",
            "50000/50000 [==============================] - 7s 134us/step - loss: 1.6781 - acc: 0.5332 - val_loss: 1.4992 - val_acc: 0.6047\n",
            "Epoch 4/5\n",
            "50000/50000 [==============================] - 6s 129us/step - loss: 1.3903 - acc: 0.6238 - val_loss: 1.2527 - val_acc: 0.6899\n",
            "Epoch 5/5\n",
            "50000/50000 [==============================] - 7s 138us/step - loss: 1.1773 - acc: 0.6970 - val_loss: 1.0557 - val_acc: 0.7607\n",
            "Train on 50000 samples, validate on 10000 samples\n",
            "Epoch 1/5\n",
            "50000/50000 [==============================] - 7s 146us/step - loss: 2.3048 - acc: 0.2044 - val_loss: 2.2680 - val_acc: 0.3335\n",
            "Epoch 2/5\n",
            "50000/50000 [==============================] - 7s 132us/step - loss: 2.2546 - acc: 0.2636 - val_loss: 2.2380 - val_acc: 0.2745\n",
            "Epoch 3/5\n",
            "50000/50000 [==============================] - 7s 130us/step - loss: 2.2215 - acc: 0.3442 - val_loss: 2.1992 - val_acc: 0.4004\n",
            "Epoch 4/5\n",
            "50000/50000 [==============================] - 7s 131us/step - loss: 2.1776 - acc: 0.4349 - val_loss: 2.1467 - val_acc: 0.4957\n",
            "Epoch 5/5\n",
            "50000/50000 [==============================] - 7s 130us/step - loss: 2.1175 - acc: 0.4953 - val_loss: 2.0747 - val_acc: 0.5356\n",
            "Train on 50000 samples, validate on 10000 samples\n",
            "Epoch 1/5\n",
            "50000/50000 [==============================] - 7s 145us/step - loss: 2.3386 - acc: 0.1036 - val_loss: 2.3005 - val_acc: 0.1265\n",
            "Epoch 2/5\n",
            "50000/50000 [==============================] - 7s 131us/step - loss: 2.2886 - acc: 0.1367 - val_loss: 2.2822 - val_acc: 0.1166\n",
            "Epoch 3/5\n",
            "50000/50000 [==============================] - 7s 132us/step - loss: 2.2756 - acc: 0.1305 - val_loss: 2.2714 - val_acc: 0.1338\n",
            "Epoch 4/5\n",
            "50000/50000 [==============================] - 6s 129us/step - loss: 2.2654 - acc: 0.1728 - val_loss: 2.2610 - val_acc: 0.1926\n",
            "Epoch 5/5\n",
            "50000/50000 [==============================] - 7s 132us/step - loss: 2.2551 - acc: 0.2115 - val_loss: 2.2503 - val_acc: 0.2543\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "display_data",
          "data": {
            "image/png": "iVBORw0KGgoAAAANSUhEUgAAAXcAAAD8CAYAAACMwORRAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\nYII=\n",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {
            "tags": []
          }
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "McUfO2B7ISVE",
        "colab_type": "text"
      },
      "source": [
        "Je vidno, že na začiatku trénovania je vhodné využiť väčší krok. Problém však môže nastať neskôr keď bude krok príliš veľký."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "apn2zQHIJjg5",
        "colab_type": "text"
      },
      "source": [
        "## Uloženie a nahratie modelu\n",
        "\n",
        "Teraz si ukážeme ako uložiť a nahrať model"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "do0otgF5KhQ8",
        "colab_type": "code",
        "outputId": "cc761a87-fbd2-48ce-fbf2-67e04a875d1a",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 224
        }
      },
      "source": [
        "model = Sequential()\n",
        "model.add(Dense(30, activation='sigmoid'))\n",
        "model.add(Dense(20, activation='sigmoid'))\n",
        "model.add(Dense(10, activation='softmax'))\n",
        "sgd = keras.optimizers.SGD(0.3)\n",
        "loss = keras.losses.categorical_crossentropy\n",
        "model.compile(loss=loss,\n",
        "              optimizer=sgd,\n",
        "              metrics=['accuracy'])\n",
        "h = model.fit(x_train, y_train, validation_data=(x_val, y_val), batch_size=32, epochs=5)\n",
        "model.save(\"model_5_epoch.h5\")"
      ],
      "execution_count": 21,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Train on 50000 samples, validate on 10000 samples\n",
            "Epoch 1/5\n",
            "50000/50000 [==============================] - 7s 149us/step - loss: 0.6828 - acc: 0.7977 - val_loss: 0.2989 - val_acc: 0.9156\n",
            "Epoch 2/5\n",
            "50000/50000 [==============================] - 7s 135us/step - loss: 0.2596 - acc: 0.9240 - val_loss: 0.2056 - val_acc: 0.9429\n",
            "Epoch 3/5\n",
            "50000/50000 [==============================] - 7s 139us/step - loss: 0.1967 - acc: 0.9426 - val_loss: 0.1715 - val_acc: 0.9536\n",
            "Epoch 4/5\n",
            "50000/50000 [==============================] - 7s 136us/step - loss: 0.1600 - acc: 0.9533 - val_loss: 0.1548 - val_acc: 0.9575\n",
            "Epoch 5/5\n",
            "50000/50000 [==============================] - 7s 136us/step - loss: 0.1378 - acc: 0.9594 - val_loss: 0.1527 - val_acc: 0.9573\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "hN0mqOZpL1JI",
        "colab_type": "code",
        "outputId": "eeab9e2c-ea04-4428-f611-3811842b562f",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 411
        }
      },
      "source": [
        "from keras.models import load_model\n",
        "\n",
        "model_loaded = load_model(\"model_5_epoch.h5\")\n",
        "\n",
        "h_l = model_loaded.fit(x_train, y_train, validation_data=(x_val, y_val), batch_size=32, epochs=10, initial_epoch=5)\n",
        "\n",
        "sgd = keras.optimizers.SGD(0.1)\n",
        "loss = keras.losses.categorical_crossentropy\n",
        "model_loaded.compile(loss=loss,\n",
        "                     optimizer=sgd,\n",
        "                     metrics=['accuracy'])\n",
        "h_l = model_loaded.fit(x_train, y_train, validation_data=(x_val, y_val), batch_size=32, epochs=15, initial_epoch=10)"
      ],
      "execution_count": 22,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Train on 50000 samples, validate on 10000 samples\n",
            "Epoch 6/10\n",
            "50000/50000 [==============================] - 7s 138us/step - loss: 0.1220 - acc: 0.9642 - val_loss: 0.1381 - val_acc: 0.9611\n",
            "Epoch 7/10\n",
            "50000/50000 [==============================] - 7s 133us/step - loss: 0.1104 - acc: 0.9675 - val_loss: 0.1443 - val_acc: 0.9586\n",
            "Epoch 8/10\n",
            "50000/50000 [==============================] - 7s 134us/step - loss: 0.1015 - acc: 0.9697 - val_loss: 0.1285 - val_acc: 0.9646\n",
            "Epoch 9/10\n",
            "50000/50000 [==============================] - 6s 130us/step - loss: 0.0943 - acc: 0.9726 - val_loss: 0.1333 - val_acc: 0.9634\n",
            "Epoch 10/10\n",
            "50000/50000 [==============================] - 7s 133us/step - loss: 0.0866 - acc: 0.9746 - val_loss: 0.1332 - val_acc: 0.9614\n",
            "Train on 50000 samples, validate on 10000 samples\n",
            "Epoch 11/15\n",
            "50000/50000 [==============================] - 8s 150us/step - loss: 0.0708 - acc: 0.9801 - val_loss: 0.1219 - val_acc: 0.9654\n",
            "Epoch 12/15\n",
            "50000/50000 [==============================] - 7s 134us/step - loss: 0.0673 - acc: 0.9815 - val_loss: 0.1245 - val_acc: 0.9648\n",
            "Epoch 13/15\n",
            "50000/50000 [==============================] - 7s 134us/step - loss: 0.0654 - acc: 0.9827 - val_loss: 0.1244 - val_acc: 0.9643\n",
            "Epoch 14/15\n",
            "50000/50000 [==============================] - 7s 134us/step - loss: 0.0635 - acc: 0.9822 - val_loss: 0.1208 - val_acc: 0.9648\n",
            "Epoch 15/15\n",
            "50000/50000 [==============================] - 7s 132us/step - loss: 0.0620 - acc: 0.9837 - val_loss: 0.1225 - val_acc: 0.9659\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Lduh4aqlM_pU",
        "colab_type": "text"
      },
      "source": [
        "## Callbacky\n",
        "\n",
        "V predchádzajúcom príklade sme robili nejaké veci vždy po nejakej epoche (zmenšovanie kroku, ukladanie). Na to môžeme použiť aj tzv. callbacky. Tie použijeme pri volaní metódy fit. To si teraz otestujeme."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "dI3Y2hSBU3_Z",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "model = Sequential()\n",
        "model.add(Dense(30, activation='sigmoid'))\n",
        "model.add(Dense(20, activation='sigmoid'))\n",
        "model.add(Dense(10, activation='softmax'))\n",
        "sgd = keras.optimizers.SGD(0.3)\n",
        "loss = keras.losses.categorical_crossentropy\n",
        "model.compile(loss=loss,\n",
        "              optimizer=sgd,\n",
        "              metrics=['accuracy'])\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "LSTIdoDkVXCk",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "from keras.callbacks import *\n",
        "callbacks = []"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "o9WtCDCmVKb2",
        "colab_type": "text"
      },
      "source": [
        "Pomerne užitočný callback je ModelCheckpoint. V jeho konštruktore je možné definovať formu názvu uloženého súboru. Takisto je možné udržať si uložený len checkpoint napr. s najlepšou validačnou presnosťou."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ckVw3fChVsNU",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "callbacks.append(ModelCheckpoint('mnist_{epoch:02d}-{val_loss:.8f}-{val_acc:.4f}.h5', verbose=1, period=1))"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "4dLp57_BWVDL",
        "colab_type": "text"
      },
      "source": [
        "Tensorboard callback nám umožňuje sledovať vývoj tréningu pomocou utility TensorBoard"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "DkQHJPxPWrZv",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "callbacks.append(TensorBoard(log_dir='./logs'))"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "TKoWjrcqcBjF",
        "colab_type": "text"
      },
      "source": [
        "Early Stopping nám umožní skončiť trénovanie ak sa dostaneme do situácie ak sa nejaká metrika (validačná presnosť, alebo loss) nezlepšuje počas nejakého množstva epôch."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "JWrNEUOicEc6",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "callbacks.append(EarlyStopping(monitor='val_loss', patience=5, verbose=1))"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "k9gnapdVXyLd",
        "colab_type": "text"
      },
      "source": [
        "Podobne použijeme callback, ktorý v prípade, že sa dostaneme do situácie ak sa nejaká metrika nezlepšuje, tak zníži krok optimalizačného algoritmu."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "cT3CFvoeY7Pd",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "callbacks.append(ReduceLROnPlateau(monitor='val_loss', factor=0.2, patience=2, min_lr=0.0001, verbose=1))"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "AXcmO3nNZhuT",
        "colab_type": "text"
      },
      "source": [
        "Nakoniec môžeme trénovať."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "oiUHRA0HZjkO",
        "colab_type": "code",
        "outputId": "5f3fc383-ff70-46f1-d6c4-5afa2350b14d",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        }
      },
      "source": [
        "model.fit(x_train, y_train, validation_data=(x_val, y_val), epochs=30, callbacks=callbacks, batch_size=32)"
      ],
      "execution_count": 29,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Train on 50000 samples, validate on 10000 samples\n",
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/keras/callbacks.py:1122: The name tf.summary.merge_all is deprecated. Please use tf.compat.v1.summary.merge_all instead.\n",
            "\n",
            "Epoch 1/30\n",
            "50000/50000 [==============================] - 7s 145us/step - loss: 0.7009 - acc: 0.7957 - val_loss: 0.2791 - val_acc: 0.9232\n",
            "\n",
            "Epoch 00001: saving model to mnist_01-0.27911393-0.9232.h5\n",
            "Epoch 2/30\n",
            "50000/50000 [==============================] - 7s 137us/step - loss: 0.2563 - acc: 0.9263 - val_loss: 0.2287 - val_acc: 0.9314\n",
            "\n",
            "Epoch 00002: saving model to mnist_02-0.22871561-0.9314.h5\n",
            "Epoch 3/30\n",
            "50000/50000 [==============================] - 7s 136us/step - loss: 0.1939 - acc: 0.9436 - val_loss: 0.1589 - val_acc: 0.9531\n",
            "\n",
            "Epoch 00003: saving model to mnist_03-0.15892626-0.9531.h5\n",
            "Epoch 4/30\n",
            "50000/50000 [==============================] - 7s 136us/step - loss: 0.1611 - acc: 0.9525 - val_loss: 0.1442 - val_acc: 0.9581\n",
            "\n",
            "Epoch 00004: saving model to mnist_04-0.14421442-0.9581.h5\n",
            "Epoch 5/30\n",
            "50000/50000 [==============================] - 7s 133us/step - loss: 0.1387 - acc: 0.9582 - val_loss: 0.1321 - val_acc: 0.9599\n",
            "\n",
            "Epoch 00005: saving model to mnist_05-0.13213147-0.9599.h5\n",
            "Epoch 6/30\n",
            "50000/50000 [==============================] - 7s 135us/step - loss: 0.1239 - acc: 0.9631 - val_loss: 0.1442 - val_acc: 0.9573\n",
            "\n",
            "Epoch 00006: saving model to mnist_06-0.14423344-0.9573.h5\n",
            "Epoch 7/30\n",
            "50000/50000 [==============================] - 7s 138us/step - loss: 0.1130 - acc: 0.9661 - val_loss: 0.1287 - val_acc: 0.9606\n",
            "\n",
            "Epoch 00007: saving model to mnist_07-0.12866882-0.9606.h5\n",
            "Epoch 8/30\n",
            "50000/50000 [==============================] - 7s 136us/step - loss: 0.1026 - acc: 0.9697 - val_loss: 0.1200 - val_acc: 0.9647\n",
            "\n",
            "Epoch 00008: saving model to mnist_08-0.11997853-0.9647.h5\n",
            "Epoch 9/30\n",
            "50000/50000 [==============================] - 7s 135us/step - loss: 0.0954 - acc: 0.9717 - val_loss: 0.1218 - val_acc: 0.9638\n",
            "\n",
            "Epoch 00009: saving model to mnist_09-0.12179321-0.9638.h5\n",
            "Epoch 10/30\n",
            "50000/50000 [==============================] - 7s 137us/step - loss: 0.0902 - acc: 0.9731 - val_loss: 0.1165 - val_acc: 0.9629\n",
            "\n",
            "Epoch 00010: saving model to mnist_10-0.11647940-0.9629.h5\n",
            "Epoch 11/30\n",
            "50000/50000 [==============================] - 7s 135us/step - loss: 0.0835 - acc: 0.9750 - val_loss: 0.1217 - val_acc: 0.9618\n",
            "\n",
            "Epoch 00011: saving model to mnist_11-0.12166740-0.9618.h5\n",
            "Epoch 12/30\n",
            "50000/50000 [==============================] - 7s 133us/step - loss: 0.0780 - acc: 0.9760 - val_loss: 0.1183 - val_acc: 0.9636\n",
            "\n",
            "Epoch 00012: saving model to mnist_12-0.11828887-0.9636.h5\n",
            "\n",
            "Epoch 00012: ReduceLROnPlateau reducing learning rate to 0.06000000238418579.\n",
            "Epoch 13/30\n",
            "50000/50000 [==============================] - 7s 137us/step - loss: 0.0608 - acc: 0.9830 - val_loss: 0.1088 - val_acc: 0.9666\n",
            "\n",
            "Epoch 00013: saving model to mnist_13-0.10883601-0.9666.h5\n",
            "Epoch 14/30\n",
            "50000/50000 [==============================] - 7s 138us/step - loss: 0.0581 - acc: 0.9842 - val_loss: 0.1093 - val_acc: 0.9659\n",
            "\n",
            "Epoch 00014: saving model to mnist_14-0.10926614-0.9659.h5\n",
            "Epoch 15/30\n",
            "50000/50000 [==============================] - 7s 140us/step - loss: 0.0571 - acc: 0.9846 - val_loss: 0.1089 - val_acc: 0.9658\n",
            "\n",
            "Epoch 00015: saving model to mnist_15-0.10885221-0.9658.h5\n",
            "\n",
            "Epoch 00015: ReduceLROnPlateau reducing learning rate to 0.012000000476837159.\n",
            "Epoch 16/30\n",
            "50000/50000 [==============================] - 7s 139us/step - loss: 0.0539 - acc: 0.9862 - val_loss: 0.1079 - val_acc: 0.9663\n",
            "\n",
            "Epoch 00016: saving model to mnist_16-0.10792685-0.9663.h5\n",
            "Epoch 17/30\n",
            "50000/50000 [==============================] - 7s 137us/step - loss: 0.0535 - acc: 0.9863 - val_loss: 0.1078 - val_acc: 0.9664\n",
            "\n",
            "Epoch 00017: saving model to mnist_17-0.10778689-0.9664.h5\n",
            "Epoch 18/30\n",
            "50000/50000 [==============================] - 7s 136us/step - loss: 0.0533 - acc: 0.9863 - val_loss: 0.1074 - val_acc: 0.9666\n",
            "\n",
            "Epoch 00018: saving model to mnist_18-0.10736712-0.9666.h5\n",
            "Epoch 19/30\n",
            "50000/50000 [==============================] - 7s 137us/step - loss: 0.0531 - acc: 0.9864 - val_loss: 0.1078 - val_acc: 0.9664\n",
            "\n",
            "Epoch 00019: saving model to mnist_19-0.10781668-0.9664.h5\n",
            "Epoch 20/30\n",
            "50000/50000 [==============================] - 7s 136us/step - loss: 0.0529 - acc: 0.9865 - val_loss: 0.1077 - val_acc: 0.9662\n",
            "\n",
            "Epoch 00020: saving model to mnist_20-0.10773215-0.9662.h5\n",
            "\n",
            "Epoch 00020: ReduceLROnPlateau reducing learning rate to 0.002400000020861626.\n",
            "Epoch 21/30\n",
            "50000/50000 [==============================] - 7s 137us/step - loss: 0.0522 - acc: 0.9868 - val_loss: 0.1076 - val_acc: 0.9665\n",
            "\n",
            "Epoch 00021: saving model to mnist_21-0.10757455-0.9665.h5\n",
            "Epoch 22/30\n",
            "50000/50000 [==============================] - 7s 135us/step - loss: 0.0522 - acc: 0.9868 - val_loss: 0.1076 - val_acc: 0.9664\n",
            "\n",
            "Epoch 00022: saving model to mnist_22-0.10760463-0.9664.h5\n",
            "\n",
            "Epoch 00022: ReduceLROnPlateau reducing learning rate to 0.00048000002279877666.\n",
            "Epoch 23/30\n",
            "50000/50000 [==============================] - 7s 135us/step - loss: 0.0520 - acc: 0.9867 - val_loss: 0.1076 - val_acc: 0.9664\n",
            "\n",
            "Epoch 00023: saving model to mnist_23-0.10760081-0.9664.h5\n",
            "Epoch 00023: early stopping\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<keras.callbacks.History at 0x7fd1107b7dd8>"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 29
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "_LZHfjjjcpEx",
        "colab_type": "text"
      },
      "source": [
        "Výsledkom tohto postupu je postupné znižovanie kroku a ukladanie modelov popri trénovaní. Modely môžeme načítať ako sme si už ukázali. Takisto sa nám uložila zložka logs s dátami pre TensorBoard."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "crpVeDj3dA_C",
        "colab_type": "code",
        "outputId": "1941648e-7027-45b5-e690-38580ffbcd9e",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 17
        }
      },
      "source": [
        "%load_ext tensorboard\n",
        "%tensorboard --logdir logs"
      ],
      "execution_count": 30,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/html": [
              "\n",
              "    <div id=\"root\"></div>\n",
              "    <script>\n",
              "      (function() {\n",
              "        window.TENSORBOARD_ENV = window.TENSORBOARD_ENV || {};\n",
              "        window.TENSORBOARD_ENV[\"IN_COLAB\"] = true;\n",
              "        document.querySelector(\"base\").href = \"https://localhost:6006\";\n",
              "        function fixUpTensorboard(root) {\n",
              "          const tftb = root.querySelector(\"tf-tensorboard\");\n",
              "          // Disable the fragment manipulation behavior in Colab. Not\n",
              "          // only is the behavior not useful (as the iframe's location\n",
              "          // is not visible to the user), it causes TensorBoard's usage\n",
              "          // of `window.replace` to navigate away from the page and to\n",
              "          // the `localhost:<port>` URL specified by the base URI, which\n",
              "          // in turn causes the frame to (likely) crash.\n",
              "          tftb.removeAttribute(\"use-hash\");\n",
              "        }\n",
              "        function executeAllScripts(root) {\n",
              "          // When `script` elements are inserted into the DOM by\n",
              "          // assigning to an element's `innerHTML`, the scripts are not\n",
              "          // executed. Thus, we manually re-insert these scripts so that\n",
              "          // TensorBoard can initialize itself.\n",
              "          for (const script of root.querySelectorAll(\"script\")) {\n",
              "            const newScript = document.createElement(\"script\");\n",
              "            newScript.type = script.type;\n",
              "            newScript.textContent = script.textContent;\n",
              "            root.appendChild(newScript);\n",
              "            script.remove();\n",
              "          }\n",
              "        }\n",
              "        function setHeight(root, height) {\n",
              "          // We set the height dynamically after the TensorBoard UI has\n",
              "          // been initialized. This avoids an intermediate state in\n",
              "          // which the container plus the UI become taller than the\n",
              "          // final width and cause the Colab output frame to be\n",
              "          // permanently resized, eventually leading to an empty\n",
              "          // vertical gap below the TensorBoard UI. It's not clear\n",
              "          // exactly what causes this problematic intermediate state,\n",
              "          // but setting the height late seems to fix it.\n",
              "          root.style.height = `${height}px`;\n",
              "        }\n",
              "        const root = document.getElementById(\"root\");\n",
              "        fetch(\".\")\n",
              "          .then((x) => x.text())\n",
              "          .then((html) => void (root.innerHTML = html))\n",
              "          .then(() => fixUpTensorboard(root))\n",
              "          .then(() => executeAllScripts(root))\n",
              "          .then(() => setHeight(root, 800));\n",
              "      })();\n",
              "    </script>\n",
              "  "
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {
            "tags": []
          }
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "HgukallNmCVZ",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "a04d6947-9e3d-43d6-8417-e89cae1cb650"
      },
      "source": [
        "!kill 1672"
      ],
      "execution_count": 31,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "/bin/bash: line 0: kill: (1672) - No such process\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "urhL7BF2zaoy",
        "colab_type": "text"
      },
      "source": [
        "### Úloha 1\n",
        "\n",
        "Existuje aj callback LearningRateScheduler. Nájdite si ho v dokumentácií kerasu a spustite si tréning s týmto callbackom, tak aby sa zmenšovanie kroku dialo podobne ako keď sme použili ReduceLROnPlateau."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Jl7J5Xu2fES9",
        "colab_type": "text"
      },
      "source": [
        "## Regularizácia\n",
        "\n",
        "Pri splite sme si ukazovali ako nastáva tzv. overfitting kedy sa model sa zlepšuje na trénovacej množine, ale voči validačnej stagnuje, alebo sa dokonca zhoršuje. Prístupy riešenia tohto problému je viacero. Teraz si ukážeme jeden prístup. Ten je založený na pozmenení výrazu cenovej funkcie. Tá bude mať tvar:\n",
        "\n",
        "$$ C_r = C + \\lambda R,$$\n",
        "\n",
        "kde $C$ je naša pôvodná cenová funkcia a $R$ je regularizačná cenová funkcia. Rozdiel medzi nimi je hlavne v tom, že $R$ je funkciou parametrov siete a vôbec nezávisí na trénovacích dátach. $\\lambda$ je hyperparameter ktorý určuje \"silu\" regularizácie. Najpoužívanejšie regularizačné cenové funkcie sú tzv. L1 a L2 regularizácia.\n",
        "\n",
        "$$ R_{L1} = \\sum_{w \\in W} |w|$$\n",
        "$$ R_{L2} = \\sum_{w \\in W} w^2$$\n",
        "\n",
        "kde $W$ je množina parametrov na ktoré aplikujeme regularizáciu. Ako je značením naznačené, tak túto regularizáciu budeme aplikovať iba na váhové vektory. Regularizáciu si teraz otestujeme na umelom príklade, kde sa pokúsime natrénovať model iba na 50 príkladoch z trénovacej množiny. Najprv bez regularizácie."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "W-eHzRZzZmNH",
        "colab_type": "code",
        "outputId": "6e838d9e-fb50-4153-bc30-591ec5ebcc18",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 391
        }
      },
      "source": [
        "x_mini = x[:20]\n",
        "y_mini = y[:20]\n",
        "\n",
        "model = Sequential()\n",
        "model.add(Dense(30, activation='sigmoid'))\n",
        "model.add(Dense(20, activation='sigmoid'))\n",
        "model.add(Dense(10, activation='softmax'))\n",
        "\n",
        "loss = keras.losses.categorical_crossentropy\n",
        "sgd = keras.optimizers.SGD(0.3)\n",
        "model.compile(loss=loss,\n",
        "              optimizer=sgd,\n",
        "              metrics=['accuracy'])\n",
        "\n",
        "h_r = model.fit(x_mini, y_mini, steps_per_epoch=1000, epochs=10)\n",
        "[loss, acc] = model.evaluate(x_val, y_val)\n",
        "print(\"Eval loss: {}, Eval acc: {}\".format(loss, acc))"
      ],
      "execution_count": 32,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Epoch 1/10\n",
            "1000/1000 [==============================] - 5s 5ms/step - loss: 0.3342 - acc: 0.9220\n",
            "Epoch 2/10\n",
            "1000/1000 [==============================] - 4s 4ms/step - loss: 0.0105 - acc: 1.0000\n",
            "Epoch 3/10\n",
            "1000/1000 [==============================] - 4s 4ms/step - loss: 0.0052 - acc: 1.0000\n",
            "Epoch 4/10\n",
            "1000/1000 [==============================] - 4s 4ms/step - loss: 0.0034 - acc: 1.0000\n",
            "Epoch 5/10\n",
            "1000/1000 [==============================] - 4s 4ms/step - loss: 0.0025 - acc: 1.0000\n",
            "Epoch 6/10\n",
            "1000/1000 [==============================] - 4s 4ms/step - loss: 0.0020 - acc: 1.0000\n",
            "Epoch 7/10\n",
            "1000/1000 [==============================] - 4s 4ms/step - loss: 0.0017 - acc: 1.0000\n",
            "Epoch 8/10\n",
            "1000/1000 [==============================] - 4s 4ms/step - loss: 0.0014 - acc: 1.0000\n",
            "Epoch 9/10\n",
            "1000/1000 [==============================] - 4s 4ms/step - loss: 0.0012 - acc: 1.0000\n",
            "Epoch 10/10\n",
            "1000/1000 [==============================] - 4s 4ms/step - loss: 0.0011 - acc: 1.0000\n",
            "10000/10000 [==============================] - 1s 82us/step\n",
            "Eval loss: 2.0962120551109313, Eval acc: 0.5512\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "U8Ef6C2w4yJi",
        "colab_type": "code",
        "outputId": "9957d40f-d221-4071-80a9-fab6a75f9ba5",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 391
        }
      },
      "source": [
        "from keras.regularizers import l1, l2\n",
        "\n",
        "x_mini = x[:20]\n",
        "y_mini = y[:20]\n",
        "\n",
        "lmbda = 0.0001\n",
        "model = Sequential()\n",
        "model.add(Dense(30, activation='sigmoid', kernel_regularizer=l2(lmbda)))\n",
        "model.add(Dense(20, activation='sigmoid', kernel_regularizer=l2(lmbda)))\n",
        "model.add(Dense(10, activation='softmax', kernel_regularizer=l2(lmbda)))\n",
        "\n",
        "loss = keras.losses.categorical_crossentropy\n",
        "sgd = keras.optimizers.SGD(0.3)\n",
        "model.compile(loss=loss,\n",
        "              optimizer=sgd,\n",
        "              metrics=['accuracy'])\n",
        "\n",
        "h_r = model.fit(x_mini, y_mini, steps_per_epoch=1000, epochs=10)\n",
        "[loss, acc] = model.evaluate(x_val, y_val)\n",
        "print(\"Eval loss: {}, Eval acc: {}\".format(loss, acc))"
      ],
      "execution_count": 33,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Epoch 1/10\n",
            "1000/1000 [==============================] - 5s 5ms/step - loss: 0.3600 - acc: 0.9313\n",
            "Epoch 2/10\n",
            "1000/1000 [==============================] - 4s 4ms/step - loss: 0.0590 - acc: 1.0000\n",
            "Epoch 3/10\n",
            "1000/1000 [==============================] - 4s 4ms/step - loss: 0.0551 - acc: 1.0000\n",
            "Epoch 4/10\n",
            "1000/1000 [==============================] - 4s 4ms/step - loss: 0.0534 - acc: 1.0000\n",
            "Epoch 5/10\n",
            "1000/1000 [==============================] - 4s 4ms/step - loss: 0.0522 - acc: 1.0000\n",
            "Epoch 6/10\n",
            "1000/1000 [==============================] - 4s 4ms/step - loss: 0.0513 - acc: 1.0000\n",
            "Epoch 7/10\n",
            "1000/1000 [==============================] - 4s 4ms/step - loss: 0.0504 - acc: 1.0000\n",
            "Epoch 8/10\n",
            "1000/1000 [==============================] - 4s 4ms/step - loss: 0.0497 - acc: 1.0000\n",
            "Epoch 9/10\n",
            "1000/1000 [==============================] - 4s 4ms/step - loss: 0.0491 - acc: 1.0000\n",
            "Epoch 10/10\n",
            "1000/1000 [==============================] - 4s 4ms/step - loss: 0.0485 - acc: 1.0000\n",
            "10000/10000 [==============================] - 1s 94us/step\n",
            "Eval loss: 1.7875657912254332, Eval acc: 0.5453\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "87VKu-O44zTh",
        "colab_type": "text"
      },
      "source": [
        "### Úloha 2\n",
        "\n",
        "Nájdite pre tento prípad najlepší parameter $\\lambda$ a krok optimalizačného algoritmu a porovnajte l1 a l2 regularizáciu."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "DfGPc5T4510U",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        ""
      ],
      "execution_count": 0,
      "outputs": []
    }
  ]
}